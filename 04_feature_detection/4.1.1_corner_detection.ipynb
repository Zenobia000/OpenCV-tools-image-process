{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.1 角點檢測 (Corner Detection)\n",
    "\n",
    "**WBS 4.1.1**: 角點檢測基礎與應用\n",
    "\n",
    "本模組涵蓋:\n",
    "- **Harris 角點檢測**: 經典角點檢測算法\n",
    "- **Shi-Tomasi 角點檢測**: 改進的 Harris 算法\n",
    "- **FAST 角點檢測**: 快速特徵檢測算法\n",
    "- **角點檢測器比較分析**: 性能與應用場景評估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 1. 什麼是角點 (Corner)?\n",
    "\n",
    "## 1-1: 角點的定義\n",
    "\n",
    "> 角點是圖像中**局部特徵最明顯**的點，具有以下特性:\n",
    "> * **兩個邊緣的交叉點**: 圖像中兩條邊緣線的交匯處\n",
    "> * **灰度梯度變化劇烈**: 在多個方向上灰度變化都很大\n",
    "> * **穩定特徵**: 具有旋轉不變性，對光照變化相對穩定\n",
    "> * **可重複檢測**: 在不同視角下仍能被檢測到\n",
    "\n",
    "## 1-2: 角點檢測的重要性\n",
    "\n",
    "> 角點檢測是計算機視覺中的**基礎操作**，廣泛應用於:\n",
    "> * **特徵匹配**: 兩張圖像之間的對應點匹配\n",
    "> * **運動估計**: 視頻序列中的物體追蹤\n",
    "> * **3D 重建**: 從多視角圖像重建三維模型\n",
    "> * **物體識別**: 識別和定位場景中的物體\n",
    "> * **影像拼接**: 全景圖像生成\n",
    "\n",
    "## 1-3: 角點 vs. 邊緣\n",
    "\n",
    "> | 特徵 | 角點 (Corner) | 邊緣 (Edge) |\n",
    "> |------|--------------|-------------|\n",
    "> | 定義 | 兩個邊緣的交點 | 圖像灰度劇烈變化的地方 |\n",
    "> | 方向性 | **多方向**梯度變化 | **單一方向**梯度變化 |\n",
    "> | 定位精度 | **精確定位** | 相對模糊 |\n",
    "> | 穩定性 | **高穩定性** | 容易受噪聲影響 |\n",
    "> | 數量 | 少量關鍵點 | 大量邊緣點 |\n",
    "\n",
    "### 視覺化示意\n",
    "\n",
    "> **平坦區域 (Flat Region)**: 各方向移動，灰度變化都很小  \n",
    "> **邊緣 (Edge)**: 垂直邊緣方向移動，灰度變化大  \n",
    "> **角點 (Corner)**: 任意方向移動，灰度變化都很大\n",
    "\n",
    "><img src=\"../assets/images/basic/corner_concept.png\" style='width:80%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 2. Harris 角點檢測\n",
    "\n",
    "## 2-1: Harris 算法原理\n",
    "\n",
    "> Harris 角點檢測是由 **Chris Harris** 和 **Mike Stephens** 於 1988 年提出的經典算法。\n",
    "\n",
    "### 核心思想\n",
    "\n",
    "> 通過計算圖像梯度的**自相關矩陣 (Autocorrelation Matrix)** 來檢測角點:\n",
    "> \n",
    "> 1. 計算圖像在 x 和 y 方向的梯度 (使用 Sobel 算子)\n",
    "> 2. 構建自相關矩陣 M\n",
    "> 3. 計算角點響應函數 R\n",
    "> 4. 根據閾值判斷是否為角點\n",
    "\n",
    "### 數學公式\n",
    "\n",
    "> **自相關矩陣 M**:\n",
    ">\n",
    "> $$M = \\sum_{x,y} w(x,y) \\begin{bmatrix} I_x^2 & I_x I_y \\\\ I_x I_y & I_y^2 \\end{bmatrix}$$\n",
    ">\n",
    "> 其中:\n",
    "> * $I_x, I_y$ 是圖像的梯度\n",
    "> * $w(x,y)$ 是高斯窗口函數\n",
    "\n",
    "> **Harris 角點響應函數 R**:\n",
    ">\n",
    "> $$R = det(M) - k \\cdot trace(M)^2$$\n",
    "> $$R = \\lambda_1 \\lambda_2 - k(\\lambda_1 + \\lambda_2)^2$$\n",
    ">\n",
    "> 其中:\n",
    "> * $\\lambda_1, \\lambda_2$ 是矩陣 M 的特徵值\n",
    "> * $k$ 是經驗常數 (通常取 0.04 ~ 0.06)\n",
    "\n",
    "### 判斷準則\n",
    "\n",
    "> | 情況 | $\\lambda_1$ | $\\lambda_2$ | R 值 | 區域類型 |\n",
    "> |------|------------|------------|------|----------|\n",
    "> | 1 | 小 | 小 | 小 | 平坦區域 |\n",
    "> | 2 | 大 | 小 | 負數 | 邊緣 |\n",
    "> | 3 | 大 | 大 | **大正數** | **角點** |\n",
    "\n",
    "## 2-2: OpenCV 實現\n",
    "\n",
    "### cv2.cornerHarris() 函數\n",
    "\n",
    "```python\n",
    "dst = cv2.cornerHarris(src, blockSize, ksize, k)\n",
    "```\n",
    "\n",
    "> **參數說明**:\n",
    "> * `src`: 輸入灰度圖像 (float32 類型)\n",
    "> * `blockSize`: 角點檢測的鄰域大小 (通常為 2~5)\n",
    "> * `ksize`: Sobel 算子的孔徑大小 (必須是奇數)\n",
    "> * `k`: Harris 檢測器的自由參數 (0.04 ~ 0.06)\n",
    ">\n",
    "> **返回值**:\n",
    "> * `dst`: 每個像素的角點響應值 (float32 類型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入必要的庫\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure matplotlib for better display\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3: Harris 角點檢測實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image\n",
    "img = cv2.imread('../assets/images/basic/lenaColor.png', 1)\n",
    "if img is None:\n",
    "    print(\"Error: Could not load image\")\n",
    "else:\n",
    "    print(f\"Image loaded: {img.shape}\")\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)  # Harris requires float32 type\n",
    "    \n",
    "    # Apply Harris corner detection\n",
    "    # blockSize: neighborhood size for corner detection\n",
    "    # ksize: aperture parameter for Sobel operator\n",
    "    # k: Harris detector free parameter (0.04-0.06)\n",
    "    dst = cv2.cornerHarris(gray, blockSize=5, ksize=3, k=0.04)\n",
    "    \n",
    "    # Result is dilated for marking the corners (optional enhancement)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    \n",
    "    # Create visualization\n",
    "    img_display = img.copy()\n",
    "    \n",
    "    # Threshold: mark corners where response > 0.01 * max response\n",
    "    img_display[dst > 0.01 * dst.max()] = [0, 0, 255]  # Red color for corners\n",
    "    \n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(dst, cmap='hot')\n",
    "    axes[1].set_title('Harris Response (Corner Strength)')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB))\n",
    "    axes[2].set_title('Detected Corners (Red)')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistics\n",
    "    corner_count = np.sum(dst > 0.01 * dst.max())\n",
    "    print(f\"\\nDetected corners: {corner_count}\")\n",
    "    print(f\"Max response: {dst.max():.2f}\")\n",
    "    print(f\"Threshold: {0.01 * dst.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參數調整影響"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different Harris parameters\n",
    "if img is not None:\n",
    "    gray = np.float32(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # Test different k values\n",
    "    k_values = [0.04, 0.06, 0.08]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    for idx, k in enumerate(k_values):\n",
    "        # Apply Harris corner detection\n",
    "        dst = cv2.cornerHarris(gray, blockSize=5, ksize=3, k=k)\n",
    "        dst = cv2.dilate(dst, None)\n",
    "        \n",
    "        # Visualize response\n",
    "        axes[0, idx].imshow(dst, cmap='hot')\n",
    "        axes[0, idx].set_title(f'Response (k={k})')\n",
    "        axes[0, idx].axis('off')\n",
    "        \n",
    "        # Mark corners\n",
    "        img_marked = img.copy()\n",
    "        img_marked[dst > 0.01 * dst.max()] = [0, 0, 255]\n",
    "        \n",
    "        axes[1, idx].imshow(cv2.cvtColor(img_marked, cv2.COLOR_BGR2RGB))\n",
    "        axes[1, idx].set_title(f'Corners (k={k}, count={np.sum(dst > 0.01 * dst.max())})')\n",
    "        axes[1, idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n📊 Parameter k 影響:\")\n",
    "    print(\"- k 越小: 檢測到更多角點 (包含弱角點)\")\n",
    "    print(\"- k 越大: 只檢測強角點 (更嚴格的判斷標準)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 3. Shi-Tomasi 角點檢測\n",
    "\n",
    "## 3-1: Shi-Tomasi 算法原理\n",
    "\n",
    "> Shi-Tomasi 算法是 **J. Shi** 和 **C. Tomasi** 於 1994 年提出的，是對 Harris 算法的改進。\n",
    "\n",
    "### 改進之處\n",
    "\n",
    "> **Harris 角點響應函數**:\n",
    "> $$R = \\lambda_1 \\lambda_2 - k(\\lambda_1 + \\lambda_2)^2$$\n",
    ">\n",
    "> **Shi-Tomasi 角點響應函數** (更簡單):\n",
    "> $$R = min(\\lambda_1, \\lambda_2)$$\n",
    "\n",
    "### 優勢\n",
    "\n",
    "> * **無需調整參數 k**: 去除了 Harris 中的經驗參數\n",
    "> * **更穩定**: 使用最小特徵值作為判斷標準\n",
    "> * **更適合追蹤**: 廣泛用於光流法和特徵追蹤\n",
    "> * **可指定數量**: 可以指定檢測最好的 N 個角點\n",
    "\n",
    "## 3-2: OpenCV 實現\n",
    "\n",
    "### cv2.goodFeaturesToTrack() 函數\n",
    "\n",
    "```python\n",
    "corners = cv2.goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance)\n",
    "```\n",
    "\n",
    "> **參數說明**:\n",
    "> * `image`: 輸入灰度圖像 (8-bit or float32)\n",
    "> * `maxCorners`: 返回角點的最大數量 (0 表示無限制)\n",
    "> * `qualityLevel`: 角點質量水平 (0~1)，低於 `qualityLevel * max(response)` 的角點被拒絕\n",
    "> * `minDistance`: 角點之間的最小歐氏距離\n",
    ">\n",
    "> **可選參數**:\n",
    "> * `mask`: 掩碼，指定檢測區域\n",
    "> * `blockSize`: 計算協方差矩陣的窗口大小\n",
    "> * `useHarrisDetector`: 是否使用 Harris 檢測器 (False 使用 Shi-Tomasi)\n",
    "> * `k`: Harris 檢測器的 k 參數\n",
    ">\n",
    "> **返回值**:\n",
    "> * `corners`: 檢測到的角點座標 array，shape 為 (N, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3: Shi-Tomasi 角點檢測實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shi-Tomasi corner detection\n",
    "if img is not None:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect corners using Shi-Tomasi method\n",
    "    # maxCorners: maximum number of corners to return\n",
    "    # qualityLevel: parameter characterizing the minimal accepted quality\n",
    "    # minDistance: minimum possible Euclidean distance between returned corners\n",
    "    corners = cv2.goodFeaturesToTrack(\n",
    "        gray,\n",
    "        maxCorners=100,\n",
    "        qualityLevel=0.01,\n",
    "        minDistance=10,\n",
    "        blockSize=7\n",
    "    )\n",
    "    \n",
    "    # Draw detected corners\n",
    "    img_corners = img.copy()\n",
    "    \n",
    "    if corners is not None:\n",
    "        corners = np.int0(corners)  # Convert to integer\n",
    "        \n",
    "        for i, corner in enumerate(corners):\n",
    "            x, y = corner.ravel()  # Extract x, y coordinates\n",
    "            # Draw circle at corner location\n",
    "            cv2.circle(img_corners, (x, y), 5, (0, 255, 0), -1)\n",
    "    \n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cv2.cvtColor(img_corners, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(f'Shi-Tomasi Corners (Green, count={len(corners)})')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print corner statistics\n",
    "    print(f\"\\nDetected {len(corners)} corners\")\n",
    "    print(f\"Corner coordinates shape: {corners.shape}\")\n",
    "    print(f\"First 5 corners:\\n{corners[:5].reshape(-1, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參數調整對比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different parameters for Shi-Tomasi\n",
    "if img is not None:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Test different parameter combinations\n",
    "    params = [\n",
    "        {'maxCorners': 50, 'qualityLevel': 0.01, 'minDistance': 10},\n",
    "        {'maxCorners': 100, 'qualityLevel': 0.01, 'minDistance': 10},\n",
    "        {'maxCorners': 100, 'qualityLevel': 0.05, 'minDistance': 10},\n",
    "        {'maxCorners': 100, 'qualityLevel': 0.01, 'minDistance': 20}\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, param in enumerate(params):\n",
    "        # Detect corners\n",
    "        corners = cv2.goodFeaturesToTrack(gray, **param)\n",
    "        \n",
    "        # Draw corners\n",
    "        img_marked = img.copy()\n",
    "        if corners is not None:\n",
    "            corners = np.int0(corners)\n",
    "            for corner in corners:\n",
    "                x, y = corner.ravel()\n",
    "                cv2.circle(img_marked, (x, y), 5, (0, 255, 0), -1)\n",
    "        \n",
    "        # Display\n",
    "        axes[idx].imshow(cv2.cvtColor(img_marked, cv2.COLOR_BGR2RGB))\n",
    "        title = f\"max={param['maxCorners']}, q={param['qualityLevel']}, d={param['minDistance']}\\n\"\n",
    "        title += f\"Detected: {len(corners) if corners is not None else 0}\"\n",
    "        axes[idx].set_title(title)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n📊 參數影響分析:\")\n",
    "    print(\"- maxCorners: 限制返回的最大角點數\")\n",
    "    print(\"- qualityLevel: 越高越嚴格，檢測到的角點越少但質量越高\")\n",
    "    print(\"- minDistance: 角點之間的最小距離，避免角點聚集\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 4. FAST 角點檢測\n",
    "\n",
    "## 4-1: FAST 算法原理\n",
    "\n",
    "> **FAST** (Features from Accelerated Segment Test) 由 **Edward Rosten** 和 **Tom Drummond** 於 2006 年提出。\n",
    "\n",
    "### 核心思想\n",
    "\n",
    "> FAST 的設計目標是**速度**，特別適合即時應用。原理簡單高效:\n",
    ">\n",
    "> 1. 選擇圖像中的一個像素 p，其灰度值為 $I_p$\n",
    "> 2. 設定閾值 t (例如 $I_p$ 的 20%)\n",
    "> 3. 考慮以 p 為中心、半徑為 3 的圓，圓上有 16 個像素點\n",
    "> 4. 如果圓上有**連續 n 個點** (通常 n=12，稱為 FAST-12):\n",
    ">    - 這些點的灰度值都 > $I_p + t$ (更亮)\n",
    ">    - 或都 < $I_p - t$ (更暗)\n",
    "> 5. 則認為 p 是一個角點\n",
    "\n",
    "### FAST 加速技巧\n",
    "\n",
    "> 為了更快的速度，FAST 使用**快速判斷策略**:\n",
    "> * 首先檢查圓上的 4 個點 (1, 5, 9, 13) - 每隔 90 度\n",
    "> * 如果其中至少有 3 個點滿足條件，才繼續檢查其他點\n",
    "> * 否則直接放棄該候選點\n",
    "\n",
    "><img src=\"../assets/images/basic/KpFast01.png\" style='width:80%'></img>\n",
    "\n",
    "### FAST 的優缺點\n",
    "\n",
    "> **優點**:\n",
    "> * ✅ **執行速度極快**: 適合即時應用和低階硬體\n",
    "> * ✅ **原理簡單**: 易於實現和理解\n",
    "> * ✅ **使用率高**: 廣泛應用於 SLAM、AR 等領域\n",
    ">\n",
    "> **缺點**:\n",
    "> * ❌ **角點聚集**: 檢測到的角點容易\"扎堆\" (需要非極大值抑制)\n",
    "> * ❌ **無方向資訊**: 不具有旋轉不變性\n",
    "> * ❌ **無尺度資訊**: 不具有尺度不變性\n",
    "> * ❌ **無描述子**: 僅檢測角點，不包含特徵描述\n",
    "\n",
    "### 非極大值抑制 (NMS)\n",
    "\n",
    "> 為了解決角點聚集問題，FAST 使用 **Non-Maximum Suppression (NMS)**:\n",
    "> * 計算每個候選角點的響應值\n",
    "> * 在鄰域內只保留響應值最大的角點\n",
    "> * 抑制其他較弱的角點\n",
    "\n",
    "## 4-2: OpenCV 實現\n",
    "\n",
    "### cv2.FastFeatureDetector 類\n",
    "\n",
    "```python\n",
    "fast = cv2.FastFeatureDetector_create(\n",
    "    threshold=10,\n",
    "    nonmaxSuppression=True,\n",
    "    type=cv2.FAST_FEATURE_DETECTOR_TYPE_9_16\n",
    ")\n",
    "keypoints = fast.detect(image, None)\n",
    "```\n",
    "\n",
    "> **參數說明**:\n",
    "> * `threshold`: 中心像素與圓上像素的差異閾值\n",
    "> * `nonmaxSuppression`: 是否進行非極大值抑制\n",
    "> * `type`: FAST 類型\n",
    ">   - `TYPE_5_8`: 圓上 8 個點，需要連續 5 個\n",
    ">   - `TYPE_7_12`: 圓上 12 個點，需要連續 7 個\n",
    ">   - `TYPE_9_16`: 圓上 16 個點，需要連續 9 個 (預設)\n",
    ">\n",
    "> **返回值**:\n",
    "> * `keypoints`: 檢測到的關鍵點列表，每個關鍵點包含位置、大小、角度等資訊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3: FAST 角點檢測實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAST feature detection\n",
    "if img is not None:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create FAST detector\n",
    "    # threshold: threshold on difference between intensity of central pixel and pixels on circle\n",
    "    # nonmaxSuppression: if true, non-maximum suppression is applied to detected corners\n",
    "    fast = cv2.FastFeatureDetector_create(\n",
    "        threshold=20,\n",
    "        nonmaxSuppression=True,\n",
    "        type=cv2.FAST_FEATURE_DETECTOR_TYPE_9_16\n",
    "    )\n",
    "    \n",
    "    # Detect keypoints\n",
    "    keypoints = fast.detect(gray, None)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_kp = cv2.drawKeypoints(\n",
    "        img,\n",
    "        keypoints,\n",
    "        None,\n",
    "        color=(0, 255, 0),\n",
    "        flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cv2.cvtColor(img_kp, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(f'FAST Keypoints (count={len(keypoints)})')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print keypoint information\n",
    "    print(f\"\\nTotal keypoints detected: {len(keypoints)}\")\n",
    "    print(f\"\\nFirst 5 keypoints information:\")\n",
    "    for i, kp in enumerate(keypoints[:5]):\n",
    "        print(f\"  KP {i}: pt=({kp.pt[0]:.1f}, {kp.pt[1]:.1f}), size={kp.size:.1f}, response={kp.response:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAST 參數影響對比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare FAST with and without Non-Maximum Suppression\n",
    "if img is not None:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # FAST without NMS\n",
    "    fast_no_nms = cv2.FastFeatureDetector_create(\n",
    "        threshold=20,\n",
    "        nonmaxSuppression=False\n",
    "    )\n",
    "    kp_no_nms = fast_no_nms.detect(gray, None)\n",
    "    img_no_nms = cv2.drawKeypoints(img, kp_no_nms, None, color=(0, 255, 0))\n",
    "    \n",
    "    # FAST with NMS\n",
    "    fast_nms = cv2.FastFeatureDetector_create(\n",
    "        threshold=20,\n",
    "        nonmaxSuppression=True\n",
    "    )\n",
    "    kp_nms = fast_nms.detect(gray, None)\n",
    "    img_nms = cv2.drawKeypoints(img, kp_nms, None, color=(0, 255, 0))\n",
    "    \n",
    "    # Display comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(img_no_nms, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(f'Without NMS (count={len(kp_no_nms)})')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cv2.cvtColor(img_nms, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(f'With NMS (count={len(kp_nms)})')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n非極大值抑制 (NMS) 效果:\")\n",
    "    print(f\"  Without NMS: {len(kp_no_nms)} keypoints (可能有聚集現象)\")\n",
    "    print(f\"  With NMS: {len(kp_nms)} keypoints (去除冗餘角點)\")\n",
    "    print(f\"  減少比例: {(1 - len(kp_nms)/len(kp_no_nms))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAST 不同閾值對比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different FAST thresholds\n",
    "if img is not None:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    thresholds = [10, 20, 40, 80]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, thresh in enumerate(thresholds):\n",
    "        # Create FAST detector with different threshold\n",
    "        fast = cv2.FastFeatureDetector_create(\n",
    "            threshold=thresh,\n",
    "            nonmaxSuppression=True\n",
    "        )\n",
    "        \n",
    "        # Detect and draw keypoints\n",
    "        keypoints = fast.detect(gray, None)\n",
    "        img_kp = cv2.drawKeypoints(img, keypoints, None, color=(0, 255, 0))\n",
    "        \n",
    "        # Display\n",
    "        axes[idx].imshow(cv2.cvtColor(img_kp, cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f'Threshold={thresh}, Keypoints={len(keypoints)}')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n📊 Threshold 影響分析:\")\n",
    "    print(\"- Threshold 越小: 檢測到更多角點 (包含弱特徵)\")\n",
    "    print(\"- Threshold 越大: 只檢測強角點 (更嚴格的標準)\")\n",
    "    print(\"- 建議根據應用場景調整: 即時追蹤用較低值，精確匹配用較高值\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 5. 角點檢測器比較分析\n",
    "\n",
    "## 5-1: 三種檢測器視覺對比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison of all three corner detectors\n",
    "if img is not None:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_float = np.float32(gray)\n",
    "    \n",
    "    # ===== 1. Harris Corner Detection =====\n",
    "    harris_dst = cv2.cornerHarris(gray_float, blockSize=5, ksize=3, k=0.04)\n",
    "    harris_dst = cv2.dilate(harris_dst, None)\n",
    "    img_harris = img.copy()\n",
    "    img_harris[harris_dst > 0.01 * harris_dst.max()] = [255, 0, 0]  # Blue\n",
    "    harris_count = np.sum(harris_dst > 0.01 * harris_dst.max())\n",
    "    \n",
    "    # ===== 2. Shi-Tomasi Corner Detection =====\n",
    "    shi_tomasi_corners = cv2.goodFeaturesToTrack(\n",
    "        gray,\n",
    "        maxCorners=100,\n",
    "        qualityLevel=0.01,\n",
    "        minDistance=10\n",
    "    )\n",
    "    img_shi_tomasi = img.copy()\n",
    "    if shi_tomasi_corners is not None:\n",
    "        shi_tomasi_corners = np.int0(shi_tomasi_corners)\n",
    "        for corner in shi_tomasi_corners:\n",
    "            x, y = corner.ravel()\n",
    "            cv2.circle(img_shi_tomasi, (x, y), 5, (0, 255, 0), -1)  # Green\n",
    "    shi_tomasi_count = len(shi_tomasi_corners) if shi_tomasi_corners is not None else 0\n",
    "    \n",
    "    # ===== 3. FAST Feature Detection =====\n",
    "    fast = cv2.FastFeatureDetector_create(threshold=20, nonmaxSuppression=True)\n",
    "    fast_keypoints = fast.detect(gray, None)\n",
    "    img_fast = img.copy()\n",
    "    for kp in fast_keypoints:\n",
    "        x, y = int(kp.pt[0]), int(kp.pt[1])\n",
    "        cv2.circle(img_fast, (x, y), 3, (0, 0, 255), -1)  # Red\n",
    "    fast_count = len(fast_keypoints)\n",
    "    \n",
    "    # Display comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(cv2.cvtColor(img_harris, cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 1].set_title(f'Harris (Blue, {harris_count} corners)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(cv2.cvtColor(img_shi_tomasi, cv2.COLOR_BGR2RGB))\n",
    "    axes[1, 0].set_title(f'Shi-Tomasi (Green, {shi_tomasi_count} corners)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(cv2.cvtColor(img_fast, cv2.COLOR_BGR2RGB))\n",
    "    axes[1, 1].set_title(f'FAST (Red, {fast_count} keypoints)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"角點檢測器統計比較\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Harris      : {harris_count} 個角點\")\n",
    "    print(f\"Shi-Tomasi  : {shi_tomasi_count} 個角點\")\n",
    "    print(f\"FAST        : {fast_count} 個關鍵點\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2: 性能基準測試 (Performance Benchmarking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Performance benchmarking\n",
    "if img is not None:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_float = np.float32(gray)\n",
    "    \n",
    "    num_runs = 10\n",
    "    \n",
    "    # ===== Benchmark Harris =====\n",
    "    start = time.time()\n",
    "    for _ in range(num_runs):\n",
    "        harris_dst = cv2.cornerHarris(gray_float, blockSize=5, ksize=3, k=0.04)\n",
    "        harris_dst = cv2.dilate(harris_dst, None)\n",
    "    harris_time = (time.time() - start) / num_runs * 1000  # Convert to ms\n",
    "    \n",
    "    # ===== Benchmark Shi-Tomasi =====\n",
    "    start = time.time()\n",
    "    for _ in range(num_runs):\n",
    "        corners = cv2.goodFeaturesToTrack(gray, maxCorners=100, qualityLevel=0.01, minDistance=10)\n",
    "    shi_tomasi_time = (time.time() - start) / num_runs * 1000\n",
    "    \n",
    "    # ===== Benchmark FAST =====\n",
    "    fast = cv2.FastFeatureDetector_create(threshold=20, nonmaxSuppression=True)\n",
    "    start = time.time()\n",
    "    for _ in range(num_runs):\n",
    "        keypoints = fast.detect(gray, None)\n",
    "    fast_time = (time.time() - start) / num_runs * 1000\n",
    "    \n",
    "    # Visualization\n",
    "    methods = ['Harris', 'Shi-Tomasi', 'FAST']\n",
    "    times = [harris_time, shi_tomasi_time, fast_time]\n",
    "    colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = ax.bar(methods, times, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, time_val in zip(bars, times):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{time_val:.2f} ms',\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel('執行時間 (milliseconds)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'角點檢測器性能比較 (平均 {num_runs} 次執行)', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"性能基準測試結果\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"圖像大小: {gray.shape}\")\n",
    "    print(f\"測試次數: {num_runs}\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"Harris      : {harris_time:.2f} ms (基準)\")\n",
    "    print(f\"Shi-Tomasi  : {shi_tomasi_time:.2f} ms ({shi_tomasi_time/harris_time:.2f}x)\")\n",
    "    print(f\"FAST        : {fast_time:.2f} ms ({fast_time/harris_time:.2f}x) ⚡\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n🏆 最快: {methods[np.argmin(times)]} ({min(times):.2f} ms)\")\n",
    "    print(f\"💡 FAST 比 Harris 快 {harris_time/fast_time:.1f} 倍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3: 綜合特性比較表\n",
    "\n",
    "| 特性 | Harris | Shi-Tomasi | FAST |\n",
    "|------|--------|------------|------|\n",
    "| **檢測速度** | 中等 | 中等 | ⚡ **極快** |\n",
    "| **檢測精度** | 高 | **最高** | 中等 |\n",
    "| **旋轉不變性** | ✅ 是 | ✅ 是 | ❌ 否 |\n",
    "| **尺度不變性** | ❌ 否 | ❌ 否 | ❌ 否 |\n",
    "| **抗噪能力** | 好 | 好 | 中等 |\n",
    "| **參數調整** | 需要 k 參數 | ✅ 簡單 | 需要閾值 |\n",
    "| **角點分佈** | 均勻 | **最均勻** | 容易聚集 |\n",
    "| **特徵描述子** | 無 | 無 | 無 (需配合其他) |\n",
    "| **適用場景** | 一般特徵檢測 | 特徵追蹤、光流 | 即時視頻、SLAM |\n",
    "\n",
    "### 算法複雜度分析\n",
    "\n",
    "| 算法 | 時間複雜度 | 空間複雜度 | 備註 |\n",
    "|------|-----------|-----------|------|\n",
    "| **Harris** | O(n²) | O(n²) | n 為圖像尺寸 |\n",
    "| **Shi-Tomasi** | O(n²) | O(n²) | 與 Harris 相似 |\n",
    "| **FAST** | O(n) | O(1) | 線性時間，常數空間 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-4: 不同場景下的表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on different types of images\n",
    "test_images = [\n",
    "    '../assets/images/basic/lenaColor.png',\n",
    "    '../assets/images/basic/chessboard.png',\n",
    "    '../assets/images/basic/building.jpg'\n",
    "]\n",
    "\n",
    "image_names = ['Lena (紋理豐富)', 'Chessboard (規則圖案)', 'Building (邊緣明顯)']\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, img_path in enumerate(test_images):\n",
    "    test_img = cv2.imread(img_path)\n",
    "    if test_img is None:\n",
    "        print(f\"Warning: Could not load {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Resize if too large\n",
    "    if max(test_img.shape[:2]) > 512:\n",
    "        scale = 512 / max(test_img.shape[:2])\n",
    "        test_img = cv2.resize(test_img, None, fx=scale, fy=scale)\n",
    "    \n",
    "    gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_float = np.float32(gray)\n",
    "    \n",
    "    # Harris\n",
    "    harris_dst = cv2.cornerHarris(gray_float, 5, 3, 0.04)\n",
    "    harris_count = np.sum(harris_dst > 0.01 * harris_dst.max())\n",
    "    \n",
    "    # Shi-Tomasi\n",
    "    corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 10)\n",
    "    shi_count = len(corners) if corners is not None else 0\n",
    "    \n",
    "    # FAST\n",
    "    fast = cv2.FastFeatureDetector_create(20, True)\n",
    "    kps = fast.detect(gray, None)\n",
    "    fast_count = len(kps)\n",
    "    \n",
    "    results.append([harris_count, shi_count, fast_count])\n",
    "\n",
    "if results:\n",
    "    # Plot comparison\n",
    "    results = np.array(results)\n",
    "    x = np.arange(len(image_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    bars1 = ax.bar(x - width, results[:, 0], width, label='Harris', color='#3498db', alpha=0.8)\n",
    "    bars2 = ax.bar(x, results[:, 1], width, label='Shi-Tomasi', color='#2ecc71', alpha=0.8)\n",
    "    bars3 = ax.bar(x + width, results[:, 2], width, label='FAST', color='#e74c3c', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('圖像類型', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('檢測到的角點數量', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('不同場景下的角點檢測表現', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(image_names)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n不同場景檢測結果:\")\n",
    "    print(\"-\" * 60)\n",
    "    for name, result in zip(image_names, results):\n",
    "        print(f\"{name:20} | Harris: {result[0]:4d} | Shi-Tomasi: {result[1]:4d} | FAST: {result[2]:4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 6. 應用場景與選擇建議\n",
    "\n",
    "## 6-1: 應用場景分析\n",
    "\n",
    "### Harris 角點檢測\n",
    "\n",
    "> **適用場景**:\n",
    "> * ✅ 靜態圖像特徵提取\n",
    "> * ✅ 圖像拼接 (panorama stitching)\n",
    "> * ✅ 3D 重建預處理\n",
    "> * ✅ 圖像配準 (image registration)\n",
    ">\n",
    "> **不適用場景**:\n",
    "> * ❌ 即時視頻處理 (速度較慢)\n",
    "> * ❌ 需要尺度不變性的應用\n",
    "> * ❌ 低端硬體設備\n",
    "\n",
    "### Shi-Tomasi 角點檢測\n",
    "\n",
    "> **適用場景**:\n",
    "> * ✅ **光流法追蹤** (Lucas-Kanade 光流) ⭐\n",
    "> * ✅ 視頻物體追蹤\n",
    "> * ✅ 需要高質量角點的應用\n",
    "> * ✅ 特徵點匹配\n",
    "> * ✅ 相機標定\n",
    ">\n",
    "> **典型應用**:\n",
    "> * OpenCV 的 `calcOpticalFlowPyrLK()` 預設使用 Shi-Tomasi\n",
    "> * 視頻穩定 (video stabilization)\n",
    "> * 運動分析\n",
    "\n",
    "### FAST 角點檢測\n",
    "\n",
    "> **適用場景**:\n",
    "> * ✅ **即時視頻處理** ⭐\n",
    "> * ✅ **SLAM (同步定位與地圖構建)** ⭐\n",
    "> * ✅ **AR/VR 應用** ⭐\n",
    "> * ✅ 移動設備應用\n",
    "> * ✅ 無人機視覺導航\n",
    "> * ✅ 低端硬體設備\n",
    ">\n",
    "> **典型應用**:\n",
    "> * ORB-SLAM (使用 ORB = Oriented FAST + BRIEF)\n",
    "> * 即時目標追蹤\n",
    "> * 移動機器人視覺\n",
    "\n",
    "## 6-2: 選擇決策樹\n",
    "\n",
    "```\n",
    "需要即時處理 (>30 FPS)?\n",
    "├─ 是 → 使用 FAST\n",
    "└─ 否\n",
    "    └─ 需要追蹤特徵點?\n",
    "        ├─ 是 → 使用 Shi-Tomasi\n",
    "        └─ 否 → 使用 Harris 或 Shi-Tomasi\n",
    "```\n",
    "\n",
    "## 6-3: 實用建議\n",
    "\n",
    "### 參數調整建議\n",
    "\n",
    "| 算法 | 關鍵參數 | 建議範圍 | 調整策略 |\n",
    "|------|---------|---------|----------|\n",
    "| **Harris** | k | 0.04 ~ 0.06 | 角點太少增加 k，太多減少 k |\n",
    "| **Harris** | threshold | 0.01 ~ 0.1 | 相對於最大響應值的比例 |\n",
    "| **Shi-Tomasi** | qualityLevel | 0.01 ~ 0.1 | 質量越高角點越少 |\n",
    "| **Shi-Tomasi** | minDistance | 5 ~ 30 | 避免角點聚集 |\n",
    "| **FAST** | threshold | 10 ~ 40 | 閾值越高角點越少 |\n",
    "| **FAST** | NMS | True/False | 建議開啟以避免聚集 |\n",
    "\n",
    "### 性能優化建議\n",
    "\n",
    "> **1. 圖像預處理**:\n",
    "> * 適當縮小圖像尺寸 (如 640x480)\n",
    "> * 使用高斯模糊去除噪聲\n",
    "> * 增強對比度 (對於低對比度圖像)\n",
    ">\n",
    "> **2. 區域限制**:\n",
    "> * 使用 mask 限制檢測區域\n",
    "> * 排除不需要檢測的區域 (如天空)\n",
    ">\n",
    "> **3. 多尺度檢測**:\n",
    "> * 構建圖像金字塔\n",
    "> * 在不同尺度上檢測角點\n",
    "> * 適用於需要尺度不變性的應用\n",
    "\n",
    "## 6-4: 進階技術\n",
    "\n",
    "### 角點檢測的改進算法\n",
    "\n",
    "> **1. ORB (Oriented FAST and Rotated BRIEF)**:\n",
    "> * 基於 FAST 的改進\n",
    "> * 添加方向信息 (旋轉不變性)\n",
    "> * 使用 BRIEF 描述子\n",
    ">\n",
    "> **2. BRISK (Binary Robust Invariant Scalable Keypoints)**:\n",
    "> * 具有尺度不變性\n",
    "> * 速度接近 FAST\n",
    "> * 適合即時應用\n",
    ">\n",
    "> **3. AGAST (Adaptive and Generic Accelerated Segment Test)**:\n",
    "> * FAST 的改進版本\n",
    "> * 更快的檢測速度\n",
    "> * 更好的檢測質量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-5: 實戰案例 - 特徵追蹤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical example: Feature tracking using Shi-Tomasi + Optical Flow\n",
    "# This demonstrates why Shi-Tomasi is preferred for tracking applications\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"實戰案例: Shi-Tomasi 角點 + Lucas-Kanade 光流追蹤\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n應用場景: 視頻物體追蹤、運動分析\")\n",
    "print(\"\\n算法流程:\")\n",
    "print(\"  1. 使用 Shi-Tomasi 檢測第一幀的角點\")\n",
    "print(\"  2. 使用 Lucas-Kanade 光流追蹤角點在後續幀中的位置\")\n",
    "print(\"  3. 根據追蹤結果分析物體運動\")\n",
    "print(\"\\n為什麼選擇 Shi-Tomasi?\")\n",
    "print(\"  ✅ 角點質量高，適合長期追蹤\")\n",
    "print(\"  ✅ 分佈均勻，覆蓋整個圖像\")\n",
    "print(\"  ✅ OpenCV 光流函數的預設選擇\")\n",
    "print(\"  ✅ 追蹤穩定性好\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Simplified code structure (actual implementation would require video input)\n",
    "code_example = '''\n",
    "# Feature tracking pseudo-code\n",
    "frame1 = capture.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect corners using Shi-Tomasi\n",
    "corners = cv2.goodFeaturesToTrack(gray1, maxCorners=100, qualityLevel=0.01, minDistance=10)\n",
    "\n",
    "while True:\n",
    "    frame2 = capture.read()\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Track corners using Lucas-Kanade optical flow\n",
    "    new_corners, status, error = cv2.calcOpticalFlowPyrLK(gray1, gray2, corners, None)\n",
    "    \n",
    "    # Draw tracked features\n",
    "    for i, (new, old) in enumerate(zip(new_corners, corners)):\n",
    "        if status[i]:\n",
    "            cv2.line(frame2, tuple(new), tuple(old), (0, 255, 0), 2)\n",
    "    \n",
    "    # Update for next iteration\n",
    "    gray1 = gray2.copy()\n",
    "    corners = new_corners\n",
    "'''\n",
    "\n",
    "print(\"\\n範例程式碼:\")\n",
    "print(code_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 7. 總結與延伸\n",
    "\n",
    "## 7-1: 核心要點回顧\n",
    "\n",
    "### 三種角點檢測器總結\n",
    "\n",
    "> **Harris 角點檢測**:\n",
    "> * 📌 經典算法，理論基礎扎實\n",
    "> * 📌 使用自相關矩陣和響應函數\n",
    "> * 📌 需要調整參數 k (0.04~0.06)\n",
    "> * 📌 適合一般圖像處理任務\n",
    ">\n",
    "> **Shi-Tomasi 角點檢測**:\n",
    "> * 📌 Harris 的改進版本\n",
    "> * 📌 使用最小特徵值，無需參數 k\n",
    "> * 📌 **最適合特徵追蹤** ⭐\n",
    "> * 📌 OpenCV 光流法的首選\n",
    ">\n",
    "> **FAST 角點檢測**:\n",
    "> * 📌 **速度最快** 的角點檢測算法 ⚡\n",
    "> * 📌 基於圓形模板的像素比較\n",
    "> * 📌 適合即時應用和低端硬體\n",
    "> * 📌 缺乏方向和尺度信息\n",
    "\n",
    "## 7-2: 選擇指南\n",
    "\n",
    "| 應用需求 | 推薦算法 | 理由 |\n",
    "|---------|---------|------|\n",
    "| 圖像拼接 | Harris / Shi-Tomasi | 需要高質量角點 |\n",
    "| 特徵追蹤 | **Shi-Tomasi** ⭐ | 最適合光流法 |\n",
    "| 即時視頻 | **FAST** ⚡ | 速度最快 |\n",
    "| SLAM | FAST + ORB | 速度 + 描述子 |\n",
    "| 3D重建 | Harris / Shi-Tomasi | 精度優先 |\n",
    "| 移動設備 | FAST | 計算資源有限 |\n",
    "\n",
    "## 7-3: 延伸學習\n",
    "\n",
    "### 後續模組預告\n",
    "\n",
    "> **4.1.2 特徵描述子 (Feature Descriptors)**:\n",
    "> * SIFT (Scale-Invariant Feature Transform)\n",
    "> * SURF (Speeded-Up Robust Features)\n",
    "> * ORB (Oriented FAST and Rotated BRIEF)\n",
    "> * BRIEF (Binary Robust Independent Elementary Features)\n",
    ">\n",
    "> **4.1.3 特徵匹配 (Feature Matching)**:\n",
    "> * Brute-Force 匹配\n",
    "> * FLANN 快速匹配\n",
    "> * 交叉驗證匹配\n",
    "> * RANSAC 外點過濾\n",
    ">\n",
    "> **4.2 光流法 (Optical Flow)**:\n",
    "> * Lucas-Kanade 光流\n",
    "> * Farneback 稠密光流\n",
    "> * 運動估計與物體追蹤\n",
    "\n",
    "## 7-4: 參考資源\n",
    "\n",
    "### 論文\n",
    "\n",
    "> * **Harris Corner Detection**:  \n",
    ">   C. Harris and M. Stephens. \"A Combined Corner and Edge Detector.\" *Alvey Vision Conference*, 1988.\n",
    ">\n",
    "> * **Shi-Tomasi Corner Detection**:  \n",
    ">   J. Shi and C. Tomasi. \"Good Features to Track.\" *IEEE Conference on CVPR*, 1994.\n",
    ">\n",
    "> * **FAST Corner Detection**:  \n",
    ">   E. Rosten and T. Drummond. \"Machine Learning for High-Speed Corner Detection.\" *ECCV*, 2006.\n",
    "\n",
    "### 線上資源\n",
    "\n",
    "> * OpenCV 官方文檔: https://docs.opencv.org/\n",
    "> * Harris Corner Detector Tutorial: https://docs.opencv.org/master/dc/d0d/tutorial_py_features_harris.html\n",
    "> * Shi-Tomasi Corner Detector: https://docs.opencv.org/master/d4/d8c/tutorial_py_shi_tomasi.html\n",
    "> * FAST Algorithm: https://docs.opencv.org/master/df/d0c/tutorial_py_fast.html\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 實作練習建議\n",
    "\n",
    "1. **比較實驗**: 在不同類型圖像上測試三種算法，分析結果差異\n",
    "2. **參數調優**: 嘗試不同參數組合，理解參數對結果的影響\n",
    "3. **性能測試**: 在不同硬體上測試算法性能，記錄執行時間\n",
    "4. **追蹤實現**: 結合 Shi-Tomasi 和光流法實現簡單的物體追蹤\n",
    "5. **即時應用**: 使用 FAST 實現即時視頻角點檢測\n",
    "\n",
    "---\n",
    "\n",
    "**模組完成！繼續學習 4.1.2 特徵描述子模組，深入了解如何描述和匹配檢測到的角點。**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
