{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.2 特徵描述子與特徵匹配 (Feature Descriptors & Matching)\n",
    "\n",
    "**WBS 4.1.2**: 特徵描述子、特徵匹配與影像配準\n",
    "\n",
    "## 學習目標\n",
    "- 理解特徵描述子的原理與應用\n",
    "- 掌握 SIFT, SURF, ORB, BRIEF, BRISK 特徵檢測器\n",
    "- 學習特徵匹配算法 (BFMatcher, FLANN)\n",
    "- 應用 Homography 進行影像配準\n",
    "- 比較不同特徵檢測器的性能\n",
    "\n",
    "**難度等級**: ⭐⭐⭐⭐ (進階)  \n",
    "**預估時間**: 120 分鐘  \n",
    "**WBS編號**: 4.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境設置與導入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.image_utils import load_image, resize_image\n",
    "from utils.visualization import display_image, display_multiple_images\n",
    "from utils.performance import time_function, benchmark_function\n",
    "\n",
    "print(f'✅ OpenCV version: {cv2.__version__}')\n",
    "print(f'✅ NumPy version: {np.__version__}')\n",
    "\n",
    "# Check for xfeatures2d (for SIFT/SURF)\n",
    "try:\n",
    "    cv2.xfeatures2d.SIFT_create()\n",
    "    print('✅ SIFT available (cv2.xfeatures2d)')\n",
    "except AttributeError:\n",
    "    try:\n",
    "        cv2.SIFT_create()\n",
    "        print('✅ SIFT available (cv2.SIFT_create)')\n",
    "    except:\n",
    "        print('⚠️ SIFT not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 特徵描述子概述\n",
    "\n",
    "### 什麼是特徵描述子？\n",
    "\n",
    "**特徵描述子 (Feature Descriptor)** 是用向量來描述影像中關鍵點周圍區域的特徵，使得這些特徵點可以被唯一識別和匹配。\n",
    "\n",
    "### 核心概念\n",
    "\n",
    "```\n",
    "特徵檢測與描述的流程:\n",
    "\n",
    "1. 特徵檢測 (Feature Detection)\n",
    "   └─> 找到影像中的關鍵點 (Keypoints)\n",
    "       - 角點、斑點、邊緣等\n",
    "\n",
    "2. 特徵描述 (Feature Description)\n",
    "   └─> 為每個關鍵點建立描述向量\n",
    "       - SIFT: 128維向量\n",
    "       - ORB: 256位元二進位字串\n",
    "\n",
    "3. 特徵匹配 (Feature Matching)\n",
    "   └─> 在不同影像間尋找相同的特徵點\n",
    "       - 比較描述子的相似度\n",
    "```\n",
    "\n",
    "### 理想特徵描述子的特性\n",
    "\n",
    "| 特性 | 說明 | 重要性 |\n",
    "|------|------|--------|\n",
    "| **尺度不變性** | Scale Invariance | 影像縮放時特徵不變 |\n",
    "| **旋轉不變性** | Rotation Invariance | 影像旋轉時特徵不變 |\n",
    "| **光照不變性** | Illumination Invariance | 亮度變化時特徵穩定 |\n",
    "| **仿射不變性** | Affine Invariance | 視角變化時特徵穩定 |\n",
    "| **區分性** | Distinctiveness | 不同特徵有明顯差異 |\n",
    "| **計算效率** | Computational Efficiency | 運算速度快 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SIFT (Scale-Invariant Feature Transform)\n",
    "\n",
    "### 2.1 SIFT 原理\n",
    "\n",
    "**SIFT** 是最經典的特徵檢測器，由 David Lowe 於 1999 年提出。\n",
    "\n",
    "#### 核心思想\n",
    "\n",
    "```\n",
    "SIFT 演算法步驟:\n",
    "\n",
    "1. 尺度空間極值檢測\n",
    "   └─> 使用 DoG (Difference of Gaussian) 找特徵點\n",
    "\n",
    "2. 關鍵點定位\n",
    "   └─> 精確定位關鍵點位置，去除不穩定點\n",
    "\n",
    "3. 方向分配\n",
    "   └─> 為每個關鍵點分配主方向（旋轉不變性）\n",
    "\n",
    "4. 關鍵點描述\n",
    "   └─> 在關鍵點周圍 16x16 區域計算梯度直方圖\n",
    "       生成 128 維特徵向量 (4x4x8)\n",
    "```\n",
    "\n",
    "#### SIFT 特點\n",
    "\n",
    "- ✅ **尺度不變**: 可檢測不同尺寸的特徵\n",
    "- ✅ **旋轉不變**: 影像旋轉不影響檢測\n",
    "- ✅ **穩定性高**: 對光照、噪聲有強魯棒性\n",
    "- ❌ **計算緩慢**: 運算量大，不適合實時應用\n",
    "- ⚠️ **專利限制**: 商業使用需授權（2020年已過期）\n",
    "\n",
    "#### SIFT 數學原理\n",
    "\n",
    "**DoG (Difference of Gaussian)**:\n",
    "```\n",
    "DoG(x,y,σ) = G(x,y,kσ) - G(x,y,σ)\n",
    "```\n",
    "\n",
    "其中 G 是高斯濾波器，k 是尺度因子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image\n",
    "img_path = '../assets/images/basic/opencv.jpg'\n",
    "if os.path.exists(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (600, 400))\n",
    "else:\n",
    "    # Create synthetic test image\n",
    "    img = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
    "    cv2.rectangle(img, (100, 100), (500, 300), (0, 0, 0), -1)\n",
    "    cv2.circle(img, (300, 200), 80, (255, 255, 255), -1)\n",
    "    \n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create SIFT detector\n",
    "try:\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "except AttributeError:\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "# Draw keypoints\n",
    "img_sift = cv2.drawKeypoints(img, keypoints, None, \n",
    "                              flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display\n",
    "display_multiple_images(\n",
    "    [img, img_sift],\n",
    "    ['Original Image', f'SIFT Keypoints ({len(keypoints)} detected)'],\n",
    "    rows=1, cols=2, figsize=(15, 5)\n",
    ")\n",
    "\n",
    "print(f'\\n✅ SIFT 檢測結果:')\n",
    "print('='*60)\n",
    "print(f'關鍵點數量: {len(keypoints)}')\n",
    "print(f'描述子維度: {descriptors.shape if descriptors is not None else \"None\"}')\n",
    "print(f'描述子類型: {descriptors.dtype if descriptors is not None else \"None\"}')\n",
    "\n",
    "if len(keypoints) > 0:\n",
    "    kp = keypoints[0]\n",
    "    print(f'\\n第一個關鍵點資訊:')\n",
    "    print(f'  位置: ({kp.pt[0]:.1f}, {kp.pt[1]:.1f})')\n",
    "    print(f'  尺度: {kp.size:.2f}')\n",
    "    print(f'  角度: {kp.angle:.2f}°')\n",
    "    print(f'  響應: {kp.response:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SIFT 尺度不變性驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SIFT scale invariance\n",
    "scales = [0.5, 1.0, 1.5, 2.0]\n",
    "results = []\n",
    "titles = []\n",
    "\n",
    "for scale in scales:\n",
    "    # Resize image\n",
    "    h, w = gray.shape\n",
    "    scaled = cv2.resize(gray, (int(w*scale), int(h*scale)))\n",
    "    \n",
    "    # Detect keypoints\n",
    "    kp, desc = sift.detectAndCompute(scaled, None)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_kp = cv2.cvtColor(scaled, cv2.COLOR_GRAY2BGR)\n",
    "    img_kp = cv2.drawKeypoints(img_kp, kp, None, color=(0, 255, 0))\n",
    "    \n",
    "    results.append(img_kp)\n",
    "    titles.append(f'Scale {scale}x\\n{len(kp)} keypoints')\n",
    "\n",
    "display_multiple_images(results, titles, rows=1, cols=4, figsize=(20, 5))\n",
    "\n",
    "print('\\n💡 觀察: SIFT 在不同尺度下都能檢測到穩定的特徵點')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SURF (Speeded-Up Robust Features)\n",
    "\n",
    "### 3.1 SURF 原理\n",
    "\n",
    "**SURF** 是 SIFT 的加速版本，由 Bay et al. 於 2006 年提出。\n",
    "\n",
    "#### 核心改進\n",
    "\n",
    "```\n",
    "SURF vs SIFT:\n",
    "\n",
    "1. 積分影像 (Integral Image)\n",
    "   └─> 快速計算矩形區域的和\n",
    "\n",
    "2. Hessian 矩陣近似\n",
    "   └─> 使用盒子濾波器代替高斯濾波器\n",
    "\n",
    "3. 64維描述子\n",
    "   └─> 比 SIFT 的 128 維更快\n",
    "\n",
    "速度: SURF ≈ 3-7x 快於 SIFT\n",
    "```\n",
    "\n",
    "#### SURF 特點\n",
    "\n",
    "- ✅ **速度快**: 比 SIFT 快 3-7 倍\n",
    "- ✅ **魯棒性好**: 對模糊和旋轉有良好的抗性\n",
    "- ❌ **專利保護**: 需要授權才能商業使用\n",
    "- ⚠️ **OpenCV 限制**: 某些版本需要 contrib 模組\n",
    "\n",
    "### ⚠️ 注意: SURF 演算法已申請專利\n",
    "\n",
    "在某些 OpenCV 配置中，SURF 可能不可用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use SURF (may not be available)\n",
    "try:\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    \n",
    "    # Detect keypoints\n",
    "    keypoints_surf, descriptors_surf = surf.detectAndCompute(gray, None)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_surf = cv2.drawKeypoints(img, keypoints_surf, None, \n",
    "                                  flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    display_multiple_images(\n",
    "        [img, img_surf],\n",
    "        ['Original', f'SURF Keypoints ({len(keypoints_surf)} detected)'],\n",
    "        rows=1, cols=2, figsize=(15, 5)\n",
    "    )\n",
    "    \n",
    "    print(f'✅ SURF 檢測結果:')\n",
    "    print(f'關鍵點數量: {len(keypoints_surf)}')\n",
    "    print(f'描述子維度: {descriptors_surf.shape}')\n",
    "    \n",
    "except (AttributeError, cv2.error) as e:\n",
    "    print('⚠️ SURF 在此配置中不可用')\n",
    "    print('   原因: SURF 演算法已申請專利，某些 OpenCV 版本將其排除')\n",
    "    print('   替代方案: 使用 ORB 或 BRISK（開源且速度快）')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ORB (Oriented FAST and Rotated BRIEF)\n",
    "\n",
    "### 4.1 ORB 原理\n",
    "\n",
    "**ORB** 是由 OpenCV 實驗室開發的開源替代方案，結合了 FAST 關鍵點檢測器和 BRIEF 描述子。\n",
    "\n",
    "#### 核心特性\n",
    "\n",
    "```\n",
    "ORB = FAST + BRIEF + 改進\n",
    "\n",
    "1. FAST 角點檢測\n",
    "   └─> 快速檢測關鍵點\n",
    "\n",
    "2. Harris 角點度量\n",
    "   └─> 選擇最好的關鍵點\n",
    "\n",
    "3. 方向分配\n",
    "   └─> 計算 intensity centroid（旋轉不變）\n",
    "\n",
    "4. rBRIEF 描述子\n",
    "   └─> 旋轉感知的 BRIEF（256 位元二進位）\n",
    "```\n",
    "\n",
    "#### ORB 優勢\n",
    "\n",
    "- ✅ **完全開源**: 無專利限制\n",
    "- ✅ **速度極快**: 比 SIFT 快 100 倍以上\n",
    "- ✅ **旋轉不變**: 對旋轉有很好的魯棒性\n",
    "- ✅ **二進位描述子**: 匹配速度快（漢明距離）\n",
    "- ⚠️ **尺度不變性弱**: 相比 SIFT 較弱\n",
    "\n",
    "#### 性能比較\n",
    "\n",
    "```\n",
    "速度排名: ORB > SURF > SIFT\n",
    "魯棒性:   SURF ≥ SIFT > ORB\n",
    "適用場景: ORB 最適合實時應用\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ORB detector\n",
    "orb = cv2.ORB_create(nfeatures=1000)  # Max 1000 keypoints\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints_orb, descriptors_orb = orb.detectAndCompute(gray, None)\n",
    "\n",
    "# Draw keypoints\n",
    "img_orb = cv2.drawKeypoints(img, keypoints_orb, None, color=(0, 255, 0))\n",
    "\n",
    "# Display\n",
    "display_multiple_images(\n",
    "    [img, img_orb],\n",
    "    ['Original Image', f'ORB Keypoints ({len(keypoints_orb)} detected)'],\n",
    "    rows=1, cols=2, figsize=(15, 5)\n",
    ")\n",
    "\n",
    "print(f'\\n✅ ORB 檢測結果:')\n",
    "print('='*60)\n",
    "print(f'關鍵點數量: {len(keypoints_orb)}')\n",
    "print(f'描述子維度: {descriptors_orb.shape}')\n",
    "print(f'描述子類型: {descriptors_orb.dtype} (二進位)')\n",
    "print(f'每個描述子: 256 位元 (32 bytes)')\n",
    "\n",
    "if len(keypoints_orb) > 0:\n",
    "    print(f'\\n第一個描述子 (前16個位元組):')\n",
    "    print(descriptors_orb[0][:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ORB 旋轉不變性驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ORB rotation invariance\n",
    "angles = [0, 45, 90, 135]\n",
    "results = []\n",
    "titles = []\n",
    "\n",
    "for angle in angles:\n",
    "    # Rotate image\n",
    "    h, w = gray.shape\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray, M, (w, h))\n",
    "    \n",
    "    # Detect keypoints\n",
    "    kp, desc = orb.detectAndCompute(rotated, None)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_kp = cv2.cvtColor(rotated, cv2.COLOR_GRAY2BGR)\n",
    "    img_kp = cv2.drawKeypoints(img_kp, kp, None, color=(0, 255, 0))\n",
    "    \n",
    "    results.append(img_kp)\n",
    "    titles.append(f'Rotation {angle}°\\n{len(kp)} keypoints')\n",
    "\n",
    "display_multiple_images(results, titles, rows=1, cols=4, figsize=(20, 5))\n",
    "\n",
    "print('\\n💡 觀察: ORB 在不同旋轉角度下都能檢測到穩定的特徵點')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BRIEF (Binary Robust Independent Elementary Features)\n",
    "\n",
    "### 5.1 BRIEF 原理\n",
    "\n",
    "**BRIEF** 是一種二進位描述子，不提供關鍵點檢測，只提供特徵描述。\n",
    "\n",
    "#### 核心思想\n",
    "\n",
    "```\n",
    "BRIEF 描述子生成:\n",
    "\n",
    "1. 在關鍵點周圍選擇像素對\n",
    "   └─> 通常選擇 256 對像素\n",
    "\n",
    "2. 比較每對像素的亮度\n",
    "   └─> If I(p1) < I(p2): bit = 1\n",
    "   └─> Else: bit = 0\n",
    "\n",
    "3. 生成 256 位元二進位字串\n",
    "   └─> 非常緊湊的描述子\n",
    "```\n",
    "\n",
    "#### BRIEF 特點\n",
    "\n",
    "- ✅ **極快**: 只需簡單的像素比較\n",
    "- ✅ **記憶體小**: 256 位元 = 32 bytes\n",
    "- ✅ **匹配快**: 使用漢明距離（XOR 操作）\n",
    "- ❌ **無旋轉不變性**: 影像旋轉會失效\n",
    "- ❌ **無尺度不變性**: 需要其他檢測器提供關鍵點\n",
    "\n",
    "### ⚠️ 重要提示\n",
    "\n",
    "BRIEF 只是描述子，需要搭配其他特徵檢測器（如 FAST）使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRIEF requires a separate keypoint detector\n",
    "try:\n",
    "    # Use FAST for keypoint detection\n",
    "    fast = cv2.FastFeatureDetector_create()\n",
    "    keypoints_fast = fast.detect(gray, None)\n",
    "    \n",
    "    # Use BRIEF for description\n",
    "    brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "    keypoints_brief, descriptors_brief = brief.compute(gray, keypoints_fast)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_brief = cv2.drawKeypoints(img, keypoints_brief, None, color=(255, 0, 0))\n",
    "    \n",
    "    display_multiple_images(\n",
    "        [img, img_brief],\n",
    "        ['Original', f'FAST + BRIEF ({len(keypoints_brief)} keypoints)'],\n",
    "        rows=1, cols=2, figsize=(15, 5)\n",
    "    )\n",
    "    \n",
    "    print(f'✅ BRIEF 檢測結果:')\n",
    "    print(f'關鍵點數量 (FAST): {len(keypoints_fast)}')\n",
    "    print(f'描述子數量: {len(keypoints_brief)}')\n",
    "    print(f'描述子維度: {descriptors_brief.shape}')\n",
    "    print(f'描述子類型: {descriptors_brief.dtype}')\n",
    "    \n",
    "except AttributeError:\n",
    "    print('⚠️ BRIEF 在此配置中不可用')\n",
    "    print('   請使用 ORB（包含改進的 rBRIEF）')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. BRISK (Binary Robust Invariant Scalable Keypoints)\n",
    "\n",
    "### 6.1 BRISK 原理\n",
    "\n",
    "**BRISK** 是另一個開源的二進位特徵檢測器，結合了 FAST 和 BRIEF 的優點。\n",
    "\n",
    "#### 核心特性\n",
    "\n",
    "```\n",
    "BRISK 改進:\n",
    "\n",
    "1. 尺度空間關鍵點檢測\n",
    "   └─> 在不同尺度上使用 FAST\n",
    "\n",
    "2. 方向估計\n",
    "   └─> 使用長距離像素對估計方向\n",
    "\n",
    "3. 採樣模式\n",
    "   └─> 使用同心圓採樣模式\n",
    "\n",
    "4. 512 位元描述子\n",
    "   └─> 比 ORB 的 256 位元更具區分性\n",
    "```\n",
    "\n",
    "#### BRISK 優勢\n",
    "\n",
    "- ✅ **尺度不變**: 支援多尺度檢測\n",
    "- ✅ **旋轉不變**: 有方向估計\n",
    "- ✅ **速度快**: 接近 ORB 的速度\n",
    "- ✅ **開源**: 無專利限制\n",
    "- ⭐ **平衡性好**: 速度與準確度的良好平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BRISK detector\n",
    "brisk = cv2.BRISK_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints_brisk, descriptors_brisk = brisk.detectAndCompute(gray, None)\n",
    "\n",
    "# Draw keypoints\n",
    "img_brisk = cv2.drawKeypoints(img, keypoints_brisk, None, \n",
    "                               flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display\n",
    "display_multiple_images(\n",
    "    [img, img_brisk],\n",
    "    ['Original Image', f'BRISK Keypoints ({len(keypoints_brisk)} detected)'],\n",
    "    rows=1, cols=2, figsize=(15, 5)\n",
    ")\n",
    "\n",
    "print(f'\\n✅ BRISK 檢測結果:')\n",
    "print('='*60)\n",
    "print(f'關鍵點數量: {len(keypoints_brisk)}')\n",
    "print(f'描述子維度: {descriptors_brisk.shape}')\n",
    "print(f'描述子類型: {descriptors_brisk.dtype} (二進位)')\n",
    "print(f'每個描述子: 512 位元 (64 bytes)')\n",
    "\n",
    "print(f'\\n💡 BRISK vs ORB:')\n",
    "print(f'   - BRISK 描述子更長 (512 vs 256 位元)')\n",
    "print(f'   - BRISK 通常檢測更多關鍵點')\n",
    "print(f'   - BRISK 有更好的尺度不變性')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 特徵檢測器比較\n",
    "\n",
    "### 7.1 同時比較所有檢測器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all detectors\n",
    "detectors = {\n",
    "    'SIFT': sift,\n",
    "    'ORB': orb,\n",
    "    'BRISK': brisk\n",
    "}\n",
    "\n",
    "results = []\n",
    "titles = []\n",
    "stats = []\n",
    "\n",
    "for name, detector in detectors.items():\n",
    "    # Detect keypoints\n",
    "    kp, desc = detector.detectAndCompute(gray, None)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_kp = cv2.drawKeypoints(img, kp, None, color=(0, 255, 0))\n",
    "    \n",
    "    results.append(img_kp)\n",
    "    titles.append(f'{name}\\n{len(kp)} keypoints')\n",
    "    \n",
    "    stats.append({\n",
    "        'name': name,\n",
    "        'keypoints': len(kp),\n",
    "        'descriptor_size': desc.shape[1] if desc is not None else 0,\n",
    "        'descriptor_type': desc.dtype if desc is not None else 'None'\n",
    "    })\n",
    "\n",
    "# Display comparison\n",
    "display_multiple_images(results, titles, rows=1, cols=3, figsize=(18, 6))\n",
    "\n",
    "# Print statistics\n",
    "print('\\n特徵檢測器統計比較:')\n",
    "print('='*80)\n",
    "print(f'{'檢測器':10} | {'關鍵點數':>10} | {'描述子維度':>12} | {'類型':>10}')\n",
    "print('-'*80)\n",
    "for s in stats:\n",
    "    print(f\"{s['name']:10} | {s['keypoints']:>10} | {s['descriptor_size']:>12} | {str(s['descriptor_type']):>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 性能基準測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmark\n",
    "test_img = cv2.resize(gray, (640, 480))\n",
    "\n",
    "print('\\n效能測試 (640x480 影像):')  \n",
    "print('='*80)\n",
    "print(f'{'檢測器':10} | {'平均時間 (ms)':>15} | {'FPS':>10} | {'關鍵點數':>10}')\n",
    "print('-'*80)\n",
    "\n",
    "for name, detector in detectors.items():\n",
    "    # Benchmark\n",
    "    def detect():\n",
    "        return detector.detectAndCompute(test_img, None)\n",
    "    \n",
    "    stats = benchmark_function(detect, iterations=10)\n",
    "    kp, _ = detect()\n",
    "    \n",
    "    avg_time = stats['average'] * 1000\n",
    "    fps = 1.0 / stats['average'] if stats['average'] > 0 else 0\n",
    "    \n",
    "    print(f'{name:10} | {avg_time:13.2f} ms | {fps:8.1f} | {len(kp):>10}')\n",
    "\n",
    "print('\\n💡 觀察:')\n",
    "print('   - ORB 最快，適合實時應用')\n",
    "print('   - BRISK 速度與品質的良好平衡')\n",
    "print('   - SIFT 最穩定但速度較慢')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 特徵匹配 (Feature Matching)\n",
    "\n",
    "### 8.1 BFMatcher (Brute-Force Matcher)\n",
    "\n",
    "**BFMatcher** 是最簡單的特徵匹配器，對每個描述子進行暴力搜索。\n",
    "\n",
    "#### 工作原理\n",
    "\n",
    "```\n",
    "BFMatcher 匹配流程:\n",
    "\n",
    "1. 取第一張影像的第一個描述子\n",
    "2. 計算與第二張影像所有描述子的距離\n",
    "3. 找到距離最小的作為匹配\n",
    "4. 重複對所有描述子進行匹配\n",
    "\n",
    "距離度量:\n",
    "- L2/L1 距離: 用於 SIFT/SURF (浮點描述子)\n",
    "- Hamming 距離: 用於 ORB/BRISK (二進位描述子)\n",
    "```\n",
    "\n",
    "#### 距離計算\n",
    "\n",
    "**Hamming 距離**: 兩個二進位字串中不同位元的數量\n",
    "```\n",
    "例: \n",
    "A = 11010101\n",
    "B = 10110001\n",
    "Hamming(A,B) = 3 (有3個位元不同)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two images for matching\n",
    "img1_path = '../assets/images/basic/opencv.jpg'\n",
    "img2_path = '../assets/images/basic/opencv.jpg'  # Same image, slightly transformed\n",
    "\n",
    "if os.path.exists(img1_path):\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img1 = cv2.resize(img1, (400, 300))\n",
    "else:\n",
    "    img1 = np.ones((300, 400, 3), dtype=np.uint8) * 255\n",
    "    cv2.rectangle(img1, (50, 50), (350, 250), (0, 0, 0), -1)\n",
    "    cv2.circle(img1, (200, 150), 60, (255, 255, 255), -1)\n",
    "\n",
    "# Create transformed version of img1\n",
    "h, w = img1.shape[:2]\n",
    "M = cv2.getRotationMatrix2D((w//2, h//2), 15, 0.9)  # Rotate 15° and scale 0.9x\n",
    "img2 = cv2.warpAffine(img1, M, (w, h))\n",
    "\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect keypoints and descriptors using ORB\n",
    "orb_match = cv2.ORB_create(nfeatures=500)\n",
    "kp1, des1 = orb_match.detectAndCompute(gray1, None)\n",
    "kp2, des2 = orb_match.detectAndCompute(gray2, None)\n",
    "\n",
    "# Create BFMatcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.match(des1, des2)\n",
    "\n",
    "# Sort matches by distance (best matches first)\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "# Draw first 50 matches\n",
    "img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:50], None,\n",
    "                               flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'BFMatcher: Top 50 matches (out of {len(matches)} total)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✅ BFMatcher 匹配結果:')\n",
    "print('='*60)\n",
    "print(f'影像1 關鍵點: {len(kp1)}')\n",
    "print(f'影像2 關鍵點: {len(kp2)}')\n",
    "print(f'總匹配數: {len(matches)}')\n",
    "print(f'\\n前5個最佳匹配的距離:')\n",
    "for i, m in enumerate(matches[:5]):\n",
    "    print(f'  Match {i+1}: distance = {m.distance:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 FLANN Matcher (Fast Library for Approximate Nearest Neighbors)\n",
    "\n",
    "**FLANN** 是一個快速近似最近鄰搜索庫，比 BFMatcher 更快。\n",
    "\n",
    "#### 核心優勢\n",
    "\n",
    "```\n",
    "FLANN vs BFMatcher:\n",
    "\n",
    "BFMatcher:\n",
    "- 精確匹配\n",
    "- 簡單直接\n",
    "- 適合小數據集\n",
    "\n",
    "FLANN:\n",
    "- 近似匹配（但非常接近精確解）\n",
    "- 使用優化的索引結構 (KD-Tree, LSH)\n",
    "- 適合大數據集\n",
    "- 速度快 10-100 倍\n",
    "```\n",
    "\n",
    "#### FLANN 參數\n",
    "\n",
    "- **KD-Tree**: 用於浮點描述子 (SIFT, SURF)\n",
    "- **LSH**: 用於二進位描述子 (ORB, BRISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect features using SIFT (for FLANN with KD-Tree)\n",
    "kp1_sift, des1_sift = sift.detectAndCompute(gray1, None)\n",
    "kp2_sift, des2_sift = sift.detectAndCompute(gray2, None)\n",
    "\n",
    "# FLANN parameters for SIFT\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)  # Higher = more accurate but slower\n",
    "\n",
    "# Create FLANN matcher\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# Match descriptors (k=2 for ratio test)\n",
    "matches_flann = flann.knnMatch(des1_sift, des2_sift, k=2)\n",
    "\n",
    "# Apply Lowe's ratio test\n",
    "good_matches = []\n",
    "for m, n in matches_flann:\n",
    "    if m.distance < 0.7 * n.distance:  # Ratio threshold\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Draw matches\n",
    "img_flann = cv2.drawMatches(img1, kp1_sift, img2, kp2_sift, good_matches[:50], None,\n",
    "                             flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(cv2.cvtColor(img_flann, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'FLANN Matcher: Top 50 good matches (out of {len(good_matches)} total)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✅ FLANN 匹配結果:')\n",
    "print('='*60)\n",
    "print(f'影像1 關鍵點: {len(kp1_sift)}')\n",
    "print(f'影像2 關鍵點: {len(kp2_sift)}')\n",
    "print(f'原始匹配數: {len(matches_flann)}')\n",
    "print(f'通過 Ratio Test 的匹配數: {len(good_matches)}')\n",
    "print(f'匹配率: {len(good_matches)/len(matches_flann)*100:.1f}%')\n",
    "\n",
    "print(f'\\n💡 Lowe\\'s Ratio Test:')\n",
    "print(f'   - 比較最佳匹配和次佳匹配的距離')\n",
    "print(f'   - 如果比例 < 0.7，認為是好的匹配')\n",
    "print(f'   - 可以過濾掉模糊的匹配')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 FLANN with ORB (LSH Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLANN parameters for binary descriptors (ORB)\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params_lsh = dict(algorithm=FLANN_INDEX_LSH,\n",
    "                        table_number=6,      # 12\n",
    "                        key_size=12,         # 20\n",
    "                        multi_probe_level=1) # 2\n",
    "search_params_lsh = dict(checks=50)\n",
    "\n",
    "# Create FLANN matcher for binary descriptors\n",
    "flann_orb = cv2.FlannBasedMatcher(index_params_lsh, search_params_lsh)\n",
    "\n",
    "# Match ORB descriptors\n",
    "matches_orb_flann = flann_orb.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Apply ratio test\n",
    "good_matches_orb = []\n",
    "for match_pair in matches_orb_flann:\n",
    "    if len(match_pair) == 2:  # Ensure we have 2 matches\n",
    "        m, n = match_pair\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches_orb.append(m)\n",
    "\n",
    "# Draw matches\n",
    "img_orb_flann = cv2.drawMatches(img1, kp1, img2, kp2, good_matches_orb[:50], None,\n",
    "                                 flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(cv2.cvtColor(img_orb_flann, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'FLANN (LSH) + ORB: Top 50 matches (out of {len(good_matches_orb)} total)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✅ FLANN (LSH) + ORB 匹配結果:')\n",
    "print('='*60)\n",
    "print(f'通過 Ratio Test 的匹配數: {len(good_matches_orb)}')\n",
    "print(f'\\n💡 LSH (Locality Sensitive Hashing):')\n",
    "print(f'   - 專為二進位描述子設計')\n",
    "print(f'   - 使用哈希表加速搜索')\n",
    "print(f'   - 比 KD-Tree 更適合高維二進位資料')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Homography 變換與影像配準\n",
    "\n",
    "### 9.1 Homography 原理\n",
    "\n",
    "**Homography** 是一種將一個平面投影到另一個平面的變換。\n",
    "\n",
    "#### 數學定義\n",
    "\n",
    "Homography 矩陣 H (3x3) 描述兩個平面間的透視變換:\n",
    "\n",
    "```\n",
    "[x']   [h11  h12  h13]   [x]\n",
    "[y'] = [h21  h22  h23] × [y]\n",
    "[1 ]   [h31  h32  h33]   [1]\n",
    "```\n",
    "\n",
    "#### 應用場景\n",
    "\n",
    "```\n",
    "Homography 應用:\n",
    "\n",
    "1. 影像拼接 (Image Stitching)\n",
    "   └─> 全景圖製作\n",
    "\n",
    "2. 視角校正 (Perspective Correction)\n",
    "   └─> 文檔掃描、道路標線\n",
    "\n",
    "3. 物體識別 (Object Recognition)\n",
    "   └─> 平面物體檢測與追蹤\n",
    "\n",
    "4. 擴增實境 (AR)\n",
    "   └─> 虛擬物體疊加\n",
    "```\n",
    "\n",
    "#### RANSAC 演算法\n",
    "\n",
    "RANSAC (Random Sample Consensus) 用於從含有外點 (outliers) 的匹配中估計 Homography:\n",
    "\n",
    "```\n",
    "RANSAC 流程:\n",
    "\n",
    "1. 隨機選擇 4 對匹配點\n",
    "2. 計算 Homography 矩陣\n",
    "3. 計算所有點的誤差\n",
    "4. 統計內點 (inliers) 數量\n",
    "5. 重複多次，選擇內點最多的模型\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need at least 4 matches for Homography\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "if len(good_matches) >= MIN_MATCH_COUNT:\n",
    "    # Extract location of good matches\n",
    "    src_pts = np.float32([kp1_sift[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2_sift[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Find Homography matrix using RANSAC\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    \n",
    "    # Draw bounding box in img2\n",
    "    h, w = gray1.shape\n",
    "    pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "    dst = cv2.perspectiveTransform(pts, M)\n",
    "    \n",
    "    img2_box = img2.copy()\n",
    "    img2_box = cv2.polylines(img2_box, [np.int32(dst)], True, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "    \n",
    "    # Draw only inliers\n",
    "    draw_params = dict(matchColor=(0, 255, 0),\n",
    "                       singlePointColor=None,\n",
    "                       matchesMask=matchesMask,\n",
    "                       flags=2)\n",
    "    \n",
    "    img_homography = cv2.drawMatches(img1, kp1_sift, img2_box, kp2_sift, \n",
    "                                      good_matches, None, **draw_params)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(18, 9))\n",
    "    plt.imshow(cv2.cvtColor(img_homography, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Homography: {sum(matchesMask)} inliers out of {len(good_matches)} matches', \n",
    "              fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'\\n✅ Homography 計算結果:')\n",
    "    print('='*60)\n",
    "    print(f'總匹配數: {len(good_matches)}')\n",
    "    print(f'內點 (inliers): {sum(matchesMask)}')\n",
    "    print(f'外點 (outliers): {len(matchesMask) - sum(matchesMask)}')\n",
    "    print(f'內點比例: {sum(matchesMask)/len(matchesMask)*100:.1f}%')\n",
    "    \n",
    "    print(f'\\nHomography 矩陣:')\n",
    "    print(M)\n",
    "    \n",
    "else:\n",
    "    print(f'⚠️ 匹配點不足 - 需要至少 {MIN_MATCH_COUNT} 個匹配點')\n",
    "    print(f'   當前僅有 {len(good_matches)} 個匹配點')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 應用 Homography 進行影像對齊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(good_matches) >= MIN_MATCH_COUNT and M is not None:\n",
    "    # Warp img1 to align with img2\n",
    "    h, w = img2.shape[:2]\n",
    "    img1_aligned = cv2.warpPerspective(img1, M, (w, h))\n",
    "    \n",
    "    # Create difference image\n",
    "    diff = cv2.absdiff(img2, img1_aligned)\n",
    "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Display\n",
    "    display_multiple_images(\n",
    "        [img1, img2, img1_aligned, diff_gray],\n",
    "        ['Original Image 1', 'Image 2 (Rotated)', 'Image 1 Aligned', 'Difference'],\n",
    "        rows=2, cols=2, figsize=(14, 10)\n",
    "    )\n",
    "    \n",
    "    # Calculate alignment quality\n",
    "    mse = np.mean((img2.astype(float) - img1_aligned.astype(float))**2)\n",
    "    psnr = 20 * np.log10(255.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
    "    \n",
    "    print(f'\\n✅ 影像對齊品質:')\n",
    "    print('='*60)\n",
    "    print(f'MSE:  {mse:.2f}')\n",
    "    print(f'PSNR: {psnr:.2f} dB')\n",
    "    print(f'\\n💡 PSNR 越高表示對齊越好（通常 > 30dB 為良好對齊）')\n",
    "else:\n",
    "    print('⚠️ 無法計算 Homography，匹配點不足')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 特徵檢測器完整比較表\n",
    "\n",
    "### 10.1 技術特性比較\n",
    "\n",
    "| 特徵 | SIFT | SURF | ORB | BRISK | BRIEF |\n",
    "|------|------|------|-----|-------|-------|\n",
    "| **尺度不變** | ✅ | ✅ | ⭐ | ✅ | ❌ |\n",
    "| **旋轉不變** | ✅ | ✅ | ✅ | ✅ | ❌ |\n",
    "| **仿射不變** | ⭐ | ⭐ | ❌ | ❌ | ❌ |\n",
    "| **光照穩定** | ✅ | ✅ | ⭐ | ⭐ | ⭐ |\n",
    "| **速度** | ⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |\n",
    "| **魯棒性** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ |\n",
    "| **記憶體** | 128維/float | 64維/float | 256位元 | 512位元 | 256位元 |\n",
    "| **專利** | 已過期 | 有專利⚠️ | 開源✅ | 開源✅ | 開源✅ |\n",
    "\n",
    "### 10.2 應用場景推薦\n",
    "\n",
    "| 場景 | 推薦檢測器 | 理由 |\n",
    "|------|-----------|------|\n",
    "| **實時應用** | ORB, BRISK | 速度最快，適合移動設備 |\n",
    "| **高精度匹配** | SIFT | 最穩定，準確度最高 |\n",
    "| **影像拼接** | SIFT, SURF | 需要尺度和旋轉不變性 |\n",
    "| **物體追蹤** | ORB | 速度快，實時性能好 |\n",
    "| **AR 應用** | BRISK, ORB | 平衡速度與準確度 |\n",
    "| **嵌入式系統** | ORB | 記憶體佔用小，計算快 |\n",
    "| **商業應用** | ORB, BRISK | 無專利限制 |\n",
    "\n",
    "### 10.3 匹配器選擇指南\n",
    "\n",
    "| 描述子類型 | 推薦匹配器 | 距離度量 | 參數設置 |\n",
    "|-----------|----------|---------|----------|\n",
    "| SIFT, SURF | FLANN (KD-Tree) | L2 範數 | trees=5, checks=50 |\n",
    "| ORB, BRISK | BFMatcher | Hamming | crossCheck=True |\n",
    "| ORB, BRISK | FLANN (LSH) | Hamming | table_number=6, key_size=12 |\n",
    "\n",
    "### 10.4 性能對比總結\n",
    "\n",
    "```\n",
    "速度排名:   ORB > BRISK > SURF > SIFT\n",
    "準確度:     SIFT > SURF > BRISK > ORB\n",
    "魯棒性:     SIFT > SURF ≈ BRISK > ORB\n",
    "記憶體:     BRIEF ≈ ORB < SURF < BRISK < SIFT\n",
    "\n",
    "綜合推薦:\n",
    "- 研究/高精度: SIFT\n",
    "- 產品/實時: ORB\n",
    "- 平衡方案: BRISK\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 實戰練習\n",
    "\n",
    "### 練習 1: 實現簡單的物體檢測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 使用特徵匹配在場景中檢測目標物體\n",
    "\n",
    "def detect_object(template, scene, detector='ORB', min_matches=10):\n",
    "    \"\"\"\n",
    "    Detect template object in scene using feature matching\n",
    "    \n",
    "    Args:\n",
    "        template: Template image (object to find)\n",
    "        scene: Scene image (where to search)\n",
    "        detector: 'SIFT', 'ORB', or 'BRISK'\n",
    "        min_matches: Minimum number of matches required\n",
    "    \n",
    "    Returns:\n",
    "        detected_image: Scene with bounding box\n",
    "        num_matches: Number of good matches found\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY) if len(template.shape) == 3 else template\n",
    "    scene_gray = cv2.cvtColor(scene, cv2.COLOR_BGR2GRAY) if len(scene.shape) == 3 else scene\n",
    "    \n",
    "    # Create detector\n",
    "    if detector == 'SIFT':\n",
    "        det = sift\n",
    "        matcher = cv2.FlannBasedMatcher(\n",
    "            dict(algorithm=1, trees=5),\n",
    "            dict(checks=50)\n",
    "        )\n",
    "    elif detector == 'ORB':\n",
    "        det = cv2.ORB_create(nfeatures=1000)\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    else:  # BRISK\n",
    "        det = cv2.BRISK_create()\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    \n",
    "    # Detect and compute\n",
    "    kp1, des1 = det.detectAndCompute(template_gray, None)\n",
    "    kp2, des2 = det.detectAndCompute(scene_gray, None)\n",
    "    \n",
    "    if des1 is None or des2 is None:\n",
    "        return scene.copy(), 0\n",
    "    \n",
    "    # Match\n",
    "    matches = matcher.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for match_pair in matches:\n",
    "        if len(match_pair) == 2:\n",
    "            m, n = match_pair\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good.append(m)\n",
    "    \n",
    "    result = scene.copy()\n",
    "    \n",
    "    # Draw bounding box if enough matches\n",
    "    if len(good) >= min_matches:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        \n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        if M is not None:\n",
    "            h, w = template_gray.shape\n",
    "            pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "            dst = cv2.perspectiveTransform(pts, M)\n",
    "            \n",
    "            result = cv2.polylines(result, [np.int32(dst)], True, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "            \n",
    "            # Add text\n",
    "            cv2.putText(result, f'{detector}: {len(good)} matches', (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    return result, len(good)\n",
    "\n",
    "# Test object detection\n",
    "template = img1[50:250, 100:300]  # Extract template from img1\n",
    "scene = img2\n",
    "\n",
    "# Try different detectors\n",
    "results = []\n",
    "titles = []\n",
    "\n",
    "for det_name in ['SIFT', 'ORB', 'BRISK']:\n",
    "    detected, n_matches = detect_object(template, scene, detector=det_name)\n",
    "    results.append(detected)\n",
    "    titles.append(f'{det_name}\\n{n_matches} matches')\n",
    "\n",
    "# Add template\n",
    "results.insert(0, cv2.cvtColor(template, cv2.COLOR_BGR2RGB))\n",
    "titles.insert(0, 'Template')\n",
    "\n",
    "display_multiple_images(results, titles, rows=1, cols=4, figsize=(20, 5))\n",
    "\n",
    "print('✅ 物體檢測完成')\n",
    "print('💡 觀察不同檢測器在物體檢測任務上的表現差異')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 2: 比較不同檢測器的旋轉魯棒性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 測試不同旋轉角度下的匹配穩定性\n",
    "\n",
    "angles = [0, 30, 60, 90, 120, 150, 180]\n",
    "detectors_test = {'SIFT': sift, 'ORB': orb, 'BRISK': brisk}\n",
    "\n",
    "results_rotation = {name: [] for name in detectors_test.keys()}\n",
    "\n",
    "for angle in angles:\n",
    "    # Rotate image\n",
    "    h, w = gray.shape\n",
    "    M_rot = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray, M_rot, (w, h))\n",
    "    \n",
    "    for name, det in detectors_test.items():\n",
    "        # Detect and match\n",
    "        kp1, des1 = det.detectAndCompute(gray, None)\n",
    "        kp2, des2 = det.detectAndCompute(rotated, None)\n",
    "        \n",
    "        if des1 is not None and des2 is not None:\n",
    "            if name == 'SIFT':\n",
    "                bf_temp = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "            else:\n",
    "                bf_temp = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            \n",
    "            matches_temp = bf_temp.match(des1, des2)\n",
    "            results_rotation[name].append(len(matches_temp))\n",
    "        else:\n",
    "            results_rotation[name].append(0)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "for name, counts in results_rotation.items():\n",
    "    plt.plot(angles, counts, marker='o', label=name, linewidth=2)\n",
    "\n",
    "plt.xlabel('Rotation Angle (degrees)', fontsize=12)\n",
    "plt.ylabel('Number of Matches', fontsize=12)\n",
    "plt.title('Rotation Robustness Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n旋轉魯棒性測試結果:')\n",
    "print('='*60)\n",
    "for name, counts in results_rotation.items():\n",
    "    avg_matches = np.mean(counts)\n",
    "    std_matches = np.std(counts)\n",
    "    print(f'{name:10} | 平均匹配數: {avg_matches:6.1f} | 標準差: {std_matches:5.1f}')\n",
    "\n",
    "print('\\n💡 標準差越小表示旋轉魯棒性越好')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 總結\n",
    "\n",
    "### 重點回顧\n",
    "\n",
    "1. **特徵檢測器家族**\n",
    "   - SIFT: 最穩定，但速度慢\n",
    "   - SURF: SIFT 加速版，有專利限制\n",
    "   - ORB: 開源，速度最快，適合實時\n",
    "   - BRISK: 平衡速度與準確度\n",
    "   - BRIEF: 只是描述子，需搭配其他檢測器\n",
    "\n",
    "2. **特徵匹配方法**\n",
    "   - BFMatcher: 精確但慢，適合小數據集\n",
    "   - FLANN: 快速近似匹配，適合大數據集\n",
    "   - Ratio Test: Lowe's 方法過濾不良匹配\n",
    "\n",
    "3. **Homography 應用**\n",
    "   - 影像拼接\n",
    "   - 視角校正\n",
    "   - 物體檢測\n",
    "   - RANSAC 過濾外點\n",
    "\n",
    "4. **實際應用建議**\n",
    "   - 研究/高精度 → SIFT\n",
    "   - 商業/實時 → ORB\n",
    "   - 平衡方案 → BRISK\n",
    "\n",
    "### 決策樹\n",
    "\n",
    "```\n",
    "選擇特徵檢測器?\n",
    "├─ 需要實時處理?\n",
    "│   ├─ 是 → ORB (最快)\n",
    "│   └─ 否 → 繼續\n",
    "│\n",
    "├─ 需要最高準確度?\n",
    "│   ├─ 是 → SIFT (最穩定)\n",
    "│   └─ 否 → 繼續\n",
    "│\n",
    "├─ 商業應用（避免專利）?\n",
    "│   ├─ 是 → ORB 或 BRISK\n",
    "│   └─ 否 → SURF (如果可用)\n",
    "│\n",
    "└─ 需要平衡方案?\n",
    "    └─ BRISK (速度與準確度平衡)\n",
    "```\n",
    "\n",
    "### 下一步學習\n",
    "\n",
    "- [x] 特徵描述子 ✅ ← **你在這裡**\n",
    "- [ ] 光流追蹤 (Optical Flow)\n",
    "- [ ] 物體追蹤演算法\n",
    "- [ ] 深度學習特徵 (CNN Features)\n",
    "- [ ] 影像拼接專案\n",
    "\n",
    "### 參考資源\n",
    "\n",
    "- OpenCV Feature Detection: https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html\n",
    "- SIFT Paper: Lowe, D.G. (2004)\n",
    "- ORB Paper: Rublee et al. (2011)\n",
    "- 本專案 utils 模組: `utils/image_utils.py`, `utils/performance.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
