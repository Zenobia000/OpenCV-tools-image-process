{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.2 ç‰¹å¾µæè¿°å­èˆ‡ç‰¹å¾µåŒ¹é… (Feature Descriptors & Matching)\n",
    "\n",
    "**WBS 4.1.2**: ç‰¹å¾µæè¿°å­ã€ç‰¹å¾µåŒ¹é…èˆ‡å½±åƒé…æº–\n",
    "\n",
    "## å­¸ç¿’ç›®æ¨™\n",
    "- ç†è§£ç‰¹å¾µæè¿°å­çš„åŸç†èˆ‡æ‡‰ç”¨\n",
    "- æŒæ¡ SIFT, SURF, ORB, BRIEF, BRISK ç‰¹å¾µæª¢æ¸¬å™¨\n",
    "- å­¸ç¿’ç‰¹å¾µåŒ¹é…ç®—æ³• (BFMatcher, FLANN)\n",
    "- æ‡‰ç”¨ Homography é€²è¡Œå½±åƒé…æº–\n",
    "- æ¯”è¼ƒä¸åŒç‰¹å¾µæª¢æ¸¬å™¨çš„æ€§èƒ½\n",
    "\n",
    "**é›£åº¦ç­‰ç´š**: â­â­â­â­ (é€²éš)  \n",
    "**é ä¼°æ™‚é–“**: 120 åˆ†é˜  \n",
    "**WBSç·¨è™Ÿ**: 4.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç’°å¢ƒè¨­ç½®èˆ‡å°å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.image_utils import load_image, resize_image\n",
    "from utils.visualization import display_image, display_multiple_images\n",
    "from utils.performance import time_function, benchmark_function\n",
    "\n",
    "print(f'âœ… OpenCV version: {cv2.__version__}')\n",
    "print(f'âœ… NumPy version: {np.__version__}')\n",
    "\n",
    "# Check for xfeatures2d (for SIFT/SURF)\n",
    "try:\n",
    "    cv2.xfeatures2d.SIFT_create()\n",
    "    print('âœ… SIFT available (cv2.xfeatures2d)')\n",
    "except AttributeError:\n",
    "    try:\n",
    "        cv2.SIFT_create()\n",
    "        print('âœ… SIFT available (cv2.SIFT_create)')\n",
    "    except:\n",
    "        print('âš ï¸ SIFT not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç‰¹å¾µæè¿°å­æ¦‚è¿°\n",
    "\n",
    "### ä»€éº¼æ˜¯ç‰¹å¾µæè¿°å­ï¼Ÿ\n",
    "\n",
    "**ç‰¹å¾µæè¿°å­ (Feature Descriptor)** æ˜¯ç”¨å‘é‡ä¾†æè¿°å½±åƒä¸­é—œéµé»å‘¨åœå€åŸŸçš„ç‰¹å¾µï¼Œä½¿å¾—é€™äº›ç‰¹å¾µé»å¯ä»¥è¢«å”¯ä¸€è­˜åˆ¥å’ŒåŒ¹é…ã€‚\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "```\n",
    "ç‰¹å¾µæª¢æ¸¬èˆ‡æè¿°çš„æµç¨‹:\n",
    "\n",
    "1. ç‰¹å¾µæª¢æ¸¬ (Feature Detection)\n",
    "   â””â”€> æ‰¾åˆ°å½±åƒä¸­çš„é—œéµé» (Keypoints)\n",
    "       - è§’é»ã€æ–‘é»ã€é‚Šç·£ç­‰\n",
    "\n",
    "2. ç‰¹å¾µæè¿° (Feature Description)\n",
    "   â””â”€> ç‚ºæ¯å€‹é—œéµé»å»ºç«‹æè¿°å‘é‡\n",
    "       - SIFT: 128ç¶­å‘é‡\n",
    "       - ORB: 256ä½å…ƒäºŒé€²ä½å­—ä¸²\n",
    "\n",
    "3. ç‰¹å¾µåŒ¹é… (Feature Matching)\n",
    "   â””â”€> åœ¨ä¸åŒå½±åƒé–“å°‹æ‰¾ç›¸åŒçš„ç‰¹å¾µé»\n",
    "       - æ¯”è¼ƒæè¿°å­çš„ç›¸ä¼¼åº¦\n",
    "```\n",
    "\n",
    "### ç†æƒ³ç‰¹å¾µæè¿°å­çš„ç‰¹æ€§\n",
    "\n",
    "| ç‰¹æ€§ | èªªæ˜ | é‡è¦æ€§ |\n",
    "|------|------|--------|\n",
    "| **å°ºåº¦ä¸è®Šæ€§** | Scale Invariance | å½±åƒç¸®æ”¾æ™‚ç‰¹å¾µä¸è®Š |\n",
    "| **æ—‹è½‰ä¸è®Šæ€§** | Rotation Invariance | å½±åƒæ—‹è½‰æ™‚ç‰¹å¾µä¸è®Š |\n",
    "| **å…‰ç…§ä¸è®Šæ€§** | Illumination Invariance | äº®åº¦è®ŠåŒ–æ™‚ç‰¹å¾µç©©å®š |\n",
    "| **ä»¿å°„ä¸è®Šæ€§** | Affine Invariance | è¦–è§’è®ŠåŒ–æ™‚ç‰¹å¾µç©©å®š |\n",
    "| **å€åˆ†æ€§** | Distinctiveness | ä¸åŒç‰¹å¾µæœ‰æ˜é¡¯å·®ç•° |\n",
    "| **è¨ˆç®—æ•ˆç‡** | Computational Efficiency | é‹ç®—é€Ÿåº¦å¿« |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SIFT (Scale-Invariant Feature Transform)\n",
    "\n",
    "### 2.1 SIFT åŸç†\n",
    "\n",
    "**SIFT** æ˜¯æœ€ç¶“å…¸çš„ç‰¹å¾µæª¢æ¸¬å™¨ï¼Œç”± David Lowe æ–¼ 1999 å¹´æå‡ºã€‚\n",
    "\n",
    "#### æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "```\n",
    "SIFT æ¼”ç®—æ³•æ­¥é©Ÿ:\n",
    "\n",
    "1. å°ºåº¦ç©ºé–“æ¥µå€¼æª¢æ¸¬\n",
    "   â””â”€> ä½¿ç”¨ DoG (Difference of Gaussian) æ‰¾ç‰¹å¾µé»\n",
    "\n",
    "2. é—œéµé»å®šä½\n",
    "   â””â”€> ç²¾ç¢ºå®šä½é—œéµé»ä½ç½®ï¼Œå»é™¤ä¸ç©©å®šé»\n",
    "\n",
    "3. æ–¹å‘åˆ†é…\n",
    "   â””â”€> ç‚ºæ¯å€‹é—œéµé»åˆ†é…ä¸»æ–¹å‘ï¼ˆæ—‹è½‰ä¸è®Šæ€§ï¼‰\n",
    "\n",
    "4. é—œéµé»æè¿°\n",
    "   â””â”€> åœ¨é—œéµé»å‘¨åœ 16x16 å€åŸŸè¨ˆç®—æ¢¯åº¦ç›´æ–¹åœ–\n",
    "       ç”Ÿæˆ 128 ç¶­ç‰¹å¾µå‘é‡ (4x4x8)\n",
    "```\n",
    "\n",
    "#### SIFT ç‰¹é»\n",
    "\n",
    "- âœ… **å°ºåº¦ä¸è®Š**: å¯æª¢æ¸¬ä¸åŒå°ºå¯¸çš„ç‰¹å¾µ\n",
    "- âœ… **æ—‹è½‰ä¸è®Š**: å½±åƒæ—‹è½‰ä¸å½±éŸ¿æª¢æ¸¬\n",
    "- âœ… **ç©©å®šæ€§é«˜**: å°å…‰ç…§ã€å™ªè²æœ‰å¼·é­¯æ£’æ€§\n",
    "- âŒ **è¨ˆç®—ç·©æ…¢**: é‹ç®—é‡å¤§ï¼Œä¸é©åˆå¯¦æ™‚æ‡‰ç”¨\n",
    "- âš ï¸ **å°ˆåˆ©é™åˆ¶**: å•†æ¥­ä½¿ç”¨éœ€æˆæ¬Šï¼ˆ2020å¹´å·²éæœŸï¼‰\n",
    "\n",
    "#### SIFT æ•¸å­¸åŸç†\n",
    "\n",
    "**DoG (Difference of Gaussian)**:\n",
    "```\n",
    "DoG(x,y,Ïƒ) = G(x,y,kÏƒ) - G(x,y,Ïƒ)\n",
    "```\n",
    "\n",
    "å…¶ä¸­ G æ˜¯é«˜æ–¯æ¿¾æ³¢å™¨ï¼Œk æ˜¯å°ºåº¦å› å­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image\n",
    "img_path = '../assets/images/basic/opencv.jpg'\n",
    "if os.path.exists(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (600, 400))\n",
    "else:\n",
    "    # Create synthetic test image\n",
    "    img = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
    "    cv2.rectangle(img, (100, 100), (500, 300), (0, 0, 0), -1)\n",
    "    cv2.circle(img, (300, 200), 80, (255, 255, 255), -1)\n",
    "    \n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create SIFT detector\n",
    "try:\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "except AttributeError:\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "# Draw keypoints\n",
    "img_sift = cv2.drawKeypoints(img, keypoints, None, \n",
    "                              flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display\n",
    "display_multiple_images(\n",
    "    [img, img_sift],\n",
    "    ['Original Image', f'SIFT Keypoints ({len(keypoints)} detected)'],\n",
    "    rows=1, cols=2, figsize=(15, 5)\n",
    ")\n",
    "\n",
    "print(f'\\nâœ… SIFT æª¢æ¸¬çµæœ:')\n",
    "print('='*60)\n",
    "print(f'é—œéµé»æ•¸é‡: {len(keypoints)}')\n",
    "print(f'æè¿°å­ç¶­åº¦: {descriptors.shape if descriptors is not None else \"None\"}')\n",
    "print(f'æè¿°å­é¡å‹: {descriptors.dtype if descriptors is not None else \"None\"}')\n",
    "\n",
    "if len(keypoints) > 0:\n",
    "    kp = keypoints[0]\n",
    "    print(f'\\nç¬¬ä¸€å€‹é—œéµé»è³‡è¨Š:')\n",
    "    print(f'  ä½ç½®: ({kp.pt[0]:.1f}, {kp.pt[1]:.1f})')\n",
    "    print(f'  å°ºåº¦: {kp.size:.2f}')\n",
    "    print(f'  è§’åº¦: {kp.angle:.2f}Â°')\n",
    "    print(f'  éŸ¿æ‡‰: {kp.response:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SIFT å°ºåº¦ä¸è®Šæ€§é©—è­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SIFT scale invariance\n",
    "scales = [0.5, 1.0, 1.5, 2.0]\n",
    "results = []\n",
    "titles = []\n",
    "\n",
    "for scale in scales:\n",
    "    # Resize image\n",
    "    h, w = gray.shape\n",
    "    scaled = cv2.resize(gray, (int(w*scale), int(h*scale)))\n",
    "    \n",
    "    # Detect keypoints\n",
    "    kp, desc = sift.detectAndCompute(scaled, None)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_kp = cv2.cvtColor(scaled, cv2.COLOR_GRAY2BGR)\n",
    "    img_kp = cv2.drawKeypoints(img_kp, kp, None, color=(0, 255, 0))\n",
    "    \n",
    "    results.append(img_kp)\n",
    "    titles.append(f'Scale {scale}x\\n{len(kp)} keypoints')\n",
    "\n",
    "display_multiple_images(results, titles, rows=1, cols=4, figsize=(20, 5))\n",
    "\n",
    "print('\\nğŸ’¡ è§€å¯Ÿ: SIFT åœ¨ä¸åŒå°ºåº¦ä¸‹éƒ½èƒ½æª¢æ¸¬åˆ°ç©©å®šçš„ç‰¹å¾µé»')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SURF (Speeded-Up Robust Features)\n",
    "\n",
    "### 3.1 SURF åŸç†\n",
    "\n",
    "**SURF** æ˜¯ SIFT çš„åŠ é€Ÿç‰ˆæœ¬ï¼Œç”± Bay et al. æ–¼ 2006 å¹´æå‡ºã€‚\n",
    "\n",
    "#### æ ¸å¿ƒæ”¹é€²\n",
    "\n",
    "```\n",
    "SURF vs SIFT:\n",
    "\n",
    "1. ç©åˆ†å½±åƒ (Integral Image)\n",
    "   â””â”€> å¿«é€Ÿè¨ˆç®—çŸ©å½¢å€åŸŸçš„å’Œ\n",
    "\n",
    "2. Hessian çŸ©é™£è¿‘ä¼¼\n",
    "   â””â”€> ä½¿ç”¨ç›’å­æ¿¾æ³¢å™¨ä»£æ›¿é«˜æ–¯æ¿¾æ³¢å™¨\n",
    "\n",
    "3. 64ç¶­æè¿°å­\n",
    "   â””â”€> æ¯” SIFT çš„ 128 ç¶­æ›´å¿«\n",
    "\n",
    "é€Ÿåº¦: SURF â‰ˆ 3-7x å¿«æ–¼ SIFT\n",
    "```\n",
    "\n",
    "#### SURF ç‰¹é»\n",
    "\n",
    "- âœ… **é€Ÿåº¦å¿«**: æ¯” SIFT å¿« 3-7 å€\n",
    "- âœ… **é­¯æ£’æ€§å¥½**: å°æ¨¡ç³Šå’Œæ—‹è½‰æœ‰è‰¯å¥½çš„æŠ—æ€§\n",
    "- âŒ **å°ˆåˆ©ä¿è­·**: éœ€è¦æˆæ¬Šæ‰èƒ½å•†æ¥­ä½¿ç”¨\n",
    "- âš ï¸ **OpenCV é™åˆ¶**: æŸäº›ç‰ˆæœ¬éœ€è¦ contrib æ¨¡çµ„\n",
    "\n",
    "### âš ï¸ æ³¨æ„: SURF æ¼”ç®—æ³•å·²ç”³è«‹å°ˆåˆ©\n",
    "\n",
    "åœ¨æŸäº› OpenCV é…ç½®ä¸­ï¼ŒSURF å¯èƒ½ä¸å¯ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use SURF (may not be available)\n",
    "try:\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    \n",
    "    # Detect keypoints\n",
    "    keypoints_surf, descriptors_surf = surf.detectAndCompute(gray, None)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_surf = cv2.drawKeypoints(img, keypoints_surf, None, \n",
    "                                  flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    display_multiple_images(\n",
    "        [img, img_surf],\n",
    "        ['Original', f'SURF Keypoints ({len(keypoints_surf)} detected)'],\n",
    "        rows=1, cols=2, figsize=(15, 5)\n",
    "    )\n",
    "    \n",
    "    print(f'âœ… SURF æª¢æ¸¬çµæœ:')\n",
    "    print(f'é—œéµé»æ•¸é‡: {len(keypoints_surf)}')\n",
    "    print(f'æè¿°å­ç¶­åº¦: {descriptors_surf.shape}')\n",
    "    \n",
    "except (AttributeError, cv2.error) as e:\n",
    "    print('âš ï¸ SURF åœ¨æ­¤é…ç½®ä¸­ä¸å¯ç”¨')\n",
    "    print('   åŸå› : SURF æ¼”ç®—æ³•å·²ç”³è«‹å°ˆåˆ©ï¼ŒæŸäº› OpenCV ç‰ˆæœ¬å°‡å…¶æ’é™¤')\n",
    "    print('   æ›¿ä»£æ–¹æ¡ˆ: ä½¿ç”¨ ORB æˆ– BRISKï¼ˆé–‹æºä¸”é€Ÿåº¦å¿«ï¼‰')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ORB (Oriented FAST and Rotated BRIEF)\n",
    "\n",
    "### 4.1 ORB åŸç†\n",
    "\n",
    "**ORB** æ˜¯ç”± OpenCV å¯¦é©—å®¤é–‹ç™¼çš„é–‹æºæ›¿ä»£æ–¹æ¡ˆï¼Œçµåˆäº† FAST é—œéµé»æª¢æ¸¬å™¨å’Œ BRIEF æè¿°å­ã€‚\n",
    "\n",
    "#### æ ¸å¿ƒç‰¹æ€§\n",
    "\n",
    "```\n",
    "ORB = FAST + BRIEF + æ”¹é€²\n",
    "\n",
    "1. FAST è§’é»æª¢æ¸¬\n",
    "   â””â”€> å¿«é€Ÿæª¢æ¸¬é—œéµé»\n",
    "\n",
    "2. Harris è§’é»åº¦é‡\n",
    "   â””â”€> é¸æ“‡æœ€å¥½çš„é—œéµé»\n",
    "\n",
    "3. æ–¹å‘åˆ†é…\n",
    "   â””â”€> è¨ˆç®— intensity centroidï¼ˆæ—‹è½‰ä¸è®Šï¼‰\n",
    "\n",
    "4. rBRIEF æè¿°å­\n",
    "   â””â”€> æ—‹è½‰æ„ŸçŸ¥çš„ BRIEFï¼ˆ256 ä½å…ƒäºŒé€²ä½ï¼‰\n",
    "```\n",
    "\n",
    "#### ORB å„ªå‹¢\n",
    "\n",
    "- âœ… **å®Œå…¨é–‹æº**: ç„¡å°ˆåˆ©é™åˆ¶\n",
    "- âœ… **é€Ÿåº¦æ¥µå¿«**: æ¯” SIFT å¿« 100 å€ä»¥ä¸Š\n",
    "- âœ… **æ—‹è½‰ä¸è®Š**: å°æ—‹è½‰æœ‰å¾ˆå¥½çš„é­¯æ£’æ€§\n",
    "- âœ… **äºŒé€²ä½æè¿°å­**: åŒ¹é…é€Ÿåº¦å¿«ï¼ˆæ¼¢æ˜è·é›¢ï¼‰\n",
    "- âš ï¸ **å°ºåº¦ä¸è®Šæ€§å¼±**: ç›¸æ¯” SIFT è¼ƒå¼±\n",
    "\n",
    "#### æ€§èƒ½æ¯”è¼ƒ\n",
    "\n",
    "```\n",
    "é€Ÿåº¦æ’å: ORB > SURF > SIFT\n",
    "é­¯æ£’æ€§:   SURF â‰¥ SIFT > ORB\n",
    "é©ç”¨å ´æ™¯: ORB æœ€é©åˆå¯¦æ™‚æ‡‰ç”¨\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ORB detector\n",
    "orb = cv2.ORB_create(nfeatures=1000)  # Max 1000 keypoints\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints_orb, descriptors_orb = orb.detectAndCompute(gray, None)\n",
    "\n",
    "# Draw keypoints\n",
    "img_orb = cv2.drawKeypoints(img, keypoints_orb, None, color=(0, 255, 0))\n",
    "\n",
    "# Display\n",
    "display_multiple_images(\n",
    "    [img, img_orb],\n",
    "    ['Original Image', f'ORB Keypoints ({len(keypoints_orb)} detected)'],\n",
    "    rows=1, cols=2, figsize=(15, 5)\n",
    ")\n",
    "\n",
    "print(f'\\nâœ… ORB æª¢æ¸¬çµæœ:')\n",
    "print('='*60)\n",
    "print(f'é—œéµé»æ•¸é‡: {len(keypoints_orb)}')\n",
    "print(f'æè¿°å­ç¶­åº¦: {descriptors_orb.shape}')\n",
    "print(f'æè¿°å­é¡å‹: {descriptors_orb.dtype} (äºŒé€²ä½)')\n",
    "print(f'æ¯å€‹æè¿°å­: 256 ä½å…ƒ (32 bytes)')\n",
    "\n",
    "if len(keypoints_orb) > 0:\n",
    "    print(f'\\nç¬¬ä¸€å€‹æè¿°å­ (å‰16å€‹ä½å…ƒçµ„):')\n",
    "    print(descriptors_orb[0][:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ORB æ—‹è½‰ä¸è®Šæ€§é©—è­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ORB rotation invariance\n",
    "angles = [0, 45, 90, 135]\n",
    "results = []\n",
    "titles = []\n",
    "\n",
    "for angle in angles:\n",
    "    # Rotate image\n",
    "    h, w = gray.shape\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray, M, (w, h))\n",
    "    \n",
    "    # Detect keypoints\n",
    "    kp, desc = orb.detectAndCompute(rotated, None)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_kp = cv2.cvtColor(rotated, cv2.COLOR_GRAY2BGR)\n",
    "    img_kp = cv2.drawKeypoints(img_kp, kp, None, color=(0, 255, 0))\n",
    "    \n",
    "    results.append(img_kp)\n",
    "    titles.append(f'Rotation {angle}Â°\\n{len(kp)} keypoints')\n",
    "\n",
    "display_multiple_images(results, titles, rows=1, cols=4, figsize=(20, 5))\n",
    "\n",
    "print('\\nğŸ’¡ è§€å¯Ÿ: ORB åœ¨ä¸åŒæ—‹è½‰è§’åº¦ä¸‹éƒ½èƒ½æª¢æ¸¬åˆ°ç©©å®šçš„ç‰¹å¾µé»')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BRIEF (Binary Robust Independent Elementary Features)\n",
    "\n",
    "### 5.1 BRIEF åŸç†\n",
    "\n",
    "**BRIEF** æ˜¯ä¸€ç¨®äºŒé€²ä½æè¿°å­ï¼Œä¸æä¾›é—œéµé»æª¢æ¸¬ï¼Œåªæä¾›ç‰¹å¾µæè¿°ã€‚\n",
    "\n",
    "#### æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "```\n",
    "BRIEF æè¿°å­ç”Ÿæˆ:\n",
    "\n",
    "1. åœ¨é—œéµé»å‘¨åœé¸æ“‡åƒç´ å°\n",
    "   â””â”€> é€šå¸¸é¸æ“‡ 256 å°åƒç´ \n",
    "\n",
    "2. æ¯”è¼ƒæ¯å°åƒç´ çš„äº®åº¦\n",
    "   â””â”€> If I(p1) < I(p2): bit = 1\n",
    "   â””â”€> Else: bit = 0\n",
    "\n",
    "3. ç”Ÿæˆ 256 ä½å…ƒäºŒé€²ä½å­—ä¸²\n",
    "   â””â”€> éå¸¸ç·Šæ¹Šçš„æè¿°å­\n",
    "```\n",
    "\n",
    "#### BRIEF ç‰¹é»\n",
    "\n",
    "- âœ… **æ¥µå¿«**: åªéœ€ç°¡å–®çš„åƒç´ æ¯”è¼ƒ\n",
    "- âœ… **è¨˜æ†¶é«”å°**: 256 ä½å…ƒ = 32 bytes\n",
    "- âœ… **åŒ¹é…å¿«**: ä½¿ç”¨æ¼¢æ˜è·é›¢ï¼ˆXOR æ“ä½œï¼‰\n",
    "- âŒ **ç„¡æ—‹è½‰ä¸è®Šæ€§**: å½±åƒæ—‹è½‰æœƒå¤±æ•ˆ\n",
    "- âŒ **ç„¡å°ºåº¦ä¸è®Šæ€§**: éœ€è¦å…¶ä»–æª¢æ¸¬å™¨æä¾›é—œéµé»\n",
    "\n",
    "### âš ï¸ é‡è¦æç¤º\n",
    "\n",
    "BRIEF åªæ˜¯æè¿°å­ï¼Œéœ€è¦æ­é…å…¶ä»–ç‰¹å¾µæª¢æ¸¬å™¨ï¼ˆå¦‚ FASTï¼‰ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRIEF requires a separate keypoint detector\n",
    "try:\n",
    "    # Use FAST for keypoint detection\n",
    "    fast = cv2.FastFeatureDetector_create()\n",
    "    keypoints_fast = fast.detect(gray, None)\n",
    "    \n",
    "    # Use BRIEF for description\n",
    "    brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "    keypoints_brief, descriptors_brief = brief.compute(gray, keypoints_fast)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_brief = cv2.drawKeypoints(img, keypoints_brief, None, color=(255, 0, 0))\n",
    "    \n",
    "    display_multiple_images(\n",
    "        [img, img_brief],\n",
    "        ['Original', f'FAST + BRIEF ({len(keypoints_brief)} keypoints)'],\n",
    "        rows=1, cols=2, figsize=(15, 5)\n",
    "    )\n",
    "    \n",
    "    print(f'âœ… BRIEF æª¢æ¸¬çµæœ:')\n",
    "    print(f'é—œéµé»æ•¸é‡ (FAST): {len(keypoints_fast)}')\n",
    "    print(f'æè¿°å­æ•¸é‡: {len(keypoints_brief)}')\n",
    "    print(f'æè¿°å­ç¶­åº¦: {descriptors_brief.shape}')\n",
    "    print(f'æè¿°å­é¡å‹: {descriptors_brief.dtype}')\n",
    "    \n",
    "except AttributeError:\n",
    "    print('âš ï¸ BRIEF åœ¨æ­¤é…ç½®ä¸­ä¸å¯ç”¨')\n",
    "    print('   è«‹ä½¿ç”¨ ORBï¼ˆåŒ…å«æ”¹é€²çš„ rBRIEFï¼‰')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. BRISK (Binary Robust Invariant Scalable Keypoints)\n",
    "\n",
    "### 6.1 BRISK åŸç†\n",
    "\n",
    "**BRISK** æ˜¯å¦ä¸€å€‹é–‹æºçš„äºŒé€²ä½ç‰¹å¾µæª¢æ¸¬å™¨ï¼Œçµåˆäº† FAST å’Œ BRIEF çš„å„ªé»ã€‚\n",
    "\n",
    "#### æ ¸å¿ƒç‰¹æ€§\n",
    "\n",
    "```\n",
    "BRISK æ”¹é€²:\n",
    "\n",
    "1. å°ºåº¦ç©ºé–“é—œéµé»æª¢æ¸¬\n",
    "   â””â”€> åœ¨ä¸åŒå°ºåº¦ä¸Šä½¿ç”¨ FAST\n",
    "\n",
    "2. æ–¹å‘ä¼°è¨ˆ\n",
    "   â””â”€> ä½¿ç”¨é•·è·é›¢åƒç´ å°ä¼°è¨ˆæ–¹å‘\n",
    "\n",
    "3. æ¡æ¨£æ¨¡å¼\n",
    "   â””â”€> ä½¿ç”¨åŒå¿ƒåœ“æ¡æ¨£æ¨¡å¼\n",
    "\n",
    "4. 512 ä½å…ƒæè¿°å­\n",
    "   â””â”€> æ¯” ORB çš„ 256 ä½å…ƒæ›´å…·å€åˆ†æ€§\n",
    "```\n",
    "\n",
    "#### BRISK å„ªå‹¢\n",
    "\n",
    "- âœ… **å°ºåº¦ä¸è®Š**: æ”¯æ´å¤šå°ºåº¦æª¢æ¸¬\n",
    "- âœ… **æ—‹è½‰ä¸è®Š**: æœ‰æ–¹å‘ä¼°è¨ˆ\n",
    "- âœ… **é€Ÿåº¦å¿«**: æ¥è¿‘ ORB çš„é€Ÿåº¦\n",
    "- âœ… **é–‹æº**: ç„¡å°ˆåˆ©é™åˆ¶\n",
    "- â­ **å¹³è¡¡æ€§å¥½**: é€Ÿåº¦èˆ‡æº–ç¢ºåº¦çš„è‰¯å¥½å¹³è¡¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BRISK detector\n",
    "brisk = cv2.BRISK_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints_brisk, descriptors_brisk = brisk.detectAndCompute(gray, None)\n",
    "\n",
    "# Draw keypoints\n",
    "img_brisk = cv2.drawKeypoints(img, keypoints_brisk, None, \n",
    "                               flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display\n",
    "display_multiple_images(\n",
    "    [img, img_brisk],\n",
    "    ['Original Image', f'BRISK Keypoints ({len(keypoints_brisk)} detected)'],\n",
    "    rows=1, cols=2, figsize=(15, 5)\n",
    ")\n",
    "\n",
    "print(f'\\nâœ… BRISK æª¢æ¸¬çµæœ:')\n",
    "print('='*60)\n",
    "print(f'é—œéµé»æ•¸é‡: {len(keypoints_brisk)}')\n",
    "print(f'æè¿°å­ç¶­åº¦: {descriptors_brisk.shape}')\n",
    "print(f'æè¿°å­é¡å‹: {descriptors_brisk.dtype} (äºŒé€²ä½)')\n",
    "print(f'æ¯å€‹æè¿°å­: 512 ä½å…ƒ (64 bytes)')\n",
    "\n",
    "print(f'\\nğŸ’¡ BRISK vs ORB:')\n",
    "print(f'   - BRISK æè¿°å­æ›´é•· (512 vs 256 ä½å…ƒ)')\n",
    "print(f'   - BRISK é€šå¸¸æª¢æ¸¬æ›´å¤šé—œéµé»')\n",
    "print(f'   - BRISK æœ‰æ›´å¥½çš„å°ºåº¦ä¸è®Šæ€§')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ç‰¹å¾µæª¢æ¸¬å™¨æ¯”è¼ƒ\n",
    "\n",
    "### 7.1 åŒæ™‚æ¯”è¼ƒæ‰€æœ‰æª¢æ¸¬å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all detectors\n",
    "detectors = {\n",
    "    'SIFT': sift,\n",
    "    'ORB': orb,\n",
    "    'BRISK': brisk\n",
    "}\n",
    "\n",
    "results = []\n",
    "titles = []\n",
    "stats = []\n",
    "\n",
    "for name, detector in detectors.items():\n",
    "    # Detect keypoints\n",
    "    kp, desc = detector.detectAndCompute(gray, None)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    img_kp = cv2.drawKeypoints(img, kp, None, color=(0, 255, 0))\n",
    "    \n",
    "    results.append(img_kp)\n",
    "    titles.append(f'{name}\\n{len(kp)} keypoints')\n",
    "    \n",
    "    stats.append({\n",
    "        'name': name,\n",
    "        'keypoints': len(kp),\n",
    "        'descriptor_size': desc.shape[1] if desc is not None else 0,\n",
    "        'descriptor_type': desc.dtype if desc is not None else 'None'\n",
    "    })\n",
    "\n",
    "# Display comparison\n",
    "display_multiple_images(results, titles, rows=1, cols=3, figsize=(18, 6))\n",
    "\n",
    "# Print statistics\n",
    "print('\\nç‰¹å¾µæª¢æ¸¬å™¨çµ±è¨ˆæ¯”è¼ƒ:')\n",
    "print('='*80)\n",
    "print(f'{'æª¢æ¸¬å™¨':10} | {'é—œéµé»æ•¸':>10} | {'æè¿°å­ç¶­åº¦':>12} | {'é¡å‹':>10}')\n",
    "print('-'*80)\n",
    "for s in stats:\n",
    "    print(f\"{s['name']:10} | {s['keypoints']:>10} | {s['descriptor_size']:>12} | {str(s['descriptor_type']):>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 æ€§èƒ½åŸºæº–æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmark\n",
    "test_img = cv2.resize(gray, (640, 480))\n",
    "\n",
    "print('\\næ•ˆèƒ½æ¸¬è©¦ (640x480 å½±åƒ):')  \n",
    "print('='*80)\n",
    "print(f'{'æª¢æ¸¬å™¨':10} | {'å¹³å‡æ™‚é–“ (ms)':>15} | {'FPS':>10} | {'é—œéµé»æ•¸':>10}')\n",
    "print('-'*80)\n",
    "\n",
    "for name, detector in detectors.items():\n",
    "    # Benchmark\n",
    "    def detect():\n",
    "        return detector.detectAndCompute(test_img, None)\n",
    "    \n",
    "    stats = benchmark_function(detect, iterations=10)\n",
    "    kp, _ = detect()\n",
    "    \n",
    "    avg_time = stats['average'] * 1000\n",
    "    fps = 1.0 / stats['average'] if stats['average'] > 0 else 0\n",
    "    \n",
    "    print(f'{name:10} | {avg_time:13.2f} ms | {fps:8.1f} | {len(kp):>10}')\n",
    "\n",
    "print('\\nğŸ’¡ è§€å¯Ÿ:')\n",
    "print('   - ORB æœ€å¿«ï¼Œé©åˆå¯¦æ™‚æ‡‰ç”¨')\n",
    "print('   - BRISK é€Ÿåº¦èˆ‡å“è³ªçš„è‰¯å¥½å¹³è¡¡')\n",
    "print('   - SIFT æœ€ç©©å®šä½†é€Ÿåº¦è¼ƒæ…¢')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç‰¹å¾µåŒ¹é… (Feature Matching)\n",
    "\n",
    "### 8.1 BFMatcher (Brute-Force Matcher)\n",
    "\n",
    "**BFMatcher** æ˜¯æœ€ç°¡å–®çš„ç‰¹å¾µåŒ¹é…å™¨ï¼Œå°æ¯å€‹æè¿°å­é€²è¡Œæš´åŠ›æœç´¢ã€‚\n",
    "\n",
    "#### å·¥ä½œåŸç†\n",
    "\n",
    "```\n",
    "BFMatcher åŒ¹é…æµç¨‹:\n",
    "\n",
    "1. å–ç¬¬ä¸€å¼µå½±åƒçš„ç¬¬ä¸€å€‹æè¿°å­\n",
    "2. è¨ˆç®—èˆ‡ç¬¬äºŒå¼µå½±åƒæ‰€æœ‰æè¿°å­çš„è·é›¢\n",
    "3. æ‰¾åˆ°è·é›¢æœ€å°çš„ä½œç‚ºåŒ¹é…\n",
    "4. é‡è¤‡å°æ‰€æœ‰æè¿°å­é€²è¡ŒåŒ¹é…\n",
    "\n",
    "è·é›¢åº¦é‡:\n",
    "- L2/L1 è·é›¢: ç”¨æ–¼ SIFT/SURF (æµ®é»æè¿°å­)\n",
    "- Hamming è·é›¢: ç”¨æ–¼ ORB/BRISK (äºŒé€²ä½æè¿°å­)\n",
    "```\n",
    "\n",
    "#### è·é›¢è¨ˆç®—\n",
    "\n",
    "**Hamming è·é›¢**: å…©å€‹äºŒé€²ä½å­—ä¸²ä¸­ä¸åŒä½å…ƒçš„æ•¸é‡\n",
    "```\n",
    "ä¾‹: \n",
    "A = 11010101\n",
    "B = 10110001\n",
    "Hamming(A,B) = 3 (æœ‰3å€‹ä½å…ƒä¸åŒ)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two images for matching\n",
    "img1_path = '../assets/images/basic/opencv.jpg'\n",
    "img2_path = '../assets/images/basic/opencv.jpg'  # Same image, slightly transformed\n",
    "\n",
    "if os.path.exists(img1_path):\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img1 = cv2.resize(img1, (400, 300))\n",
    "else:\n",
    "    img1 = np.ones((300, 400, 3), dtype=np.uint8) * 255\n",
    "    cv2.rectangle(img1, (50, 50), (350, 250), (0, 0, 0), -1)\n",
    "    cv2.circle(img1, (200, 150), 60, (255, 255, 255), -1)\n",
    "\n",
    "# Create transformed version of img1\n",
    "h, w = img1.shape[:2]\n",
    "M = cv2.getRotationMatrix2D((w//2, h//2), 15, 0.9)  # Rotate 15Â° and scale 0.9x\n",
    "img2 = cv2.warpAffine(img1, M, (w, h))\n",
    "\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect keypoints and descriptors using ORB\n",
    "orb_match = cv2.ORB_create(nfeatures=500)\n",
    "kp1, des1 = orb_match.detectAndCompute(gray1, None)\n",
    "kp2, des2 = orb_match.detectAndCompute(gray2, None)\n",
    "\n",
    "# Create BFMatcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.match(des1, des2)\n",
    "\n",
    "# Sort matches by distance (best matches first)\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "# Draw first 50 matches\n",
    "img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:50], None,\n",
    "                               flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'BFMatcher: Top 50 matches (out of {len(matches)} total)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nâœ… BFMatcher åŒ¹é…çµæœ:')\n",
    "print('='*60)\n",
    "print(f'å½±åƒ1 é—œéµé»: {len(kp1)}')\n",
    "print(f'å½±åƒ2 é—œéµé»: {len(kp2)}')\n",
    "print(f'ç¸½åŒ¹é…æ•¸: {len(matches)}')\n",
    "print(f'\\nå‰5å€‹æœ€ä½³åŒ¹é…çš„è·é›¢:')\n",
    "for i, m in enumerate(matches[:5]):\n",
    "    print(f'  Match {i+1}: distance = {m.distance:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 FLANN Matcher (Fast Library for Approximate Nearest Neighbors)\n",
    "\n",
    "**FLANN** æ˜¯ä¸€å€‹å¿«é€Ÿè¿‘ä¼¼æœ€è¿‘é„°æœç´¢åº«ï¼Œæ¯” BFMatcher æ›´å¿«ã€‚\n",
    "\n",
    "#### æ ¸å¿ƒå„ªå‹¢\n",
    "\n",
    "```\n",
    "FLANN vs BFMatcher:\n",
    "\n",
    "BFMatcher:\n",
    "- ç²¾ç¢ºåŒ¹é…\n",
    "- ç°¡å–®ç›´æ¥\n",
    "- é©åˆå°æ•¸æ“šé›†\n",
    "\n",
    "FLANN:\n",
    "- è¿‘ä¼¼åŒ¹é…ï¼ˆä½†éå¸¸æ¥è¿‘ç²¾ç¢ºè§£ï¼‰\n",
    "- ä½¿ç”¨å„ªåŒ–çš„ç´¢å¼•çµæ§‹ (KD-Tree, LSH)\n",
    "- é©åˆå¤§æ•¸æ“šé›†\n",
    "- é€Ÿåº¦å¿« 10-100 å€\n",
    "```\n",
    "\n",
    "#### FLANN åƒæ•¸\n",
    "\n",
    "- **KD-Tree**: ç”¨æ–¼æµ®é»æè¿°å­ (SIFT, SURF)\n",
    "- **LSH**: ç”¨æ–¼äºŒé€²ä½æè¿°å­ (ORB, BRISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect features using SIFT (for FLANN with KD-Tree)\n",
    "kp1_sift, des1_sift = sift.detectAndCompute(gray1, None)\n",
    "kp2_sift, des2_sift = sift.detectAndCompute(gray2, None)\n",
    "\n",
    "# FLANN parameters for SIFT\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)  # Higher = more accurate but slower\n",
    "\n",
    "# Create FLANN matcher\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# Match descriptors (k=2 for ratio test)\n",
    "matches_flann = flann.knnMatch(des1_sift, des2_sift, k=2)\n",
    "\n",
    "# Apply Lowe's ratio test\n",
    "good_matches = []\n",
    "for m, n in matches_flann:\n",
    "    if m.distance < 0.7 * n.distance:  # Ratio threshold\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Draw matches\n",
    "img_flann = cv2.drawMatches(img1, kp1_sift, img2, kp2_sift, good_matches[:50], None,\n",
    "                             flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(cv2.cvtColor(img_flann, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'FLANN Matcher: Top 50 good matches (out of {len(good_matches)} total)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nâœ… FLANN åŒ¹é…çµæœ:')\n",
    "print('='*60)\n",
    "print(f'å½±åƒ1 é—œéµé»: {len(kp1_sift)}')\n",
    "print(f'å½±åƒ2 é—œéµé»: {len(kp2_sift)}')\n",
    "print(f'åŸå§‹åŒ¹é…æ•¸: {len(matches_flann)}')\n",
    "print(f'é€šé Ratio Test çš„åŒ¹é…æ•¸: {len(good_matches)}')\n",
    "print(f'åŒ¹é…ç‡: {len(good_matches)/len(matches_flann)*100:.1f}%')\n",
    "\n",
    "print(f'\\nğŸ’¡ Lowe\\'s Ratio Test:')\n",
    "print(f'   - æ¯”è¼ƒæœ€ä½³åŒ¹é…å’Œæ¬¡ä½³åŒ¹é…çš„è·é›¢')\n",
    "print(f'   - å¦‚æœæ¯”ä¾‹ < 0.7ï¼Œèªç‚ºæ˜¯å¥½çš„åŒ¹é…')\n",
    "print(f'   - å¯ä»¥éæ¿¾æ‰æ¨¡ç³Šçš„åŒ¹é…')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 FLANN with ORB (LSH Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLANN parameters for binary descriptors (ORB)\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params_lsh = dict(algorithm=FLANN_INDEX_LSH,\n",
    "                        table_number=6,      # 12\n",
    "                        key_size=12,         # 20\n",
    "                        multi_probe_level=1) # 2\n",
    "search_params_lsh = dict(checks=50)\n",
    "\n",
    "# Create FLANN matcher for binary descriptors\n",
    "flann_orb = cv2.FlannBasedMatcher(index_params_lsh, search_params_lsh)\n",
    "\n",
    "# Match ORB descriptors\n",
    "matches_orb_flann = flann_orb.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Apply ratio test\n",
    "good_matches_orb = []\n",
    "for match_pair in matches_orb_flann:\n",
    "    if len(match_pair) == 2:  # Ensure we have 2 matches\n",
    "        m, n = match_pair\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches_orb.append(m)\n",
    "\n",
    "# Draw matches\n",
    "img_orb_flann = cv2.drawMatches(img1, kp1, img2, kp2, good_matches_orb[:50], None,\n",
    "                                 flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(cv2.cvtColor(img_orb_flann, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'FLANN (LSH) + ORB: Top 50 matches (out of {len(good_matches_orb)} total)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nâœ… FLANN (LSH) + ORB åŒ¹é…çµæœ:')\n",
    "print('='*60)\n",
    "print(f'é€šé Ratio Test çš„åŒ¹é…æ•¸: {len(good_matches_orb)}')\n",
    "print(f'\\nğŸ’¡ LSH (Locality Sensitive Hashing):')\n",
    "print(f'   - å°ˆç‚ºäºŒé€²ä½æè¿°å­è¨­è¨ˆ')\n",
    "print(f'   - ä½¿ç”¨å“ˆå¸Œè¡¨åŠ é€Ÿæœç´¢')\n",
    "print(f'   - æ¯” KD-Tree æ›´é©åˆé«˜ç¶­äºŒé€²ä½è³‡æ–™')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Homography è®Šæ›èˆ‡å½±åƒé…æº–\n",
    "\n",
    "### 9.1 Homography åŸç†\n",
    "\n",
    "**Homography** æ˜¯ä¸€ç¨®å°‡ä¸€å€‹å¹³é¢æŠ•å½±åˆ°å¦ä¸€å€‹å¹³é¢çš„è®Šæ›ã€‚\n",
    "\n",
    "#### æ•¸å­¸å®šç¾©\n",
    "\n",
    "Homography çŸ©é™£ H (3x3) æè¿°å…©å€‹å¹³é¢é–“çš„é€è¦–è®Šæ›:\n",
    "\n",
    "```\n",
    "[x']   [h11  h12  h13]   [x]\n",
    "[y'] = [h21  h22  h23] Ã— [y]\n",
    "[1 ]   [h31  h32  h33]   [1]\n",
    "```\n",
    "\n",
    "#### æ‡‰ç”¨å ´æ™¯\n",
    "\n",
    "```\n",
    "Homography æ‡‰ç”¨:\n",
    "\n",
    "1. å½±åƒæ‹¼æ¥ (Image Stitching)\n",
    "   â””â”€> å…¨æ™¯åœ–è£½ä½œ\n",
    "\n",
    "2. è¦–è§’æ ¡æ­£ (Perspective Correction)\n",
    "   â””â”€> æ–‡æª”æƒæã€é“è·¯æ¨™ç·š\n",
    "\n",
    "3. ç‰©é«”è­˜åˆ¥ (Object Recognition)\n",
    "   â””â”€> å¹³é¢ç‰©é«”æª¢æ¸¬èˆ‡è¿½è¹¤\n",
    "\n",
    "4. æ“´å¢å¯¦å¢ƒ (AR)\n",
    "   â””â”€> è™›æ“¬ç‰©é«”ç–ŠåŠ \n",
    "```\n",
    "\n",
    "#### RANSAC æ¼”ç®—æ³•\n",
    "\n",
    "RANSAC (Random Sample Consensus) ç”¨æ–¼å¾å«æœ‰å¤–é» (outliers) çš„åŒ¹é…ä¸­ä¼°è¨ˆ Homography:\n",
    "\n",
    "```\n",
    "RANSAC æµç¨‹:\n",
    "\n",
    "1. éš¨æ©Ÿé¸æ“‡ 4 å°åŒ¹é…é»\n",
    "2. è¨ˆç®— Homography çŸ©é™£\n",
    "3. è¨ˆç®—æ‰€æœ‰é»çš„èª¤å·®\n",
    "4. çµ±è¨ˆå…§é» (inliers) æ•¸é‡\n",
    "5. é‡è¤‡å¤šæ¬¡ï¼Œé¸æ“‡å…§é»æœ€å¤šçš„æ¨¡å‹\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need at least 4 matches for Homography\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "if len(good_matches) >= MIN_MATCH_COUNT:\n",
    "    # Extract location of good matches\n",
    "    src_pts = np.float32([kp1_sift[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2_sift[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Find Homography matrix using RANSAC\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    \n",
    "    # Draw bounding box in img2\n",
    "    h, w = gray1.shape\n",
    "    pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "    dst = cv2.perspectiveTransform(pts, M)\n",
    "    \n",
    "    img2_box = img2.copy()\n",
    "    img2_box = cv2.polylines(img2_box, [np.int32(dst)], True, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "    \n",
    "    # Draw only inliers\n",
    "    draw_params = dict(matchColor=(0, 255, 0),\n",
    "                       singlePointColor=None,\n",
    "                       matchesMask=matchesMask,\n",
    "                       flags=2)\n",
    "    \n",
    "    img_homography = cv2.drawMatches(img1, kp1_sift, img2_box, kp2_sift, \n",
    "                                      good_matches, None, **draw_params)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(18, 9))\n",
    "    plt.imshow(cv2.cvtColor(img_homography, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Homography: {sum(matchesMask)} inliers out of {len(good_matches)} matches', \n",
    "              fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'\\nâœ… Homography è¨ˆç®—çµæœ:')\n",
    "    print('='*60)\n",
    "    print(f'ç¸½åŒ¹é…æ•¸: {len(good_matches)}')\n",
    "    print(f'å…§é» (inliers): {sum(matchesMask)}')\n",
    "    print(f'å¤–é» (outliers): {len(matchesMask) - sum(matchesMask)}')\n",
    "    print(f'å…§é»æ¯”ä¾‹: {sum(matchesMask)/len(matchesMask)*100:.1f}%')\n",
    "    \n",
    "    print(f'\\nHomography çŸ©é™£:')\n",
    "    print(M)\n",
    "    \n",
    "else:\n",
    "    print(f'âš ï¸ åŒ¹é…é»ä¸è¶³ - éœ€è¦è‡³å°‘ {MIN_MATCH_COUNT} å€‹åŒ¹é…é»')\n",
    "    print(f'   ç•¶å‰åƒ…æœ‰ {len(good_matches)} å€‹åŒ¹é…é»')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 æ‡‰ç”¨ Homography é€²è¡Œå½±åƒå°é½Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(good_matches) >= MIN_MATCH_COUNT and M is not None:\n",
    "    # Warp img1 to align with img2\n",
    "    h, w = img2.shape[:2]\n",
    "    img1_aligned = cv2.warpPerspective(img1, M, (w, h))\n",
    "    \n",
    "    # Create difference image\n",
    "    diff = cv2.absdiff(img2, img1_aligned)\n",
    "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Display\n",
    "    display_multiple_images(\n",
    "        [img1, img2, img1_aligned, diff_gray],\n",
    "        ['Original Image 1', 'Image 2 (Rotated)', 'Image 1 Aligned', 'Difference'],\n",
    "        rows=2, cols=2, figsize=(14, 10)\n",
    "    )\n",
    "    \n",
    "    # Calculate alignment quality\n",
    "    mse = np.mean((img2.astype(float) - img1_aligned.astype(float))**2)\n",
    "    psnr = 20 * np.log10(255.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
    "    \n",
    "    print(f'\\nâœ… å½±åƒå°é½Šå“è³ª:')\n",
    "    print('='*60)\n",
    "    print(f'MSE:  {mse:.2f}')\n",
    "    print(f'PSNR: {psnr:.2f} dB')\n",
    "    print(f'\\nğŸ’¡ PSNR è¶Šé«˜è¡¨ç¤ºå°é½Šè¶Šå¥½ï¼ˆé€šå¸¸ > 30dB ç‚ºè‰¯å¥½å°é½Šï¼‰')\n",
    "else:\n",
    "    print('âš ï¸ ç„¡æ³•è¨ˆç®— Homographyï¼ŒåŒ¹é…é»ä¸è¶³')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ç‰¹å¾µæª¢æ¸¬å™¨å®Œæ•´æ¯”è¼ƒè¡¨\n",
    "\n",
    "### 10.1 æŠ€è¡“ç‰¹æ€§æ¯”è¼ƒ\n",
    "\n",
    "| ç‰¹å¾µ | SIFT | SURF | ORB | BRISK | BRIEF |\n",
    "|------|------|------|-----|-------|-------|\n",
    "| **å°ºåº¦ä¸è®Š** | âœ… | âœ… | â­ | âœ… | âŒ |\n",
    "| **æ—‹è½‰ä¸è®Š** | âœ… | âœ… | âœ… | âœ… | âŒ |\n",
    "| **ä»¿å°„ä¸è®Š** | â­ | â­ | âŒ | âŒ | âŒ |\n",
    "| **å…‰ç…§ç©©å®š** | âœ… | âœ… | â­ | â­ | â­ |\n",
    "| **é€Ÿåº¦** | â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |\n",
    "| **é­¯æ£’æ€§** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­ | â­â­ |\n",
    "| **è¨˜æ†¶é«”** | 128ç¶­/float | 64ç¶­/float | 256ä½å…ƒ | 512ä½å…ƒ | 256ä½å…ƒ |\n",
    "| **å°ˆåˆ©** | å·²éæœŸ | æœ‰å°ˆåˆ©âš ï¸ | é–‹æºâœ… | é–‹æºâœ… | é–‹æºâœ… |\n",
    "\n",
    "### 10.2 æ‡‰ç”¨å ´æ™¯æ¨è–¦\n",
    "\n",
    "| å ´æ™¯ | æ¨è–¦æª¢æ¸¬å™¨ | ç†ç”± |\n",
    "|------|-----------|------|\n",
    "| **å¯¦æ™‚æ‡‰ç”¨** | ORB, BRISK | é€Ÿåº¦æœ€å¿«ï¼Œé©åˆç§»å‹•è¨­å‚™ |\n",
    "| **é«˜ç²¾åº¦åŒ¹é…** | SIFT | æœ€ç©©å®šï¼Œæº–ç¢ºåº¦æœ€é«˜ |\n",
    "| **å½±åƒæ‹¼æ¥** | SIFT, SURF | éœ€è¦å°ºåº¦å’Œæ—‹è½‰ä¸è®Šæ€§ |\n",
    "| **ç‰©é«”è¿½è¹¤** | ORB | é€Ÿåº¦å¿«ï¼Œå¯¦æ™‚æ€§èƒ½å¥½ |\n",
    "| **AR æ‡‰ç”¨** | BRISK, ORB | å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºåº¦ |\n",
    "| **åµŒå…¥å¼ç³»çµ±** | ORB | è¨˜æ†¶é«”ä½”ç”¨å°ï¼Œè¨ˆç®—å¿« |\n",
    "| **å•†æ¥­æ‡‰ç”¨** | ORB, BRISK | ç„¡å°ˆåˆ©é™åˆ¶ |\n",
    "\n",
    "### 10.3 åŒ¹é…å™¨é¸æ“‡æŒ‡å—\n",
    "\n",
    "| æè¿°å­é¡å‹ | æ¨è–¦åŒ¹é…å™¨ | è·é›¢åº¦é‡ | åƒæ•¸è¨­ç½® |\n",
    "|-----------|----------|---------|----------|\n",
    "| SIFT, SURF | FLANN (KD-Tree) | L2 ç¯„æ•¸ | trees=5, checks=50 |\n",
    "| ORB, BRISK | BFMatcher | Hamming | crossCheck=True |\n",
    "| ORB, BRISK | FLANN (LSH) | Hamming | table_number=6, key_size=12 |\n",
    "\n",
    "### 10.4 æ€§èƒ½å°æ¯”ç¸½çµ\n",
    "\n",
    "```\n",
    "é€Ÿåº¦æ’å:   ORB > BRISK > SURF > SIFT\n",
    "æº–ç¢ºåº¦:     SIFT > SURF > BRISK > ORB\n",
    "é­¯æ£’æ€§:     SIFT > SURF â‰ˆ BRISK > ORB\n",
    "è¨˜æ†¶é«”:     BRIEF â‰ˆ ORB < SURF < BRISK < SIFT\n",
    "\n",
    "ç¶œåˆæ¨è–¦:\n",
    "- ç ”ç©¶/é«˜ç²¾åº¦: SIFT\n",
    "- ç”¢å“/å¯¦æ™‚: ORB\n",
    "- å¹³è¡¡æ–¹æ¡ˆ: BRISK\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. å¯¦æˆ°ç·´ç¿’\n",
    "\n",
    "### ç·´ç¿’ 1: å¯¦ç¾ç°¡å–®çš„ç‰©é«”æª¢æ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ä½¿ç”¨ç‰¹å¾µåŒ¹é…åœ¨å ´æ™¯ä¸­æª¢æ¸¬ç›®æ¨™ç‰©é«”\n",
    "\n",
    "def detect_object(template, scene, detector='ORB', min_matches=10):\n",
    "    \"\"\"\n",
    "    Detect template object in scene using feature matching\n",
    "    \n",
    "    Args:\n",
    "        template: Template image (object to find)\n",
    "        scene: Scene image (where to search)\n",
    "        detector: 'SIFT', 'ORB', or 'BRISK'\n",
    "        min_matches: Minimum number of matches required\n",
    "    \n",
    "    Returns:\n",
    "        detected_image: Scene with bounding box\n",
    "        num_matches: Number of good matches found\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY) if len(template.shape) == 3 else template\n",
    "    scene_gray = cv2.cvtColor(scene, cv2.COLOR_BGR2GRAY) if len(scene.shape) == 3 else scene\n",
    "    \n",
    "    # Create detector\n",
    "    if detector == 'SIFT':\n",
    "        det = sift\n",
    "        matcher = cv2.FlannBasedMatcher(\n",
    "            dict(algorithm=1, trees=5),\n",
    "            dict(checks=50)\n",
    "        )\n",
    "    elif detector == 'ORB':\n",
    "        det = cv2.ORB_create(nfeatures=1000)\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    else:  # BRISK\n",
    "        det = cv2.BRISK_create()\n",
    "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    \n",
    "    # Detect and compute\n",
    "    kp1, des1 = det.detectAndCompute(template_gray, None)\n",
    "    kp2, des2 = det.detectAndCompute(scene_gray, None)\n",
    "    \n",
    "    if des1 is None or des2 is None:\n",
    "        return scene.copy(), 0\n",
    "    \n",
    "    # Match\n",
    "    matches = matcher.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for match_pair in matches:\n",
    "        if len(match_pair) == 2:\n",
    "            m, n = match_pair\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good.append(m)\n",
    "    \n",
    "    result = scene.copy()\n",
    "    \n",
    "    # Draw bounding box if enough matches\n",
    "    if len(good) >= min_matches:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        \n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        if M is not None:\n",
    "            h, w = template_gray.shape\n",
    "            pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "            dst = cv2.perspectiveTransform(pts, M)\n",
    "            \n",
    "            result = cv2.polylines(result, [np.int32(dst)], True, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "            \n",
    "            # Add text\n",
    "            cv2.putText(result, f'{detector}: {len(good)} matches', (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    return result, len(good)\n",
    "\n",
    "# Test object detection\n",
    "template = img1[50:250, 100:300]  # Extract template from img1\n",
    "scene = img2\n",
    "\n",
    "# Try different detectors\n",
    "results = []\n",
    "titles = []\n",
    "\n",
    "for det_name in ['SIFT', 'ORB', 'BRISK']:\n",
    "    detected, n_matches = detect_object(template, scene, detector=det_name)\n",
    "    results.append(detected)\n",
    "    titles.append(f'{det_name}\\n{n_matches} matches')\n",
    "\n",
    "# Add template\n",
    "results.insert(0, cv2.cvtColor(template, cv2.COLOR_BGR2RGB))\n",
    "titles.insert(0, 'Template')\n",
    "\n",
    "display_multiple_images(results, titles, rows=1, cols=4, figsize=(20, 5))\n",
    "\n",
    "print('âœ… ç‰©é«”æª¢æ¸¬å®Œæˆ')\n",
    "print('ğŸ’¡ è§€å¯Ÿä¸åŒæª¢æ¸¬å™¨åœ¨ç‰©é«”æª¢æ¸¬ä»»å‹™ä¸Šçš„è¡¨ç¾å·®ç•°')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç·´ç¿’ 2: æ¯”è¼ƒä¸åŒæª¢æ¸¬å™¨çš„æ—‹è½‰é­¯æ£’æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: æ¸¬è©¦ä¸åŒæ—‹è½‰è§’åº¦ä¸‹çš„åŒ¹é…ç©©å®šæ€§\n",
    "\n",
    "angles = [0, 30, 60, 90, 120, 150, 180]\n",
    "detectors_test = {'SIFT': sift, 'ORB': orb, 'BRISK': brisk}\n",
    "\n",
    "results_rotation = {name: [] for name in detectors_test.keys()}\n",
    "\n",
    "for angle in angles:\n",
    "    # Rotate image\n",
    "    h, w = gray.shape\n",
    "    M_rot = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray, M_rot, (w, h))\n",
    "    \n",
    "    for name, det in detectors_test.items():\n",
    "        # Detect and match\n",
    "        kp1, des1 = det.detectAndCompute(gray, None)\n",
    "        kp2, des2 = det.detectAndCompute(rotated, None)\n",
    "        \n",
    "        if des1 is not None and des2 is not None:\n",
    "            if name == 'SIFT':\n",
    "                bf_temp = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "            else:\n",
    "                bf_temp = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            \n",
    "            matches_temp = bf_temp.match(des1, des2)\n",
    "            results_rotation[name].append(len(matches_temp))\n",
    "        else:\n",
    "            results_rotation[name].append(0)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "for name, counts in results_rotation.items():\n",
    "    plt.plot(angles, counts, marker='o', label=name, linewidth=2)\n",
    "\n",
    "plt.xlabel('Rotation Angle (degrees)', fontsize=12)\n",
    "plt.ylabel('Number of Matches', fontsize=12)\n",
    "plt.title('Rotation Robustness Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\næ—‹è½‰é­¯æ£’æ€§æ¸¬è©¦çµæœ:')\n",
    "print('='*60)\n",
    "for name, counts in results_rotation.items():\n",
    "    avg_matches = np.mean(counts)\n",
    "    std_matches = np.std(counts)\n",
    "    print(f'{name:10} | å¹³å‡åŒ¹é…æ•¸: {avg_matches:6.1f} | æ¨™æº–å·®: {std_matches:5.1f}')\n",
    "\n",
    "print('\\nğŸ’¡ æ¨™æº–å·®è¶Šå°è¡¨ç¤ºæ—‹è½‰é­¯æ£’æ€§è¶Šå¥½')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ç¸½çµ\n",
    "\n",
    "### é‡é»å›é¡§\n",
    "\n",
    "1. **ç‰¹å¾µæª¢æ¸¬å™¨å®¶æ—**\n",
    "   - SIFT: æœ€ç©©å®šï¼Œä½†é€Ÿåº¦æ…¢\n",
    "   - SURF: SIFT åŠ é€Ÿç‰ˆï¼Œæœ‰å°ˆåˆ©é™åˆ¶\n",
    "   - ORB: é–‹æºï¼Œé€Ÿåº¦æœ€å¿«ï¼Œé©åˆå¯¦æ™‚\n",
    "   - BRISK: å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºåº¦\n",
    "   - BRIEF: åªæ˜¯æè¿°å­ï¼Œéœ€æ­é…å…¶ä»–æª¢æ¸¬å™¨\n",
    "\n",
    "2. **ç‰¹å¾µåŒ¹é…æ–¹æ³•**\n",
    "   - BFMatcher: ç²¾ç¢ºä½†æ…¢ï¼Œé©åˆå°æ•¸æ“šé›†\n",
    "   - FLANN: å¿«é€Ÿè¿‘ä¼¼åŒ¹é…ï¼Œé©åˆå¤§æ•¸æ“šé›†\n",
    "   - Ratio Test: Lowe's æ–¹æ³•éæ¿¾ä¸è‰¯åŒ¹é…\n",
    "\n",
    "3. **Homography æ‡‰ç”¨**\n",
    "   - å½±åƒæ‹¼æ¥\n",
    "   - è¦–è§’æ ¡æ­£\n",
    "   - ç‰©é«”æª¢æ¸¬\n",
    "   - RANSAC éæ¿¾å¤–é»\n",
    "\n",
    "4. **å¯¦éš›æ‡‰ç”¨å»ºè­°**\n",
    "   - ç ”ç©¶/é«˜ç²¾åº¦ â†’ SIFT\n",
    "   - å•†æ¥­/å¯¦æ™‚ â†’ ORB\n",
    "   - å¹³è¡¡æ–¹æ¡ˆ â†’ BRISK\n",
    "\n",
    "### æ±ºç­–æ¨¹\n",
    "\n",
    "```\n",
    "é¸æ“‡ç‰¹å¾µæª¢æ¸¬å™¨?\n",
    "â”œâ”€ éœ€è¦å¯¦æ™‚è™•ç†?\n",
    "â”‚   â”œâ”€ æ˜¯ â†’ ORB (æœ€å¿«)\n",
    "â”‚   â””â”€ å¦ â†’ ç¹¼çºŒ\n",
    "â”‚\n",
    "â”œâ”€ éœ€è¦æœ€é«˜æº–ç¢ºåº¦?\n",
    "â”‚   â”œâ”€ æ˜¯ â†’ SIFT (æœ€ç©©å®š)\n",
    "â”‚   â””â”€ å¦ â†’ ç¹¼çºŒ\n",
    "â”‚\n",
    "â”œâ”€ å•†æ¥­æ‡‰ç”¨ï¼ˆé¿å…å°ˆåˆ©ï¼‰?\n",
    "â”‚   â”œâ”€ æ˜¯ â†’ ORB æˆ– BRISK\n",
    "â”‚   â””â”€ å¦ â†’ SURF (å¦‚æœå¯ç”¨)\n",
    "â”‚\n",
    "â””â”€ éœ€è¦å¹³è¡¡æ–¹æ¡ˆ?\n",
    "    â””â”€ BRISK (é€Ÿåº¦èˆ‡æº–ç¢ºåº¦å¹³è¡¡)\n",
    "```\n",
    "\n",
    "### ä¸‹ä¸€æ­¥å­¸ç¿’\n",
    "\n",
    "- [x] ç‰¹å¾µæè¿°å­ âœ… â† **ä½ åœ¨é€™è£¡**\n",
    "- [ ] å…‰æµè¿½è¹¤ (Optical Flow)\n",
    "- [ ] ç‰©é«”è¿½è¹¤æ¼”ç®—æ³•\n",
    "- [ ] æ·±åº¦å­¸ç¿’ç‰¹å¾µ (CNN Features)\n",
    "- [ ] å½±åƒæ‹¼æ¥å°ˆæ¡ˆ\n",
    "\n",
    "### åƒè€ƒè³‡æº\n",
    "\n",
    "- OpenCV Feature Detection: https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html\n",
    "- SIFT Paper: Lowe, D.G. (2004)\n",
    "- ORB Paper: Rublee et al. (2011)\n",
    "- æœ¬å°ˆæ¡ˆ utils æ¨¡çµ„: `utils/image_utils.py`, `utils/performance.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
