{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.3 物體追蹤 (Object Tracking)\n",
    "\n",
    "**WBS 4.1.3**: 光流法與物體追蹤技術\n",
    "\n",
    "## 學習目標\n",
    "- 理解光流法 (Optical Flow) 的原理與應用\n",
    "- 掌握 Lucas-Kanade 稀疏光流追蹤\n",
    "- 學習 Farneback 稠密光流\n",
    "- 實現多目標追蹤基礎\n",
    "- (進階) 卡爾曼濾波器基礎\n",
    "- 比較不同追蹤方法的性能\n",
    "\n",
    "**難度等級**: ⭐⭐⭐⭐ (進階)  \n",
    "**預估時間**: 120 分鐘  \n",
    "**WBS編號**: 4.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 1. 光流法概述\n",
    "\n",
    "## 1-1: 什麼是光流 (Optical Flow)?\n",
    "\n",
    "> **光流** 是描述影像中像素移動模式的向量場，表示連續影格之間像素的運動方向和速度。\n",
    "\n",
    "### 核心概念\n",
    "\n",
    "```\n",
    "光流法基本假設:\n",
    "\n",
    "1. 亮度恆定假設 (Brightness Constancy)\n",
    "   └─> 同一像素在連續影格中亮度不變\n",
    "       I(x, y, t) = I(x+dx, y+dy, t+dt)\n",
    "\n",
    "2. 小運動假設 (Small Motion)\n",
    "   └─> 連續影格間的位移很小\n",
    "\n",
    "3. 空間一致性假設 (Spatial Coherence)\n",
    "   └─> 鄰近像素具有相似的運動\n",
    "```\n",
    "\n",
    "### 光流方程式\n",
    "\n",
    "> **泰勒展開與光流約束方程**:\n",
    ">\n",
    "> $$I(x+dx, y+dy, t+dt) \\approx I(x,y,t) + \\frac{\\partial I}{\\partial x}dx + \\frac{\\partial I}{\\partial y}dy + \\frac{\\partial I}{\\partial t}dt$$\n",
    ">\n",
    "> 根據亮度恆定假設:\n",
    ">\n",
    "> $$\\frac{\\partial I}{\\partial x}\\frac{dx}{dt} + \\frac{\\partial I}{\\partial y}\\frac{dy}{dt} + \\frac{\\partial I}{\\partial t} = 0$$\n",
    ">\n",
    "> 簡化為:\n",
    ">\n",
    "> $$I_x u + I_y v + I_t = 0$$\n",
    ">\n",
    "> 其中:\n",
    "> * $I_x, I_y$ 是影像的空間梯度\n",
    "> * $I_t$ 是影像的時間梯度\n",
    "> * $(u, v)$ 是光流向量 (要求解)\n",
    "\n",
    "### Aperture Problem\n",
    "\n",
    "> **孔徑問題**: 一個方程式有兩個未知數 (u, v)，無法唯一求解！\n",
    ">\n",
    "> **解決方案**:\n",
    "> * **稀疏光流**: 追蹤特定特徵點 (Lucas-Kanade)\n",
    "> * **稠密光流**: 為所有像素計算光流 (Farneback, Horn-Schunck)\n",
    "\n",
    "## 1-2: 光流法的分類\n",
    "\n",
    "| 類型 | 方法 | 特點 | 應用 |\n",
    "|------|------|------|------|\n",
    "| **稀疏光流** | Lucas-Kanade | 追蹤少量特徵點 | 物體追蹤、視覺測程 |\n",
    "| **稠密光流** | Farneback | 計算所有像素的光流 | 視頻穩定、運動分析 |\n",
    "| **深度學習** | FlowNet, PWC-Net | 端到端學習 | 自動駕駛、動作識別 |\n",
    "\n",
    "## 1-3: 光流法的應用\n",
    "\n",
    "> * **物體追蹤**: 追蹤視頻中的目標物體\n",
    "> * **運動估計**: 分析場景中的運動模式\n",
    "> * **視頻壓縮**: MPEG 編碼中的運動補償\n",
    "> * **動作識別**: 識別人體動作和手勢\n",
    "> * **視頻穩定**: 相機抖動補償\n",
    "> * **自動駕駛**: 場景理解和障礙物檢測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境設置與導入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(f'✅ OpenCV version: {cv2.__version__}')\n",
    "print(f'✅ NumPy version: {np.__version__}')\n",
    "\n",
    "# Check available video files\n",
    "video_dir = '../assets/videos/'\n",
    "if os.path.exists(video_dir):\n",
    "    videos = [f for f in os.listdir(video_dir) if f.endswith('.mp4')]\n",
    "    print(f'✅ Available videos: {len(videos)}')\n",
    "    for v in videos:\n",
    "        print(f'   - {v}')\n",
    "else:\n",
    "    print('⚠️ Video directory not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輔助函數：影像視覺化工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_flow(img, flow, step=16):\n",
    "    \"\"\"\n",
    "    Draw optical flow on image\n",
    "    \n",
    "    Args:\n",
    "        img: Input image (BGR)\n",
    "        flow: Optical flow (H x W x 2)\n",
    "        step: Sampling step for visualization\n",
    "    \n",
    "    Returns:\n",
    "        vis: Visualization image\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    \n",
    "    # Create line endpoints\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    \n",
    "    # Draw flow vectors\n",
    "    vis = img.copy()\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        # Calculate magnitude for color coding\n",
    "        mag = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        \n",
    "        # Color based on magnitude\n",
    "        if mag > 2:  # Only draw significant motion\n",
    "            color = (0, int(255 * min(mag/20, 1)), 0)\n",
    "            cv2.arrowedLine(vis, (x1, y1), (x2, y2), color, 1, cv2.LINE_AA, tipLength=0.3)\n",
    "    \n",
    "    return vis\n",
    "\n",
    "\n",
    "def draw_hsv_flow(flow):\n",
    "    \"\"\"\n",
    "    Convert flow to HSV color representation\n",
    "    \n",
    "    Args:\n",
    "        flow: Optical flow (H x W x 2)\n",
    "    \n",
    "    Returns:\n",
    "        bgr: HSV flow visualization in BGR\n",
    "    \"\"\"\n",
    "    h, w = flow.shape[:2]\n",
    "    fx, fy = flow[:, :, 0], flow[:, :, 1]\n",
    "    \n",
    "    # Convert to polar coordinates\n",
    "    mag, ang = cv2.cartToPolar(fx, fy)\n",
    "    \n",
    "    # Create HSV image\n",
    "    hsv = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2  # Hue: direction\n",
    "    hsv[..., 1] = 255  # Saturation: full\n",
    "    hsv[..., 2] = np.uint8(np.minimum(mag * 4, 255))  # Value: magnitude\n",
    "    \n",
    "    # Convert to BGR\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return bgr\n",
    "\n",
    "\n",
    "def create_color_wheel():\n",
    "    \"\"\"\n",
    "    Create a color wheel legend for optical flow visualization\n",
    "    \"\"\"\n",
    "    # Create circular color wheel\n",
    "    size = 200\n",
    "    wheel = np.zeros((size, size, 3), dtype=np.uint8)\n",
    "    \n",
    "    y, x = np.ogrid[-size//2:size//2, -size//2:size//2]\n",
    "    radius = np.sqrt(x*x + y*y)\n",
    "    angle = np.arctan2(y, x)\n",
    "    \n",
    "    # Create HSV wheel\n",
    "    hsv = np.zeros((size, size, 3), dtype=np.uint8)\n",
    "    hsv[..., 0] = ((angle + np.pi) / (2 * np.pi) * 180).astype(np.uint8)\n",
    "    hsv[..., 1] = 255\n",
    "    hsv[..., 2] = np.uint8(np.minimum(radius / (size//2) * 255, 255))\n",
    "    \n",
    "    # Mask circle\n",
    "    mask = radius <= size // 2\n",
    "    hsv[~mask] = 0\n",
    "    \n",
    "    wheel = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Add labels\n",
    "    cv2.putText(wheel, 'Right', (size-50, size//2), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    cv2.putText(wheel, 'Left', (5, size//2), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    cv2.putText(wheel, 'Up', (size//2-10, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    cv2.putText(wheel, 'Down', (size//2-20, size-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    \n",
    "    return wheel\n",
    "\n",
    "print('✅ Utility functions loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 2. Lucas-Kanade 光流法\n",
    "\n",
    "## 2-1: Lucas-Kanade 原理\n",
    "\n",
    "> **Lucas-Kanade** 是最經典的稀疏光流算法，由 Bruce D. Lucas 和 Takeo Kanade 於 1981 年提出。\n",
    "\n",
    "### 核心思想\n",
    "\n",
    "```\n",
    "Lucas-Kanade 方法:\n",
    "\n",
    "1. 假設局部鄰域內的像素有相同的運動\n",
    "   └─> 將單一方程式問題轉為過定方程組\n",
    "\n",
    "2. 在 n×n 窗口內建立方程組\n",
    "   └─> 對於每個像素: I_x·u + I_y·v + I_t = 0\n",
    "\n",
    "3. 使用最小平方法求解\n",
    "   └─> 最小化誤差的平方和\n",
    "```\n",
    "\n",
    "### 數學推導\n",
    "\n",
    "> **矩陣形式**:\n",
    ">\n",
    "> $$A \\mathbf{v} = \\mathbf{b}$$\n",
    ">\n",
    "> 其中:\n",
    ">\n",
    "> $$A = \\begin{bmatrix} I_x(p_1) & I_y(p_1) \\\\ I_x(p_2) & I_y(p_2) \\\\ \\vdots & \\vdots \\\\ I_x(p_n) & I_y(p_n) \\end{bmatrix}, \\quad \\mathbf{v} = \\begin{bmatrix} u \\\\ v \\end{bmatrix}, \\quad \\mathbf{b} = -\\begin{bmatrix} I_t(p_1) \\\\ I_t(p_2) \\\\ \\vdots \\\\ I_t(p_n) \\end{bmatrix}$$\n",
    ">\n",
    "> **最小平方解**:\n",
    ">\n",
    "> $$\\mathbf{v} = (A^T A)^{-1} A^T \\mathbf{b}$$\n",
    ">\n",
    "> 展開為:\n",
    ">\n",
    "> $$\\begin{bmatrix} u \\\\ v \\end{bmatrix} = \\begin{bmatrix} \\sum I_x^2 & \\sum I_x I_y \\\\ \\sum I_x I_y & \\sum I_y^2 \\end{bmatrix}^{-1} \\begin{bmatrix} -\\sum I_x I_t \\\\ -\\sum I_y I_t \\end{bmatrix}$$\n",
    "\n",
    "### 金字塔 Lucas-Kanade\n",
    "\n",
    "> **問題**: 基本 LK 方法只適用於小位移\n",
    ">\n",
    "> **解決**: 使用**影像金字塔** (Image Pyramid) 處理大位移:\n",
    ">\n",
    "> ```\n",
    "> 金字塔處理流程:\n",
    "> \n",
    "> Level 2 (最小) ─┐\n",
    ">                 ├─> 從粗糙到精細\n",
    "> Level 1         │   逐層求解光流\n",
    ">                 │\n",
    "> Level 0 (原始) ─┘\n",
    "> ```\n",
    "\n",
    "## 2-2: OpenCV 實現\n",
    "\n",
    "### cv2.calcOpticalFlowPyrLK() 函數\n",
    "\n",
    "```python\n",
    "nextPts, status, err = cv2.calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts)\n",
    "```\n",
    "\n",
    "> **參數說明**:\n",
    "> * `prevImg`: 前一幀灰度影像\n",
    "> * `nextImg`: 當前幀灰度影像\n",
    "> * `prevPts`: 前一幀的特徵點 (N×1×2 array)\n",
    "> * `nextPts`: 當前幀的特徵點 (初始猜測，可為 None)\n",
    "> * `winSize`: 搜索窗口大小 (預設 (21, 21))\n",
    "> * `maxLevel`: 金字塔層數 (預設 3)\n",
    ">\n",
    "> **返回值**:\n",
    "> * `nextPts`: 當前幀中的特徵點位置\n",
    "> * `status`: 追蹤狀態 (1=成功, 0=失敗)\n",
    "> * `err`: 追蹤誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3: Lucas-Kanade 實作 - 單點追蹤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video or create synthetic video\n",
    "video_path = '../assets/videos/car_chase_01.mp4'\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    print(f'✅ Loaded video: {video_path}')\n",
    "else:\n",
    "    # Create synthetic moving ball video\n",
    "    print('⚠️ Video not found, creating synthetic video')\n",
    "    cap = None\n",
    "\n",
    "# Read first frame\n",
    "if cap is not None:\n",
    "    ret, frame1 = cap.read()\n",
    "    if not ret:\n",
    "        print('❌ Failed to read video')\n",
    "        cap = None\n",
    "\n",
    "# If no video, create synthetic data\n",
    "if cap is None:\n",
    "    # Create synthetic video with moving circle\n",
    "    frames = []\n",
    "    for i in range(50):\n",
    "        frame = np.ones((480, 640, 3), dtype=np.uint8) * 255\n",
    "        x = int(100 + i * 10)\n",
    "        y = int(240 + 50 * np.sin(i * 0.2))\n",
    "        cv2.circle(frame, (x, y), 30, (0, 0, 255), -1)\n",
    "        frames.append(frame)\n",
    "    frame1 = frames[0]\n",
    "    print('✅ Created synthetic video with moving circle')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect good features to track (using Shi-Tomasi)\n",
    "feature_params = dict(\n",
    "    maxCorners=100,\n",
    "    qualityLevel=0.3,\n",
    "    minDistance=7,\n",
    "    blockSize=7\n",
    ")\n",
    "\n",
    "p0 = cv2.goodFeaturesToTrack(gray1, mask=None, **feature_params)\n",
    "\n",
    "# Display first frame with detected features\n",
    "frame1_display = frame1.copy()\n",
    "if p0 is not None:\n",
    "    for i in p0:\n",
    "        x, y = i.ravel()\n",
    "        cv2.circle(frame1_display, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(cv2.cvtColor(frame1_display, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Initial Features to Track ({len(p0)} points)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✅ Lucas-Kanade 初始化:')\n",
    "print('='*60)\n",
    "print(f'初始特徵點數量: {len(p0)}')\n",
    "print(f'影像尺寸: {frame1.shape[:2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucas-Kanade 追蹤實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),          # Search window size\n",
    "    maxLevel=2,                # Pyramid levels\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    ")\n",
    "\n",
    "# Create random colors for tracking visualization\n",
    "color = np.random.randint(0, 255, (len(p0), 3))\n",
    "\n",
    "# Create mask for drawing\n",
    "mask = np.zeros_like(frame1)\n",
    "\n",
    "# Track through multiple frames\n",
    "num_frames_to_track = 30\n",
    "tracked_frames = []\n",
    "\n",
    "# Prepare for tracking\n",
    "if cap is not None:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset to first frame\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_idx = 0\n",
    "else:\n",
    "    old_gray = gray1.copy()\n",
    "    frame_idx = 0\n",
    "\n",
    "p0_orig = p0.copy()\n",
    "\n",
    "for i in range(num_frames_to_track):\n",
    "    # Read next frame\n",
    "    if cap is not None:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    else:\n",
    "        if frame_idx + 1 >= len(frames):\n",
    "            break\n",
    "        frame = frames[frame_idx + 1]\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    \n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    # Draw tracks\n",
    "    frame_vis = frame.copy()\n",
    "    for j, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        \n",
    "        # Draw line on mask\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), \n",
    "                       color[j].tolist(), 2)\n",
    "        \n",
    "        # Draw circle on frame\n",
    "        frame_vis = cv2.circle(frame_vis, (int(a), int(b)), 5, \n",
    "                              color[j].tolist(), -1)\n",
    "    \n",
    "    # Combine frame and mask\n",
    "    output = cv2.add(frame_vis, mask)\n",
    "    \n",
    "    # Add frame info\n",
    "    cv2.putText(output, f'Frame: {i+1}/{num_frames_to_track}', (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(output, f'Tracked: {len(good_new)} points', (10, 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    tracked_frames.append(output)\n",
    "    \n",
    "    # Update for next iteration\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "    frame_idx += 1\n",
    "\n",
    "# Display tracking results (show every 5th frame)\n",
    "if len(tracked_frames) > 0:\n",
    "    display_indices = [0, len(tracked_frames)//4, len(tracked_frames)//2, \n",
    "                      3*len(tracked_frames)//4, -1]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, i in enumerate(display_indices):\n",
    "        axes[idx].imshow(cv2.cvtColor(tracked_frames[i], cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f'Frame {i+1}', fontsize=12)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Add color wheel legend\n",
    "    wheel = create_color_wheel()\n",
    "    axes[5].imshow(cv2.cvtColor(wheel, cv2.COLOR_BGR2RGB))\n",
    "    axes[5].set_title('Motion Direction Legend', fontsize=12)\n",
    "    axes[5].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n✅ Lucas-Kanade 追蹤結果:')\n",
    "    print('='*60)\n",
    "    print(f'總追蹤幀數: {len(tracked_frames)}')\n",
    "    print(f'初始特徵點: {len(p0_orig)}')\n",
    "    print(f'最終追蹤點: {len(good_new)}')\n",
    "    print(f'追蹤保留率: {len(good_new)/len(p0_orig)*100:.1f}%')\n",
    "\n",
    "# Close video capture\n",
    "if cap is not None:\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucas-Kanade 參數影響分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different window sizes\n",
    "print('\\n📊 Lucas-Kanade 參數影響分析:')\n",
    "print('='*60)\n",
    "\n",
    "window_sizes = [(7, 7), (15, 15), (21, 21), (31, 31)]\n",
    "\n",
    "# Reset to first two frames\n",
    "if cap is None and 'frames' in locals():\n",
    "    frame1 = frames[0]\n",
    "    frame2 = frames[5]\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "else:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame1 = cap.read()\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    for _ in range(5):\n",
    "        ret, frame2 = cap.read()\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    cap.release()\n",
    "\n",
    "# Detect features\n",
    "p0 = cv2.goodFeaturesToTrack(gray1, maxCorners=50, qualityLevel=0.3, \n",
    "                             minDistance=7, blockSize=7)\n",
    "\n",
    "results = []\n",
    "\n",
    "for win_size in window_sizes:\n",
    "    lk_params_test = dict(\n",
    "        winSize=win_size,\n",
    "        maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "    \n",
    "    # Calculate flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(gray1, gray2, p0, None, **lk_params_test)\n",
    "    \n",
    "    if p1 is not None:\n",
    "        good = p1[st == 1]\n",
    "        success_rate = len(good) / len(p0) * 100\n",
    "        avg_error = np.mean(err[st == 1]) if np.any(st == 1) else 0\n",
    "    else:\n",
    "        success_rate = 0\n",
    "        avg_error = 0\n",
    "    \n",
    "    results.append({\n",
    "        'window': win_size,\n",
    "        'success_rate': success_rate,\n",
    "        'avg_error': avg_error\n",
    "    })\n",
    "    \n",
    "    print(f'Window Size {win_size}: {success_rate:.1f}% success, '\n",
    "          f'avg error: {avg_error:.3f}')\n",
    "\n",
    "print('\\n💡 參數調整建議:')\n",
    "print('   - winSize 小 (7x7): 快速但對大位移不穩定')\n",
    "print('   - winSize 中 (15x15): 平衡速度與準確度 [推薦]')\n",
    "print('   - winSize 大 (31x31): 穩定但計算慢，適合大位移')\n",
    "print('   - maxLevel 高: 可處理更大的位移')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 3. Farneback 稠密光流\n",
    "\n",
    "## 3-1: Farneback 原理\n",
    "\n",
    "> **Farneback 光流** 是一種計算稠密光流的方法，由 Gunnar Farnebäck 於 2003 年提出。\n",
    "\n",
    "### 核心思想\n",
    "\n",
    "```\n",
    "Farneback 方法:\n",
    "\n",
    "1. 多項式展開 (Polynomial Expansion)\n",
    "   └─> 在每個像素鄰域用二次多項式近似信號\n",
    "       f(x) ≈ x^T A x + b^T x + c\n",
    "\n",
    "2. 多項式係數比較\n",
    "   └─> 比較兩幀中相同位置的多項式係數\n",
    "\n",
    "3. 全局位移場\n",
    "   └─> 為所有像素計算光流向量\n",
    "```\n",
    "\n",
    "### Farneback vs Lucas-Kanade\n",
    "\n",
    "| 特性 | Lucas-Kanade | Farneback |\n",
    "|------|-------------|----------|\n",
    "| **輸出** | 稀疏光流 (特徵點) | 稠密光流 (所有像素) |\n",
    "| **速度** | 快 | 較慢 |\n",
    "| **應用** | 物體追蹤 | 運動場分析、視頻穩定 |\n",
    "| **記憶體** | 低 | 高 |\n",
    "| **可視化** | 追蹤軌跡 | 運動向量場 |\n",
    "\n",
    "## 3-2: OpenCV 實現\n",
    "\n",
    "### cv2.calcOpticalFlowFarneback() 函數\n",
    "\n",
    "```python\n",
    "flow = cv2.calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, \n",
    "                                    winsize, iterations, poly_n, poly_sigma, flags)\n",
    "```\n",
    "\n",
    "> **參數說明**:\n",
    "> * `prev`: 前一幀灰度影像\n",
    "> * `next`: 當前幀灰度影像\n",
    "> * `flow`: 初始光流 (可為 None)\n",
    "> * `pyr_scale`: 金字塔縮放比例 (0.5 表示每層縮小一半)\n",
    "> * `levels`: 金字塔層數\n",
    "> * `winsize`: 平均窗口大小\n",
    "> * `iterations`: 每層迭代次數\n",
    "> * `poly_n`: 多項式展開的鄰域大小 (5 或 7)\n",
    "> * `poly_sigma`: 高斯標準差 (通常 1.1 或 1.5)\n",
    "> * `flags`: 操作標誌\n",
    ">\n",
    "> **返回值**:\n",
    "> * `flow`: 光流場 (H × W × 2)，包含每個像素的 (dx, dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3: Farneback 稠密光流實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video\n",
    "video_path = '../assets/videos/car_chase_01.mp4'\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame1 = cap.read()\n",
    "    \n",
    "    # Resize for faster computation\n",
    "    frame1 = cv2.resize(frame1, (640, 360))\n",
    "else:\n",
    "    # Use synthetic data\n",
    "    frame1 = frames[0]\n",
    "    cap = None\n",
    "\n",
    "prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Parameters for Farneback optical flow\n",
    "farneback_params = dict(\n",
    "    pyr_scale=0.5,      # Pyramid scale\n",
    "    levels=3,           # Number of pyramid levels\n",
    "    winsize=15,         # Averaging window size\n",
    "    iterations=3,       # Iterations at each pyramid level\n",
    "    poly_n=5,           # Size of pixel neighborhood (5 or 7)\n",
    "    poly_sigma=1.2,     # Gaussian sigma for polynomial expansion\n",
    "    flags=0             # Operation flags\n",
    ")\n",
    "\n",
    "print('\\n✅ Farneback 稠密光流設置:')\n",
    "print('='*60)\n",
    "print(f'影像尺寸: {frame1.shape[:2]}')\n",
    "print(f'金字塔層數: {farneback_params[\"levels\"]}')\n",
    "print(f'窗口大小: {farneback_params[\"winsize\"]}')\n",
    "print(f'多項式鄰域: {farneback_params[\"poly_n\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Process multiple frames\n",
    "flow_frames = []\n",
    "num_frames = 20\n",
    "\n",
    "# Reset video\n",
    "if cap is not None:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ret, prev_frame = cap.read()\n",
    "    prev_frame = cv2.resize(prev_frame, (640, 360))\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_idx = 0\n",
    "else:\n",
    "    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "    frame_idx = 0\n",
    "\n",
    "computation_times = []\n",
    "\n",
    "for i in range(num_frames):\n",
    "    # Read next frame\n",
    "    if cap is not None:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (640, 360))\n",
    "    else:\n",
    "        if frame_idx + 1 >= len(frames):\n",
    "            break\n",
    "        frame = frames[frame_idx + 1]\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate dense optical flow\n",
    "    start_time = time.time()\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, **farneback_params)\n",
    "    computation_times.append(time.time() - start_time)\n",
    "    \n",
    "    # Visualize flow\n",
    "    # 1. HSV representation\n",
    "    flow_hsv = draw_hsv_flow(flow)\n",
    "    \n",
    "    # 2. Arrow representation\n",
    "    flow_arrows = draw_flow(frame, flow, step=16)\n",
    "    \n",
    "    # 3. Magnitude visualization\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    mag_norm = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    mag_vis = cv2.applyColorMap(mag_norm.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    \n",
    "    flow_frames.append({\n",
    "        'original': frame,\n",
    "        'hsv': flow_hsv,\n",
    "        'arrows': flow_arrows,\n",
    "        'magnitude': mag_vis,\n",
    "        'flow': flow\n",
    "    })\n",
    "    \n",
    "    # Update for next iteration\n",
    "    prev_gray = gray\n",
    "    frame_idx += 1\n",
    "\n",
    "if cap is not None:\n",
    "    cap.release()\n",
    "\n",
    "print(f'\\n✅ Farneback 光流計算完成')\n",
    "print('='*60)\n",
    "print(f'處理幀數: {len(flow_frames)}')\n",
    "print(f'平均計算時間: {np.mean(computation_times)*1000:.2f} ms')\n",
    "print(f'處理速度: {1/np.mean(computation_times):.1f} FPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Farneback flow results\n",
    "if len(flow_frames) > 0:\n",
    "    # Select representative frames\n",
    "    display_idx = len(flow_frames) // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Original frame\n",
    "    axes[0, 0].imshow(cv2.cvtColor(flow_frames[display_idx]['original'], cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 0].set_title('Original Frame', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # HSV flow\n",
    "    axes[0, 1].imshow(cv2.cvtColor(flow_frames[display_idx]['hsv'], cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 1].set_title('Dense Flow (HSV: Hue=Direction, Value=Magnitude)', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Arrow visualization\n",
    "    axes[1, 0].imshow(cv2.cvtColor(flow_frames[display_idx]['arrows'], cv2.COLOR_BGR2RGB))\n",
    "    axes[1, 0].set_title('Flow Vectors (Arrows)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Magnitude\n",
    "    axes[1, 1].imshow(cv2.cvtColor(flow_frames[display_idx]['magnitude'], cv2.COLOR_BGR2RGB))\n",
    "    axes[1, 1].set_title('Flow Magnitude (Speed)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Flow statistics\n",
    "    flow_data = flow_frames[display_idx]['flow']\n",
    "    mag, ang = cv2.cartToPolar(flow_data[..., 0], flow_data[..., 1])\n",
    "    \n",
    "    print('\\n📊 光流統計分析:')\n",
    "    print('='*60)\n",
    "    print(f'平均位移量: {np.mean(mag):.3f} pixels')\n",
    "    print(f'最大位移量: {np.max(mag):.3f} pixels')\n",
    "    print(f'運動像素比例: {np.sum(mag > 1.0) / mag.size * 100:.1f}%')\n",
    "    print(f'主要運動方向: {np.degrees(np.mean(ang[mag > 1.0])):.1f}°')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farneback 參數調整對比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different parameter settings\n",
    "if len(flow_frames) > 0:\n",
    "    # Get two consecutive frames\n",
    "    gray1 = cv2.cvtColor(flow_frames[0]['original'], cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(flow_frames[5]['original'], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Test different parameters\n",
    "    param_sets = [\n",
    "        {'levels': 2, 'winsize': 10, 'name': 'Fast (Low Quality)'},\n",
    "        {'levels': 3, 'winsize': 15, 'name': 'Balanced [Default]'},\n",
    "        {'levels': 4, 'winsize': 20, 'name': 'High Quality (Slow)'},\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    print('\\n📊 Farneback 參數對比:')\n",
    "    print('='*60)\n",
    "    \n",
    "    for idx, params in enumerate(param_sets):\n",
    "        # Calculate flow with different parameters\n",
    "        test_params = farneback_params.copy()\n",
    "        test_params['levels'] = params['levels']\n",
    "        test_params['winsize'] = params['winsize']\n",
    "        \n",
    "        start = time.time()\n",
    "        flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, **test_params)\n",
    "        elapsed = (time.time() - start) * 1000\n",
    "        \n",
    "        # Visualize\n",
    "        flow_vis = draw_hsv_flow(flow)\n",
    "        \n",
    "        axes[idx].imshow(cv2.cvtColor(flow_vis, cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f\"{params['name']}\\n{elapsed:.1f} ms\", \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        print(f\"{params['name']:20} | Levels: {params['levels']} | \"\n",
    "              f\"WinSize: {params['winsize']} | Time: {elapsed:.1f} ms\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n💡 參數調整建議:')\n",
    "    print('   - levels 高: 可處理更大的運動，但計算慢')\n",
    "    print('   - winsize 大: 光流更平滑，但細節較少')\n",
    "    print('   - poly_n (5/7): 5 較快，7 較準確')\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 4. 稀疏光流 vs 稠密光流比較\n",
    "\n",
    "## 4-1: 視覺化比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison of sparse and dense optical flow\n",
    "\n",
    "# Load or create test frames\n",
    "video_path = '../assets/videos/car_chase_01.mp4'\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame1 = cap.read()\n",
    "    frame1 = cv2.resize(frame1, (640, 360))\n",
    "    \n",
    "    for _ in range(5):\n",
    "        ret, frame2 = cap.read()\n",
    "    frame2 = cv2.resize(frame2, (640, 360))\n",
    "    cap.release()\n",
    "else:\n",
    "    frame1 = frames[0]\n",
    "    frame2 = frames[5]\n",
    "\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 1. Lucas-Kanade (Sparse)\n",
    "p0 = cv2.goodFeaturesToTrack(gray1, maxCorners=200, qualityLevel=0.3, \n",
    "                             minDistance=7, blockSize=7)\n",
    "\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "start_lk = time.time()\n",
    "p1, st, err = cv2.calcOpticalFlowPyrLK(gray1, gray2, p0, None, **lk_params)\n",
    "time_lk = (time.time() - start_lk) * 1000\n",
    "\n",
    "# Visualize sparse flow\n",
    "frame_lk = frame2.copy()\n",
    "if p1 is not None:\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "    \n",
    "    for new, old in zip(good_new, good_old):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        frame_lk = cv2.arrowedLine(frame_lk, (int(c), int(d)), (int(a), int(b)),\n",
    "                                   (0, 255, 0), 2, tipLength=0.3)\n",
    "        frame_lk = cv2.circle(frame_lk, (int(a), int(b)), 3, (0, 0, 255), -1)\n",
    "\n",
    "# 2. Farneback (Dense)\n",
    "start_fb = time.time()\n",
    "flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "time_fb = (time.time() - start_fb) * 1000\n",
    "\n",
    "frame_fb = draw_hsv_flow(flow)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Frame t', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Frame t+1', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(frame_lk, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title(f'Lucas-Kanade (Sparse)\\n'\n",
    "                    f'{len(good_new)} points tracked | {time_lk:.1f} ms',\n",
    "                    fontsize=14, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(frame_fb, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f'Farneback (Dense)\\n'\n",
    "                    f'{flow.shape[0]*flow.shape[1]} vectors | {time_fb:.1f} ms',\n",
    "                    fontsize=14, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n📊 稀疏 vs 稠密光流比較:')\n",
    "print('='*60)\n",
    "print(f'Lucas-Kanade (稀疏):')\n",
    "print(f'  - 追蹤點數: {len(good_new)}')\n",
    "print(f'  - 計算時間: {time_lk:.2f} ms')\n",
    "print(f'  - 記憶體: 低 (只儲存特徵點)')\n",
    "print(f'  - 適用: 物體追蹤、相機運動估計')\n",
    "print()\n",
    "print(f'Farneback (稠密):')\n",
    "print(f'  - 向量數量: {flow.shape[0] * flow.shape[1]:,}')\n",
    "print(f'  - 計算時間: {time_fb:.2f} ms')\n",
    "print(f'  - 記憶體: 高 (儲存所有像素)')\n",
    "print(f'  - 適用: 運動分析、視頻穩定、視覺效果')\n",
    "print()\n",
    "print(f'速度比: Lucas-Kanade 快 {time_fb/time_lk:.1f}x')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2: 特性對比表\n",
    "\n",
    "| 特性 | Lucas-Kanade (稀疏) | Farneback (稠密) |\n",
    "|------|-------------------|----------------|\n",
    "| **計算範圍** | 選定的特徵點 | 所有像素 |\n",
    "| **輸出** | N個向量 (N<1000) | H×W 個向量 (>100,000) |\n",
    "| **速度** | ⚡⚡⚡ 快 | ⭐⭐ 較慢 |\n",
    "| **記憶體** | 低 | 高 |\n",
    "| **準確度** | 高 (特徵點處) | 中等 (全域) |\n",
    "| **適用場景** | 物體追蹤、SLAM | 運動分析、視頻穩定 |\n",
    "| **實時性** | ✅ 適合 | ⚠️ 需要優化 |\n",
    "| **魯棒性** | 依賴特徵檢測 | 對紋理敏感 |\n",
    "\n",
    "## 4-3: 應用場景決策樹\n",
    "\n",
    "```\n",
    "選擇光流方法?\n",
    "├─ 需要追蹤特定物體?\n",
    "│   └─ 是 → Lucas-Kanade (稀疏光流)\n",
    "│\n",
    "├─ 需要分析整體運動模式?\n",
    "│   └─ 是 → Farneback (稠密光流)\n",
    "│\n",
    "├─ 需要實時處理 (>30 FPS)?\n",
    "│   └─ 是 → Lucas-Kanade\n",
    "│\n",
    "├─ 需要視頻穩定或特效?\n",
    "│   └─> 是 → Farneback\n",
    "│\n",
    "└─ 高精度物體追蹤?\n",
    "    └─ 使用 Lucas-Kanade + 卡爾曼濾波\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 5. 多目標追蹤基礎\n",
    "\n",
    "## 5-1: 多目標追蹤概述\n",
    "\n",
    "> **多目標追蹤 (Multi-Object Tracking, MOT)** 是在視頻序列中同時追蹤多個目標物體的技術。\n",
    "\n",
    "### 核心挑戰\n",
    "\n",
    "```\n",
    "多目標追蹤的挑戰:\n",
    "\n",
    "1. 數據關聯 (Data Association)\n",
    "   └─> 將檢測結果與已有軌跡配對\n",
    "\n",
    "2. 遮擋處理 (Occlusion Handling)\n",
    "   └─> 物體被遮擋時如何維持追蹤\n",
    "\n",
    "3. 目標外觀變化\n",
    "   └─> 光照、視角、姿態變化\n",
    "\n",
    "4. 新目標進入與離開\n",
    "   └─> 動態管理追蹤目標\n",
    "```\n",
    "\n",
    "### 追蹤流程\n",
    "\n",
    "```\n",
    "MOT 典型流程:\n",
    "\n",
    "Frame t\n",
    "  ↓\n",
    "1. 物體檢測 (Detection)\n",
    "  └─> 找到所有候選目標\n",
    "  ↓\n",
    "2. 特徵提取 (Feature Extraction)\n",
    "  └─> 計算目標特徵 (位置、外觀、運動)\n",
    "  ↓\n",
    "3. 數據關聯 (Data Association)\n",
    "  └─> 匹配檢測結果與已有軌跡\n",
    "  ↓\n",
    "4. 狀態更新 (State Update)\n",
    "  └─> 更新軌跡狀態 (卡爾曼濾波)\n",
    "  ↓\n",
    "5. 軌跡管理 (Track Management)\n",
    "  └─> 創建、維護、刪除軌跡\n",
    "```\n",
    "\n",
    "## 5-2: 基於光流的多目標追蹤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTracker:\n",
    "    \"\"\"\n",
    "    Simple multi-object tracker using optical flow\n",
    "    \"\"\"\n",
    "    def __init__(self, max_age=30, min_hits=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_age: Maximum frames to keep lost tracks\n",
    "            min_hits: Minimum detections before confirmed track\n",
    "        \"\"\"\n",
    "        self.tracks = []  # List of active tracks\n",
    "        self.next_id = 0\n",
    "        self.max_age = max_age\n",
    "        self.min_hits = min_hits\n",
    "        \n",
    "        # Lucas-Kanade parameters\n",
    "        self.lk_params = dict(\n",
    "            winSize=(21, 21),\n",
    "            maxLevel=3,\n",
    "            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "        )\n",
    "    \n",
    "    def update(self, frame, detections):\n",
    "        \"\"\"\n",
    "        Update tracker with new frame and detections\n",
    "        \n",
    "        Args:\n",
    "            frame: Current frame (grayscale)\n",
    "            detections: List of detected bounding boxes [(x, y, w, h), ...]\n",
    "        \n",
    "        Returns:\n",
    "            tracks: List of active tracks with IDs\n",
    "        \"\"\"\n",
    "        # Initialize tracks from detections if first frame\n",
    "        if len(self.tracks) == 0:\n",
    "            for det in detections:\n",
    "                self.tracks.append({\n",
    "                    'id': self.next_id,\n",
    "                    'bbox': det,\n",
    "                    'age': 0,\n",
    "                    'hits': 1,\n",
    "                    'points': self._get_feature_points(frame, det),\n",
    "                    'prev_frame': frame.copy()\n",
    "                })\n",
    "                self.next_id += 1\n",
    "            return self.tracks\n",
    "        \n",
    "        # Track existing points using optical flow\n",
    "        for track in self.tracks:\n",
    "            if track['points'] is not None and len(track['points']) > 0:\n",
    "                # Calculate optical flow\n",
    "                new_points, status, _ = cv2.calcOpticalFlowPyrLK(\n",
    "                    track['prev_frame'], frame, track['points'], None, **self.lk_params\n",
    "                )\n",
    "                \n",
    "                if new_points is not None:\n",
    "                    good_new = new_points[status == 1]\n",
    "                    \n",
    "                    if len(good_new) > 0:\n",
    "                        # Update bounding box based on tracked points\n",
    "                        x_coords = good_new[:, 0]\n",
    "                        y_coords = good_new[:, 1]\n",
    "                        \n",
    "                        x = int(np.min(x_coords))\n",
    "                        y = int(np.min(y_coords))\n",
    "                        w = int(np.max(x_coords) - x)\n",
    "                        h = int(np.max(y_coords) - y)\n",
    "                        \n",
    "                        track['bbox'] = (x, y, w, h)\n",
    "                        track['points'] = good_new.reshape(-1, 1, 2)\n",
    "                        track['age'] = 0  # Reset age\n",
    "                    else:\n",
    "                        track['age'] += 1\n",
    "                else:\n",
    "                    track['age'] += 1\n",
    "            else:\n",
    "                track['age'] += 1\n",
    "            \n",
    "            track['prev_frame'] = frame.copy()\n",
    "        \n",
    "        # Remove old tracks\n",
    "        self.tracks = [t for t in self.tracks if t['age'] < self.max_age]\n",
    "        \n",
    "        # Add new detections (simple: add if far from existing tracks)\n",
    "        for det in detections:\n",
    "            is_new = True\n",
    "            for track in self.tracks:\n",
    "                if self._bbox_iou(det, track['bbox']) > 0.3:\n",
    "                    is_new = False\n",
    "                    # Refresh feature points\n",
    "                    track['points'] = self._get_feature_points(frame, det)\n",
    "                    track['hits'] += 1\n",
    "                    break\n",
    "            \n",
    "            if is_new:\n",
    "                self.tracks.append({\n",
    "                    'id': self.next_id,\n",
    "                    'bbox': det,\n",
    "                    'age': 0,\n",
    "                    'hits': 1,\n",
    "                    'points': self._get_feature_points(frame, det),\n",
    "                    'prev_frame': frame.copy()\n",
    "                })\n",
    "                self.next_id += 1\n",
    "        \n",
    "        return [t for t in self.tracks if t['hits'] >= self.min_hits]\n",
    "    \n",
    "    def _get_feature_points(self, frame, bbox):\n",
    "        \"\"\"Extract feature points within bounding box\"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        \n",
    "        # Ensure bbox is within frame\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        w = min(w, frame.shape[1] - x)\n",
    "        h = min(h, frame.shape[0] - y)\n",
    "        \n",
    "        if w <= 0 or h <= 0:\n",
    "            return None\n",
    "        \n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        if roi.size == 0:\n",
    "            return None\n",
    "        \n",
    "        # Detect features in ROI\n",
    "        points = cv2.goodFeaturesToTrack(roi, maxCorners=20, qualityLevel=0.01,\n",
    "                                        minDistance=5, blockSize=7)\n",
    "        \n",
    "        if points is not None:\n",
    "            # Offset points to global coordinates\n",
    "            points[:, :, 0] += x\n",
    "            points[:, :, 1] += y\n",
    "            return points\n",
    "        return None\n",
    "    \n",
    "    def _bbox_iou(self, bbox1, bbox2):\n",
    "        \"\"\"Calculate IoU between two bounding boxes\"\"\"\n",
    "        x1, y1, w1, h1 = bbox1\n",
    "        x2, y2, w2, h2 = bbox2\n",
    "        \n",
    "        # Calculate intersection\n",
    "        xi1 = max(x1, x2)\n",
    "        yi1 = max(y1, y2)\n",
    "        xi2 = min(x1 + w1, x2 + w2)\n",
    "        yi2 = min(y1 + h1, y2 + h2)\n",
    "        \n",
    "        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "        \n",
    "        # Calculate union\n",
    "        box1_area = w1 * h1\n",
    "        box2_area = w2 * h2\n",
    "        union_area = box1_area + box2_area - inter_area\n",
    "        \n",
    "        return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "print('✅ SimpleTracker class defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多目標追蹤示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate multi-object tracking\n",
    "\n",
    "# For demonstration, we'll create synthetic detections\n",
    "# In real applications, use object detection models (YOLO, SSD, etc.)\n",
    "\n",
    "def simulate_detections(frame_idx, num_frames):\n",
    "    \"\"\"\n",
    "    Simulate object detections for demonstration\n",
    "    In practice, use real object detector\n",
    "    \"\"\"\n",
    "    detections = []\n",
    "    \n",
    "    # Simulate two moving objects\n",
    "    # Object 1: moving right\n",
    "    x1 = 50 + frame_idx * 10\n",
    "    y1 = 100\n",
    "    if x1 < 550:\n",
    "        detections.append((x1, y1, 80, 80))\n",
    "    \n",
    "    # Object 2: moving diagonally\n",
    "    x2 = 500 - frame_idx * 8\n",
    "    y2 = 50 + frame_idx * 5\n",
    "    if x2 > 50 and y2 < 300:\n",
    "        detections.append((x2, y2, 60, 60))\n",
    "    \n",
    "    # Object 3: appears later\n",
    "    if frame_idx > 15:\n",
    "        x3 = 300\n",
    "        y3 = 200 + (frame_idx - 15) * 3\n",
    "        if y3 < 320:\n",
    "            detections.append((x3, y3, 70, 70))\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "# Create synthetic video for tracking\n",
    "tracker = SimpleTracker(max_age=10, min_hits=2)\n",
    "tracking_frames = []\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]\n",
    "\n",
    "num_frames = 40\n",
    "\n",
    "for frame_idx in range(num_frames):\n",
    "    # Create frame\n",
    "    frame = np.ones((400, 640, 3), dtype=np.uint8) * 255\n",
    "    \n",
    "    # Get simulated detections\n",
    "    detections = simulate_detections(frame_idx, num_frames)\n",
    "    \n",
    "    # Draw detections (dashed rectangles)\n",
    "    for det in detections:\n",
    "        x, y, w, h = det\n",
    "        # Draw dashed rectangle\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 128, 128), 1, cv2.LINE_AA)\n",
    "        # Fill with semi-transparent color\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (x, y), (x+w, y+h), (200, 200, 200), -1)\n",
    "        cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)\n",
    "    \n",
    "    # Convert to grayscale for tracking\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Update tracker\n",
    "    tracks = tracker.update(gray, detections)\n",
    "    \n",
    "    # Draw tracks\n",
    "    for track in tracks:\n",
    "        track_id = track['id']\n",
    "        x, y, w, h = track['bbox']\n",
    "        color = colors[track_id % len(colors)]\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)\n",
    "        \n",
    "        # Draw ID\n",
    "        cv2.putText(frame, f'ID: {track_id}', (x, y-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        # Draw tracked points\n",
    "        if track['points'] is not None:\n",
    "            for pt in track['points']:\n",
    "                px, py = pt.ravel()\n",
    "                cv2.circle(frame, (int(px), int(py)), 3, color, -1)\n",
    "    \n",
    "    # Add frame info\n",
    "    cv2.putText(frame, f'Frame: {frame_idx+1}/{num_frames}', (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "    cv2.putText(frame, f'Active Tracks: {len(tracks)}', (10, 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "    \n",
    "    tracking_frames.append(frame)\n",
    "\n",
    "# Display tracking results\n",
    "if len(tracking_frames) > 0:\n",
    "    display_indices = [0, 10, 20, 30, 39]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, i in enumerate(display_indices):\n",
    "        axes[idx].imshow(cv2.cvtColor(tracking_frames[i], cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f'Frame {i+1}', fontsize=14, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Legend\n",
    "    axes[5].text(0.1, 0.9, 'Legend:', fontsize=14, fontweight='bold', \n",
    "                transform=axes[5].transAxes)\n",
    "    axes[5].text(0.1, 0.7, '■ Gray dashed box: Detection', fontsize=12,\n",
    "                transform=axes[5].transAxes, color='gray')\n",
    "    axes[5].text(0.1, 0.5, '■ Colored solid box: Tracked object', fontsize=12,\n",
    "                transform=axes[5].transAxes, color='blue')\n",
    "    axes[5].text(0.1, 0.3, '● Points: Tracked features', fontsize=12,\n",
    "                transform=axes[5].transAxes)\n",
    "    axes[5].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n✅ 多目標追蹤演示完成')\n",
    "    print('='*60)\n",
    "    print('觀察:')\n",
    "    print('  1. 每個目標被分配唯一 ID')\n",
    "    print('  2. 使用光流追蹤特徵點')\n",
    "    print('  3. 新目標出現時自動分配新 ID')\n",
    "    print('  4. 失去追蹤的目標會在一段時間後被移除')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 6. 卡爾曼濾波器基礎 (進階)\n",
    "\n",
    "## 6-1: 卡爾曼濾波器概述\n",
    "\n",
    "> **卡爾曼濾波器 (Kalman Filter)** 是一種遞迴貝葉斯濾波器，用於估計動態系統的狀態。\n",
    "\n",
    "### 為什麼需要卡爾曼濾波？\n",
    "\n",
    "```\n",
    "物體追蹤中的問題:\n",
    "\n",
    "1. 測量噪聲\n",
    "   └─> 檢測器不完美，位置有誤差\n",
    "\n",
    "2. 暫時遮擋\n",
    "   └─> 物體被遮擋時無法檢測\n",
    "\n",
    "3. 運動預測\n",
    "   └─> 需要預測下一幀的位置\n",
    "\n",
    "卡爾曼濾波的解決方案:\n",
    "- 融合預測值與測量值\n",
    "- 估計最優狀態\n",
    "- 提供不確定性度量\n",
    "```\n",
    "\n",
    "### 卡爾曼濾波器的兩個步驟\n",
    "\n",
    "> **1. 預測 (Prediction)**:\n",
    ">\n",
    "> $$\\hat{x}_{k|k-1} = F_k \\hat{x}_{k-1|k-1} + B_k u_k$$\n",
    "> $$P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k$$\n",
    ">\n",
    "> **2. 更新 (Update)**:\n",
    ">\n",
    "> $$K_k = P_{k|k-1} H_k^T (H_k P_{k|k-1} H_k^T + R_k)^{-1}$$\n",
    "> $$\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k (z_k - H_k \\hat{x}_{k|k-1})$$\n",
    "> $$P_{k|k} = (I - K_k H_k) P_{k|k-1}$$\n",
    "\n",
    "### 矩陣說明\n",
    "\n",
    "| 矩陣 | 名稱 | 說明 |\n",
    "|------|------|------|\n",
    "| $F_k$ | 狀態轉移矩陣 | 描述狀態如何隨時間變化 |\n",
    "| $H_k$ | 觀測矩陣 | 將狀態映射到測量空間 |\n",
    "| $Q_k$ | 過程噪聲協方差 | 模型不確定性 |\n",
    "| $R_k$ | 測量噪聲協方差 | 測量不確定性 |\n",
    "| $K_k$ | 卡爾曼增益 | 決定信任預測還是測量 |\n",
    "\n",
    "## 6-2: 簡單的 1D 追蹤範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleKalmanFilter:\n",
    "    \"\"\"\n",
    "    Simple 1D Kalman Filter for demonstration\n",
    "    State: [position, velocity]\n",
    "    \"\"\"\n",
    "    def __init__(self, process_noise=0.1, measurement_noise=1.0):\n",
    "        # State: [position, velocity]\n",
    "        self.x = np.array([[0.0], [0.0]])  # Initial state\n",
    "        \n",
    "        # State covariance\n",
    "        self.P = np.eye(2) * 1000  # High uncertainty initially\n",
    "        \n",
    "        # State transition matrix (constant velocity model)\n",
    "        dt = 1.0  # Time step\n",
    "        self.F = np.array([[1, dt],\n",
    "                          [0, 1]])\n",
    "        \n",
    "        # Observation matrix (we only measure position)\n",
    "        self.H = np.array([[1, 0]])\n",
    "        \n",
    "        # Process noise covariance\n",
    "        self.Q = np.eye(2) * process_noise\n",
    "        \n",
    "        # Measurement noise covariance\n",
    "        self.R = np.array([[measurement_noise]])\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Prediction step\n",
    "        \"\"\"\n",
    "        # Predict state\n",
    "        self.x = self.F @ self.x\n",
    "        \n",
    "        # Predict covariance\n",
    "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
    "        \n",
    "        return self.x[0, 0]\n",
    "    \n",
    "    def update(self, measurement):\n",
    "        \"\"\"\n",
    "        Update step with measurement\n",
    "        \"\"\"\n",
    "        # Measurement residual\n",
    "        y = np.array([[measurement]]) - self.H @ self.x\n",
    "        \n",
    "        # Residual covariance\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        \n",
    "        # Kalman gain\n",
    "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
    "        \n",
    "        # Update state\n",
    "        self.x = self.x + K @ y\n",
    "        \n",
    "        # Update covariance\n",
    "        I = np.eye(2)\n",
    "        self.P = (I - K @ self.H) @ self.P\n",
    "        \n",
    "        return self.x[0, 0]\n",
    "\n",
    "# Demonstrate Kalman Filter\n",
    "print('\\n📊 卡爾曼濾波器演示 (1D 追蹤):')\n",
    "print('='*60)\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "true_positions = np.linspace(0, 100, 50) + np.sin(np.linspace(0, 4*np.pi, 50)) * 5\n",
    "measurements = true_positions + np.random.randn(50) * 3  # Add noise\n",
    "\n",
    "# Apply Kalman filter\n",
    "kf = SimpleKalmanFilter(process_noise=0.1, measurement_noise=3.0)\n",
    "filtered_positions = []\n",
    "predicted_positions = []\n",
    "\n",
    "for measurement in measurements:\n",
    "    # Predict\n",
    "    prediction = kf.predict()\n",
    "    predicted_positions.append(prediction)\n",
    "    \n",
    "    # Update with measurement\n",
    "    filtered = kf.update(measurement)\n",
    "    filtered_positions.append(filtered)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(true_positions, 'g-', linewidth=2, label='True Position', alpha=0.7)\n",
    "plt.plot(measurements, 'rx', markersize=8, label='Noisy Measurements', alpha=0.5)\n",
    "plt.plot(filtered_positions, 'b-', linewidth=2, label='Kalman Filter Output')\n",
    "plt.plot(predicted_positions, 'y--', linewidth=1.5, label='Predictions', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Time Step', fontsize=12)\n",
    "plt.ylabel('Position', fontsize=12)\n",
    "plt.title('Kalman Filter: Smoothing Noisy Measurements', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate errors\n",
    "measurement_error = np.mean(np.abs(measurements - true_positions))\n",
    "filtered_error = np.mean(np.abs(np.array(filtered_positions) - true_positions))\n",
    "\n",
    "print(f'平均測量誤差: {measurement_error:.2f}')\n",
    "print(f'平均濾波誤差: {filtered_error:.2f}')\n",
    "print(f'誤差降低: {(1 - filtered_error/measurement_error)*100:.1f}%')\n",
    "print('\\n💡 卡爾曼濾波器的效果:')\n",
    "print('   - 平滑噪聲測量')\n",
    "   '   - 預測未來位置')\n",
    "print('   - 減少誤差')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3: 卡爾曼濾波器在物體追蹤中的應用\n",
    "\n",
    "### 常用狀態模型\n",
    "\n",
    "```python\n",
    "# 1. 恆速模型 (Constant Velocity)\n",
    "# State: [x, y, vx, vy]\n",
    "state = [position_x, position_y, velocity_x, velocity_y]\n",
    "\n",
    "# 2. 恆加速度模型 (Constant Acceleration)\n",
    "# State: [x, y, vx, vy, ax, ay]\n",
    "state = [position_x, position_y, velocity_x, velocity_y, accel_x, accel_y]\n",
    "\n",
    "# 3. 中心點+尺寸模型 (Center + Scale)\n",
    "# State: [cx, cy, w, h, vx, vy, vw, vh]\n",
    "state = [center_x, center_y, width, height, v_x, v_y, v_w, v_h]\n",
    "```\n",
    "\n",
    "### 實際應用案例\n",
    "\n",
    "| 應用 | 狀態模型 | 特點 |\n",
    "|------|---------|------|\n",
    "| **行人追蹤** | 恆速模型 | 運動相對平滑 |\n",
    "| **車輛追蹤** | 恆速/恆加速 | 需考慮加速度 |\n",
    "| **無人機追蹤** | 中心點+尺寸 | 尺度變化大 |\n",
    "| **運動分析** | 關節點模型 | 多個關鍵點 |\n",
    "\n",
    "### 進階: SORT / DeepSORT\n",
    "\n",
    "> **SORT** (Simple Online and Realtime Tracking):\n",
    "> * 結合卡爾曼濾波器與匈牙利算法\n",
    "> * 用於數據關聯\n",
    "> * 適合實時追蹤\n",
    ">\n",
    "> **DeepSORT**:\n",
    "> * SORT + 深度外觀特徵\n",
    "> * 使用 CNN 提取外觀特徵\n",
    "> * 更強的遮擋處理能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 7. 實戰練習\n",
    "\n",
    "## 練習 1: 視頻特徵點追蹤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實現視頻特徵點追蹤\n",
    "# 任務: 使用 Lucas-Kanade 追蹤視頻中的特徵點，繪製運動軌跡\n",
    "\n",
    "print('\\n📝 練習 1: 視頻特徵點追蹤')\n",
    "print('='*60)\n",
    "print('任務:')\n",
    "print('  1. 讀取視頻文件')\n",
    "print('  2. 使用 Shi-Tomasi 檢測第一幀的特徵點')\n",
    "print('  3. 使用 Lucas-Kanade 追蹤特徵點')\n",
    "print('  4. 繪製追蹤軌跡')\n",
    "print('  5. 統計追蹤成功率')\n",
    "print('\\n提示:')\n",
    "print('  - 使用 cv2.goodFeaturesToTrack() 檢測特徵')\n",
    "print('  - 使用 cv2.calcOpticalFlowPyrLK() 追蹤')\n",
    "print('  - 根據 status 過濾失敗的追蹤')\n",
    "print('='*60)\n",
    "\n",
    "# Solution framework\n",
    "def track_video_features(video_path, max_frames=50):\n",
    "    \"\"\"\n",
    "    Track features in video using Lucas-Kanade\n",
    "    \"\"\"\n",
    "    # TODO: Implement feature tracking\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Uncomment to test\n",
    "# track_video_features('../assets/videos/car_chase_01.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習 2: 運動向量視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實現運動向量視覺化\n",
    "# 任務: 使用 Farneback 計算稠密光流，並進行多種視覺化\n",
    "\n",
    "print('\\n📝 練習 2: 運動向量視覺化')\n",
    "print('='*60)\n",
    "print('任務:')\n",
    "print('  1. 讀取連續的兩幀影像')\n",
    "print('  2. 使用 Farneback 計算稠密光流')\n",
    "print('  3. 實現三種視覺化方式:')\n",
    "print('     a) HSV 顏色編碼')\n",
    "print('     b) 箭頭向量場')\n",
    "print('     c) 運動幅度熱力圖')\n",
    "print('  4. 分析運動統計 (平均速度、方向分佈)')\n",
    "print('\\n提示:')\n",
    "print('  - 使用 cv2.calcOpticalFlowFarneback()')\n",
    "print('  - 使用 cv2.cartToPolar() 轉換為極座標')\n",
    "print('  - 參考本模組的 draw_flow() 和 draw_hsv_flow() 函數')\n",
    "print('='*60)\n",
    "\n",
    "# Solution framework\n",
    "def visualize_motion_vectors(frame1, frame2):\n",
    "    \"\"\"\n",
    "    Visualize optical flow in multiple ways\n",
    "    \"\"\"\n",
    "    # TODO: Implement motion vector visualization\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Uncomment to test\n",
    "# visualize_motion_vectors(frame1, frame2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習 3: 簡易物體追蹤系統 (挑戰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實現簡易物體追蹤系統\n",
    "# 任務: 整合特徵檢測、光流追蹤和卡爾曼濾波\n",
    "\n",
    "print('\\n📝 練習 3: 簡易物體追蹤系統 (挑戰)')\n",
    "print('='*60)\n",
    "print('任務:')\n",
    "print('  1. 讓用戶在第一幀選擇追蹤目標 (ROI)')\n",
    "print('  2. 使用光流法追蹤目標')\n",
    "print('  3. 使用卡爾曼濾波器預測位置')\n",
    "print('  4. 處理遮擋情況 (依賴預測)')\n",
    "print('  5. 顯示追蹤結果和置信度')\n",
    "print('\\n進階挑戰:')\n",
    "print('  - 支持多目標追蹤')\n",
    "print('  - 自動重新初始化丟失的追蹤')\n",
    "print('  - 添加追蹤質量評估')\n",
    "print('='*60)\n",
    "\n",
    "# Solution framework\n",
    "class ObjectTracker:\n",
    "    def __init__(self):\n",
    "        # TODO: Initialize tracker components\n",
    "        pass\n",
    "    \n",
    "    def initialize(self, frame, bbox):\n",
    "        # TODO: Initialize tracking with first frame and bbox\n",
    "        pass\n",
    "    \n",
    "    def update(self, frame):\n",
    "        # TODO: Update tracking with new frame\n",
    "        pass\n",
    "\n",
    "# Uncomment to test\n",
    "# tracker = ObjectTracker()\n",
    "# tracker.initialize(first_frame, bbox)\n",
    "# for frame in video_frames:\n",
    "#     result = tracker.update(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 8. 總結與延伸\n",
    "\n",
    "## 8-1: 核心要點回顧\n",
    "\n",
    "### 光流法\n",
    "\n",
    "> **Lucas-Kanade (稀疏光流)**:\n",
    "> * 📌 追蹤特定特徵點\n",
    "> * 📌 使用局部鄰域假設求解光流\n",
    "> * 📌 金字塔結構處理大位移\n",
    "> * 📌 適合物體追蹤、視覺測程\n",
    ">\n",
    "> **Farneback (稠密光流)**:\n",
    "> * 📌 計算所有像素的光流\n",
    "> * 📌 基於多項式展開\n",
    "> * 📌 適合運動分析、視頻穩定\n",
    "> * 📌 計算量大，需要優化\n",
    "\n",
    "### 物體追蹤\n",
    "\n",
    "> **多目標追蹤流程**:\n",
    "> 1. 物體檢測 (Detection)\n",
    "> 2. 特徵提取 (Feature Extraction)\n",
    "> 3. 數據關聯 (Data Association)\n",
    "> 4. 狀態更新 (State Update)\n",
    "> 5. 軌跡管理 (Track Management)\n",
    "\n",
    "### 卡爾曼濾波器\n",
    "\n",
    "> **兩步驟流程**:\n",
    "> 1. 預測 (Prediction): 根據運動模型預測狀態\n",
    "> 2. 更新 (Update): 融合測量值校正預測\n",
    ">\n",
    "> **優勢**:\n",
    "> * 平滑噪聲測量\n",
    "> * 預測未來位置\n",
    "> * 處理暫時遮擋\n",
    "\n",
    "## 8-2: 性能比較總結\n",
    "\n",
    "| 方法 | 速度 | 準確度 | 魯棒性 | 適用場景 |\n",
    "|------|------|--------|--------|----------|\n",
    "| **Lucas-Kanade** | ⚡⚡⚡ | ⭐⭐⭐⭐ | ⭐⭐⭐ | 物體追蹤、SLAM |\n",
    "| **Farneback** | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | 運動分析、視頻穩定 |\n",
    "| **LK + Kalman** | ⚡⚡ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | 高精度追蹤 |\n",
    "| **DeepSORT** | ⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 多目標追蹤 |\n",
    "\n",
    "## 8-3: 應用場景決策樹\n",
    "\n",
    "```\n",
    "選擇追蹤方法?\n",
    "├─ 單一目標追蹤?\n",
    "│   ├─ 需要實時 (>30 FPS)?\n",
    "│   │   └─ Lucas-Kanade\n",
    "│   └─ 需要高精度?\n",
    "│       └─ Lucas-Kanade + Kalman Filter\n",
    "│\n",
    "├─ 多目標追蹤?\n",
    "│   ├─ 簡單場景?\n",
    "│   │   └─ SORT (Kalman + Hungarian)\n",
    "│   └─ 複雜場景 (遮擋多)?\n",
    "│       └─ DeepSORT (SORT + Deep Features)\n",
    "│\n",
    "├─ 運動場分析?\n",
    "│   └─ Farneback Dense Flow\n",
    "│\n",
    "└─ 視頻穩定?\n",
    "    └─ Farneback + 平滑處理\n",
    "```\n",
    "\n",
    "## 8-4: 實用建議\n",
    "\n",
    "### 參數調整技巧\n",
    "\n",
    "```python\n",
    "# Lucas-Kanade 參數\n",
    "lk_params = dict(\n",
    "    winSize=(21, 21),      # 大位移用大窗口\n",
    "    maxLevel=3,            # 金字塔層數，處理大運動\n",
    "    criteria=(...)         # 迭代終止條件\n",
    ")\n",
    "\n",
    "# Farneback 參數\n",
    "fb_params = dict(\n",
    "    pyr_scale=0.5,         # 金字塔縮放\n",
    "    levels=3,              # 層數越多越慢但更準確\n",
    "    winsize=15,            # 窗口越大越平滑\n",
    "    iterations=3,          # 迭代次數\n",
    "    poly_n=5,              # 5 或 7\n",
    "    poly_sigma=1.2         # 1.1 ~ 1.5\n",
    ")\n",
    "```\n",
    "\n",
    "### 性能優化建議\n",
    "\n",
    "> 1. **影像預處理**:\n",
    ">    * 降低解析度 (640x480 通常足夠)\n",
    ">    * 使用 ROI 限制處理區域\n",
    ">    * 高斯模糊去噪\n",
    ">\n",
    "> 2. **特徵點管理**:\n",
    ">    * 定期重新檢測特徵點\n",
    ">    * 移除品質差的追蹤點\n",
    ">    * 維持適當的特徵點密度\n",
    ">\n",
    "> 3. **多線程加速**:\n",
    ">    * 檢測和追蹤並行處理\n",
    ">    * 使用 GPU 加速 (CUDA)\n",
    "\n",
    "## 8-5: 延伸學習\n",
    "\n",
    "### 進階主題\n",
    "\n",
    "> * **深度學習光流**: FlowNet, PWC-Net, RAFT\n",
    "> * **3D 運動估計**: 場景流 (Scene Flow)\n",
    "> * **擴展卡爾曼濾波**: EKF, UKF\n",
    "> * **粒子濾波器**: 非線性追蹤\n",
    "> * **視覺慣性測程**: VIO (Visual-Inertial Odometry)\n",
    "\n",
    "### 下一步學習\n",
    "\n",
    "- [x] 角點檢測 (4.1.1) ✅\n",
    "- [x] 特徵描述子 (4.1.2) ✅\n",
    "- [x] 物體追蹤 (4.1.3) ✅ ← **你在這裡**\n",
    "- [ ] 深度學習物體檢測 (YOLO, SSD)\n",
    "- [ ] 實時多目標追蹤專案\n",
    "- [ ] SLAM (同步定位與地圖構建)\n",
    "\n",
    "## 8-6: 參考資源\n",
    "\n",
    "### 論文\n",
    "\n",
    "> * **Lucas-Kanade**:  \n",
    ">   Lucas, B. D., & Kanade, T. (1981). \"An iterative image registration technique.\"\n",
    ">\n",
    "> * **Pyramidal Lucas-Kanade**:  \n",
    ">   Bouguet, J. Y. (2001). \"Pyramidal implementation of the Lucas Kanade feature tracker.\"\n",
    ">\n",
    "> * **Farneback**:  \n",
    ">   Farnebäck, G. (2003). \"Two-frame motion estimation based on polynomial expansion.\"\n",
    ">\n",
    "> * **Kalman Filter**:  \n",
    ">   Kalman, R. E. (1960). \"A new approach to linear filtering and prediction problems.\"\n",
    ">\n",
    "> * **SORT**:  \n",
    ">   Bewley et al. (2016). \"Simple Online and Realtime Tracking.\"\n",
    ">\n",
    "> * **DeepSORT**:  \n",
    ">   Wojke et al. (2017). \"Simple Online and Realtime Tracking with a Deep Association Metric.\"\n",
    "\n",
    "### 線上資源\n",
    "\n",
    "> * OpenCV Optical Flow Tutorial: https://docs.opencv.org/master/d4/dee/tutorial_optical_flow.html\n",
    "> * Kalman Filter Explained: https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/\n",
    "> * Multiple Object Tracking: https://motchallenge.net/\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 學習成果檢查清單\n",
    "\n",
    "完成本模組後，你應該能夠:\n",
    "\n",
    "- [ ] 理解光流法的基本原理和假設\n",
    "- [ ] 實現 Lucas-Kanade 稀疏光流追蹤\n",
    "- [ ] 實現 Farneback 稠密光流分析\n",
    "- [ ] 比較稀疏光流和稠密光流的差異\n",
    "- [ ] 建立基本的多目標追蹤系統\n",
    "- [ ] 理解卡爾曼濾波器的工作原理\n",
    "- [ ] 將卡爾曼濾波器應用於物體追蹤\n",
    "- [ ] 根據應用場景選擇適當的追蹤方法\n",
    "- [ ] 調整參數以優化追蹤性能\n",
    "- [ ] 處理追蹤中的常見問題 (遮擋、漂移)\n",
    "\n",
    "---\n",
    "\n",
    "**模組完成！繼續學習機器學習模組 (05_machine_learning)，探索深度學習在計算機視覺中的應用。**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
