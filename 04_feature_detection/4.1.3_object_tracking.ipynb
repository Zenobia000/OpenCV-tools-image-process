{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.3 ç‰©é«”è¿½è¹¤ (Object Tracking)\n",
    "\n",
    "**WBS 4.1.3**: å…‰æµæ³•èˆ‡ç‰©é«”è¿½è¹¤æŠ€è¡“\n",
    "\n",
    "## å­¸ç¿’ç›®æ¨™\n",
    "- ç†è§£å…‰æµæ³• (Optical Flow) çš„åŸç†èˆ‡æ‡‰ç”¨\n",
    "- æŒæ¡ Lucas-Kanade ç¨€ç–å…‰æµè¿½è¹¤\n",
    "- å­¸ç¿’ Farneback ç¨ å¯†å…‰æµ\n",
    "- å¯¦ç¾å¤šç›®æ¨™è¿½è¹¤åŸºç¤\n",
    "- (é€²éš) å¡çˆ¾æ›¼æ¿¾æ³¢å™¨åŸºç¤\n",
    "- æ¯”è¼ƒä¸åŒè¿½è¹¤æ–¹æ³•çš„æ€§èƒ½\n",
    "\n",
    "**é›£åº¦ç­‰ç´š**: â­â­â­â­ (é€²éš)  \n",
    "**é ä¼°æ™‚é–“**: 120 åˆ†é˜  \n",
    "**WBSç·¨è™Ÿ**: 4.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 1. å…‰æµæ³•æ¦‚è¿°\n",
    "\n",
    "## 1-1: ä»€éº¼æ˜¯å…‰æµ (Optical Flow)?\n",
    "\n",
    "> **å…‰æµ** æ˜¯æè¿°å½±åƒä¸­åƒç´ ç§»å‹•æ¨¡å¼çš„å‘é‡å ´ï¼Œè¡¨ç¤ºé€£çºŒå½±æ ¼ä¹‹é–“åƒç´ çš„é‹å‹•æ–¹å‘å’Œé€Ÿåº¦ã€‚\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "```\n",
    "å…‰æµæ³•åŸºæœ¬å‡è¨­:\n",
    "\n",
    "1. äº®åº¦æ†å®šå‡è¨­ (Brightness Constancy)\n",
    "   â””â”€> åŒä¸€åƒç´ åœ¨é€£çºŒå½±æ ¼ä¸­äº®åº¦ä¸è®Š\n",
    "       I(x, y, t) = I(x+dx, y+dy, t+dt)\n",
    "\n",
    "2. å°é‹å‹•å‡è¨­ (Small Motion)\n",
    "   â””â”€> é€£çºŒå½±æ ¼é–“çš„ä½ç§»å¾ˆå°\n",
    "\n",
    "3. ç©ºé–“ä¸€è‡´æ€§å‡è¨­ (Spatial Coherence)\n",
    "   â””â”€> é„°è¿‘åƒç´ å…·æœ‰ç›¸ä¼¼çš„é‹å‹•\n",
    "```\n",
    "\n",
    "### å…‰æµæ–¹ç¨‹å¼\n",
    "\n",
    "> **æ³°å‹’å±•é–‹èˆ‡å…‰æµç´„æŸæ–¹ç¨‹**:\n",
    ">\n",
    "> $$I(x+dx, y+dy, t+dt) \\approx I(x,y,t) + \\frac{\\partial I}{\\partial x}dx + \\frac{\\partial I}{\\partial y}dy + \\frac{\\partial I}{\\partial t}dt$$\n",
    ">\n",
    "> æ ¹æ“šäº®åº¦æ†å®šå‡è¨­:\n",
    ">\n",
    "> $$\\frac{\\partial I}{\\partial x}\\frac{dx}{dt} + \\frac{\\partial I}{\\partial y}\\frac{dy}{dt} + \\frac{\\partial I}{\\partial t} = 0$$\n",
    ">\n",
    "> ç°¡åŒ–ç‚º:\n",
    ">\n",
    "> $$I_x u + I_y v + I_t = 0$$\n",
    ">\n",
    "> å…¶ä¸­:\n",
    "> * $I_x, I_y$ æ˜¯å½±åƒçš„ç©ºé–“æ¢¯åº¦\n",
    "> * $I_t$ æ˜¯å½±åƒçš„æ™‚é–“æ¢¯åº¦\n",
    "> * $(u, v)$ æ˜¯å…‰æµå‘é‡ (è¦æ±‚è§£)\n",
    "\n",
    "### Aperture Problem\n",
    "\n",
    "> **å­”å¾‘å•é¡Œ**: ä¸€å€‹æ–¹ç¨‹å¼æœ‰å…©å€‹æœªçŸ¥æ•¸ (u, v)ï¼Œç„¡æ³•å”¯ä¸€æ±‚è§£ï¼\n",
    ">\n",
    "> **è§£æ±ºæ–¹æ¡ˆ**:\n",
    "> * **ç¨€ç–å…‰æµ**: è¿½è¹¤ç‰¹å®šç‰¹å¾µé» (Lucas-Kanade)\n",
    "> * **ç¨ å¯†å…‰æµ**: ç‚ºæ‰€æœ‰åƒç´ è¨ˆç®—å…‰æµ (Farneback, Horn-Schunck)\n",
    "\n",
    "## 1-2: å…‰æµæ³•çš„åˆ†é¡\n",
    "\n",
    "| é¡å‹ | æ–¹æ³• | ç‰¹é» | æ‡‰ç”¨ |\n",
    "|------|------|------|------|\n",
    "| **ç¨€ç–å…‰æµ** | Lucas-Kanade | è¿½è¹¤å°‘é‡ç‰¹å¾µé» | ç‰©é«”è¿½è¹¤ã€è¦–è¦ºæ¸¬ç¨‹ |\n",
    "| **ç¨ å¯†å…‰æµ** | Farneback | è¨ˆç®—æ‰€æœ‰åƒç´ çš„å…‰æµ | è¦–é »ç©©å®šã€é‹å‹•åˆ†æ |\n",
    "| **æ·±åº¦å­¸ç¿’** | FlowNet, PWC-Net | ç«¯åˆ°ç«¯å­¸ç¿’ | è‡ªå‹•é§•é§›ã€å‹•ä½œè­˜åˆ¥ |\n",
    "\n",
    "## 1-3: å…‰æµæ³•çš„æ‡‰ç”¨\n",
    "\n",
    "> * **ç‰©é«”è¿½è¹¤**: è¿½è¹¤è¦–é »ä¸­çš„ç›®æ¨™ç‰©é«”\n",
    "> * **é‹å‹•ä¼°è¨ˆ**: åˆ†æå ´æ™¯ä¸­çš„é‹å‹•æ¨¡å¼\n",
    "> * **è¦–é »å£“ç¸®**: MPEG ç·¨ç¢¼ä¸­çš„é‹å‹•è£œå„Ÿ\n",
    "> * **å‹•ä½œè­˜åˆ¥**: è­˜åˆ¥äººé«”å‹•ä½œå’Œæ‰‹å‹¢\n",
    "> * **è¦–é »ç©©å®š**: ç›¸æ©ŸæŠ–å‹•è£œå„Ÿ\n",
    "> * **è‡ªå‹•é§•é§›**: å ´æ™¯ç†è§£å’Œéšœç¤™ç‰©æª¢æ¸¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç’°å¢ƒè¨­ç½®èˆ‡å°å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(f'âœ… OpenCV version: {cv2.__version__}')\n",
    "print(f'âœ… NumPy version: {np.__version__}')\n",
    "\n",
    "# Check available video files\n",
    "video_dir = '../assets/videos/'\n",
    "if os.path.exists(video_dir):\n",
    "    videos = [f for f in os.listdir(video_dir) if f.endswith('.mp4')]\n",
    "    print(f'âœ… Available videos: {len(videos)}')\n",
    "    for v in videos:\n",
    "        print(f'   - {v}')\n",
    "else:\n",
    "    print('âš ï¸ Video directory not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¼”åŠ©å‡½æ•¸ï¼šå½±åƒè¦–è¦ºåŒ–å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_flow(img, flow, step=16):\n",
    "    \"\"\"\n",
    "    Draw optical flow on image\n",
    "    \n",
    "    Args:\n",
    "        img: Input image (BGR)\n",
    "        flow: Optical flow (H x W x 2)\n",
    "        step: Sampling step for visualization\n",
    "    \n",
    "    Returns:\n",
    "        vis: Visualization image\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    \n",
    "    # Create line endpoints\n",
    "    lines = np.vstack([x, y, x+fx, y+fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    \n",
    "    # Draw flow vectors\n",
    "    vis = img.copy()\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        # Calculate magnitude for color coding\n",
    "        mag = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        \n",
    "        # Color based on magnitude\n",
    "        if mag > 2:  # Only draw significant motion\n",
    "            color = (0, int(255 * min(mag/20, 1)), 0)\n",
    "            cv2.arrowedLine(vis, (x1, y1), (x2, y2), color, 1, cv2.LINE_AA, tipLength=0.3)\n",
    "    \n",
    "    return vis\n",
    "\n",
    "\n",
    "def draw_hsv_flow(flow):\n",
    "    \"\"\"\n",
    "    Convert flow to HSV color representation\n",
    "    \n",
    "    Args:\n",
    "        flow: Optical flow (H x W x 2)\n",
    "    \n",
    "    Returns:\n",
    "        bgr: HSV flow visualization in BGR\n",
    "    \"\"\"\n",
    "    h, w = flow.shape[:2]\n",
    "    fx, fy = flow[:, :, 0], flow[:, :, 1]\n",
    "    \n",
    "    # Convert to polar coordinates\n",
    "    mag, ang = cv2.cartToPolar(fx, fy)\n",
    "    \n",
    "    # Create HSV image\n",
    "    hsv = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2  # Hue: direction\n",
    "    hsv[..., 1] = 255  # Saturation: full\n",
    "    hsv[..., 2] = np.uint8(np.minimum(mag * 4, 255))  # Value: magnitude\n",
    "    \n",
    "    # Convert to BGR\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return bgr\n",
    "\n",
    "\n",
    "def create_color_wheel():\n",
    "    \"\"\"\n",
    "    Create a color wheel legend for optical flow visualization\n",
    "    \"\"\"\n",
    "    # Create circular color wheel\n",
    "    size = 200\n",
    "    wheel = np.zeros((size, size, 3), dtype=np.uint8)\n",
    "    \n",
    "    y, x = np.ogrid[-size//2:size//2, -size//2:size//2]\n",
    "    radius = np.sqrt(x*x + y*y)\n",
    "    angle = np.arctan2(y, x)\n",
    "    \n",
    "    # Create HSV wheel\n",
    "    hsv = np.zeros((size, size, 3), dtype=np.uint8)\n",
    "    hsv[..., 0] = ((angle + np.pi) / (2 * np.pi) * 180).astype(np.uint8)\n",
    "    hsv[..., 1] = 255\n",
    "    hsv[..., 2] = np.uint8(np.minimum(radius / (size//2) * 255, 255))\n",
    "    \n",
    "    # Mask circle\n",
    "    mask = radius <= size // 2\n",
    "    hsv[~mask] = 0\n",
    "    \n",
    "    wheel = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Add labels\n",
    "    cv2.putText(wheel, 'Right', (size-50, size//2), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    cv2.putText(wheel, 'Left', (5, size//2), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    cv2.putText(wheel, 'Up', (size//2-10, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    cv2.putText(wheel, 'Down', (size//2-20, size-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    \n",
    "    return wheel\n",
    "\n",
    "print('âœ… Utility functions loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 2. Lucas-Kanade å…‰æµæ³•\n",
    "\n",
    "## 2-1: Lucas-Kanade åŸç†\n",
    "\n",
    "> **Lucas-Kanade** æ˜¯æœ€ç¶“å…¸çš„ç¨€ç–å…‰æµç®—æ³•ï¼Œç”± Bruce D. Lucas å’Œ Takeo Kanade æ–¼ 1981 å¹´æå‡ºã€‚\n",
    "\n",
    "### æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "```\n",
    "Lucas-Kanade æ–¹æ³•:\n",
    "\n",
    "1. å‡è¨­å±€éƒ¨é„°åŸŸå…§çš„åƒç´ æœ‰ç›¸åŒçš„é‹å‹•\n",
    "   â””â”€> å°‡å–®ä¸€æ–¹ç¨‹å¼å•é¡Œè½‰ç‚ºéå®šæ–¹ç¨‹çµ„\n",
    "\n",
    "2. åœ¨ nÃ—n çª—å£å…§å»ºç«‹æ–¹ç¨‹çµ„\n",
    "   â””â”€> å°æ–¼æ¯å€‹åƒç´ : I_xÂ·u + I_yÂ·v + I_t = 0\n",
    "\n",
    "3. ä½¿ç”¨æœ€å°å¹³æ–¹æ³•æ±‚è§£\n",
    "   â””â”€> æœ€å°åŒ–èª¤å·®çš„å¹³æ–¹å’Œ\n",
    "```\n",
    "\n",
    "### æ•¸å­¸æ¨å°\n",
    "\n",
    "> **çŸ©é™£å½¢å¼**:\n",
    ">\n",
    "> $$A \\mathbf{v} = \\mathbf{b}$$\n",
    ">\n",
    "> å…¶ä¸­:\n",
    ">\n",
    "> $$A = \\begin{bmatrix} I_x(p_1) & I_y(p_1) \\\\ I_x(p_2) & I_y(p_2) \\\\ \\vdots & \\vdots \\\\ I_x(p_n) & I_y(p_n) \\end{bmatrix}, \\quad \\mathbf{v} = \\begin{bmatrix} u \\\\ v \\end{bmatrix}, \\quad \\mathbf{b} = -\\begin{bmatrix} I_t(p_1) \\\\ I_t(p_2) \\\\ \\vdots \\\\ I_t(p_n) \\end{bmatrix}$$\n",
    ">\n",
    "> **æœ€å°å¹³æ–¹è§£**:\n",
    ">\n",
    "> $$\\mathbf{v} = (A^T A)^{-1} A^T \\mathbf{b}$$\n",
    ">\n",
    "> å±•é–‹ç‚º:\n",
    ">\n",
    "> $$\\begin{bmatrix} u \\\\ v \\end{bmatrix} = \\begin{bmatrix} \\sum I_x^2 & \\sum I_x I_y \\\\ \\sum I_x I_y & \\sum I_y^2 \\end{bmatrix}^{-1} \\begin{bmatrix} -\\sum I_x I_t \\\\ -\\sum I_y I_t \\end{bmatrix}$$\n",
    "\n",
    "### é‡‘å­—å¡” Lucas-Kanade\n",
    "\n",
    "> **å•é¡Œ**: åŸºæœ¬ LK æ–¹æ³•åªé©ç”¨æ–¼å°ä½ç§»\n",
    ">\n",
    "> **è§£æ±º**: ä½¿ç”¨**å½±åƒé‡‘å­—å¡”** (Image Pyramid) è™•ç†å¤§ä½ç§»:\n",
    ">\n",
    "> ```\n",
    "> é‡‘å­—å¡”è™•ç†æµç¨‹:\n",
    "> \n",
    "> Level 2 (æœ€å°) â”€â”\n",
    ">                 â”œâ”€> å¾ç²—ç³™åˆ°ç²¾ç´°\n",
    "> Level 1         â”‚   é€å±¤æ±‚è§£å…‰æµ\n",
    ">                 â”‚\n",
    "> Level 0 (åŸå§‹) â”€â”˜\n",
    "> ```\n",
    "\n",
    "## 2-2: OpenCV å¯¦ç¾\n",
    "\n",
    "### cv2.calcOpticalFlowPyrLK() å‡½æ•¸\n",
    "\n",
    "```python\n",
    "nextPts, status, err = cv2.calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts)\n",
    "```\n",
    "\n",
    "> **åƒæ•¸èªªæ˜**:\n",
    "> * `prevImg`: å‰ä¸€å¹€ç°åº¦å½±åƒ\n",
    "> * `nextImg`: ç•¶å‰å¹€ç°åº¦å½±åƒ\n",
    "> * `prevPts`: å‰ä¸€å¹€çš„ç‰¹å¾µé» (NÃ—1Ã—2 array)\n",
    "> * `nextPts`: ç•¶å‰å¹€çš„ç‰¹å¾µé» (åˆå§‹çŒœæ¸¬ï¼Œå¯ç‚º None)\n",
    "> * `winSize`: æœç´¢çª—å£å¤§å° (é è¨­ (21, 21))\n",
    "> * `maxLevel`: é‡‘å­—å¡”å±¤æ•¸ (é è¨­ 3)\n",
    ">\n",
    "> **è¿”å›å€¼**:\n",
    "> * `nextPts`: ç•¶å‰å¹€ä¸­çš„ç‰¹å¾µé»ä½ç½®\n",
    "> * `status`: è¿½è¹¤ç‹€æ…‹ (1=æˆåŠŸ, 0=å¤±æ•—)\n",
    "> * `err`: è¿½è¹¤èª¤å·®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3: Lucas-Kanade å¯¦ä½œ - å–®é»è¿½è¹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video or create synthetic video\n",
    "video_path = '../assets/videos/car_chase_01.mp4'\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    print(f'âœ… Loaded video: {video_path}')\n",
    "else:\n",
    "    # Create synthetic moving ball video\n",
    "    print('âš ï¸ Video not found, creating synthetic video')\n",
    "    cap = None\n",
    "\n",
    "# Read first frame\n",
    "if cap is not None:\n",
    "    ret, frame1 = cap.read()\n",
    "    if not ret:\n",
    "        print('âŒ Failed to read video')\n",
    "        cap = None\n",
    "\n",
    "# If no video, create synthetic data\n",
    "if cap is None:\n",
    "    # Create synthetic video with moving circle\n",
    "    frames = []\n",
    "    for i in range(50):\n",
    "        frame = np.ones((480, 640, 3), dtype=np.uint8) * 255\n",
    "        x = int(100 + i * 10)\n",
    "        y = int(240 + 50 * np.sin(i * 0.2))\n",
    "        cv2.circle(frame, (x, y), 30, (0, 0, 255), -1)\n",
    "        frames.append(frame)\n",
    "    frame1 = frames[0]\n",
    "    print('âœ… Created synthetic video with moving circle')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect good features to track (using Shi-Tomasi)\n",
    "feature_params = dict(\n",
    "    maxCorners=100,\n",
    "    qualityLevel=0.3,\n",
    "    minDistance=7,\n",
    "    blockSize=7\n",
    ")\n",
    "\n",
    "p0 = cv2.goodFeaturesToTrack(gray1, mask=None, **feature_params)\n",
    "\n",
    "# Display first frame with detected features\n",
    "frame1_display = frame1.copy()\n",
    "if p0 is not None:\n",
    "    for i in p0:\n",
    "        x, y = i.ravel()\n",
    "        cv2.circle(frame1_display, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(cv2.cvtColor(frame1_display, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Initial Features to Track ({len(p0)} points)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nâœ… Lucas-Kanade åˆå§‹åŒ–:')\n",
    "print('='*60)\n",
    "print(f'åˆå§‹ç‰¹å¾µé»æ•¸é‡: {len(p0)}')\n",
    "print(f'å½±åƒå°ºå¯¸: {frame1.shape[:2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucas-Kanade è¿½è¹¤å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),          # Search window size\n",
    "    maxLevel=2,                # Pyramid levels\n",
    "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    ")\n",
    "\n",
    "# Create random colors for tracking visualization\n",
    "color = np.random.randint(0, 255, (len(p0), 3))\n",
    "\n",
    "# Create mask for drawing\n",
    "mask = np.zeros_like(frame1)\n",
    "\n",
    "# Track through multiple frames\n",
    "num_frames_to_track = 30\n",
    "tracked_frames = []\n",
    "\n",
    "# Prepare for tracking\n",
    "if cap is not None:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset to first frame\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_idx = 0\n",
    "else:\n",
    "    old_gray = gray1.copy()\n",
    "    frame_idx = 0\n",
    "\n",
    "p0_orig = p0.copy()\n",
    "\n",
    "for i in range(num_frames_to_track):\n",
    "    # Read next frame\n",
    "    if cap is not None:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    else:\n",
    "        if frame_idx + 1 >= len(frames):\n",
    "            break\n",
    "        frame = frames[frame_idx + 1]\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    \n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    # Draw tracks\n",
    "    frame_vis = frame.copy()\n",
    "    for j, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        \n",
    "        # Draw line on mask\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), \n",
    "                       color[j].tolist(), 2)\n",
    "        \n",
    "        # Draw circle on frame\n",
    "        frame_vis = cv2.circle(frame_vis, (int(a), int(b)), 5, \n",
    "                              color[j].tolist(), -1)\n",
    "    \n",
    "    # Combine frame and mask\n",
    "    output = cv2.add(frame_vis, mask)\n",
    "    \n",
    "    # Add frame info\n",
    "    cv2.putText(output, f'Frame: {i+1}/{num_frames_to_track}', (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(output, f'Tracked: {len(good_new)} points', (10, 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    tracked_frames.append(output)\n",
    "    \n",
    "    # Update for next iteration\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "    frame_idx += 1\n",
    "\n",
    "# Display tracking results (show every 5th frame)\n",
    "if len(tracked_frames) > 0:\n",
    "    display_indices = [0, len(tracked_frames)//4, len(tracked_frames)//2, \n",
    "                      3*len(tracked_frames)//4, -1]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, i in enumerate(display_indices):\n",
    "        axes[idx].imshow(cv2.cvtColor(tracked_frames[i], cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f'Frame {i+1}', fontsize=12)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Add color wheel legend\n",
    "    wheel = create_color_wheel()\n",
    "    axes[5].imshow(cv2.cvtColor(wheel, cv2.COLOR_BGR2RGB))\n",
    "    axes[5].set_title('Motion Direction Legend', fontsize=12)\n",
    "    axes[5].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nâœ… Lucas-Kanade è¿½è¹¤çµæœ:')\n",
    "    print('='*60)\n",
    "    print(f'ç¸½è¿½è¹¤å¹€æ•¸: {len(tracked_frames)}')\n",
    "    print(f'åˆå§‹ç‰¹å¾µé»: {len(p0_orig)}')\n",
    "    print(f'æœ€çµ‚è¿½è¹¤é»: {len(good_new)}')\n",
    "    print(f'è¿½è¹¤ä¿ç•™ç‡: {len(good_new)/len(p0_orig)*100:.1f}%')\n",
    "\n",
    "# Close video capture\n",
    "if cap is not None:\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucas-Kanade åƒæ•¸å½±éŸ¿åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different window sizes\n",
    "print('\\nğŸ“Š Lucas-Kanade åƒæ•¸å½±éŸ¿åˆ†æ:')\n",
    "print('='*60)\n",
    "\n",
    "window_sizes = [(7, 7), (15, 15), (21, 21), (31, 31)]\n",
    "\n",
    "# Reset to first two frames\n",
    "if cap is None and 'frames' in locals():\n",
    "    frame1 = frames[0]\n",
    "    frame2 = frames[5]\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "else:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame1 = cap.read()\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    for _ in range(5):\n",
    "        ret, frame2 = cap.read()\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    cap.release()\n",
    "\n",
    "# Detect features\n",
    "p0 = cv2.goodFeaturesToTrack(gray1, maxCorners=50, qualityLevel=0.3, \n",
    "                             minDistance=7, blockSize=7)\n",
    "\n",
    "results = []\n",
    "\n",
    "for win_size in window_sizes:\n",
    "    lk_params_test = dict(\n",
    "        winSize=win_size,\n",
    "        maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "    \n",
    "    # Calculate flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(gray1, gray2, p0, None, **lk_params_test)\n",
    "    \n",
    "    if p1 is not None:\n",
    "        good = p1[st == 1]\n",
    "        success_rate = len(good) / len(p0) * 100\n",
    "        avg_error = np.mean(err[st == 1]) if np.any(st == 1) else 0\n",
    "    else:\n",
    "        success_rate = 0\n",
    "        avg_error = 0\n",
    "    \n",
    "    results.append({\n",
    "        'window': win_size,\n",
    "        'success_rate': success_rate,\n",
    "        'avg_error': avg_error\n",
    "    })\n",
    "    \n",
    "    print(f'Window Size {win_size}: {success_rate:.1f}% success, '\n",
    "          f'avg error: {avg_error:.3f}')\n",
    "\n",
    "print('\\nğŸ’¡ åƒæ•¸èª¿æ•´å»ºè­°:')\n",
    "print('   - winSize å° (7x7): å¿«é€Ÿä½†å°å¤§ä½ç§»ä¸ç©©å®š')\n",
    "print('   - winSize ä¸­ (15x15): å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºåº¦ [æ¨è–¦]')\n",
    "print('   - winSize å¤§ (31x31): ç©©å®šä½†è¨ˆç®—æ…¢ï¼Œé©åˆå¤§ä½ç§»')\n",
    "print('   - maxLevel é«˜: å¯è™•ç†æ›´å¤§çš„ä½ç§»')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 3. Farneback ç¨ å¯†å…‰æµ\n",
    "\n",
    "## 3-1: Farneback åŸç†\n",
    "\n",
    "> **Farneback å…‰æµ** æ˜¯ä¸€ç¨®è¨ˆç®—ç¨ å¯†å…‰æµçš„æ–¹æ³•ï¼Œç”± Gunnar FarnebÃ¤ck æ–¼ 2003 å¹´æå‡ºã€‚\n",
    "\n",
    "### æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "```\n",
    "Farneback æ–¹æ³•:\n",
    "\n",
    "1. å¤šé …å¼å±•é–‹ (Polynomial Expansion)\n",
    "   â””â”€> åœ¨æ¯å€‹åƒç´ é„°åŸŸç”¨äºŒæ¬¡å¤šé …å¼è¿‘ä¼¼ä¿¡è™Ÿ\n",
    "       f(x) â‰ˆ x^T A x + b^T x + c\n",
    "\n",
    "2. å¤šé …å¼ä¿‚æ•¸æ¯”è¼ƒ\n",
    "   â””â”€> æ¯”è¼ƒå…©å¹€ä¸­ç›¸åŒä½ç½®çš„å¤šé …å¼ä¿‚æ•¸\n",
    "\n",
    "3. å…¨å±€ä½ç§»å ´\n",
    "   â””â”€> ç‚ºæ‰€æœ‰åƒç´ è¨ˆç®—å…‰æµå‘é‡\n",
    "```\n",
    "\n",
    "### Farneback vs Lucas-Kanade\n",
    "\n",
    "| ç‰¹æ€§ | Lucas-Kanade | Farneback |\n",
    "|------|-------------|----------|\n",
    "| **è¼¸å‡º** | ç¨€ç–å…‰æµ (ç‰¹å¾µé») | ç¨ å¯†å…‰æµ (æ‰€æœ‰åƒç´ ) |\n",
    "| **é€Ÿåº¦** | å¿« | è¼ƒæ…¢ |\n",
    "| **æ‡‰ç”¨** | ç‰©é«”è¿½è¹¤ | é‹å‹•å ´åˆ†æã€è¦–é »ç©©å®š |\n",
    "| **è¨˜æ†¶é«”** | ä½ | é«˜ |\n",
    "| **å¯è¦–åŒ–** | è¿½è¹¤è»Œè·¡ | é‹å‹•å‘é‡å ´ |\n",
    "\n",
    "## 3-2: OpenCV å¯¦ç¾\n",
    "\n",
    "### cv2.calcOpticalFlowFarneback() å‡½æ•¸\n",
    "\n",
    "```python\n",
    "flow = cv2.calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, \n",
    "                                    winsize, iterations, poly_n, poly_sigma, flags)\n",
    "```\n",
    "\n",
    "> **åƒæ•¸èªªæ˜**:\n",
    "> * `prev`: å‰ä¸€å¹€ç°åº¦å½±åƒ\n",
    "> * `next`: ç•¶å‰å¹€ç°åº¦å½±åƒ\n",
    "> * `flow`: åˆå§‹å…‰æµ (å¯ç‚º None)\n",
    "> * `pyr_scale`: é‡‘å­—å¡”ç¸®æ”¾æ¯”ä¾‹ (0.5 è¡¨ç¤ºæ¯å±¤ç¸®å°ä¸€åŠ)\n",
    "> * `levels`: é‡‘å­—å¡”å±¤æ•¸\n",
    "> * `winsize`: å¹³å‡çª—å£å¤§å°\n",
    "> * `iterations`: æ¯å±¤è¿­ä»£æ¬¡æ•¸\n",
    "> * `poly_n`: å¤šé …å¼å±•é–‹çš„é„°åŸŸå¤§å° (5 æˆ– 7)\n",
    "> * `poly_sigma`: é«˜æ–¯æ¨™æº–å·® (é€šå¸¸ 1.1 æˆ– 1.5)\n",
    "> * `flags`: æ“ä½œæ¨™èªŒ\n",
    ">\n",
    "> **è¿”å›å€¼**:\n",
    "> * `flow`: å…‰æµå ´ (H Ã— W Ã— 2)ï¼ŒåŒ…å«æ¯å€‹åƒç´ çš„ (dx, dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3: Farneback ç¨ å¯†å…‰æµå¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video\n",
    "video_path = '../assets/videos/car_chase_01.mp4'\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame1 = cap.read()\n",
    "    \n",
    "    # Resize for faster computation\n",
    "    frame1 = cv2.resize(frame1, (640, 360))\n",
    "else:\n",
    "    # Use synthetic data\n",
    "    frame1 = frames[0]\n",
    "    cap = None\n",
    "\n",
    "prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Parameters for Farneback optical flow\n",
    "farneback_params = dict(\n",
    "    pyr_scale=0.5,      # Pyramid scale\n",
    "    levels=3,           # Number of pyramid levels\n",
    "    winsize=15,         # Averaging window size\n",
    "    iterations=3,       # Iterations at each pyramid level\n",
    "    poly_n=5,           # Size of pixel neighborhood (5 or 7)\n",
    "    poly_sigma=1.2,     # Gaussian sigma for polynomial expansion\n",
    "    flags=0             # Operation flags\n",
    ")\n",
    "\n",
    "print('\\nâœ… Farneback ç¨ å¯†å…‰æµè¨­ç½®:')\n",
    "print('='*60)\n",
    "print(f'å½±åƒå°ºå¯¸: {frame1.shape[:2]}')\n",
    "print(f'é‡‘å­—å¡”å±¤æ•¸: {farneback_params[\"levels\"]}')\n",
    "print(f'çª—å£å¤§å°: {farneback_params[\"winsize\"]}')\n",
    "print(f'å¤šé …å¼é„°åŸŸ: {farneback_params[\"poly_n\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Process multiple frames\n",
    "flow_frames = []\n",
    "num_frames = 20\n",
    "\n",
    "# Reset video\n",
    "if cap is not None:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ret, prev_frame = cap.read()\n",
    "    prev_frame = cv2.resize(prev_frame, (640, 360))\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_idx = 0\n",
    "else:\n",
    "    prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "    frame_idx = 0\n",
    "\n",
    "computation_times = []\n",
    "\n",
    "for i in range(num_frames):\n",
    "    # Read next frame\n",
    "    if cap is not None:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (640, 360))\n",
    "    else:\n",
    "        if frame_idx + 1 >= len(frames):\n",
    "            break\n",
    "        frame = frames[frame_idx + 1]\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate dense optical flow\n",
    "    start_time = time.time()\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, **farneback_params)\n",
    "    computation_times.append(time.time() - start_time)\n",
    "    \n",
    "    # Visualize flow\n",
    "    # 1. HSV representation\n",
    "    flow_hsv = draw_hsv_flow(flow)\n",
    "    \n",
    "    # 2. Arrow representation\n",
    "    flow_arrows = draw_flow(frame, flow, step=16)\n",
    "    \n",
    "    # 3. Magnitude visualization\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    mag_norm = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    mag_vis = cv2.applyColorMap(mag_norm.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    \n",
    "    flow_frames.append({\n",
    "        'original': frame,\n",
    "        'hsv': flow_hsv,\n",
    "        'arrows': flow_arrows,\n",
    "        'magnitude': mag_vis,\n",
    "        'flow': flow\n",
    "    })\n",
    "    \n",
    "    # Update for next iteration\n",
    "    prev_gray = gray\n",
    "    frame_idx += 1\n",
    "\n",
    "if cap is not None:\n",
    "    cap.release()\n",
    "\n",
    "print(f'\\nâœ… Farneback å…‰æµè¨ˆç®—å®Œæˆ')\n",
    "print('='*60)\n",
    "print(f'è™•ç†å¹€æ•¸: {len(flow_frames)}')\n",
    "print(f'å¹³å‡è¨ˆç®—æ™‚é–“: {np.mean(computation_times)*1000:.2f} ms')\n",
    "print(f'è™•ç†é€Ÿåº¦: {1/np.mean(computation_times):.1f} FPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Farneback flow results\n",
    "if len(flow_frames) > 0:\n",
    "    # Select representative frames\n",
    "    display_idx = len(flow_frames) // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Original frame\n",
    "    axes[0, 0].imshow(cv2.cvtColor(flow_frames[display_idx]['original'], cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 0].set_title('Original Frame', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # HSV flow\n",
    "    axes[0, 1].imshow(cv2.cvtColor(flow_frames[display_idx]['hsv'], cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 1].set_title('Dense Flow (HSV: Hue=Direction, Value=Magnitude)', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Arrow visualization\n",
    "    axes[1, 0].imshow(cv2.cvtColor(flow_frames[display_idx]['arrows'], cv2.COLOR_BGR2RGB))\n",
    "    axes[1, 0].set_title('Flow Vectors (Arrows)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Magnitude\n",
    "    axes[1, 1].imshow(cv2.cvtColor(flow_frames[display_idx]['magnitude'], cv2.COLOR_BGR2RGB))\n",
    "    axes[1, 1].set_title('Flow Magnitude (Speed)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Flow statistics\n",
    "    flow_data = flow_frames[display_idx]['flow']\n",
    "    mag, ang = cv2.cartToPolar(flow_data[..., 0], flow_data[..., 1])\n",
    "    \n",
    "    print('\\nğŸ“Š å…‰æµçµ±è¨ˆåˆ†æ:')\n",
    "    print('='*60)\n",
    "    print(f'å¹³å‡ä½ç§»é‡: {np.mean(mag):.3f} pixels')\n",
    "    print(f'æœ€å¤§ä½ç§»é‡: {np.max(mag):.3f} pixels')\n",
    "    print(f'é‹å‹•åƒç´ æ¯”ä¾‹: {np.sum(mag > 1.0) / mag.size * 100:.1f}%')\n",
    "    print(f'ä¸»è¦é‹å‹•æ–¹å‘: {np.degrees(np.mean(ang[mag > 1.0])):.1f}Â°')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farneback åƒæ•¸èª¿æ•´å°æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different parameter settings\n",
    "if len(flow_frames) > 0:\n",
    "    # Get two consecutive frames\n",
    "    gray1 = cv2.cvtColor(flow_frames[0]['original'], cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(flow_frames[5]['original'], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Test different parameters\n",
    "    param_sets = [\n",
    "        {'levels': 2, 'winsize': 10, 'name': 'Fast (Low Quality)'},\n",
    "        {'levels': 3, 'winsize': 15, 'name': 'Balanced [Default]'},\n",
    "        {'levels': 4, 'winsize': 20, 'name': 'High Quality (Slow)'},\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    print('\\nğŸ“Š Farneback åƒæ•¸å°æ¯”:')\n",
    "    print('='*60)\n",
    "    \n",
    "    for idx, params in enumerate(param_sets):\n",
    "        # Calculate flow with different parameters\n",
    "        test_params = farneback_params.copy()\n",
    "        test_params['levels'] = params['levels']\n",
    "        test_params['winsize'] = params['winsize']\n",
    "        \n",
    "        start = time.time()\n",
    "        flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, **test_params)\n",
    "        elapsed = (time.time() - start) * 1000\n",
    "        \n",
    "        # Visualize\n",
    "        flow_vis = draw_hsv_flow(flow)\n",
    "        \n",
    "        axes[idx].imshow(cv2.cvtColor(flow_vis, cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f\"{params['name']}\\n{elapsed:.1f} ms\", \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        print(f\"{params['name']:20} | Levels: {params['levels']} | \"\n",
    "              f\"WinSize: {params['winsize']} | Time: {elapsed:.1f} ms\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nğŸ’¡ åƒæ•¸èª¿æ•´å»ºè­°:')\n",
    "    print('   - levels é«˜: å¯è™•ç†æ›´å¤§çš„é‹å‹•ï¼Œä½†è¨ˆç®—æ…¢')\n",
    "    print('   - winsize å¤§: å…‰æµæ›´å¹³æ»‘ï¼Œä½†ç´°ç¯€è¼ƒå°‘')\n",
    "    print('   - poly_n (5/7): 5 è¼ƒå¿«ï¼Œ7 è¼ƒæº–ç¢º')\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 4. ç¨€ç–å…‰æµ vs ç¨ å¯†å…‰æµæ¯”è¼ƒ\n",
    "\n",
    "## 4-1: è¦–è¦ºåŒ–æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison of sparse and dense optical flow\n",
    "\n",
    "# Load or create test frames\n",
    "video_path = '../assets/videos/car_chase_01.mp4'\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame1 = cap.read()\n",
    "    frame1 = cv2.resize(frame1, (640, 360))\n",
    "    \n",
    "    for _ in range(5):\n",
    "        ret, frame2 = cap.read()\n",
    "    frame2 = cv2.resize(frame2, (640, 360))\n",
    "    cap.release()\n",
    "else:\n",
    "    frame1 = frames[0]\n",
    "    frame2 = frames[5]\n",
    "\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 1. Lucas-Kanade (Sparse)\n",
    "p0 = cv2.goodFeaturesToTrack(gray1, maxCorners=200, qualityLevel=0.3, \n",
    "                             minDistance=7, blockSize=7)\n",
    "\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "start_lk = time.time()\n",
    "p1, st, err = cv2.calcOpticalFlowPyrLK(gray1, gray2, p0, None, **lk_params)\n",
    "time_lk = (time.time() - start_lk) * 1000\n",
    "\n",
    "# Visualize sparse flow\n",
    "frame_lk = frame2.copy()\n",
    "if p1 is not None:\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "    \n",
    "    for new, old in zip(good_new, good_old):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        frame_lk = cv2.arrowedLine(frame_lk, (int(c), int(d)), (int(a), int(b)),\n",
    "                                   (0, 255, 0), 2, tipLength=0.3)\n",
    "        frame_lk = cv2.circle(frame_lk, (int(a), int(b)), 3, (0, 0, 255), -1)\n",
    "\n",
    "# 2. Farneback (Dense)\n",
    "start_fb = time.time()\n",
    "flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "time_fb = (time.time() - start_fb) * 1000\n",
    "\n",
    "frame_fb = draw_hsv_flow(flow)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Frame t', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Frame t+1', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(frame_lk, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title(f'Lucas-Kanade (Sparse)\\n'\n",
    "                    f'{len(good_new)} points tracked | {time_lk:.1f} ms',\n",
    "                    fontsize=14, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(frame_fb, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f'Farneback (Dense)\\n'\n",
    "                    f'{flow.shape[0]*flow.shape[1]} vectors | {time_fb:.1f} ms',\n",
    "                    fontsize=14, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nğŸ“Š ç¨€ç– vs ç¨ å¯†å…‰æµæ¯”è¼ƒ:')\n",
    "print('='*60)\n",
    "print(f'Lucas-Kanade (ç¨€ç–):')\n",
    "print(f'  - è¿½è¹¤é»æ•¸: {len(good_new)}')\n",
    "print(f'  - è¨ˆç®—æ™‚é–“: {time_lk:.2f} ms')\n",
    "print(f'  - è¨˜æ†¶é«”: ä½ (åªå„²å­˜ç‰¹å¾µé»)')\n",
    "print(f'  - é©ç”¨: ç‰©é«”è¿½è¹¤ã€ç›¸æ©Ÿé‹å‹•ä¼°è¨ˆ')\n",
    "print()\n",
    "print(f'Farneback (ç¨ å¯†):')\n",
    "print(f'  - å‘é‡æ•¸é‡: {flow.shape[0] * flow.shape[1]:,}')\n",
    "print(f'  - è¨ˆç®—æ™‚é–“: {time_fb:.2f} ms')\n",
    "print(f'  - è¨˜æ†¶é«”: é«˜ (å„²å­˜æ‰€æœ‰åƒç´ )')\n",
    "print(f'  - é©ç”¨: é‹å‹•åˆ†æã€è¦–é »ç©©å®šã€è¦–è¦ºæ•ˆæœ')\n",
    "print()\n",
    "print(f'é€Ÿåº¦æ¯”: Lucas-Kanade å¿« {time_fb/time_lk:.1f}x')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2: ç‰¹æ€§å°æ¯”è¡¨\n",
    "\n",
    "| ç‰¹æ€§ | Lucas-Kanade (ç¨€ç–) | Farneback (ç¨ å¯†) |\n",
    "|------|-------------------|----------------|\n",
    "| **è¨ˆç®—ç¯„åœ** | é¸å®šçš„ç‰¹å¾µé» | æ‰€æœ‰åƒç´  |\n",
    "| **è¼¸å‡º** | Nå€‹å‘é‡ (N<1000) | HÃ—W å€‹å‘é‡ (>100,000) |\n",
    "| **é€Ÿåº¦** | âš¡âš¡âš¡ å¿« | â­â­ è¼ƒæ…¢ |\n",
    "| **è¨˜æ†¶é«”** | ä½ | é«˜ |\n",
    "| **æº–ç¢ºåº¦** | é«˜ (ç‰¹å¾µé»è™•) | ä¸­ç­‰ (å…¨åŸŸ) |\n",
    "| **é©ç”¨å ´æ™¯** | ç‰©é«”è¿½è¹¤ã€SLAM | é‹å‹•åˆ†æã€è¦–é »ç©©å®š |\n",
    "| **å¯¦æ™‚æ€§** | âœ… é©åˆ | âš ï¸ éœ€è¦å„ªåŒ– |\n",
    "| **é­¯æ£’æ€§** | ä¾è³´ç‰¹å¾µæª¢æ¸¬ | å°ç´‹ç†æ•æ„Ÿ |\n",
    "\n",
    "## 4-3: æ‡‰ç”¨å ´æ™¯æ±ºç­–æ¨¹\n",
    "\n",
    "```\n",
    "é¸æ“‡å…‰æµæ–¹æ³•?\n",
    "â”œâ”€ éœ€è¦è¿½è¹¤ç‰¹å®šç‰©é«”?\n",
    "â”‚   â””â”€ æ˜¯ â†’ Lucas-Kanade (ç¨€ç–å…‰æµ)\n",
    "â”‚\n",
    "â”œâ”€ éœ€è¦åˆ†ææ•´é«”é‹å‹•æ¨¡å¼?\n",
    "â”‚   â””â”€ æ˜¯ â†’ Farneback (ç¨ å¯†å…‰æµ)\n",
    "â”‚\n",
    "â”œâ”€ éœ€è¦å¯¦æ™‚è™•ç† (>30 FPS)?\n",
    "â”‚   â””â”€ æ˜¯ â†’ Lucas-Kanade\n",
    "â”‚\n",
    "â”œâ”€ éœ€è¦è¦–é »ç©©å®šæˆ–ç‰¹æ•ˆ?\n",
    "â”‚   â””â”€> æ˜¯ â†’ Farneback\n",
    "â”‚\n",
    "â””â”€ é«˜ç²¾åº¦ç‰©é«”è¿½è¹¤?\n",
    "    â””â”€ ä½¿ç”¨ Lucas-Kanade + å¡çˆ¾æ›¼æ¿¾æ³¢\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 5. å¤šç›®æ¨™è¿½è¹¤åŸºç¤\n",
    "\n",
    "## 5-1: å¤šç›®æ¨™è¿½è¹¤æ¦‚è¿°\n",
    "\n",
    "> **å¤šç›®æ¨™è¿½è¹¤ (Multi-Object Tracking, MOT)** æ˜¯åœ¨è¦–é »åºåˆ—ä¸­åŒæ™‚è¿½è¹¤å¤šå€‹ç›®æ¨™ç‰©é«”çš„æŠ€è¡“ã€‚\n",
    "\n",
    "### æ ¸å¿ƒæŒ‘æˆ°\n",
    "\n",
    "```\n",
    "å¤šç›®æ¨™è¿½è¹¤çš„æŒ‘æˆ°:\n",
    "\n",
    "1. æ•¸æ“šé—œè¯ (Data Association)\n",
    "   â””â”€> å°‡æª¢æ¸¬çµæœèˆ‡å·²æœ‰è»Œè·¡é…å°\n",
    "\n",
    "2. é®æ“‹è™•ç† (Occlusion Handling)\n",
    "   â””â”€> ç‰©é«”è¢«é®æ“‹æ™‚å¦‚ä½•ç¶­æŒè¿½è¹¤\n",
    "\n",
    "3. ç›®æ¨™å¤–è§€è®ŠåŒ–\n",
    "   â””â”€> å…‰ç…§ã€è¦–è§’ã€å§¿æ…‹è®ŠåŒ–\n",
    "\n",
    "4. æ–°ç›®æ¨™é€²å…¥èˆ‡é›¢é–‹\n",
    "   â””â”€> å‹•æ…‹ç®¡ç†è¿½è¹¤ç›®æ¨™\n",
    "```\n",
    "\n",
    "### è¿½è¹¤æµç¨‹\n",
    "\n",
    "```\n",
    "MOT å…¸å‹æµç¨‹:\n",
    "\n",
    "Frame t\n",
    "  â†“\n",
    "1. ç‰©é«”æª¢æ¸¬ (Detection)\n",
    "  â””â”€> æ‰¾åˆ°æ‰€æœ‰å€™é¸ç›®æ¨™\n",
    "  â†“\n",
    "2. ç‰¹å¾µæå– (Feature Extraction)\n",
    "  â””â”€> è¨ˆç®—ç›®æ¨™ç‰¹å¾µ (ä½ç½®ã€å¤–è§€ã€é‹å‹•)\n",
    "  â†“\n",
    "3. æ•¸æ“šé—œè¯ (Data Association)\n",
    "  â””â”€> åŒ¹é…æª¢æ¸¬çµæœèˆ‡å·²æœ‰è»Œè·¡\n",
    "  â†“\n",
    "4. ç‹€æ…‹æ›´æ–° (State Update)\n",
    "  â””â”€> æ›´æ–°è»Œè·¡ç‹€æ…‹ (å¡çˆ¾æ›¼æ¿¾æ³¢)\n",
    "  â†“\n",
    "5. è»Œè·¡ç®¡ç† (Track Management)\n",
    "  â””â”€> å‰µå»ºã€ç¶­è­·ã€åˆªé™¤è»Œè·¡\n",
    "```\n",
    "\n",
    "## 5-2: åŸºæ–¼å…‰æµçš„å¤šç›®æ¨™è¿½è¹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTracker:\n",
    "    \"\"\"\n",
    "    Simple multi-object tracker using optical flow\n",
    "    \"\"\"\n",
    "    def __init__(self, max_age=30, min_hits=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_age: Maximum frames to keep lost tracks\n",
    "            min_hits: Minimum detections before confirmed track\n",
    "        \"\"\"\n",
    "        self.tracks = []  # List of active tracks\n",
    "        self.next_id = 0\n",
    "        self.max_age = max_age\n",
    "        self.min_hits = min_hits\n",
    "        \n",
    "        # Lucas-Kanade parameters\n",
    "        self.lk_params = dict(\n",
    "            winSize=(21, 21),\n",
    "            maxLevel=3,\n",
    "            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "        )\n",
    "    \n",
    "    def update(self, frame, detections):\n",
    "        \"\"\"\n",
    "        Update tracker with new frame and detections\n",
    "        \n",
    "        Args:\n",
    "            frame: Current frame (grayscale)\n",
    "            detections: List of detected bounding boxes [(x, y, w, h), ...]\n",
    "        \n",
    "        Returns:\n",
    "            tracks: List of active tracks with IDs\n",
    "        \"\"\"\n",
    "        # Initialize tracks from detections if first frame\n",
    "        if len(self.tracks) == 0:\n",
    "            for det in detections:\n",
    "                self.tracks.append({\n",
    "                    'id': self.next_id,\n",
    "                    'bbox': det,\n",
    "                    'age': 0,\n",
    "                    'hits': 1,\n",
    "                    'points': self._get_feature_points(frame, det),\n",
    "                    'prev_frame': frame.copy()\n",
    "                })\n",
    "                self.next_id += 1\n",
    "            return self.tracks\n",
    "        \n",
    "        # Track existing points using optical flow\n",
    "        for track in self.tracks:\n",
    "            if track['points'] is not None and len(track['points']) > 0:\n",
    "                # Calculate optical flow\n",
    "                new_points, status, _ = cv2.calcOpticalFlowPyrLK(\n",
    "                    track['prev_frame'], frame, track['points'], None, **self.lk_params\n",
    "                )\n",
    "                \n",
    "                if new_points is not None:\n",
    "                    good_new = new_points[status == 1]\n",
    "                    \n",
    "                    if len(good_new) > 0:\n",
    "                        # Update bounding box based on tracked points\n",
    "                        x_coords = good_new[:, 0]\n",
    "                        y_coords = good_new[:, 1]\n",
    "                        \n",
    "                        x = int(np.min(x_coords))\n",
    "                        y = int(np.min(y_coords))\n",
    "                        w = int(np.max(x_coords) - x)\n",
    "                        h = int(np.max(y_coords) - y)\n",
    "                        \n",
    "                        track['bbox'] = (x, y, w, h)\n",
    "                        track['points'] = good_new.reshape(-1, 1, 2)\n",
    "                        track['age'] = 0  # Reset age\n",
    "                    else:\n",
    "                        track['age'] += 1\n",
    "                else:\n",
    "                    track['age'] += 1\n",
    "            else:\n",
    "                track['age'] += 1\n",
    "            \n",
    "            track['prev_frame'] = frame.copy()\n",
    "        \n",
    "        # Remove old tracks\n",
    "        self.tracks = [t for t in self.tracks if t['age'] < self.max_age]\n",
    "        \n",
    "        # Add new detections (simple: add if far from existing tracks)\n",
    "        for det in detections:\n",
    "            is_new = True\n",
    "            for track in self.tracks:\n",
    "                if self._bbox_iou(det, track['bbox']) > 0.3:\n",
    "                    is_new = False\n",
    "                    # Refresh feature points\n",
    "                    track['points'] = self._get_feature_points(frame, det)\n",
    "                    track['hits'] += 1\n",
    "                    break\n",
    "            \n",
    "            if is_new:\n",
    "                self.tracks.append({\n",
    "                    'id': self.next_id,\n",
    "                    'bbox': det,\n",
    "                    'age': 0,\n",
    "                    'hits': 1,\n",
    "                    'points': self._get_feature_points(frame, det),\n",
    "                    'prev_frame': frame.copy()\n",
    "                })\n",
    "                self.next_id += 1\n",
    "        \n",
    "        return [t for t in self.tracks if t['hits'] >= self.min_hits]\n",
    "    \n",
    "    def _get_feature_points(self, frame, bbox):\n",
    "        \"\"\"Extract feature points within bounding box\"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        \n",
    "        # Ensure bbox is within frame\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        w = min(w, frame.shape[1] - x)\n",
    "        h = min(h, frame.shape[0] - y)\n",
    "        \n",
    "        if w <= 0 or h <= 0:\n",
    "            return None\n",
    "        \n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        if roi.size == 0:\n",
    "            return None\n",
    "        \n",
    "        # Detect features in ROI\n",
    "        points = cv2.goodFeaturesToTrack(roi, maxCorners=20, qualityLevel=0.01,\n",
    "                                        minDistance=5, blockSize=7)\n",
    "        \n",
    "        if points is not None:\n",
    "            # Offset points to global coordinates\n",
    "            points[:, :, 0] += x\n",
    "            points[:, :, 1] += y\n",
    "            return points\n",
    "        return None\n",
    "    \n",
    "    def _bbox_iou(self, bbox1, bbox2):\n",
    "        \"\"\"Calculate IoU between two bounding boxes\"\"\"\n",
    "        x1, y1, w1, h1 = bbox1\n",
    "        x2, y2, w2, h2 = bbox2\n",
    "        \n",
    "        # Calculate intersection\n",
    "        xi1 = max(x1, x2)\n",
    "        yi1 = max(y1, y2)\n",
    "        xi2 = min(x1 + w1, x2 + w2)\n",
    "        yi2 = min(y1 + h1, y2 + h2)\n",
    "        \n",
    "        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "        \n",
    "        # Calculate union\n",
    "        box1_area = w1 * h1\n",
    "        box2_area = w2 * h2\n",
    "        union_area = box1_area + box2_area - inter_area\n",
    "        \n",
    "        return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "print('âœ… SimpleTracker class defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¤šç›®æ¨™è¿½è¹¤ç¤ºç¯„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate multi-object tracking\n",
    "\n",
    "# For demonstration, we'll create synthetic detections\n",
    "# In real applications, use object detection models (YOLO, SSD, etc.)\n",
    "\n",
    "def simulate_detections(frame_idx, num_frames):\n",
    "    \"\"\"\n",
    "    Simulate object detections for demonstration\n",
    "    In practice, use real object detector\n",
    "    \"\"\"\n",
    "    detections = []\n",
    "    \n",
    "    # Simulate two moving objects\n",
    "    # Object 1: moving right\n",
    "    x1 = 50 + frame_idx * 10\n",
    "    y1 = 100\n",
    "    if x1 < 550:\n",
    "        detections.append((x1, y1, 80, 80))\n",
    "    \n",
    "    # Object 2: moving diagonally\n",
    "    x2 = 500 - frame_idx * 8\n",
    "    y2 = 50 + frame_idx * 5\n",
    "    if x2 > 50 and y2 < 300:\n",
    "        detections.append((x2, y2, 60, 60))\n",
    "    \n",
    "    # Object 3: appears later\n",
    "    if frame_idx > 15:\n",
    "        x3 = 300\n",
    "        y3 = 200 + (frame_idx - 15) * 3\n",
    "        if y3 < 320:\n",
    "            detections.append((x3, y3, 70, 70))\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "# Create synthetic video for tracking\n",
    "tracker = SimpleTracker(max_age=10, min_hits=2)\n",
    "tracking_frames = []\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]\n",
    "\n",
    "num_frames = 40\n",
    "\n",
    "for frame_idx in range(num_frames):\n",
    "    # Create frame\n",
    "    frame = np.ones((400, 640, 3), dtype=np.uint8) * 255\n",
    "    \n",
    "    # Get simulated detections\n",
    "    detections = simulate_detections(frame_idx, num_frames)\n",
    "    \n",
    "    # Draw detections (dashed rectangles)\n",
    "    for det in detections:\n",
    "        x, y, w, h = det\n",
    "        # Draw dashed rectangle\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (128, 128, 128), 1, cv2.LINE_AA)\n",
    "        # Fill with semi-transparent color\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (x, y), (x+w, y+h), (200, 200, 200), -1)\n",
    "        cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)\n",
    "    \n",
    "    # Convert to grayscale for tracking\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Update tracker\n",
    "    tracks = tracker.update(gray, detections)\n",
    "    \n",
    "    # Draw tracks\n",
    "    for track in tracks:\n",
    "        track_id = track['id']\n",
    "        x, y, w, h = track['bbox']\n",
    "        color = colors[track_id % len(colors)]\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)\n",
    "        \n",
    "        # Draw ID\n",
    "        cv2.putText(frame, f'ID: {track_id}', (x, y-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        # Draw tracked points\n",
    "        if track['points'] is not None:\n",
    "            for pt in track['points']:\n",
    "                px, py = pt.ravel()\n",
    "                cv2.circle(frame, (int(px), int(py)), 3, color, -1)\n",
    "    \n",
    "    # Add frame info\n",
    "    cv2.putText(frame, f'Frame: {frame_idx+1}/{num_frames}', (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "    cv2.putText(frame, f'Active Tracks: {len(tracks)}', (10, 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "    \n",
    "    tracking_frames.append(frame)\n",
    "\n",
    "# Display tracking results\n",
    "if len(tracking_frames) > 0:\n",
    "    display_indices = [0, 10, 20, 30, 39]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, i in enumerate(display_indices):\n",
    "        axes[idx].imshow(cv2.cvtColor(tracking_frames[i], cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f'Frame {i+1}', fontsize=14, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Legend\n",
    "    axes[5].text(0.1, 0.9, 'Legend:', fontsize=14, fontweight='bold', \n",
    "                transform=axes[5].transAxes)\n",
    "    axes[5].text(0.1, 0.7, 'â–  Gray dashed box: Detection', fontsize=12,\n",
    "                transform=axes[5].transAxes, color='gray')\n",
    "    axes[5].text(0.1, 0.5, 'â–  Colored solid box: Tracked object', fontsize=12,\n",
    "                transform=axes[5].transAxes, color='blue')\n",
    "    axes[5].text(0.1, 0.3, 'â— Points: Tracked features', fontsize=12,\n",
    "                transform=axes[5].transAxes)\n",
    "    axes[5].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nâœ… å¤šç›®æ¨™è¿½è¹¤æ¼”ç¤ºå®Œæˆ')\n",
    "    print('='*60)\n",
    "    print('è§€å¯Ÿ:')\n",
    "    print('  1. æ¯å€‹ç›®æ¨™è¢«åˆ†é…å”¯ä¸€ ID')\n",
    "    print('  2. ä½¿ç”¨å…‰æµè¿½è¹¤ç‰¹å¾µé»')\n",
    "    print('  3. æ–°ç›®æ¨™å‡ºç¾æ™‚è‡ªå‹•åˆ†é…æ–° ID')\n",
    "    print('  4. å¤±å»è¿½è¹¤çš„ç›®æ¨™æœƒåœ¨ä¸€æ®µæ™‚é–“å¾Œè¢«ç§»é™¤')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 6. å¡çˆ¾æ›¼æ¿¾æ³¢å™¨åŸºç¤ (é€²éš)\n",
    "\n",
    "## 6-1: å¡çˆ¾æ›¼æ¿¾æ³¢å™¨æ¦‚è¿°\n",
    "\n",
    "> **å¡çˆ¾æ›¼æ¿¾æ³¢å™¨ (Kalman Filter)** æ˜¯ä¸€ç¨®éè¿´è²è‘‰æ–¯æ¿¾æ³¢å™¨ï¼Œç”¨æ–¼ä¼°è¨ˆå‹•æ…‹ç³»çµ±çš„ç‹€æ…‹ã€‚\n",
    "\n",
    "### ç‚ºä»€éº¼éœ€è¦å¡çˆ¾æ›¼æ¿¾æ³¢ï¼Ÿ\n",
    "\n",
    "```\n",
    "ç‰©é«”è¿½è¹¤ä¸­çš„å•é¡Œ:\n",
    "\n",
    "1. æ¸¬é‡å™ªè²\n",
    "   â””â”€> æª¢æ¸¬å™¨ä¸å®Œç¾ï¼Œä½ç½®æœ‰èª¤å·®\n",
    "\n",
    "2. æš«æ™‚é®æ“‹\n",
    "   â””â”€> ç‰©é«”è¢«é®æ“‹æ™‚ç„¡æ³•æª¢æ¸¬\n",
    "\n",
    "3. é‹å‹•é æ¸¬\n",
    "   â””â”€> éœ€è¦é æ¸¬ä¸‹ä¸€å¹€çš„ä½ç½®\n",
    "\n",
    "å¡çˆ¾æ›¼æ¿¾æ³¢çš„è§£æ±ºæ–¹æ¡ˆ:\n",
    "- èåˆé æ¸¬å€¼èˆ‡æ¸¬é‡å€¼\n",
    "- ä¼°è¨ˆæœ€å„ªç‹€æ…‹\n",
    "- æä¾›ä¸ç¢ºå®šæ€§åº¦é‡\n",
    "```\n",
    "\n",
    "### å¡çˆ¾æ›¼æ¿¾æ³¢å™¨çš„å…©å€‹æ­¥é©Ÿ\n",
    "\n",
    "> **1. é æ¸¬ (Prediction)**:\n",
    ">\n",
    "> $$\\hat{x}_{k|k-1} = F_k \\hat{x}_{k-1|k-1} + B_k u_k$$\n",
    "> $$P_{k|k-1} = F_k P_{k-1|k-1} F_k^T + Q_k$$\n",
    ">\n",
    "> **2. æ›´æ–° (Update)**:\n",
    ">\n",
    "> $$K_k = P_{k|k-1} H_k^T (H_k P_{k|k-1} H_k^T + R_k)^{-1}$$\n",
    "> $$\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k (z_k - H_k \\hat{x}_{k|k-1})$$\n",
    "> $$P_{k|k} = (I - K_k H_k) P_{k|k-1}$$\n",
    "\n",
    "### çŸ©é™£èªªæ˜\n",
    "\n",
    "| çŸ©é™£ | åç¨± | èªªæ˜ |\n",
    "|------|------|------|\n",
    "| $F_k$ | ç‹€æ…‹è½‰ç§»çŸ©é™£ | æè¿°ç‹€æ…‹å¦‚ä½•éš¨æ™‚é–“è®ŠåŒ– |\n",
    "| $H_k$ | è§€æ¸¬çŸ©é™£ | å°‡ç‹€æ…‹æ˜ å°„åˆ°æ¸¬é‡ç©ºé–“ |\n",
    "| $Q_k$ | éç¨‹å™ªè²å”æ–¹å·® | æ¨¡å‹ä¸ç¢ºå®šæ€§ |\n",
    "| $R_k$ | æ¸¬é‡å™ªè²å”æ–¹å·® | æ¸¬é‡ä¸ç¢ºå®šæ€§ |\n",
    "| $K_k$ | å¡çˆ¾æ›¼å¢ç›Š | æ±ºå®šä¿¡ä»»é æ¸¬é‚„æ˜¯æ¸¬é‡ |\n",
    "\n",
    "## 6-2: ç°¡å–®çš„ 1D è¿½è¹¤ç¯„ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleKalmanFilter:\n",
    "    \"\"\"\n",
    "    Simple 1D Kalman Filter for demonstration\n",
    "    State: [position, velocity]\n",
    "    \"\"\"\n",
    "    def __init__(self, process_noise=0.1, measurement_noise=1.0):\n",
    "        # State: [position, velocity]\n",
    "        self.x = np.array([[0.0], [0.0]])  # Initial state\n",
    "        \n",
    "        # State covariance\n",
    "        self.P = np.eye(2) * 1000  # High uncertainty initially\n",
    "        \n",
    "        # State transition matrix (constant velocity model)\n",
    "        dt = 1.0  # Time step\n",
    "        self.F = np.array([[1, dt],\n",
    "                          [0, 1]])\n",
    "        \n",
    "        # Observation matrix (we only measure position)\n",
    "        self.H = np.array([[1, 0]])\n",
    "        \n",
    "        # Process noise covariance\n",
    "        self.Q = np.eye(2) * process_noise\n",
    "        \n",
    "        # Measurement noise covariance\n",
    "        self.R = np.array([[measurement_noise]])\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Prediction step\n",
    "        \"\"\"\n",
    "        # Predict state\n",
    "        self.x = self.F @ self.x\n",
    "        \n",
    "        # Predict covariance\n",
    "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
    "        \n",
    "        return self.x[0, 0]\n",
    "    \n",
    "    def update(self, measurement):\n",
    "        \"\"\"\n",
    "        Update step with measurement\n",
    "        \"\"\"\n",
    "        # Measurement residual\n",
    "        y = np.array([[measurement]]) - self.H @ self.x\n",
    "        \n",
    "        # Residual covariance\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        \n",
    "        # Kalman gain\n",
    "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
    "        \n",
    "        # Update state\n",
    "        self.x = self.x + K @ y\n",
    "        \n",
    "        # Update covariance\n",
    "        I = np.eye(2)\n",
    "        self.P = (I - K @ self.H) @ self.P\n",
    "        \n",
    "        return self.x[0, 0]\n",
    "\n",
    "# Demonstrate Kalman Filter\n",
    "print('\\nğŸ“Š å¡çˆ¾æ›¼æ¿¾æ³¢å™¨æ¼”ç¤º (1D è¿½è¹¤):')\n",
    "print('='*60)\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "true_positions = np.linspace(0, 100, 50) + np.sin(np.linspace(0, 4*np.pi, 50)) * 5\n",
    "measurements = true_positions + np.random.randn(50) * 3  # Add noise\n",
    "\n",
    "# Apply Kalman filter\n",
    "kf = SimpleKalmanFilter(process_noise=0.1, measurement_noise=3.0)\n",
    "filtered_positions = []\n",
    "predicted_positions = []\n",
    "\n",
    "for measurement in measurements:\n",
    "    # Predict\n",
    "    prediction = kf.predict()\n",
    "    predicted_positions.append(prediction)\n",
    "    \n",
    "    # Update with measurement\n",
    "    filtered = kf.update(measurement)\n",
    "    filtered_positions.append(filtered)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(true_positions, 'g-', linewidth=2, label='True Position', alpha=0.7)\n",
    "plt.plot(measurements, 'rx', markersize=8, label='Noisy Measurements', alpha=0.5)\n",
    "plt.plot(filtered_positions, 'b-', linewidth=2, label='Kalman Filter Output')\n",
    "plt.plot(predicted_positions, 'y--', linewidth=1.5, label='Predictions', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Time Step', fontsize=12)\n",
    "plt.ylabel('Position', fontsize=12)\n",
    "plt.title('Kalman Filter: Smoothing Noisy Measurements', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate errors\n",
    "measurement_error = np.mean(np.abs(measurements - true_positions))\n",
    "filtered_error = np.mean(np.abs(np.array(filtered_positions) - true_positions))\n",
    "\n",
    "print(f'å¹³å‡æ¸¬é‡èª¤å·®: {measurement_error:.2f}')\n",
    "print(f'å¹³å‡æ¿¾æ³¢èª¤å·®: {filtered_error:.2f}')\n",
    "print(f'èª¤å·®é™ä½: {(1 - filtered_error/measurement_error)*100:.1f}%')\n",
    "print('\\nğŸ’¡ å¡çˆ¾æ›¼æ¿¾æ³¢å™¨çš„æ•ˆæœ:')\n",
    "print('   - å¹³æ»‘å™ªè²æ¸¬é‡')\n",
    "   '   - é æ¸¬æœªä¾†ä½ç½®')\n",
    "print('   - æ¸›å°‘èª¤å·®')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3: å¡çˆ¾æ›¼æ¿¾æ³¢å™¨åœ¨ç‰©é«”è¿½è¹¤ä¸­çš„æ‡‰ç”¨\n",
    "\n",
    "### å¸¸ç”¨ç‹€æ…‹æ¨¡å‹\n",
    "\n",
    "```python\n",
    "# 1. æ†é€Ÿæ¨¡å‹ (Constant Velocity)\n",
    "# State: [x, y, vx, vy]\n",
    "state = [position_x, position_y, velocity_x, velocity_y]\n",
    "\n",
    "# 2. æ†åŠ é€Ÿåº¦æ¨¡å‹ (Constant Acceleration)\n",
    "# State: [x, y, vx, vy, ax, ay]\n",
    "state = [position_x, position_y, velocity_x, velocity_y, accel_x, accel_y]\n",
    "\n",
    "# 3. ä¸­å¿ƒé»+å°ºå¯¸æ¨¡å‹ (Center + Scale)\n",
    "# State: [cx, cy, w, h, vx, vy, vw, vh]\n",
    "state = [center_x, center_y, width, height, v_x, v_y, v_w, v_h]\n",
    "```\n",
    "\n",
    "### å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹\n",
    "\n",
    "| æ‡‰ç”¨ | ç‹€æ…‹æ¨¡å‹ | ç‰¹é» |\n",
    "|------|---------|------|\n",
    "| **è¡Œäººè¿½è¹¤** | æ†é€Ÿæ¨¡å‹ | é‹å‹•ç›¸å°å¹³æ»‘ |\n",
    "| **è»Šè¼›è¿½è¹¤** | æ†é€Ÿ/æ†åŠ é€Ÿ | éœ€è€ƒæ…®åŠ é€Ÿåº¦ |\n",
    "| **ç„¡äººæ©Ÿè¿½è¹¤** | ä¸­å¿ƒé»+å°ºå¯¸ | å°ºåº¦è®ŠåŒ–å¤§ |\n",
    "| **é‹å‹•åˆ†æ** | é—œç¯€é»æ¨¡å‹ | å¤šå€‹é—œéµé» |\n",
    "\n",
    "### é€²éš: SORT / DeepSORT\n",
    "\n",
    "> **SORT** (Simple Online and Realtime Tracking):\n",
    "> * çµåˆå¡çˆ¾æ›¼æ¿¾æ³¢å™¨èˆ‡åŒˆç‰™åˆ©ç®—æ³•\n",
    "> * ç”¨æ–¼æ•¸æ“šé—œè¯\n",
    "> * é©åˆå¯¦æ™‚è¿½è¹¤\n",
    ">\n",
    "> **DeepSORT**:\n",
    "> * SORT + æ·±åº¦å¤–è§€ç‰¹å¾µ\n",
    "> * ä½¿ç”¨ CNN æå–å¤–è§€ç‰¹å¾µ\n",
    "> * æ›´å¼·çš„é®æ“‹è™•ç†èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 7. å¯¦æˆ°ç·´ç¿’\n",
    "\n",
    "## ç·´ç¿’ 1: è¦–é »ç‰¹å¾µé»è¿½è¹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ç¾è¦–é »ç‰¹å¾µé»è¿½è¹¤\n",
    "# ä»»å‹™: ä½¿ç”¨ Lucas-Kanade è¿½è¹¤è¦–é »ä¸­çš„ç‰¹å¾µé»ï¼Œç¹ªè£½é‹å‹•è»Œè·¡\n",
    "\n",
    "print('\\nğŸ“ ç·´ç¿’ 1: è¦–é »ç‰¹å¾µé»è¿½è¹¤')\n",
    "print('='*60)\n",
    "print('ä»»å‹™:')\n",
    "print('  1. è®€å–è¦–é »æ–‡ä»¶')\n",
    "print('  2. ä½¿ç”¨ Shi-Tomasi æª¢æ¸¬ç¬¬ä¸€å¹€çš„ç‰¹å¾µé»')\n",
    "print('  3. ä½¿ç”¨ Lucas-Kanade è¿½è¹¤ç‰¹å¾µé»')\n",
    "print('  4. ç¹ªè£½è¿½è¹¤è»Œè·¡')\n",
    "print('  5. çµ±è¨ˆè¿½è¹¤æˆåŠŸç‡')\n",
    "print('\\næç¤º:')\n",
    "print('  - ä½¿ç”¨ cv2.goodFeaturesToTrack() æª¢æ¸¬ç‰¹å¾µ')\n",
    "print('  - ä½¿ç”¨ cv2.calcOpticalFlowPyrLK() è¿½è¹¤')\n",
    "print('  - æ ¹æ“š status éæ¿¾å¤±æ•—çš„è¿½è¹¤')\n",
    "print('='*60)\n",
    "\n",
    "# Solution framework\n",
    "def track_video_features(video_path, max_frames=50):\n",
    "    \"\"\"\n",
    "    Track features in video using Lucas-Kanade\n",
    "    \"\"\"\n",
    "    # TODO: Implement feature tracking\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Uncomment to test\n",
    "# track_video_features('../assets/videos/car_chase_01.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç·´ç¿’ 2: é‹å‹•å‘é‡è¦–è¦ºåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ç¾é‹å‹•å‘é‡è¦–è¦ºåŒ–\n",
    "# ä»»å‹™: ä½¿ç”¨ Farneback è¨ˆç®—ç¨ å¯†å…‰æµï¼Œä¸¦é€²è¡Œå¤šç¨®è¦–è¦ºåŒ–\n",
    "\n",
    "print('\\nğŸ“ ç·´ç¿’ 2: é‹å‹•å‘é‡è¦–è¦ºåŒ–')\n",
    "print('='*60)\n",
    "print('ä»»å‹™:')\n",
    "print('  1. è®€å–é€£çºŒçš„å…©å¹€å½±åƒ')\n",
    "print('  2. ä½¿ç”¨ Farneback è¨ˆç®—ç¨ å¯†å…‰æµ')\n",
    "print('  3. å¯¦ç¾ä¸‰ç¨®è¦–è¦ºåŒ–æ–¹å¼:')\n",
    "print('     a) HSV é¡è‰²ç·¨ç¢¼')\n",
    "print('     b) ç®­é ­å‘é‡å ´')\n",
    "print('     c) é‹å‹•å¹…åº¦ç†±åŠ›åœ–')\n",
    "print('  4. åˆ†æé‹å‹•çµ±è¨ˆ (å¹³å‡é€Ÿåº¦ã€æ–¹å‘åˆ†ä½ˆ)')\n",
    "print('\\næç¤º:')\n",
    "print('  - ä½¿ç”¨ cv2.calcOpticalFlowFarneback()')\n",
    "print('  - ä½¿ç”¨ cv2.cartToPolar() è½‰æ›ç‚ºæ¥µåº§æ¨™')\n",
    "print('  - åƒè€ƒæœ¬æ¨¡çµ„çš„ draw_flow() å’Œ draw_hsv_flow() å‡½æ•¸')\n",
    "print('='*60)\n",
    "\n",
    "# Solution framework\n",
    "def visualize_motion_vectors(frame1, frame2):\n",
    "    \"\"\"\n",
    "    Visualize optical flow in multiple ways\n",
    "    \"\"\"\n",
    "    # TODO: Implement motion vector visualization\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Uncomment to test\n",
    "# visualize_motion_vectors(frame1, frame2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç·´ç¿’ 3: ç°¡æ˜“ç‰©é«”è¿½è¹¤ç³»çµ± (æŒ‘æˆ°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ç¾ç°¡æ˜“ç‰©é«”è¿½è¹¤ç³»çµ±\n",
    "# ä»»å‹™: æ•´åˆç‰¹å¾µæª¢æ¸¬ã€å…‰æµè¿½è¹¤å’Œå¡çˆ¾æ›¼æ¿¾æ³¢\n",
    "\n",
    "print('\\nğŸ“ ç·´ç¿’ 3: ç°¡æ˜“ç‰©é«”è¿½è¹¤ç³»çµ± (æŒ‘æˆ°)')\n",
    "print('='*60)\n",
    "print('ä»»å‹™:')\n",
    "print('  1. è®“ç”¨æˆ¶åœ¨ç¬¬ä¸€å¹€é¸æ“‡è¿½è¹¤ç›®æ¨™ (ROI)')\n",
    "print('  2. ä½¿ç”¨å…‰æµæ³•è¿½è¹¤ç›®æ¨™')\n",
    "print('  3. ä½¿ç”¨å¡çˆ¾æ›¼æ¿¾æ³¢å™¨é æ¸¬ä½ç½®')\n",
    "print('  4. è™•ç†é®æ“‹æƒ…æ³ (ä¾è³´é æ¸¬)')\n",
    "print('  5. é¡¯ç¤ºè¿½è¹¤çµæœå’Œç½®ä¿¡åº¦')\n",
    "print('\\né€²éšæŒ‘æˆ°:')\n",
    "print('  - æ”¯æŒå¤šç›®æ¨™è¿½è¹¤')\n",
    "print('  - è‡ªå‹•é‡æ–°åˆå§‹åŒ–ä¸Ÿå¤±çš„è¿½è¹¤')\n",
    "print('  - æ·»åŠ è¿½è¹¤è³ªé‡è©•ä¼°')\n",
    "print('='*60)\n",
    "\n",
    "# Solution framework\n",
    "class ObjectTracker:\n",
    "    def __init__(self):\n",
    "        # TODO: Initialize tracker components\n",
    "        pass\n",
    "    \n",
    "    def initialize(self, frame, bbox):\n",
    "        # TODO: Initialize tracking with first frame and bbox\n",
    "        pass\n",
    "    \n",
    "    def update(self, frame):\n",
    "        # TODO: Update tracking with new frame\n",
    "        pass\n",
    "\n",
    "# Uncomment to test\n",
    "# tracker = ObjectTracker()\n",
    "# tracker.initialize(first_frame, bbox)\n",
    "# for frame in video_frames:\n",
    "#     result = tracker.update(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 8. ç¸½çµèˆ‡å»¶ä¼¸\n",
    "\n",
    "## 8-1: æ ¸å¿ƒè¦é»å›é¡§\n",
    "\n",
    "### å…‰æµæ³•\n",
    "\n",
    "> **Lucas-Kanade (ç¨€ç–å…‰æµ)**:\n",
    "> * ğŸ“Œ è¿½è¹¤ç‰¹å®šç‰¹å¾µé»\n",
    "> * ğŸ“Œ ä½¿ç”¨å±€éƒ¨é„°åŸŸå‡è¨­æ±‚è§£å…‰æµ\n",
    "> * ğŸ“Œ é‡‘å­—å¡”çµæ§‹è™•ç†å¤§ä½ç§»\n",
    "> * ğŸ“Œ é©åˆç‰©é«”è¿½è¹¤ã€è¦–è¦ºæ¸¬ç¨‹\n",
    ">\n",
    "> **Farneback (ç¨ å¯†å…‰æµ)**:\n",
    "> * ğŸ“Œ è¨ˆç®—æ‰€æœ‰åƒç´ çš„å…‰æµ\n",
    "> * ğŸ“Œ åŸºæ–¼å¤šé …å¼å±•é–‹\n",
    "> * ğŸ“Œ é©åˆé‹å‹•åˆ†æã€è¦–é »ç©©å®š\n",
    "> * ğŸ“Œ è¨ˆç®—é‡å¤§ï¼Œéœ€è¦å„ªåŒ–\n",
    "\n",
    "### ç‰©é«”è¿½è¹¤\n",
    "\n",
    "> **å¤šç›®æ¨™è¿½è¹¤æµç¨‹**:\n",
    "> 1. ç‰©é«”æª¢æ¸¬ (Detection)\n",
    "> 2. ç‰¹å¾µæå– (Feature Extraction)\n",
    "> 3. æ•¸æ“šé—œè¯ (Data Association)\n",
    "> 4. ç‹€æ…‹æ›´æ–° (State Update)\n",
    "> 5. è»Œè·¡ç®¡ç† (Track Management)\n",
    "\n",
    "### å¡çˆ¾æ›¼æ¿¾æ³¢å™¨\n",
    "\n",
    "> **å…©æ­¥é©Ÿæµç¨‹**:\n",
    "> 1. é æ¸¬ (Prediction): æ ¹æ“šé‹å‹•æ¨¡å‹é æ¸¬ç‹€æ…‹\n",
    "> 2. æ›´æ–° (Update): èåˆæ¸¬é‡å€¼æ ¡æ­£é æ¸¬\n",
    ">\n",
    "> **å„ªå‹¢**:\n",
    "> * å¹³æ»‘å™ªè²æ¸¬é‡\n",
    "> * é æ¸¬æœªä¾†ä½ç½®\n",
    "> * è™•ç†æš«æ™‚é®æ“‹\n",
    "\n",
    "## 8-2: æ€§èƒ½æ¯”è¼ƒç¸½çµ\n",
    "\n",
    "| æ–¹æ³• | é€Ÿåº¦ | æº–ç¢ºåº¦ | é­¯æ£’æ€§ | é©ç”¨å ´æ™¯ |\n",
    "|------|------|--------|--------|----------|\n",
    "| **Lucas-Kanade** | âš¡âš¡âš¡ | â­â­â­â­ | â­â­â­ | ç‰©é«”è¿½è¹¤ã€SLAM |\n",
    "| **Farneback** | â­â­ | â­â­â­ | â­â­â­ | é‹å‹•åˆ†æã€è¦–é »ç©©å®š |\n",
    "| **LK + Kalman** | âš¡âš¡ | â­â­â­â­â­ | â­â­â­â­ | é«˜ç²¾åº¦è¿½è¹¤ |\n",
    "| **DeepSORT** | â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | å¤šç›®æ¨™è¿½è¹¤ |\n",
    "\n",
    "## 8-3: æ‡‰ç”¨å ´æ™¯æ±ºç­–æ¨¹\n",
    "\n",
    "```\n",
    "é¸æ“‡è¿½è¹¤æ–¹æ³•?\n",
    "â”œâ”€ å–®ä¸€ç›®æ¨™è¿½è¹¤?\n",
    "â”‚   â”œâ”€ éœ€è¦å¯¦æ™‚ (>30 FPS)?\n",
    "â”‚   â”‚   â””â”€ Lucas-Kanade\n",
    "â”‚   â””â”€ éœ€è¦é«˜ç²¾åº¦?\n",
    "â”‚       â””â”€ Lucas-Kanade + Kalman Filter\n",
    "â”‚\n",
    "â”œâ”€ å¤šç›®æ¨™è¿½è¹¤?\n",
    "â”‚   â”œâ”€ ç°¡å–®å ´æ™¯?\n",
    "â”‚   â”‚   â””â”€ SORT (Kalman + Hungarian)\n",
    "â”‚   â””â”€ è¤‡é›œå ´æ™¯ (é®æ“‹å¤š)?\n",
    "â”‚       â””â”€ DeepSORT (SORT + Deep Features)\n",
    "â”‚\n",
    "â”œâ”€ é‹å‹•å ´åˆ†æ?\n",
    "â”‚   â””â”€ Farneback Dense Flow\n",
    "â”‚\n",
    "â””â”€ è¦–é »ç©©å®š?\n",
    "    â””â”€ Farneback + å¹³æ»‘è™•ç†\n",
    "```\n",
    "\n",
    "## 8-4: å¯¦ç”¨å»ºè­°\n",
    "\n",
    "### åƒæ•¸èª¿æ•´æŠ€å·§\n",
    "\n",
    "```python\n",
    "# Lucas-Kanade åƒæ•¸\n",
    "lk_params = dict(\n",
    "    winSize=(21, 21),      # å¤§ä½ç§»ç”¨å¤§çª—å£\n",
    "    maxLevel=3,            # é‡‘å­—å¡”å±¤æ•¸ï¼Œè™•ç†å¤§é‹å‹•\n",
    "    criteria=(...)         # è¿­ä»£çµ‚æ­¢æ¢ä»¶\n",
    ")\n",
    "\n",
    "# Farneback åƒæ•¸\n",
    "fb_params = dict(\n",
    "    pyr_scale=0.5,         # é‡‘å­—å¡”ç¸®æ”¾\n",
    "    levels=3,              # å±¤æ•¸è¶Šå¤šè¶Šæ…¢ä½†æ›´æº–ç¢º\n",
    "    winsize=15,            # çª—å£è¶Šå¤§è¶Šå¹³æ»‘\n",
    "    iterations=3,          # è¿­ä»£æ¬¡æ•¸\n",
    "    poly_n=5,              # 5 æˆ– 7\n",
    "    poly_sigma=1.2         # 1.1 ~ 1.5\n",
    ")\n",
    "```\n",
    "\n",
    "### æ€§èƒ½å„ªåŒ–å»ºè­°\n",
    "\n",
    "> 1. **å½±åƒé è™•ç†**:\n",
    ">    * é™ä½è§£æåº¦ (640x480 é€šå¸¸è¶³å¤ )\n",
    ">    * ä½¿ç”¨ ROI é™åˆ¶è™•ç†å€åŸŸ\n",
    ">    * é«˜æ–¯æ¨¡ç³Šå»å™ª\n",
    ">\n",
    "> 2. **ç‰¹å¾µé»ç®¡ç†**:\n",
    ">    * å®šæœŸé‡æ–°æª¢æ¸¬ç‰¹å¾µé»\n",
    ">    * ç§»é™¤å“è³ªå·®çš„è¿½è¹¤é»\n",
    ">    * ç¶­æŒé©ç•¶çš„ç‰¹å¾µé»å¯†åº¦\n",
    ">\n",
    "> 3. **å¤šç·šç¨‹åŠ é€Ÿ**:\n",
    ">    * æª¢æ¸¬å’Œè¿½è¹¤ä¸¦è¡Œè™•ç†\n",
    ">    * ä½¿ç”¨ GPU åŠ é€Ÿ (CUDA)\n",
    "\n",
    "## 8-5: å»¶ä¼¸å­¸ç¿’\n",
    "\n",
    "### é€²éšä¸»é¡Œ\n",
    "\n",
    "> * **æ·±åº¦å­¸ç¿’å…‰æµ**: FlowNet, PWC-Net, RAFT\n",
    "> * **3D é‹å‹•ä¼°è¨ˆ**: å ´æ™¯æµ (Scene Flow)\n",
    "> * **æ“´å±•å¡çˆ¾æ›¼æ¿¾æ³¢**: EKF, UKF\n",
    "> * **ç²’å­æ¿¾æ³¢å™¨**: éç·šæ€§è¿½è¹¤\n",
    "> * **è¦–è¦ºæ…£æ€§æ¸¬ç¨‹**: VIO (Visual-Inertial Odometry)\n",
    "\n",
    "### ä¸‹ä¸€æ­¥å­¸ç¿’\n",
    "\n",
    "- [x] è§’é»æª¢æ¸¬ (4.1.1) âœ…\n",
    "- [x] ç‰¹å¾µæè¿°å­ (4.1.2) âœ…\n",
    "- [x] ç‰©é«”è¿½è¹¤ (4.1.3) âœ… â† **ä½ åœ¨é€™è£¡**\n",
    "- [ ] æ·±åº¦å­¸ç¿’ç‰©é«”æª¢æ¸¬ (YOLO, SSD)\n",
    "- [ ] å¯¦æ™‚å¤šç›®æ¨™è¿½è¹¤å°ˆæ¡ˆ\n",
    "- [ ] SLAM (åŒæ­¥å®šä½èˆ‡åœ°åœ–æ§‹å»º)\n",
    "\n",
    "## 8-6: åƒè€ƒè³‡æº\n",
    "\n",
    "### è«–æ–‡\n",
    "\n",
    "> * **Lucas-Kanade**:  \n",
    ">   Lucas, B. D., & Kanade, T. (1981). \"An iterative image registration technique.\"\n",
    ">\n",
    "> * **Pyramidal Lucas-Kanade**:  \n",
    ">   Bouguet, J. Y. (2001). \"Pyramidal implementation of the Lucas Kanade feature tracker.\"\n",
    ">\n",
    "> * **Farneback**:  \n",
    ">   FarnebÃ¤ck, G. (2003). \"Two-frame motion estimation based on polynomial expansion.\"\n",
    ">\n",
    "> * **Kalman Filter**:  \n",
    ">   Kalman, R. E. (1960). \"A new approach to linear filtering and prediction problems.\"\n",
    ">\n",
    "> * **SORT**:  \n",
    ">   Bewley et al. (2016). \"Simple Online and Realtime Tracking.\"\n",
    ">\n",
    "> * **DeepSORT**:  \n",
    ">   Wojke et al. (2017). \"Simple Online and Realtime Tracking with a Deep Association Metric.\"\n",
    "\n",
    "### ç·šä¸Šè³‡æº\n",
    "\n",
    "> * OpenCV Optical Flow Tutorial: https://docs.opencv.org/master/d4/dee/tutorial_optical_flow.html\n",
    "> * Kalman Filter Explained: https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/\n",
    "> * Multiple Object Tracking: https://motchallenge.net/\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ å­¸ç¿’æˆæœæª¢æŸ¥æ¸…å–®\n",
    "\n",
    "å®Œæˆæœ¬æ¨¡çµ„å¾Œï¼Œä½ æ‡‰è©²èƒ½å¤ :\n",
    "\n",
    "- [ ] ç†è§£å…‰æµæ³•çš„åŸºæœ¬åŸç†å’Œå‡è¨­\n",
    "- [ ] å¯¦ç¾ Lucas-Kanade ç¨€ç–å…‰æµè¿½è¹¤\n",
    "- [ ] å¯¦ç¾ Farneback ç¨ å¯†å…‰æµåˆ†æ\n",
    "- [ ] æ¯”è¼ƒç¨€ç–å…‰æµå’Œç¨ å¯†å…‰æµçš„å·®ç•°\n",
    "- [ ] å»ºç«‹åŸºæœ¬çš„å¤šç›®æ¨™è¿½è¹¤ç³»çµ±\n",
    "- [ ] ç†è§£å¡çˆ¾æ›¼æ¿¾æ³¢å™¨çš„å·¥ä½œåŸç†\n",
    "- [ ] å°‡å¡çˆ¾æ›¼æ¿¾æ³¢å™¨æ‡‰ç”¨æ–¼ç‰©é«”è¿½è¹¤\n",
    "- [ ] æ ¹æ“šæ‡‰ç”¨å ´æ™¯é¸æ“‡é©ç•¶çš„è¿½è¹¤æ–¹æ³•\n",
    "- [ ] èª¿æ•´åƒæ•¸ä»¥å„ªåŒ–è¿½è¹¤æ€§èƒ½\n",
    "- [ ] è™•ç†è¿½è¹¤ä¸­çš„å¸¸è¦‹å•é¡Œ (é®æ“‹ã€æ¼‚ç§»)\n",
    "\n",
    "---\n",
    "\n",
    "**æ¨¡çµ„å®Œæˆï¼ç¹¼çºŒå­¸ç¿’æ©Ÿå™¨å­¸ç¿’æ¨¡çµ„ (05_machine_learning)ï¼Œæ¢ç´¢æ·±åº¦å­¸ç¿’åœ¨è¨ˆç®—æ©Ÿè¦–è¦ºä¸­çš„æ‡‰ç”¨ã€‚**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
