{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.1 模板匹配 (Template Matching)\n",
    "\n",
    "**WBS 4.2.1**: 模板匹配基礎與應用\n",
    "\n",
    "本模組涵蓋:\n",
    "- **模板匹配基礎原理**: 滑動窗口與相似度計算\n",
    "- **六種匹配方法**: TM_CCOEFF, TM_CCORR, TM_SQDIFF 及其歸一化版本\n",
    "- **多尺度模板匹配**: 解決尺度變化問題\n",
    "- **多目標檢測**: 使用非極大值抑制 (NMS) 檢測多個目標\n",
    "- **實戰應用**: Logo檢測、多目標檢測、不同光照條件匹配\n",
    "- **限制與解決方案**: 旋轉、尺度、光照變化的應對策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 1. 模板匹配基礎原理\n",
    "\n",
    "## 1-1: 什麼是模板匹配?\n",
    "\n",
    "> 模板匹配 (Template Matching) 是一種在較大圖像中搜尋和定位模板圖像位置的方法。\n",
    ">\n",
    "> **核心思想**: 將模板圖像在原圖上滑動，計算每個位置的相似度，找出最相似的位置。\n",
    "\n",
    "## 1-2: 工作原理\n",
    "\n",
    "> **滑動窗口機制**:\n",
    "> 1. 從原圖左上角開始，將模板圖像在原圖上滑動\n",
    "> 2. 在每個位置計算模板與原圖對應區域的相似度\n",
    "> 3. 將相似度結果存儲在結果矩陣中\n",
    "> 4. 找出結果矩陣中的最大值或最小值位置（取決於匹配方法）\n",
    ">\n",
    "> **結果矩陣尺寸**:\n",
    "> - 原圖尺寸: W × H\n",
    "> - 模板尺寸: w × h  \n",
    "> - 結果矩陣: (W-w+1) × (H-h+1)\n",
    "\n",
    "## 1-3: 應用場景\n",
    "\n",
    "> **適用場景**:\n",
    "> * ✅ Logo 檢測與定位\n",
    "> * ✅ 簡單物體檢測\n",
    "> * ✅ UI 自動化測試（圖標定位）\n",
    "> * ✅ 遊戲開發（地圖匹配）\n",
    "> * ✅ 工業檢測（缺陷檢測）\n",
    ">\n",
    "> **不適用場景**:\n",
    "> * ❌ 物體有旋轉變化\n",
    "> * ❌ 物體有尺度變化（需要多尺度匹配）\n",
    "> * ❌ 複雜背景下的物體識別\n",
    "> * ❌ 需要高度魯棒性的應用\n",
    "\n",
    "## 1-4: 優缺點分析\n",
    "\n",
    "> | 特性 | 優點 | 缺點 |\n",
    "> |------|------|------|\n",
    "> | **實現難度** | ✅ 簡單易用，OpenCV 內建 | - |\n",
    "> | **計算速度** | ✅ 相對快速 | ❌ 大圖像計算量大 |\n",
    "> | **旋轉不變性** | - | ❌ 無旋轉不變性 |\n",
    "> | **尺度不變性** | - | ❌ 無尺度不變性 |\n",
    "> | **光照變化** | 部分方法魯棒 | ❌ 需選擇適當方法 |\n",
    "> | **精確度** | ✅ 固定模板檢測精確 | ❌ 環境變化敏感 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Configure matplotlib for better display\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 2. OpenCV 模板匹配方法\n",
    "\n",
    "## 2-1: cv2.matchTemplate() 函數\n",
    "\n",
    "```python\n",
    "result = cv2.matchTemplate(image, template, method)\n",
    "```\n",
    "\n",
    "> **參數說明**:\n",
    "> * `image`: 原始圖像（被搜尋的圖像）\n",
    "> * `template`: 模板圖像（要查找的圖像）\n",
    "> * `method`: 匹配方法（共6種）\n",
    ">\n",
    "> **返回值**:\n",
    "> * `result`: 匹配結果矩陣，每個元素表示對應位置的相似度\n",
    "> * 結果尺寸: (W-w+1) × (H-h+1)\n",
    "\n",
    "## 2-2: 六種匹配方法詳解\n",
    "\n",
    "### 方法 1: TM_SQDIFF (平方差匹配)\n",
    "\n",
    "> **公式**:\n",
    "> $$R(x,y) = \\sum_{x',y'}[T(x',y') - I(x+x',y+y')]^2$$\n",
    ">\n",
    "> **特點**:\n",
    "> * 計算模板與圖像對應區域的平方差\n",
    "> * **值越小表示匹配越好**（0 表示完美匹配）\n",
    "> * 對亮度變化敏感\n",
    "\n",
    "### 方法 2: TM_SQDIFF_NORMED (歸一化平方差匹配)\n",
    "\n",
    "> **公式**:\n",
    "> $$R(x,y) = \\frac{\\sum_{x',y'}[T(x',y') - I(x+x',y+y')]^2}{\\sqrt{\\sum_{x',y'}T(x',y')^2 \\cdot \\sum_{x',y'}I(x+x',y+y')^2}}$$\n",
    ">\n",
    "> **特點**:\n",
    "> * 歸一化版本，結果範圍 [0, 1]\n",
    "> * **值越小越好**\n",
    "> * 對亮度變化較不敏感\n",
    "\n",
    "### 方法 3: TM_CCORR (相關匹配)\n",
    "\n",
    "> **公式**:\n",
    "> $$R(x,y) = \\sum_{x',y'}[T(x',y') \\cdot I(x+x',y+y')]$$\n",
    ">\n",
    "> **特點**:\n",
    "> * 計算模板與圖像的互相關\n",
    "> * **值越大表示匹配越好**\n",
    "> * 對亮度變化非常敏感\n",
    "\n",
    "### 方法 4: TM_CCORR_NORMED (歸一化相關匹配)\n",
    "\n",
    "> **公式**:\n",
    "> $$R(x,y) = \\frac{\\sum_{x',y'}[T(x',y') \\cdot I(x+x',y+y')]}{\\sqrt{\\sum_{x',y'}T(x',y')^2 \\cdot \\sum_{x',y'}I(x+x',y+y')^2}}$$\n",
    ">\n",
    "> **特點**:\n",
    "> * 歸一化版本，結果範圍 [-1, 1]\n",
    "> * **值越大越好**\n",
    "> * 對亮度變化有一定抵抗力\n",
    "\n",
    "### 方法 5: TM_CCOEFF (相關係數匹配) ⭐\n",
    "\n",
    "> **公式**:\n",
    "> $$R(x,y) = \\sum_{x',y'}[T'(x',y') \\cdot I'(x+x',y+y')]$$\n",
    ">\n",
    "> 其中 $T'$ 和 $I'$ 是去除均值後的圖像:\n",
    "> $$T'(x',y') = T(x',y') - \\frac{1}{wh}\\sum_{x'',y''}T(x'',y'')$$\n",
    ">\n",
    "> **特點**:\n",
    "> * 去除均值，考慮圖像的相對變化\n",
    "> * **值越大越好**\n",
    "> * **對亮度變化魯棒** ✅\n",
    "\n",
    "### 方法 6: TM_CCOEFF_NORMED (歸一化相關係數匹配) ⭐⭐⭐\n",
    "\n",
    "> **公式**:\n",
    "> $$R(x,y) = \\frac{\\sum_{x',y'}[T'(x',y') \\cdot I'(x+x',y+y')]}{\\sqrt{\\sum_{x',y'}T'(x',y')^2 \\cdot \\sum_{x',y'}I'(x+x',y+y')^2}}$$\n",
    ">\n",
    "> **特點**:\n",
    "> * 歸一化版本，結果範圍 [-1, 1]\n",
    "> * **值越大越好**（1 表示完美匹配）\n",
    "> * **最常用、最魯棒的方法** ✅✅✅\n",
    "> * 對光照、亮度變化不敏感\n",
    "\n",
    "## 2-3: 六種方法比較表\n",
    "\n",
    "> | 方法 | 結果範圍 | 最佳值 | 歸一化 | 對光照敏感度 | 推薦度 |\n",
    "> |------|---------|--------|--------|-------------|--------|\n",
    "> | **TM_SQDIFF** | [0, ∞) | 最小值 | ❌ | 高 | ⭐ |\n",
    "> | **TM_SQDIFF_NORMED** | [0, 1] | 最小值 | ✅ | 中 | ⭐⭐ |\n",
    "> | **TM_CCORR** | [0, ∞) | 最大值 | ❌ | 非常高 | ⭐ |\n",
    "> | **TM_CCORR_NORMED** | [0, 1] | 最大值 | ✅ | 高 | ⭐⭐ |\n",
    "> | **TM_CCOEFF** | (-∞, ∞) | 最大值 | ❌ | 低 | ⭐⭐⭐ |\n",
    "> | **TM_CCOEFF_NORMED** | [-1, 1] | 最大值 | ✅ | **很低** | ⭐⭐⭐⭐⭐ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4: 基礎模板匹配實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image and template\n",
    "# We'll create a simple test case first\n",
    "img = cv2.imread('../assets/images/basic/lenaColor.png')\n",
    "\n",
    "if img is None:\n",
    "    # Create a test image with colored squares\n",
    "    img = np.ones((400, 600, 3), dtype=np.uint8) * 200\n",
    "    cv2.rectangle(img, (50, 50), (200, 200), (255, 0, 0), -1)  # Blue square\n",
    "    cv2.rectangle(img, (250, 150), (400, 300), (0, 255, 0), -1)  # Green square\n",
    "    cv2.rectangle(img, (450, 250), (550, 350), (0, 0, 255), -1)  # Red square\n",
    "    print(\"Created test image\")\n",
    "else:\n",
    "    print(f\"Loaded image: {img.shape}\")\n",
    "\n",
    "# Extract a template from the image (top-left region)\n",
    "template = img[50:150, 50:150].copy()\n",
    "\n",
    "# Get dimensions\n",
    "h, w = template.shape[:2]\n",
    "print(f\"Template size: {w}x{h}\")\n",
    "\n",
    "# Apply template matching using TM_CCOEFF_NORMED (recommended method)\n",
    "result = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Find the location with highest correlation\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "# For TM_CCOEFF_NORMED, we need the maximum value\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "# Draw rectangle on the result\n",
    "img_result = img.copy()\n",
    "cv2.rectangle(img_result, top_left, bottom_right, (0, 255, 0), 3)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(template, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Template', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(result, cmap='hot')\n",
    "axes[1, 0].set_title('Matching Result Heatmap', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f'Detected Location (Score: {max_val:.3f})', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMatching Score: {max_val:.4f}\")\n",
    "print(f\"Best Match Location: {top_left}\")\n",
    "print(f\"Result matrix shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 3. 六種匹配方法視覺對比\n",
    "\n",
    "## 3-1: 所有方法的匹配結果比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all six matching methods\n",
    "methods = [\n",
    "    ('TM_CCOEFF_NORMED', cv2.TM_CCOEFF_NORMED, 'max'),\n",
    "    ('TM_CCOEFF', cv2.TM_CCOEFF, 'max'),\n",
    "    ('TM_CCORR_NORMED', cv2.TM_CCORR_NORMED, 'max'),\n",
    "    ('TM_CCORR', cv2.TM_CCORR, 'max'),\n",
    "    ('TM_SQDIFF_NORMED', cv2.TM_SQDIFF_NORMED, 'min'),\n",
    "    ('TM_SQDIFF', cv2.TM_SQDIFF, 'min')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 16))\n",
    "axes = axes.ravel()\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for idx, (method_name, method, extremum) in enumerate(methods):\n",
    "    # Apply template matching\n",
    "    result = cv2.matchTemplate(img, template, method)\n",
    "    \n",
    "    # Find best match location\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    \n",
    "    # Determine which value to use based on method\n",
    "    if extremum == 'min':\n",
    "        match_val = min_val\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        match_val = max_val\n",
    "        top_left = max_loc\n",
    "    \n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    \n",
    "    # Draw rectangle\n",
    "    img_display = img.copy()\n",
    "    cv2.rectangle(img_display, top_left, bottom_right, (0, 255, 0), 3)\n",
    "    \n",
    "    # Add method name and score to image\n",
    "    text = f\"{method_name}: {match_val:.3f}\"\n",
    "    cv2.putText(img_display, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display\n",
    "    axes[idx].imshow(cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx].set_title(f'{method_name}\\nScore: {match_val:.4f}', \n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Store results\n",
    "    results_summary.append({\n",
    "        'method': method_name,\n",
    "        'score': match_val,\n",
    "        'location': top_left\n",
    "    })\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"六種匹配方法結果總結\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'方法':<25} {'匹配分數':<15} {'位置 (x, y)'}\")\n",
    "print(\"-\"*70)\n",
    "for result in results_summary:\n",
    "    print(f\"{result['method']:<25} {result['score']:>10.4f}     {result['location']}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2: 匹配熱圖視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize matching heatmaps for all methods\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (method_name, method, extremum) in enumerate(methods):\n",
    "    # Apply template matching\n",
    "    result = cv2.matchTemplate(img, template, method)\n",
    "    \n",
    "    # Normalize result for visualization\n",
    "    result_normalized = cv2.normalize(result, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Display heatmap\n",
    "    im = axes[idx].imshow(result, cmap='hot', interpolation='nearest')\n",
    "    axes[idx].set_title(f'{method_name}\\n({extremum.upper()} is best)', \n",
    "                       fontsize=10, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=axes[idx], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.suptitle('匹配方法熱圖比較 (亮處表示高相似度)', \n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 觀察要點:\")\n",
    "print(\"- TM_CCOEFF_NORMED: 熱圖最清晰，峰值最明顯\")\n",
    "print(\"- TM_SQDIFF 系列: 值越小越好（熱圖中暗處為最佳匹配）\")\n",
    "print(\"- 歸一化方法: 結果範圍統一，更易於設定閾值\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 4. 光照變化魯棒性測試\n",
    "\n",
    "## 4-1: 不同光照條件下的匹配表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test robustness to illumination changes\n",
    "# Create variations of the image with different brightness levels\n",
    "brightness_factors = [0.5, 0.7, 1.0, 1.3, 1.5]  # 50%, 70%, 100%, 130%, 150%\n",
    "\n",
    "# Test with three representative methods\n",
    "test_methods = [\n",
    "    ('TM_CCOEFF_NORMED', cv2.TM_CCOEFF_NORMED, 'max'),\n",
    "    ('TM_CCORR_NORMED', cv2.TM_CCORR_NORMED, 'max'),\n",
    "    ('TM_SQDIFF_NORMED', cv2.TM_SQDIFF_NORMED, 'min')\n",
    "]\n",
    "\n",
    "# Store results\n",
    "illumination_results = {method[0]: [] for method in test_methods}\n",
    "\n",
    "fig, axes = plt.subplots(len(test_methods), len(brightness_factors), \n",
    "                        figsize=(16, 10))\n",
    "\n",
    "for method_idx, (method_name, method, extremum) in enumerate(test_methods):\n",
    "    for bright_idx, factor in enumerate(brightness_factors):\n",
    "        # Create brightness-adjusted image\n",
    "        img_adjusted = np.clip(img * factor, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # Apply template matching\n",
    "        result = cv2.matchTemplate(img_adjusted, template, method)\n",
    "        \n",
    "        # Find best match\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if extremum == 'min':\n",
    "            match_val = min_val\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            match_val = max_val\n",
    "            top_left = max_loc\n",
    "        \n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        \n",
    "        # Draw result\n",
    "        img_display = img_adjusted.copy()\n",
    "        cv2.rectangle(img_display, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display\n",
    "        axes[method_idx, bright_idx].imshow(cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB))\n",
    "        axes[method_idx, bright_idx].set_title(\n",
    "            f'{int(factor*100)}% Brightness\\nScore: {match_val:.3f}',\n",
    "            fontsize=9\n",
    "        )\n",
    "        axes[method_idx, bright_idx].axis('off')\n",
    "        \n",
    "        # Store score\n",
    "        illumination_results[method_name].append(match_val)\n",
    "    \n",
    "    # Add method name to the left\n",
    "    axes[method_idx, 0].set_ylabel(method_name, fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('光照變化魯棒性測試', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot score variations\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for method_name, scores in illumination_results.items():\n",
    "    ax.plot(brightness_factors, scores, marker='o', linewidth=2, \n",
    "           markersize=8, label=method_name)\n",
    "\n",
    "ax.set_xlabel('亮度係數', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('匹配分數', fontsize=12, fontweight='bold')\n",
    "ax.set_title('不同匹配方法對光照變化的魯棒性', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.axvline(x=1.0, color='red', linestyle='--', alpha=0.5, label='原始亮度')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 結論:\")\n",
    "print(\"- TM_CCOEFF_NORMED: 對光照變化最魯棒，分數波動最小 ✅\")\n",
    "print(\"- TM_CCORR_NORMED: 對光照變化較敏感，分數波動較大\")\n",
    "print(\"- TM_SQDIFF_NORMED: 中等魯棒性\")\n",
    "print(\"\\n推薦: 實際應用中優先使用 TM_CCOEFF_NORMED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 5. 多目標檢測\n",
    "\n",
    "## 5-1: 檢測多個相同目標\n",
    "\n",
    "> **問題**: `cv2.matchTemplate()` 只能找到單一最佳匹配位置\n",
    ">\n",
    "> **解決方案**: \n",
    "> 1. 設定閾值，找出所有超過閾值的位置\n",
    "> 2. 使用非極大值抑制 (NMS) 去除重複檢測\n",
    "\n",
    "## 5-2: 非極大值抑制 (Non-Maximum Suppression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image with multiple instances of the same object\n",
    "img_multi = np.ones((500, 700, 3), dtype=np.uint8) * 220\n",
    "\n",
    "# Create a simple template (a colored circle)\n",
    "template_multi = np.ones((60, 60, 3), dtype=np.uint8) * 220\n",
    "cv2.circle(template_multi, (30, 30), 25, (0, 0, 255), -1)\n",
    "cv2.circle(template_multi, (30, 30), 15, (255, 255, 0), -1)\n",
    "\n",
    "# Place template at multiple locations\n",
    "locations = [(100, 100), (300, 150), (500, 200), (150, 350), (400, 380)]\n",
    "for loc in locations:\n",
    "    x, y = loc\n",
    "    img_multi[y:y+60, x:x+60] = template_multi\n",
    "\n",
    "print(f\"Created test image with {len(locations)} target instances\")\n",
    "print(f\"Image size: {img_multi.shape}\")\n",
    "print(f\"Template size: {template_multi.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply template matching\n",
    "gray_img = cv2.cvtColor(img_multi, cv2.COLOR_BGR2GRAY)\n",
    "gray_template = cv2.cvtColor(template_multi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "result = cv2.matchTemplate(gray_img, gray_template, cv2.TM_CCOEFF_NORMED)\n",
    "h_t, w_t = gray_template.shape\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.8\n",
    "\n",
    "# Find all locations above threshold\n",
    "locations_found = np.where(result >= threshold)\n",
    "locations_found = list(zip(*locations_found[::-1]))  # (x, y) format\n",
    "\n",
    "print(f\"\\nFound {len(locations_found)} locations above threshold {threshold}\")\n",
    "\n",
    "# Draw all detections (before NMS)\n",
    "img_before_nms = img_multi.copy()\n",
    "for pt in locations_found:\n",
    "    cv2.rectangle(img_before_nms, pt, (pt[0] + w_t, pt[1] + h_t), \n",
    "                 (0, 255, 0), 2)\n",
    "\n",
    "# Display before NMS\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(img_multi, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(result, cmap='hot')\n",
    "axes[1].set_title('Matching Heatmap', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(img_before_nms, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title(f'All Detections (Before NMS)\\nTotal: {len(locations_found)}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n⚠️ 問題: 檢測到許多重疊的矩形框\")\n",
    "print(\"解決方案: 使用非極大值抑制 (NMS) 去除重複檢測\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression to remove overlapping boxes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    boxes : list of tuples\n",
    "        List of bounding boxes [(x1, y1, x2, y2), ...]\n",
    "    scores : list of floats\n",
    "        Confidence scores for each box\n",
    "    threshold : float\n",
    "        IoU threshold for suppression\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    keep : list\n",
    "        Indices of boxes to keep\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    boxes = np.array(boxes).astype(float)\n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    # Get coordinates\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    \n",
    "    # Calculate area\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    \n",
    "    # Sort by scores\n",
    "    order = scores.argsort()[::-1]\n",
    "    \n",
    "    keep = []\n",
    "    \n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        \n",
    "        # Calculate IoU with remaining boxes\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        \n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        \n",
    "        intersection = w * h\n",
    "        iou = intersection / (areas[i] + areas[order[1:]] - intersection)\n",
    "        \n",
    "        # Keep boxes with IoU less than threshold\n",
    "        inds = np.where(iou <= threshold)[0]\n",
    "        order = order[inds + 1]\n",
    "    \n",
    "    return keep\n",
    "\n",
    "# Prepare boxes and scores for NMS\n",
    "boxes = []\n",
    "scores = []\n",
    "\n",
    "for pt in locations_found:\n",
    "    x1, y1 = pt\n",
    "    x2, y2 = x1 + w_t, y1 + h_t\n",
    "    boxes.append([x1, y1, x2, y2])\n",
    "    scores.append(result[y1, x1])\n",
    "\n",
    "# Apply NMS\n",
    "keep_indices = non_max_suppression(boxes, scores, threshold=0.3)\n",
    "\n",
    "print(f\"\\nAfter NMS: {len(keep_indices)} detections remain\")\n",
    "print(f\"Removed: {len(boxes) - len(keep_indices)} overlapping detections\")\n",
    "\n",
    "# Draw final detections\n",
    "img_after_nms = img_multi.copy()\n",
    "for idx in keep_indices:\n",
    "    x1, y1, x2, y2 = boxes[idx]\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    cv2.rectangle(img_after_nms, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    # Add confidence score\n",
    "    cv2.putText(img_after_nms, f'{scores[idx]:.2f}', (x1, y1-5),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(img_before_nms, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(f'Before NMS\\nDetections: {len(locations_found)}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(img_after_nms, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'After NMS\\nDetections: {len(keep_indices)}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ NMS 成功去除重複檢測!\")\n",
    "print(f\"原始檢測數: {len(locations_found)}\")\n",
    "print(f\"NMS 後檢測數: {len(keep_indices)}\")\n",
    "print(f\"去除比例: {(1 - len(keep_indices)/len(locations_found))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 6. 多尺度模板匹配\n",
    "\n",
    "## 6-1: 尺度不變性問題\n",
    "\n",
    "> **問題**: 標準模板匹配無法處理尺度變化\n",
    ">\n",
    "> **解決方案**: \n",
    "> - 在多個尺度上進行模板匹配\n",
    "> - 記錄每個尺度的最佳匹配\n",
    "> - 選擇所有尺度中的最佳結果\n",
    "\n",
    "## 6-2: 多尺度匹配實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_scale_template_matching(image, template, scales, method=cv2.TM_CCOEFF_NORMED):\n",
    "    \"\"\"\n",
    "    Perform template matching across multiple scales\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : numpy.ndarray\n",
    "        Input image\n",
    "    template : numpy.ndarray\n",
    "        Template image\n",
    "    scales : list\n",
    "        List of scale factors to try\n",
    "    method : int\n",
    "        OpenCV matching method\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    best_match : dict\n",
    "        Dictionary containing best match information\n",
    "    all_results : list\n",
    "        List of all scale results\n",
    "    \"\"\"\n",
    "    best_match = {\n",
    "        'score': -np.inf,\n",
    "        'location': None,\n",
    "        'scale': None,\n",
    "        'size': None\n",
    "    }\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Get original template dimensions\n",
    "    tH, tW = template.shape[:2]\n",
    "    \n",
    "    for scale in scales:\n",
    "        # Resize template\n",
    "        resized_template = cv2.resize(template, None, fx=scale, fy=scale)\n",
    "        rH, rW = resized_template.shape[:2]\n",
    "        \n",
    "        # Skip if resized template is larger than image\n",
    "        if rW > image.shape[1] or rH > image.shape[0]:\n",
    "            continue\n",
    "        \n",
    "        # Apply template matching\n",
    "        result = cv2.matchTemplate(image, resized_template, method)\n",
    "        \n",
    "        # Find best match for this scale\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        \n",
    "        # For TM_CCOEFF_NORMED, higher is better\n",
    "        score = max_val\n",
    "        location = max_loc\n",
    "        \n",
    "        # Store result\n",
    "        scale_result = {\n",
    "            'scale': scale,\n",
    "            'score': score,\n",
    "            'location': location,\n",
    "            'size': (rW, rH)\n",
    "        }\n",
    "        all_results.append(scale_result)\n",
    "        \n",
    "        # Update best match\n",
    "        if score > best_match['score']:\n",
    "            best_match = scale_result.copy()\n",
    "    \n",
    "    return best_match, all_results\n",
    "\n",
    "# Create test image with scaled template\n",
    "img_scaled = np.ones((600, 800, 3), dtype=np.uint8) * 200\n",
    "\n",
    "# Create a distinctive template\n",
    "template_scale_test = np.ones((80, 80, 3), dtype=np.uint8) * 200\n",
    "cv2.rectangle(template_scale_test, (10, 10), (70, 70), (255, 0, 0), -1)\n",
    "cv2.rectangle(template_scale_test, (25, 25), (55, 55), (0, 255, 0), -1)\n",
    "cv2.circle(template_scale_test, (40, 40), 10, (0, 0, 255), -1)\n",
    "\n",
    "# Place scaled versions in the image\n",
    "scale_factors = [0.5, 0.75, 1.0, 1.25, 1.5]\n",
    "positions = [(100, 100), (250, 200), (400, 150), (550, 300), (150, 400)]\n",
    "\n",
    "for scale, pos in zip(scale_factors, positions):\n",
    "    scaled_tmpl = cv2.resize(template_scale_test, None, fx=scale, fy=scale)\n",
    "    h_s, w_s = scaled_tmpl.shape[:2]\n",
    "    x, y = pos\n",
    "    \n",
    "    # Ensure it fits in the image\n",
    "    if x + w_s <= img_scaled.shape[1] and y + h_s <= img_scaled.shape[0]:\n",
    "        img_scaled[y:y+h_s, x:x+w_s] = scaled_tmpl\n",
    "\n",
    "print(\"Created test image with multiple scaled instances\")\n",
    "print(f\"Template size: {template_scale_test.shape[:2]}\")\n",
    "print(f\"Scales used: {scale_factors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale for matching\n",
    "gray_img_scaled = cv2.cvtColor(img_scaled, cv2.COLOR_BGR2GRAY)\n",
    "gray_template_scaled = cv2.cvtColor(template_scale_test, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define scales to search\n",
    "scales_to_search = np.linspace(0.3, 2.0, 20)\n",
    "\n",
    "# Perform multi-scale matching\n",
    "print(\"\\nPerforming multi-scale template matching...\")\n",
    "start_time = time.time()\n",
    "\n",
    "best_match, all_results = multi_scale_template_matching(\n",
    "    gray_img_scaled, \n",
    "    gray_template_scaled, \n",
    "    scales_to_search\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Completed in {elapsed:.2f} seconds\")\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nBest Match:\")\n",
    "print(f\"  Scale: {best_match['scale']:.2f}\")\n",
    "print(f\"  Score: {best_match['score']:.4f}\")\n",
    "print(f\"  Location: {best_match['location']}\")\n",
    "print(f\"  Size: {best_match['size']}\")\n",
    "\n",
    "# Draw best match\n",
    "img_best_match = img_scaled.copy()\n",
    "x, y = best_match['location']\n",
    "w, h = best_match['size']\n",
    "cv2.rectangle(img_best_match, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "cv2.putText(img_best_match, f\"Scale: {best_match['scale']:.2f}\", (x, y-10),\n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "# Draw all detected instances\n",
    "img_all_detections = img_scaled.copy()\n",
    "threshold_multi = 0.7\n",
    "\n",
    "for result in all_results:\n",
    "    if result['score'] >= threshold_multi:\n",
    "        x, y = result['location']\n",
    "        w, h = result['size']\n",
    "        cv2.rectangle(img_all_detections, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(img_scaled, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image\\n(Multiple Scales)', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(img_best_match, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f'Best Match\\nScale: {best_match[\"scale\"]:.2f}, Score: {best_match[\"score\"]:.3f}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(img_all_detections, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title(f'All Detections (Score > {threshold_multi})', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot matching scores across scales\n",
    "scales_list = [r['scale'] for r in all_results]\n",
    "scores_list = [r['score'] for r in all_results]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(scales_list, scores_list, marker='o', linewidth=2, markersize=6)\n",
    "ax.axhline(y=threshold_multi, color='r', linestyle='--', label=f'Threshold ({threshold_multi})')\n",
    "ax.axvline(x=best_match['scale'], color='g', linestyle='--', \n",
    "          label=f'Best Scale ({best_match[\"scale\"]:.2f})')\n",
    "\n",
    "ax.set_xlabel('Scale Factor', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Matching Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Matching Score vs Scale Factor', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 觀察:\")\n",
    "print(\"- 匹配分數在正確尺度附近達到峰值\")\n",
    "print(\"- 多尺度匹配可以找到不同大小的目標\")\n",
    "print(\"- 計算成本隨搜尋尺度數量增加而增加\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 7. 實戰應用案例\n",
    "\n",
    "## 7-1: 應用1 - Logo 檢測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample scene with multiple logos\n",
    "scene = np.ones((500, 700, 3), dtype=np.uint8) * 240\n",
    "\n",
    "# Create a simple logo template\n",
    "logo_template = np.ones((50, 50, 3), dtype=np.uint8) * 240\n",
    "cv2.circle(logo_template, (25, 25), 20, (0, 0, 200), -1)\n",
    "cv2.circle(logo_template, (25, 25), 12, (240, 240, 240), -1)\n",
    "cv2.putText(logo_template, 'CV', (13, 32), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "           0.6, (0, 0, 200), 2)\n",
    "\n",
    "# Place logos at various locations with slight variations\n",
    "logo_positions = [(50, 50), (200, 100), (400, 150), (100, 300), (500, 350), (300, 400)]\n",
    "\n",
    "for pos in logo_positions:\n",
    "    x, y = pos\n",
    "    # Add slight brightness variation\n",
    "    brightness = np.random.uniform(0.9, 1.1)\n",
    "    logo_variant = np.clip(logo_template * brightness, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    h_l, w_l = logo_variant.shape[:2]\n",
    "    if x + w_l <= scene.shape[1] and y + h_l <= scene.shape[0]:\n",
    "        scene[y:y+h_l, x:x+w_l] = logo_variant\n",
    "\n",
    "# Add some noise and other elements\n",
    "cv2.rectangle(scene, (550, 50), (650, 150), (100, 200, 100), 2)\n",
    "cv2.circle(scene, (600, 300), 30, (200, 100, 100), 3)\n",
    "\n",
    "print(\"Created scene with multiple logos\")\n",
    "print(f\"Number of logos: {len(logo_positions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect all logos\n",
    "gray_scene = cv2.cvtColor(scene, cv2.COLOR_BGR2GRAY)\n",
    "gray_logo = cv2.cvtColor(logo_template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply template matching\n",
    "result_logo = cv2.matchTemplate(gray_scene, gray_logo, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Find all matches above threshold\n",
    "threshold_logo = 0.75\n",
    "locations_logo = np.where(result_logo >= threshold_logo)\n",
    "locations_logo = list(zip(*locations_logo[::-1]))\n",
    "\n",
    "h_logo, w_logo = gray_logo.shape\n",
    "\n",
    "# Prepare for NMS\n",
    "boxes_logo = []\n",
    "scores_logo = []\n",
    "\n",
    "for pt in locations_logo:\n",
    "    x1, y1 = pt\n",
    "    x2, y2 = x1 + w_logo, y1 + h_logo\n",
    "    boxes_logo.append([x1, y1, x2, y2])\n",
    "    scores_logo.append(result_logo[y1, x1])\n",
    "\n",
    "# Apply NMS\n",
    "keep_logo = non_max_suppression(boxes_logo, scores_logo, threshold=0.3)\n",
    "\n",
    "# Draw detections\n",
    "scene_detected = scene.copy()\n",
    "for idx in keep_logo:\n",
    "    x1, y1, x2, y2 = boxes_logo[idx]\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    cv2.rectangle(scene_detected, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(scene_detected, f'{scores_logo[idx]:.2f}', (x1, y1-5),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(logo_template, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Logo Template', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(scene, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Scene with Multiple Logos', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(result_logo, cmap='hot')\n",
    "axes[1, 0].set_title('Matching Heatmap', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(scene_detected, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f'Detected Logos: {len(keep_logo)}', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Logo 檢測完成!\")\n",
    "print(f\"檢測到的 Logo 數量: {len(keep_logo)}\")\n",
    "print(f\"實際 Logo 數量: {len(logo_positions)}\")\n",
    "print(f\"檢測準確率: {len(keep_logo)/len(logo_positions)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-2: 應用2 - UI 元素定位 (自動化測試)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple UI mockup\n",
    "ui_screen = np.ones((600, 800, 3), dtype=np.uint8) * 250\n",
    "\n",
    "# Add UI elements\n",
    "# Title bar\n",
    "cv2.rectangle(ui_screen, (0, 0), (800, 60), (200, 200, 200), -1)\n",
    "cv2.putText(ui_screen, 'Application Title', (20, 40), \n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 1.2, (50, 50, 50), 2)\n",
    "\n",
    "# Buttons\n",
    "button_positions = [(100, 150), (300, 150), (500, 150),\n",
    "                   (100, 250), (300, 250), (500, 250)]\n",
    "button_labels = ['Save', 'Load', 'Export', 'Delete', 'Cancel', 'OK']\n",
    "\n",
    "for pos, label in zip(button_positions, button_labels):\n",
    "    x, y = pos\n",
    "    cv2.rectangle(ui_screen, (x, y), (x+150, y+60), (100, 150, 200), -1)\n",
    "    cv2.rectangle(ui_screen, (x, y), (x+150, y+60), (70, 120, 170), 3)\n",
    "    \n",
    "    # Center text\n",
    "    text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "    text_x = x + (150 - text_size[0]) // 2\n",
    "    text_y = y + (60 + text_size[1]) // 2\n",
    "    cv2.putText(ui_screen, label, (text_x, text_y),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "# Create button template (OK button)\n",
    "ok_button_template = ui_screen[250:310, 500:650].copy()\n",
    "\n",
    "print(\"Created UI mockup\")\n",
    "print(f\"UI size: {ui_screen.shape}\")\n",
    "print(f\"Button template size: {ok_button_template.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the OK button\n",
    "gray_ui = cv2.cvtColor(ui_screen, cv2.COLOR_BGR2GRAY)\n",
    "gray_button = cv2.cvtColor(ok_button_template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "result_ui = cv2.matchTemplate(gray_ui, gray_button, cv2.TM_CCOEFF_NORMED)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result_ui)\n",
    "\n",
    "h_btn, w_btn = gray_button.shape\n",
    "top_left_btn = max_loc\n",
    "bottom_right_btn = (top_left_btn[0] + w_btn, top_left_btn[1] + h_btn)\n",
    "\n",
    "# Calculate button center (for clicking)\n",
    "button_center = (\n",
    "    top_left_btn[0] + w_btn // 2,\n",
    "    top_left_btn[1] + h_btn // 2\n",
    ")\n",
    "\n",
    "# Visualize detection\n",
    "ui_detected = ui_screen.copy()\n",
    "cv2.rectangle(ui_detected, top_left_btn, bottom_right_btn, (0, 255, 0), 3)\n",
    "cv2.circle(ui_detected, button_center, 5, (255, 0, 0), -1)\n",
    "cv2.putText(ui_detected, 'Click Here', (button_center[0]-50, button_center[1]-20),\n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(ui_screen, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('UI Screen', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(ok_button_template, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Target Button Template', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(ui_detected, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title(f'Button Located (Score: {max_val:.3f})', fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ UI 元素定位成功!\")\n",
    "print(f\"按鈕位置: {top_left_btn}\")\n",
    "print(f\"點擊座標: {button_center}\")\n",
    "print(f\"匹配分數: {max_val:.4f}\")\n",
    "print(\"\\n應用場景: 自動化測試、RPA、遊戲機器人等\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 8. 性能基準測試\n",
    "\n",
    "## 8-1: 不同匹配方法的性能比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "num_iterations = 50\n",
    "\n",
    "print(f\"Performance Benchmark ({num_iterations} iterations)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "timing_results = []\n",
    "\n",
    "for method_name, method, _ in methods:\n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        result = cv2.matchTemplate(gray_img, gray_template, method)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    \n",
    "    elapsed = (time.time() - start) / num_iterations * 1000  # Convert to ms\n",
    "    \n",
    "    timing_results.append({\n",
    "        'method': method_name,\n",
    "        'time_ms': elapsed\n",
    "    })\n",
    "    \n",
    "    print(f\"{method_name:<25} : {elapsed:>8.3f} ms/iter\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualize timing results\n",
    "methods_list = [r['method'] for r in timing_results]\n",
    "times_list = [r['time_ms'] for r in timing_results]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = ['#e74c3c' if 'NORMED' in m else '#3498db' for m in methods_list]\n",
    "bars = ax.bar(methods_list, times_list, color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "# Add value labels\n",
    "for bar, time_val in zip(bars, times_list):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "           f'{time_val:.2f} ms',\n",
    "           ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('執行時間 (milliseconds)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('模板匹配方法性能比較', fontsize=14, fontweight='bold')\n",
    "ax.set_xticklabels(methods_list, rotation=45, ha='right')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#3498db', edgecolor='black', label='非歸一化'),\n",
    "    Patch(facecolor='#e74c3c', edgecolor='black', label='歸一化')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 性能觀察:\")\n",
    "print(\"- 歸一化方法稍慢，但結果更可靠\")\n",
    "print(\"- TM_SQDIFF 系列通常最快\")\n",
    "print(\"- 實際應用中，性能差異通常可以忽略\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 9. 限制與解決方案\n",
    "\n",
    "## 9-1: 模板匹配的主要限制\n",
    "\n",
    "### 限制 1: 旋轉不變性 ❌\n",
    "\n",
    "> **問題**: 模板匹配無法處理旋轉變化\n",
    ">\n",
    "> **解決方案**:\n",
    "> 1. **多角度匹配**: 旋轉模板並嘗試多個角度\n",
    "> 2. **特徵匹配**: 使用 SIFT/SURF/ORB 等旋轉不變特徵\n",
    "> 3. **深度學習**: 使用 CNN 進行物體檢測\n",
    "\n",
    "### 限制 2: 尺度不變性 ❌\n",
    "\n",
    "> **問題**: 目標大小變化時匹配失敗\n",
    ">\n",
    "> **解決方案**:\n",
    "> 1. **多尺度匹配**: 如本模組第 6 節所示\n",
    "> 2. **圖像金字塔**: 構建多尺度圖像金字塔\n",
    "> 3. **特徵匹配**: SIFT/SURF 具有尺度不變性\n",
    "\n",
    "### 限制 3: 光照變化敏感 ⚠️\n",
    "\n",
    "> **問題**: 光照條件變化影響匹配\n",
    ">\n",
    "> **解決方案**:\n",
    "> 1. **使用歸一化方法**: TM_CCOEFF_NORMED 最魯棒\n",
    "> 2. **直方圖均衡化**: 預處理圖像\n",
    "> 3. **梯度特徵**: 使用邊緣或梯度進行匹配\n",
    "\n",
    "### 限制 4: 部分遮擋 ❌\n",
    "\n",
    "> **問題**: 目標被部分遮擋時匹配失敗\n",
    ">\n",
    "> **解決方案**:\n",
    "> 1. **特徵點匹配**: SIFT/SURF/ORB + RANSAC\n",
    "> 2. **深度學習**: 使用物體檢測模型\n",
    "> 3. **多模板匹配**: 使用目標的不同部分作為模板\n",
    "\n",
    "### 限制 5: 計算效率 ⚠️\n",
    "\n",
    "> **問題**: 大圖像或多尺度匹配計算量大\n",
    ">\n",
    "> **解決方案**:\n",
    "> 1. **ROI 限制**: 只在感興趣區域搜索\n",
    "> 2. **圖像降採樣**: 先在低解析度匹配，再精確定位\n",
    "> 3. **GPU 加速**: 使用 CUDA 加速（cv2.cuda 模組）\n",
    "> 4. **快速匹配**: 使用更快的特徵檢測器\n",
    "\n",
    "## 9-2: 方法選擇決策樹\n",
    "\n",
    "```\n",
    "目標特性分析\n",
    "│\n",
    "├─ 固定大小、固定方向、簡單背景?\n",
    "│   └─ 是 → 使用模板匹配 (TM_CCOEFF_NORMED)\n",
    "│\n",
    "├─ 有尺度變化?\n",
    "│   └─ 是 → 多尺度模板匹配 或 特徵匹配\n",
    "│\n",
    "├─ 有旋轉變化?\n",
    "│   └─ 是 → 特徵匹配 (SIFT/SURF/ORB) 或 深度學習\n",
    "│\n",
    "├─ 有遮擋?\n",
    "│   └─ 是 → 特徵匹配 + RANSAC 或 深度學習\n",
    "│\n",
    "└─ 複雜場景、多類別?\n",
    "    └─ 是 → 深度學習 (YOLO/SSD/Faster R-CNN)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>\n",
    "\n",
    "# 10. 總結與延伸\n",
    "\n",
    "## 10-1: 核心要點回顧\n",
    "\n",
    "### 模板匹配基礎\n",
    "\n",
    "> **工作原理**:\n",
    "> * 滑動窗口機制，計算每個位置的相似度\n",
    "> * 結果矩陣尺寸: (W-w+1) × (H-h+1)\n",
    "> * 簡單易用，OpenCV 內建支援\n",
    "\n",
    "### 六種匹配方法\n",
    "\n",
    "> **推薦順序**:\n",
    "> 1. **TM_CCOEFF_NORMED** ⭐⭐⭐⭐⭐ - 最佳選擇\n",
    "> 2. **TM_CCOEFF** ⭐⭐⭐ - 不需要歸一化時使用\n",
    "> 3. **TM_SQDIFF_NORMED** ⭐⭐ - 備選方案\n",
    "> 4. 其他方法 - 特殊情況使用\n",
    "\n",
    "### 進階技術\n",
    "\n",
    "> **多目標檢測**:\n",
    "> * 閾值過濾 + 非極大值抑制 (NMS)\n",
    "> * 適合檢測多個相同物體\n",
    ">\n",
    "> **多尺度匹配**:\n",
    "> * 解決尺度變化問題\n",
    "> * 在多個尺度上搜索最佳匹配\n",
    ">\n",
    "> **光照魯棒性**:\n",
    "> * TM_CCOEFF_NORMED 最魯棒\n",
    "> * 考慮使用直方圖均衡化預處理\n",
    "\n",
    "## 10-2: 實戰應用指南\n",
    "\n",
    "### 適用場景\n",
    "\n",
    "> | 應用 | 難度 | 推薦方法 | 備註 |\n",
    "> |------|------|---------|------|\n",
    "> | Logo 檢測 | ⭐ | TM_CCOEFF_NORMED | 簡單直接 |\n",
    "> | UI 自動化 | ⭐ | TM_CCOEFF_NORMED + NMS | 適合固定 UI |\n",
    "> | 工業檢測 | ⭐⭐ | 多尺度 + NMS | 需要精確定位 |\n",
    "> | 遊戲機器人 | ⭐⭐ | TM_CCOEFF_NORMED | 實時性要求 |\n",
    "> | 監控系統 | ⭐⭐⭐ | 特徵匹配 | 環境變化大 |\n",
    "\n",
    "### 參數調優建議\n",
    "\n",
    "> **閾值設定**:\n",
    "> * TM_CCOEFF_NORMED: 0.7 ~ 0.9 (越高越嚴格)\n",
    "> * 調整策略: 從高閾值開始，逐步降低直到滿足需求\n",
    ">\n",
    "> **NMS 參數**:\n",
    "> * IoU 閾值: 0.3 ~ 0.5 (越小去除越多)\n",
    "> * 根據目標密集程度調整\n",
    ">\n",
    "> **多尺度範圍**:\n",
    "> * 尺度範圍: 0.5 ~ 2.0 (根據實際情況)\n",
    "> * 尺度步長: 0.1 (平衡精度與速度)\n",
    "\n",
    "## 10-3: 性能優化技巧\n",
    "\n",
    "> **1. 圖像預處理**:\n",
    "> ```python\n",
    "> # 轉換為灰階\n",
    "> gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "> \n",
    "> # 降採樣（速度優先）\n",
    "> small = cv2.resize(gray, None, fx=0.5, fy=0.5)\n",
    "> \n",
    "> # 直方圖均衡化（魯棒性優先）\n",
    "> equalized = cv2.equalizeHist(gray)\n",
    "> ```\n",
    ">\n",
    "> **2. ROI 限制**:\n",
    "> ```python\n",
    "> # 只在感興趣區域搜索\n",
    "> roi = image[y1:y2, x1:x2]\n",
    "> result = cv2.matchTemplate(roi, template, method)\n",
    "> ```\n",
    ">\n",
    "> **3. 粗到細策略**:\n",
    "> ```python\n",
    "> # 第一步：低解析度快速定位\n",
    "> small_img = cv2.resize(image, None, fx=0.25, fy=0.25)\n",
    "> small_template = cv2.resize(template, None, fx=0.25, fy=0.25)\n",
    "> result = cv2.matchTemplate(small_img, small_template, method)\n",
    "> \n",
    "> # 第二步：在原圖上精確定位\n",
    "> rough_location = cv2.minMaxLoc(result)[3]\n",
    "> refined_roi = image[rough_y:rough_y+h, rough_x:rough_x+w]\n",
    "> final_result = cv2.matchTemplate(refined_roi, template, method)\n",
    "> ```\n",
    "\n",
    "## 10-4: 何時不使用模板匹配\n",
    "\n",
    "> **考慮其他方法的情況**:\n",
    ">\n",
    "> 1. **目標有旋轉變化** → 使用特徵匹配 (SIFT/SURF/ORB)\n",
    "> 2. **複雜背景** → 使用深度學習物體檢測\n",
    "> 3. **多類別物體** → 使用分類或檢測模型\n",
    "> 4. **需要語義理解** → 使用深度學習\n",
    "> 5. **實時性要求極高** → 考慮硬體加速或更快算法\n",
    "\n",
    "## 10-5: 延伸學習\n",
    "\n",
    "### 後續模組預告\n",
    "\n",
    "> **4.2.2 特徵匹配 (Feature Matching)**:\n",
    "> * SIFT/SURF/ORB 特徵檢測與描述\n",
    "> * Brute-Force 與 FLANN 匹配\n",
    "> * RANSAC 外點過濾\n",
    "> * 單應性矩陣 (Homography) 估計\n",
    ">\n",
    "> **4.3 物體追蹤 (Object Tracking)**:\n",
    "> * 光流法追蹤\n",
    "> * MeanShift / CamShift 追蹤\n",
    "> * KCF / CSRT 追蹤器\n",
    "> * 多目標追蹤\n",
    ">\n",
    "> **5.1 深度學習物體檢測**:\n",
    "> * YOLO / SSD / Faster R-CNN\n",
    "> * 預訓練模型使用\n",
    "> * 自定義物體檢測\n",
    "\n",
    "### 推薦資源\n",
    "\n",
    "> **官方文檔**:\n",
    "> * OpenCV Template Matching: https://docs.opencv.org/4.x/d4/dc6/tutorial_py_template_matching.html\n",
    "> * OpenCV Feature Detection: https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html\n",
    ">\n",
    "> **論文**:\n",
    "> * \"Template Matching Techniques: A Survey\" - Essam A. Rashed\n",
    "> * \"Distinctive Image Features from Scale-Invariant Keypoints\" - David Lowe (SIFT)\n",
    ">\n",
    "> **實用工具**:\n",
    "> * OpenCV Documentation\n",
    "> * LearnOpenCV Blog\n",
    "> * PyImageSearch Tutorials\n",
    "\n",
    "## 10-6: 實作練習建議\n",
    "\n",
    "### 初級練習\n",
    "\n",
    "> 1. **基礎匹配**: 實作簡單的模板匹配，比較不同方法\n",
    "> 2. **閾值調整**: 嘗試不同閾值，觀察結果變化\n",
    "> 3. **多目標檢測**: 實作 NMS 算法\n",
    "\n",
    "### 中級練習\n",
    "\n",
    "> 4. **多尺度匹配**: 實作完整的多尺度模板匹配\n",
    "> 5. **UI 自動化**: 開發簡單的 UI 元素定位工具\n",
    "> 6. **性能優化**: 實作粗到細策略，比較性能提升\n",
    "\n",
    "### 高級練習\n",
    "\n",
    "> 7. **旋轉匹配**: 實作多角度模板匹配\n",
    "> 8. **混合方法**: 結合模板匹配與特徵匹配\n",
    "> 9. **實際項目**: 開發完整的物體檢測應用\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 總結\n",
    "\n",
    "模板匹配是計算機視覺中最基礎且實用的技術之一。雖然有其限制，但在適合的場景下，它仍然是最簡單、最有效的解決方案。\n",
    "\n",
    "**關鍵建議**:\n",
    "- ✅ 優先使用 TM_CCOEFF_NORMED\n",
    "- ✅ 多目標檢測必須使用 NMS\n",
    "- ✅ 尺度變化使用多尺度匹配\n",
    "- ✅ 了解限制，選擇合適方法\n",
    "- ✅ 性能優化從圖像預處理開始\n",
    "\n",
    "**下一步**: 繼續學習 4.2.2 特徵匹配模組，掌握更強大、更魯棒的物體檢測技術。\n",
    "\n",
    "---\n",
    "\n",
    "**模組完成！繼續學習 4.2.2 特徵匹配，探索旋轉不變和尺度不變的特徵檢測方法。**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
