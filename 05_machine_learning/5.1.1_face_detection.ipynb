{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.1 人臉檢測 (Face Detection)\n",
    "\n",
    "**WBS 5.1.1**: 傳統機器學習人臉檢測方法\n",
    "\n",
    "本模組深入探討三種經典人臉檢測方法，從理論到實作，涵蓋參數調優、性能分析與實戰應用。\n",
    "\n",
    "## 學習目標\n",
    "- 理解 Haar Cascade、LBP Cascade、HOG + SVM 三種檢測器的原理\n",
    "- 掌握多尺度檢測與參數優化技巧\n",
    "- 學習人臉檢測的性能優化策略\n",
    "- 實作單圖、多圖、實時視訊人臉檢測\n",
    "- 比較不同方法的速度與準確度權衡\n",
    "\n",
    "## 前置知識\n",
    "- Python 基礎語法\n",
    "- NumPy 陣列操作\n",
    "- OpenCV 圖像讀取與處理\n",
    "- 滑動窗口與特徵提取概念\n",
    "\n",
    "## 課程大綱\n",
    "1. 人臉檢測基礎概念\n",
    "2. Haar Cascade 人臉檢測\n",
    "3. LBP Cascade 人臉檢測\n",
    "4. HOG + SVM 人臉檢測 (dlib)\n",
    "5. 多尺度檢測與參數優化\n",
    "6. 性能比較與應用場景\n",
    "7. 實戰應用\n",
    "8. 進階主題與深度學習預覽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入必要的庫\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "# 設置中文顯示\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 設置圖像顯示大小\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "\n",
    "# 嘗試導入 dlib\n",
    "try:\n",
    "    import dlib\n",
    "    DLIB_AVAILABLE = True\n",
    "    print(\"dlib version:\", dlib.__version__ if hasattr(dlib, '__version__') else \"available\")\n",
    "except ImportError:\n",
    "    DLIB_AVAILABLE = False\n",
    "    print(\"dlib not available (install with: pip install dlib)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 人臉檢測基礎概念\n",
    "\n",
    "### 什麼是人臉檢測？\n",
    "\n",
    "人臉檢測（Face Detection）是計算機視覺的基礎任務，目標是在圖像中定位人臉的位置。\n",
    "\n",
    "### 人臉檢測 vs 人臉識別\n",
    "\n",
    "| 任務 | 目標 | 輸出 | 難度 |\n",
    "|-----|------|-----|-----|\n",
    "| 人臉檢測 | 找到人臉位置 | 邊界框 (x, y, w, h) | 中等 |\n",
    "| 人臉識別 | 識別人臉身份 | 人名/ID | 較高 |\n",
    "| 人臉對齊 | 標準化人臉姿態 | 關鍵點坐標 | 中等 |\n",
    "| 人臉驗證 | 判斷是否同一人 | True/False | 較高 |\n",
    "\n",
    "### 經典檢測方法演進\n",
    "\n",
    "```\n",
    "2001: Viola-Jones (Haar Cascade) → 實時檢測突破\n",
    "2006: LBP Cascade → 更快速度\n",
    "2005: HOG + SVM → 更高準確度\n",
    "2015: CNN (Deep Learning) → 準確度飛躍\n",
    "2017: MTCNN, Dlib CNN → 多任務學習\n",
    "2020+: RetinaFace, YOLOv5-Face → SOTA性能\n",
    "```\n",
    "\n",
    "### 檢測挑戰\n",
    "\n",
    "1. **姿態變化**: 正臉、側臉、仰視、俯視\n",
    "2. **光照條件**: 強光、背光、陰影\n",
    "3. **遮擋問題**: 口罩、眼鏡、頭髮\n",
    "4. **尺度變化**: 遠處小臉、近處大臉\n",
    "5. **表情變化**: 微笑、張嘴、閉眼\n",
    "6. **圖像質量**: 模糊、噪點、低分辨率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Haar Cascade 人臉檢測\n",
    "\n",
    "### 原理說明\n",
    "\n",
    "**Haar Cascade** 由 Viola 和 Jones 於 2001 年提出，是第一個實時人臉檢測算法。\n",
    "\n",
    "#### 核心概念\n",
    "\n",
    "1. **Haar-like 特徵**\n",
    "   - 矩形特徵：黑白區域差值\n",
    "   - 邊緣特徵：檢測明暗變化\n",
    "   - 線特徵：檢測線狀結構\n",
    "   - 四矩形特徵：檢測複雜模式\n",
    "\n",
    "2. **積分圖 (Integral Image)**\n",
    "   - 快速計算矩形區域和\n",
    "   - 時間複雜度：O(1)\n",
    "\n",
    "3. **AdaBoost 算法**\n",
    "   - 選擇最佳特徵\n",
    "   - 組合弱分類器成強分類器\n",
    "\n",
    "4. **級聯分類器 (Cascade)**\n",
    "   - 多層過濾器\n",
    "   - 快速排除非人臉區域\n",
    "   - 只有通過所有層的才是人臉\n",
    "\n",
    "#### 優缺點\n",
    "\n",
    "**優點**:\n",
    "- 速度快，適合實時應用\n",
    "- 輕量級，資源消耗少\n",
    "- OpenCV 內建，易於使用\n",
    "- 預訓練模型豐富\n",
    "\n",
    "**缺點**:\n",
    "- 側臉檢測效果差\n",
    "- 對光照敏感\n",
    "- 誤檢率較高\n",
    "- 無法處理大角度旋轉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Haar Cascade 分類器\n",
    "# OpenCV 提供多個預訓練模型\n",
    "\n",
    "# 方法1: 使用 OpenCV 內建路徑\n",
    "haar_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "\n",
    "# 方法2: 使用專案 assets 路徑（如果已複製）\n",
    "# haar_cascade_path = '../assets/models/haarcascade_frontalface_default.xml'\n",
    "\n",
    "# 載入分類器\n",
    "face_cascade = cv2.CascadeClassifier(haar_cascade_path)\n",
    "\n",
    "# 驗證載入成功\n",
    "if face_cascade.empty():\n",
    "    print(\"Error: Failed to load Haar Cascade classifier\")\n",
    "else:\n",
    "    print(\"Haar Cascade classifier loaded successfully\")\n",
    "    print(f\"Model path: {haar_cascade_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入測試圖像\n",
    "test_image_path = '../assets/images/basic/faces.jpg'\n",
    "\n",
    "if not Path(test_image_path).exists():\n",
    "    print(f\"Warning: {test_image_path} not found, creating demo image\")\n",
    "    # 創建示範圖像\n",
    "    img = np.ones((400, 600, 3), dtype=np.uint8) * 200\n",
    "    cv2.putText(img, \"Place test face image at:\", (50, 150), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "    cv2.putText(img, test_image_path, (50, 200), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1)\n",
    "else:\n",
    "    img = cv2.imread(test_image_path)\n",
    "\n",
    "# 顯示原始圖像\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image size: {img.shape[1]} x {img.shape[0]} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haar Cascade 基本檢測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_haar(image: np.ndarray, \n",
    "                       cascade: cv2.CascadeClassifier,\n",
    "                       scale_factor: float = 1.1,\n",
    "                       min_neighbors: int = 5,\n",
    "                       min_size: Tuple[int, int] = (30, 30)) -> Tuple[np.ndarray, List, float]:\n",
    "    \"\"\"\n",
    "    Detect faces using Haar Cascade classifier\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray\n",
    "        Input image in BGR format\n",
    "    cascade : cv2.CascadeClassifier\n",
    "        Loaded Haar Cascade classifier\n",
    "    scale_factor : float\n",
    "        Scale factor for multi-scale detection (1.05-1.4)\n",
    "    min_neighbors : int\n",
    "        Minimum neighbors for valid detection (3-6)\n",
    "    min_size : tuple\n",
    "        Minimum face size (width, height)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    gray : np.ndarray\n",
    "        Grayscale image\n",
    "    faces : list\n",
    "        List of face rectangles [(x, y, w, h), ...]\n",
    "    elapsed_time : float\n",
    "        Detection time in seconds\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Histogram equalization for better detection\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Detect faces\n",
    "    start_time = time.time()\n",
    "    faces = cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=scale_factor,\n",
    "        minNeighbors=min_neighbors,\n",
    "        minSize=min_size,\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    return gray, faces, elapsed_time\n",
    "\n",
    "\n",
    "def draw_faces(image: np.ndarray, \n",
    "               faces: List, \n",
    "               color: Tuple[int, int, int] = (0, 255, 0),\n",
    "               thickness: int = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw rectangles around detected faces\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray\n",
    "        Input image\n",
    "    faces : list\n",
    "        List of face rectangles\n",
    "    color : tuple\n",
    "        Rectangle color in BGR\n",
    "    thickness : int\n",
    "        Rectangle line thickness\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    output : np.ndarray\n",
    "        Image with drawn rectangles\n",
    "    \"\"\"\n",
    "    output = image.copy()\n",
    "    \n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(output, (x, y), (x+w, y+h), color, thickness)\n",
    "        \n",
    "        # Draw face number\n",
    "        label = f\"Face {i+1}\"\n",
    "        cv2.putText(output, label, (x, y-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# 執行人臉檢測\n",
    "gray, faces_haar, time_haar = detect_faces_haar(img, face_cascade)\n",
    "\n",
    "# 繪製檢測結果\n",
    "img_result = draw_faces(img, faces_haar, color=(0, 255, 0))\n",
    "\n",
    "# 顯示結果\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original Image', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(gray, cmap='gray')\n",
    "axes[1].set_title('Preprocessed (Grayscale + Equalization)', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title(f'Haar Cascade Detection: {len(faces_haar)} faces\\nTime: {time_haar*1000:.2f}ms', fontsize=12)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 輸出詳細信息\n",
    "print(f\"\\nDetection Results:\")\n",
    "print(f\"Number of faces detected: {len(faces_haar)}\")\n",
    "print(f\"Detection time: {time_haar*1000:.2f} ms\")\n",
    "print(f\"\\nFace coordinates (x, y, w, h):\")\n",
    "for i, (x, y, w, h) in enumerate(faces_haar, 1):\n",
    "    print(f\"Face {i}: ({x}, {y}, {w}, {h})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參數調優實驗\n",
    "\n",
    "#### 關鍵參數說明\n",
    "\n",
    "1. **scaleFactor** (1.05 - 1.4)\n",
    "   - 每次縮放的比例\n",
    "   - 值越小：檢測越細緻，但速度越慢\n",
    "   - 推薦：1.1 (平衡) / 1.05 (高精度) / 1.3 (高速度)\n",
    "\n",
    "2. **minNeighbors** (3 - 6)\n",
    "   - 每個候選區域需要的鄰居數\n",
    "   - 值越大：誤檢越少，但可能漏檢\n",
    "   - 推薦：5 (平衡) / 3 (高召回) / 6 (高精確)\n",
    "\n",
    "3. **minSize** / **maxSize**\n",
    "   - 最小/最大人臉尺寸\n",
    "   - 限制檢測範圍，提升速度\n",
    "   - 推薦：(30, 30) 最小尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數調優實驗\n",
    "param_experiments = [\n",
    "    {\"name\": \"High Precision\", \"scale_factor\": 1.05, \"min_neighbors\": 6, \"color\": (255, 0, 0)},\n",
    "    {\"name\": \"Balanced\", \"scale_factor\": 1.1, \"min_neighbors\": 5, \"color\": (0, 255, 0)},\n",
    "    {\"name\": \"High Recall\", \"scale_factor\": 1.1, \"min_neighbors\": 3, \"color\": (0, 0, 255)},\n",
    "    {\"name\": \"Fast Detection\", \"scale_factor\": 1.3, \"min_neighbors\": 4, \"color\": (255, 255, 0)}\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, params in enumerate(param_experiments):\n",
    "    # 執行檢測\n",
    "    gray, faces, elapsed = detect_faces_haar(\n",
    "        img, face_cascade,\n",
    "        scale_factor=params[\"scale_factor\"],\n",
    "        min_neighbors=params[\"min_neighbors\"]\n",
    "    )\n",
    "    \n",
    "    # 繪製結果\n",
    "    img_result = draw_faces(img, faces, color=params[\"color\"])\n",
    "    \n",
    "    # 顯示\n",
    "    axes[idx].imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
    "    axes[idx].set_title(\n",
    "        f\"{params['name']}\\n\"\n",
    "        f\"scaleFactor={params['scale_factor']}, minNeighbors={params['min_neighbors']}\\n\"\n",
    "        f\"Faces: {len(faces)}, Time: {elapsed*1000:.2f}ms\",\n",
    "        fontsize=11\n",
    "    )\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    results.append({\n",
    "        \"name\": params[\"name\"],\n",
    "        \"faces\": len(faces),\n",
    "        \"time_ms\": elapsed * 1000\n",
    "    })\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 輸出比較表\n",
    "print(\"\\nParameter Tuning Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Configuration':<20} {'Faces':<10} {'Time (ms)':<15}\")\n",
    "print(\"=\" * 60)\n",
    "for result in results:\n",
    "    print(f\"{result['name']:<20} {result['faces']:<10} {result['time_ms']:<15.2f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LBP Cascade 人臉檢測\n",
    "\n",
    "### 原理說明\n",
    "\n",
    "**LBP (Local Binary Patterns)** Cascade 是 Haar Cascade 的輕量級替代方案。\n",
    "\n",
    "#### 核心概念\n",
    "\n",
    "1. **LBP 特徵**\n",
    "   - 局部二值模式\n",
    "   - 比較中心像素與周圍像素\n",
    "   - 編碼局部紋理信息\n",
    "\n",
    "2. **計算流程**\n",
    "   ```\n",
    "   1. 取 3x3 鄰域\n",
    "   2. 比較中心與周圍 8 個像素\n",
    "   3. 大於中心記為 1，否則記為 0\n",
    "   4. 得到 8 位二進制數\n",
    "   ```\n",
    "\n",
    "#### 優缺點\n",
    "\n",
    "**優點**:\n",
    "- 比 Haar Cascade 快 2-3 倍\n",
    "- 訓練速度快\n",
    "- 對光照變化更魯棒\n",
    "- 模型文件更小\n",
    "\n",
    "**缺點**:\n",
    "- 準確度略低於 Haar\n",
    "- 誤檢率稍高\n",
    "- 對複雜背景敏感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 LBP Cascade 分類器\n",
    "# 注意：OpenCV 的 LBP 模型在不同版本中可能不包含\n",
    "# 可以從 OpenCV GitHub 下載或使用 Haar 作為替代\n",
    "\n",
    "try:\n",
    "    # 嘗試載入 LBP 模型\n",
    "    lbp_cascade_path = cv2.data.haarcascades + 'lbpcascade_frontalface.xml'\n",
    "    if not Path(lbp_cascade_path).exists():\n",
    "        # 嘗試替代路徑\n",
    "        lbp_cascade_path = cv2.data.haarcascades + 'lbpcascade_frontalface_improved.xml'\n",
    "    \n",
    "    face_cascade_lbp = cv2.CascadeClassifier(lbp_cascade_path)\n",
    "    \n",
    "    if face_cascade_lbp.empty():\n",
    "        raise FileNotFoundError(\"LBP Cascade not found\")\n",
    "    \n",
    "    LBP_AVAILABLE = True\n",
    "    print(\"LBP Cascade classifier loaded successfully\")\n",
    "    print(f\"Model path: {lbp_cascade_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    LBP_AVAILABLE = False\n",
    "    print(f\"LBP Cascade not available: {e}\")\n",
    "    print(\"Download from: https://github.com/opencv/opencv/tree/master/data/lbpcascades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LBP_AVAILABLE:\n",
    "    # 執行 LBP 檢測\n",
    "    gray_lbp, faces_lbp, time_lbp = detect_faces_haar(img, face_cascade_lbp)\n",
    "    \n",
    "    # 繪製結果\n",
    "    img_result_lbp = draw_faces(img, faces_lbp, color=(255, 0, 0))\n",
    "    \n",
    "    # Haar vs LBP 比較\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(f'Haar Cascade\\nFaces: {len(faces_haar)}, Time: {time_haar*1000:.2f}ms', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cv2.cvtColor(img_result_lbp, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(f'LBP Cascade\\nFaces: {len(faces_lbp)}, Time: {time_lbp*1000:.2f}ms', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 性能比較\n",
    "    print(\"\\nHaar vs LBP Comparison:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Metric':<20} {'Haar':<15} {'LBP':<15}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Faces detected':<20} {len(faces_haar):<15} {len(faces_lbp):<15}\")\n",
    "    print(f\"{'Time (ms)':<20} {time_haar*1000:<15.2f} {time_lbp*1000:<15.2f}\")\n",
    "    speedup = time_haar / time_lbp\n",
    "    print(f\"{'Speedup':<20} {'1.00x':<15} {f'{speedup:.2f}x':<15}\")\n",
    "    print(\"=\" * 50)\n",
    "else:\n",
    "    print(\"Skipping LBP comparison (LBP cascade not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HOG + SVM 人臉檢測 (dlib)\n",
    "\n",
    "### 原理說明\n",
    "\n",
    "**HOG (Histogram of Oriented Gradients) + SVM** 是 dlib 採用的人臉檢測方法。\n",
    "\n",
    "#### 核心概念\n",
    "\n",
    "1. **HOG 特徵**\n",
    "   - 梯度方向直方圖\n",
    "   - 描述局部形狀和邊緣信息\n",
    "   - 對光照變化魯棒\n",
    "\n",
    "2. **SVM 分類器**\n",
    "   - Support Vector Machine\n",
    "   - 線性分類器\n",
    "   - 最大間隔分類\n",
    "\n",
    "3. **滑動窗口**\n",
    "   - 多尺度搜索\n",
    "   - 金字塔縮放\n",
    "\n",
    "#### 優缺點\n",
    "\n",
    "**優點**:\n",
    "- 準確度高於 Haar/LBP\n",
    "- 誤檢率低\n",
    "- 處理側臉效果較好\n",
    "- 對遮擋有一定魯棒性\n",
    "\n",
    "**缺點**:\n",
    "- 速度較慢（比 Haar 慢 5-10 倍）\n",
    "- 需要額外安裝 dlib\n",
    "- 資源消耗較大\n",
    "- 不適合大分辨率圖像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DLIB_AVAILABLE:\n",
    "    # 初始化 dlib HOG 人臉檢測器\n",
    "    hog_detector = dlib.get_frontal_face_detector()\n",
    "    print(\"dlib HOG face detector initialized\")\n",
    "    \n",
    "    def detect_faces_hog(image: np.ndarray, \n",
    "                         detector,\n",
    "                         upsample_num: int = 1) -> Tuple[np.ndarray, List, float]:\n",
    "        \"\"\"\n",
    "        Detect faces using dlib HOG detector\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image (BGR or RGB)\n",
    "        detector : dlib.fhog_object_detector\n",
    "            dlib HOG face detector\n",
    "        upsample_num : int\n",
    "            Number of times to upsample image (0-2)\n",
    "            0: fastest, 1: balanced, 2: highest accuracy\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        rgb : np.ndarray\n",
    "            RGB image\n",
    "        faces : list\n",
    "            List of face rectangles [(x, y, w, h), ...]\n",
    "        elapsed_time : float\n",
    "            Detection time in seconds\n",
    "        \"\"\"\n",
    "        # dlib expects RGB\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        start_time = time.time()\n",
    "        dets = detector(rgb, upsample_num)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Convert dlib rectangles to (x, y, w, h) format\n",
    "        faces = []\n",
    "        for det in dets:\n",
    "            x = det.left()\n",
    "            y = det.top()\n",
    "            w = det.right() - x\n",
    "            h = det.bottom() - y\n",
    "            faces.append((x, y, w, h))\n",
    "        \n",
    "        return rgb, faces, elapsed_time\n",
    "    \n",
    "    # 執行 HOG 檢測\n",
    "    rgb_hog, faces_hog, time_hog = detect_faces_hog(img, hog_detector, upsample_num=1)\n",
    "    \n",
    "    # 繪製結果\n",
    "    img_result_hog = draw_faces(img, faces_hog, color=(255, 0, 255))\n",
    "    \n",
    "    # 三種方法比較\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(f'Haar Cascade\\nFaces: {len(faces_haar)}, Time: {time_haar*1000:.2f}ms', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    if LBP_AVAILABLE:\n",
    "        axes[1].imshow(cv2.cvtColor(img_result_lbp, cv2.COLOR_BGR2RGB))\n",
    "        axes[1].set_title(f'LBP Cascade\\nFaces: {len(faces_lbp)}, Time: {time_lbp*1000:.2f}ms', fontsize=12)\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'LBP Not Available', ha='center', va='center', fontsize=14)\n",
    "        axes[1].set_title('LBP Cascade', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(cv2.cvtColor(img_result_hog, cv2.COLOR_BGR2RGB))\n",
    "    axes[2].set_title(f'HOG + SVM (dlib)\\nFaces: {len(faces_hog)}, Time: {time_hog*1000:.2f}ms', fontsize=12)\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 性能比較\n",
    "    print(\"\\nThree-Method Comparison:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Metric':<20} {'Haar':<15} {'LBP':<15} {'HOG (dlib)':<15}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Faces detected':<20} {len(faces_haar):<15} {len(faces_lbp) if LBP_AVAILABLE else 'N/A':<15} {len(faces_hog):<15}\")\n",
    "    print(f\"{'Time (ms)':<20} {time_haar*1000:<15.2f} {time_lbp*1000 if LBP_AVAILABLE else 'N/A':<15} {time_hog*1000:<15.2f}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "else:\n",
    "    print(\"dlib not available. Install with: pip install dlib\")\n",
    "    print(\"Note: dlib requires CMake and C++ compiler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 多尺度檢測與參數優化\n",
    "\n",
    "### 多尺度檢測原理\n",
    "\n",
    "人臉在圖像中可能有不同大小，多尺度檢測通過圖像金字塔來檢測不同尺度的人臉。\n",
    "\n",
    "```\n",
    "原始圖像 → 檢測\n",
    "縮小 10% → 檢測\n",
    "縮小 20% → 檢測\n",
    "...\n",
    "縮小到最小尺寸 → 檢測\n",
    "```\n",
    "\n",
    "### 參數優化策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建不同尺度的測試圖像\n",
    "scales = [0.5, 0.75, 1.0, 1.5]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
    "\n",
    "for idx, scale in enumerate(scales):\n",
    "    # 縮放圖像\n",
    "    width = int(img.shape[1] * scale)\n",
    "    height = int(img.shape[0] * scale)\n",
    "    img_scaled = cv2.resize(img, (width, height))\n",
    "    \n",
    "    # 檢測人臉\n",
    "    gray_scaled, faces_scaled, time_scaled = detect_faces_haar(\n",
    "        img_scaled, face_cascade,\n",
    "        scale_factor=1.1,\n",
    "        min_neighbors=5\n",
    "    )\n",
    "    \n",
    "    # 繪製結果\n",
    "    img_result_scaled = draw_faces(img_scaled, faces_scaled)\n",
    "    \n",
    "    # 顯示原圖\n",
    "    axes[0, idx].imshow(cv2.cvtColor(img_scaled, cv2.COLOR_BGR2RGB))\n",
    "    axes[0, idx].set_title(f'Scale {scale}x\\nSize: {width}x{height}', fontsize=10)\n",
    "    axes[0, idx].axis('off')\n",
    "    \n",
    "    # 顯示檢測結果\n",
    "    axes[1, idx].imshow(cv2.cvtColor(img_result_scaled, cv2.COLOR_BGR2RGB))\n",
    "    axes[1, idx].set_title(f'Detected: {len(faces_scaled)} faces\\nTime: {time_scaled*1000:.2f}ms', fontsize=10)\n",
    "    axes[1, idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能優化技巧\n",
    "\n",
    "#### 1. 圖像預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_detection(image: np.ndarray, \n",
    "                             target_width: int = 640,\n",
    "                             apply_equalization: bool = True,\n",
    "                             apply_blur: bool = False) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Preprocess image for faster and more accurate detection\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray\n",
    "        Input image\n",
    "    target_width : int\n",
    "        Resize to this width (keep aspect ratio)\n",
    "    apply_equalization : bool\n",
    "        Apply histogram equalization\n",
    "    apply_blur : bool\n",
    "        Apply Gaussian blur to reduce noise\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    processed : np.ndarray\n",
    "        Preprocessed image\n",
    "    scale : float\n",
    "        Scaling factor applied\n",
    "    \"\"\"\n",
    "    # Resize if image is too large\n",
    "    height, width = image.shape[:2]\n",
    "    if width > target_width:\n",
    "        scale = target_width / width\n",
    "        new_height = int(height * scale)\n",
    "        processed = cv2.resize(image, (target_width, new_height))\n",
    "    else:\n",
    "        processed = image.copy()\n",
    "        scale = 1.0\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    if len(processed.shape) == 3:\n",
    "        processed = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    if apply_equalization:\n",
    "        processed = cv2.equalizeHist(processed)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    if apply_blur:\n",
    "        processed = cv2.GaussianBlur(processed, (3, 3), 0)\n",
    "    \n",
    "    return processed, scale\n",
    "\n",
    "\n",
    "# 測試不同預處理方法\n",
    "preprocessing_configs = [\n",
    "    {\"name\": \"No Preprocessing\", \"equalization\": False, \"blur\": False},\n",
    "    {\"name\": \"Equalization Only\", \"equalization\": True, \"blur\": False},\n",
    "    {\"name\": \"Blur Only\", \"equalization\": False, \"blur\": True},\n",
    "    {\"name\": \"Both\", \"equalization\": True, \"blur\": True}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
    "\n",
    "for idx, config in enumerate(preprocessing_configs):\n",
    "    # 預處理\n",
    "    processed, scale = preprocess_for_detection(\n",
    "        img,\n",
    "        target_width=640,\n",
    "        apply_equalization=config[\"equalization\"],\n",
    "        apply_blur=config[\"blur\"]\n",
    "    )\n",
    "    \n",
    "    # 檢測（注意：這裡直接在灰階圖上檢測）\n",
    "    start_time = time.time()\n",
    "    faces_preprocessed = face_cascade.detectMultiScale(\n",
    "        processed,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    time_preprocessed = time.time() - start_time\n",
    "    \n",
    "    # 顯示預處理圖像\n",
    "    axes[0, idx].imshow(processed, cmap='gray')\n",
    "    axes[0, idx].set_title(f\"{config['name']}\\nScale: {scale:.2f}x\", fontsize=10)\n",
    "    axes[0, idx].axis('off')\n",
    "    \n",
    "    # 繪製檢測結果（在灰階圖上）\n",
    "    result_gray = cv2.cvtColor(processed, cv2.COLOR_GRAY2BGR)\n",
    "    result_gray = draw_faces(result_gray, faces_preprocessed)\n",
    "    \n",
    "    axes[1, idx].imshow(cv2.cvtColor(result_gray, cv2.COLOR_BGR2RGB))\n",
    "    axes[1, idx].set_title(f\"Faces: {len(faces_preprocessed)}\\nTime: {time_preprocessed*1000:.2f}ms\", fontsize=10)\n",
    "    axes[1, idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPreprocessing Impact:\")\n",
    "print(\"Equalization improves contrast and helps detect faces in poor lighting\")\n",
    "print(\"Blur reduces noise but may reduce detection accuracy\")\n",
    "print(\"Resizing to fixed width significantly speeds up detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 性能比較與應用場景\n",
    "\n",
    "### 綜合性能分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建性能比較表\n",
    "comparison_data = {\n",
    "    \"Method\": [\"Haar Cascade\", \"LBP Cascade\", \"HOG + SVM (dlib)\"],\n",
    "    \"Speed\": [\"Fast (15-30ms)\", \"Very Fast (8-15ms)\", \"Slow (50-150ms)\"],\n",
    "    \"Accuracy\": [\"Good\", \"Fair\", \"Very Good\"],\n",
    "    \"False Positive\": [\"Medium\", \"High\", \"Low\"],\n",
    "    \"Side Face\": [\"Poor\", \"Poor\", \"Fair\"],\n",
    "    \"Lighting\": [\"Sensitive\", \"Robust\", \"Robust\"],\n",
    "    \"Use Case\": [\"Real-time apps\", \"Embedded systems\", \"High accuracy apps\"]\n",
    "}\n",
    "\n",
    "# 以表格形式顯示\n",
    "print(\"\\nMethod Comparison:\")\n",
    "print(\"=\" * 120)\n",
    "print(f\"{'Method':<20} {'Speed':<20} {'Accuracy':<15} {'False Positive':<15} {'Side Face':<12} {'Lighting':<12} {'Use Case':<25}\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "for i in range(len(comparison_data[\"Method\"])):\n",
    "    print(f\"{comparison_data['Method'][i]:<20} \"\n",
    "          f\"{comparison_data['Speed'][i]:<20} \"\n",
    "          f\"{comparison_data['Accuracy'][i]:<15} \"\n",
    "          f\"{comparison_data['False Positive'][i]:<15} \"\n",
    "          f\"{comparison_data['Side Face'][i]:<12} \"\n",
    "          f\"{comparison_data['Lighting'][i]:<12} \"\n",
    "          f\"{comparison_data['Use Case'][i]:<25}\")\n",
    "print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 應用場景推薦\n",
    "\n",
    "#### 1. 實時視訊監控\n",
    "- **推薦**: LBP Cascade\n",
    "- **原因**: 速度最快，資源消耗低\n",
    "\n",
    "#### 2. 手機 App\n",
    "- **推薦**: Haar Cascade\n",
    "- **原因**: 平衡速度與準確度\n",
    "\n",
    "#### 3. 安全驗證系統\n",
    "- **推薦**: HOG + SVM\n",
    "- **原因**: 高準確度，低誤檢率\n",
    "\n",
    "#### 4. 嵌入式設備\n",
    "- **推薦**: LBP Cascade\n",
    "- **原因**: 模型小，計算簡單\n",
    "\n",
    "#### 5. 大規模照片處理\n",
    "- **推薦**: Haar Cascade + 並行處理\n",
    "- **原因**: 可批次處理，速度可接受"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 實戰應用\n",
    "\n",
    "### 應用 1: 批次圖像人臉檢測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_face_detection(image_paths: List[str], \n",
    "                        cascade: cv2.CascadeClassifier,\n",
    "                        output_dir: str = None) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Batch face detection for multiple images\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_paths : list\n",
    "        List of image file paths\n",
    "    cascade : cv2.CascadeClassifier\n",
    "        Face detector\n",
    "    output_dir : str, optional\n",
    "        Directory to save results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results : list\n",
    "        List of detection results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        if not Path(img_path).exists():\n",
    "            print(f\"Warning: {img_path} not found\")\n",
    "            continue\n",
    "        \n",
    "        # Load image\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Failed to load {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Detect faces\n",
    "        gray, faces, elapsed = detect_faces_haar(img, cascade)\n",
    "        \n",
    "        # Save result\n",
    "        result = {\n",
    "            \"path\": img_path,\n",
    "            \"faces\": len(faces),\n",
    "            \"time_ms\": elapsed * 1000,\n",
    "            \"coordinates\": faces\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        # Save annotated image if output_dir specified\n",
    "        if output_dir:\n",
    "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "            img_result = draw_faces(img, faces)\n",
    "            output_path = Path(output_dir) / Path(img_path).name\n",
    "            cv2.imwrite(str(output_path), img_result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# 測試批次檢測\n",
    "test_images = [\n",
    "    '../assets/images/basic/faces.jpg',\n",
    "    '../assets/images/basic/face03.jpg',\n",
    "    '../assets/images/basic/faces01.jpg'\n",
    "]\n",
    "\n",
    "# 只處理存在的圖像\n",
    "existing_images = [p for p in test_images if Path(p).exists()]\n",
    "\n",
    "if existing_images:\n",
    "    batch_results = batch_face_detection(\n",
    "        existing_images,\n",
    "        face_cascade,\n",
    "        output_dir='../assets/images/output/face_detection'\n",
    "    )\n",
    "    \n",
    "    # 輸出統計\n",
    "    print(\"\\nBatch Detection Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Image':<40} {'Faces':<10} {'Time (ms)':<15}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    total_faces = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for result in batch_results:\n",
    "        img_name = Path(result['path']).name\n",
    "        print(f\"{img_name:<40} {result['faces']:<10} {result['time_ms']:<15.2f}\")\n",
    "        total_faces += result['faces']\n",
    "        total_time += result['time_ms']\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total: {len(batch_results)} images, {total_faces} faces, {total_time:.2f}ms\")\n",
    "    print(f\"Average: {total_time/len(batch_results):.2f}ms per image\")\n",
    "else:\n",
    "    print(\"No test images found. Please add images to test batch detection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 應用 2: 人臉提取與裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(image: np.ndarray, \n",
    "                  faces: List,\n",
    "                  padding: float = 0.2,\n",
    "                  target_size: Tuple[int, int] = (128, 128)) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract and crop face regions from image\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray\n",
    "        Input image\n",
    "    faces : list\n",
    "        List of face coordinates [(x, y, w, h), ...]\n",
    "    padding : float\n",
    "        Padding ratio around face (0.0-0.5)\n",
    "    target_size : tuple\n",
    "        Resize face to this size\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    face_crops : list\n",
    "        List of cropped face images\n",
    "    \"\"\"\n",
    "    face_crops = []\n",
    "    h_img, w_img = image.shape[:2]\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        # Add padding\n",
    "        pad_w = int(w * padding)\n",
    "        pad_h = int(h * padding)\n",
    "        \n",
    "        x1 = max(0, x - pad_w)\n",
    "        y1 = max(0, y - pad_h)\n",
    "        x2 = min(w_img, x + w + pad_w)\n",
    "        y2 = min(h_img, y + h + pad_h)\n",
    "        \n",
    "        # Crop face\n",
    "        face_crop = image[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize\n",
    "        if target_size:\n",
    "            face_crop = cv2.resize(face_crop, target_size)\n",
    "        \n",
    "        face_crops.append(face_crop)\n",
    "    \n",
    "    return face_crops\n",
    "\n",
    "\n",
    "# 提取人臉\n",
    "face_crops = extract_faces(img, faces_haar, padding=0.2, target_size=(128, 128))\n",
    "\n",
    "# 顯示提取的人臉\n",
    "if face_crops:\n",
    "    n_faces = len(face_crops)\n",
    "    n_cols = min(5, n_faces)\n",
    "    n_rows = (n_faces + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3*n_rows))\n",
    "    if n_faces == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten() if n_rows > 1 else axes\n",
    "    \n",
    "    for idx, face_crop in enumerate(face_crops):\n",
    "        axes[idx].imshow(cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f'Face {idx+1}', fontsize=12)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_faces, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nExtracted {len(face_crops)} face(s)\")\n",
    "    print(f\"Face size: {face_crops[0].shape}\")\n",
    "else:\n",
    "    print(\"No faces detected to extract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 應用 3: 視訊流實時人臉檢測\n",
    "\n",
    "**注意**: 在 Jupyter Notebook 中實時視訊可能無法正常顯示，建議在獨立 Python 腳本中運行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realtime_face_detection_demo(cascade: cv2.CascadeClassifier,\n",
    "                                 camera_id: int = 0,\n",
    "                                 max_frames: int = 100):\n",
    "    \"\"\"\n",
    "    Real-time face detection from webcam (demo version)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cascade : cv2.CascadeClassifier\n",
    "        Face detector\n",
    "    camera_id : int\n",
    "        Camera device ID\n",
    "    max_frames : int\n",
    "        Maximum frames to process (for demo)\n",
    "    \n",
    "    Note:\n",
    "    -----\n",
    "    This is a demo function. For actual real-time detection,\n",
    "    run as a standalone Python script.\n",
    "    \"\"\"\n",
    "    print(\"Real-time Face Detection Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"This function demonstrates real-time detection code.\")\n",
    "    print(\"To run actual webcam detection:\")\n",
    "    print(\"1. Save this code to a .py file\")\n",
    "    print(\"2. Run: python face_detection_realtime.py\")\n",
    "    print(\"3. Press 'q' to quit\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Demo code (commented out for notebook)\n",
    "    demo_code = '''\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Load cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# FPS calculation\n",
    "fps_list = []\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Read frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Preprocess\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    \n",
    "    # Draw results\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Face\", (x, y-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    \n",
    "    # Calculate FPS\n",
    "    elapsed = time.time() - start_time\n",
    "    fps = 1 / elapsed if elapsed > 0 else 0\n",
    "    fps_list.append(fps)\n",
    "    avg_fps = sum(fps_list[-30:]) / len(fps_list[-30:])\n",
    "    \n",
    "    # Display info\n",
    "    cv2.putText(frame, f\"Faces: {len(faces)}\", (10, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"FPS: {avg_fps:.1f}\", (10, 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Show frame\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    \n",
    "    # Check for quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processed {frame_count} frames\")\n",
    "print(f\"Average FPS: {sum(fps_list)/len(fps_list):.2f}\")\n",
    "    '''\n",
    "    \n",
    "    print(\"\\nExample Code:\")\n",
    "    print(demo_code)\n",
    "\n",
    "# 顯示 demo 說明\n",
    "realtime_face_detection_demo(face_cascade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 應用 4: 多人臉追蹤與編號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_faces_simple(faces_prev: List, \n",
    "                       faces_curr: List,\n",
    "                       max_distance: int = 50) -> List[Tuple[int, Tuple]]:\n",
    "    \"\"\"\n",
    "    Simple face tracking by distance matching\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    faces_prev : list\n",
    "        Previous frame faces [(id, (x, y, w, h)), ...]\n",
    "    faces_curr : list\n",
    "        Current frame faces [(x, y, w, h), ...]\n",
    "    max_distance : int\n",
    "        Maximum distance for matching\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tracked : list\n",
    "        Tracked faces [(id, (x, y, w, h)), ...]\n",
    "    \"\"\"\n",
    "    if not faces_prev:\n",
    "        # First frame: assign new IDs\n",
    "        return [(i, face) for i, face in enumerate(faces_curr)]\n",
    "    \n",
    "    tracked = []\n",
    "    used_ids = set()\n",
    "    next_id = max([fid for fid, _ in faces_prev]) + 1\n",
    "    \n",
    "    for curr_face in faces_curr:\n",
    "        x_curr, y_curr, w_curr, h_curr = curr_face\n",
    "        cx_curr = x_curr + w_curr // 2\n",
    "        cy_curr = y_curr + h_curr // 2\n",
    "        \n",
    "        # Find closest previous face\n",
    "        min_dist = float('inf')\n",
    "        matched_id = None\n",
    "        \n",
    "        for prev_id, prev_face in faces_prev:\n",
    "            if prev_id in used_ids:\n",
    "                continue\n",
    "            \n",
    "            x_prev, y_prev, w_prev, h_prev = prev_face\n",
    "            cx_prev = x_prev + w_prev // 2\n",
    "            cy_prev = y_prev + h_prev // 2\n",
    "            \n",
    "            # Euclidean distance\n",
    "            dist = np.sqrt((cx_curr - cx_prev)**2 + (cy_curr - cy_prev)**2)\n",
    "            \n",
    "            if dist < min_dist and dist < max_distance:\n",
    "                min_dist = dist\n",
    "                matched_id = prev_id\n",
    "        \n",
    "        # Assign ID\n",
    "        if matched_id is not None:\n",
    "            tracked.append((matched_id, curr_face))\n",
    "            used_ids.add(matched_id)\n",
    "        else:\n",
    "            # New face\n",
    "            tracked.append((next_id, curr_face))\n",
    "            next_id += 1\n",
    "    \n",
    "    return tracked\n",
    "\n",
    "\n",
    "print(\"Face tracking function defined.\")\n",
    "print(\"This can be used for video processing to maintain face IDs across frames.\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"\"\"\n",
    "tracked_faces = []\n",
    "for frame in video:\n",
    "    faces = detect_faces_haar(frame, face_cascade)\n",
    "    tracked_faces = track_faces_simple(tracked_faces, faces)\n",
    "    # Draw with IDs...\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 進階主題與深度學習預覽\n",
    "\n",
    "### 8.1 級聯分類器訓練基礎\n",
    "\n",
    "#### 訓練自己的 Haar Cascade\n",
    "\n",
    "雖然 OpenCV 提供了預訓練模型，但有時需要訓練自定義檢測器（如特定姿勢、特定物體）。\n",
    "\n",
    "**訓練步驟**:\n",
    "\n",
    "1. **準備數據集**\n",
    "   - 正樣本（包含目標物體）: 1000-5000 張\n",
    "   - 負樣本（不含目標）: 3000-10000 張\n",
    "\n",
    "2. **創建樣本描述文件**\n",
    "   ```bash\n",
    "   opencv_createsamples -info positives.txt -vec samples.vec -w 24 -h 24\n",
    "   ```\n",
    "\n",
    "3. **訓練級聯分類器**\n",
    "   ```bash\n",
    "   opencv_traincascade -data cascade/ -vec samples.vec -bg negatives.txt \\\n",
    "       -numPos 800 -numNeg 400 -numStages 20 -w 24 -h 24\n",
    "   ```\n",
    "\n",
    "4. **測試與優化**\n",
    "   - 調整 numStages\n",
    "   - 調整 minHitRate 和 maxFalseAlarmRate\n",
    "\n",
    "### 8.2 誤檢與漏檢處理\n",
    "\n",
    "#### 減少誤檢 (False Positives)\n",
    "\n",
    "1. **提高 minNeighbors** - 更嚴格的檢測標準\n",
    "2. **限制檢測區域** - 只在可能出現人臉的區域檢測\n",
    "3. **多檢測器投票** - 使用多個檢測器，只接受多數同意的結果\n",
    "4. **後處理過濾** - 根據人臉特徵（長寬比、膚色等）過濾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_false_positives(image: np.ndarray, \n",
    "                          faces: List,\n",
    "                          aspect_ratio_range: Tuple[float, float] = (0.75, 1.3),\n",
    "                          min_area: int = 900) -> List:\n",
    "    \"\"\"\n",
    "    Filter false positive detections\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray\n",
    "        Input image\n",
    "    faces : list\n",
    "        Detected faces [(x, y, w, h), ...]\n",
    "    aspect_ratio_range : tuple\n",
    "        Valid aspect ratio range (w/h)\n",
    "    min_area : int\n",
    "        Minimum face area (w*h)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    filtered : list\n",
    "        Filtered faces\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        # Check aspect ratio\n",
    "        aspect_ratio = w / h if h > 0 else 0\n",
    "        if not (aspect_ratio_range[0] <= aspect_ratio <= aspect_ratio_range[1]):\n",
    "            continue\n",
    "        \n",
    "        # Check area\n",
    "        area = w * h\n",
    "        if area < min_area:\n",
    "            continue\n",
    "        \n",
    "        # Additional checks can be added here:\n",
    "        # - Skin color detection\n",
    "        # - Edge density\n",
    "        # - Symmetry\n",
    "        \n",
    "        filtered.append((x, y, w, h))\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "# 測試過濾\n",
    "faces_filtered = filter_false_positives(\n",
    "    img, faces_haar,\n",
    "    aspect_ratio_range=(0.8, 1.2),\n",
    "    min_area=900\n",
    ")\n",
    "\n",
    "print(f\"\\nFalse Positive Filtering:\")\n",
    "print(f\"Original detections: {len(faces_haar)}\")\n",
    "print(f\"After filtering: {len(faces_filtered)}\")\n",
    "print(f\"Removed: {len(faces_haar) - len(faces_filtered)}\")\n",
    "\n",
    "# 視覺化比較\n",
    "if len(faces_haar) != len(faces_filtered):\n",
    "    img_before = draw_faces(img, faces_haar, color=(0, 0, 255))\n",
    "    img_after = draw_faces(img, faces_filtered, color=(0, 255, 0))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(img_before, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(f'Before Filtering: {len(faces_haar)} faces', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cv2.cvtColor(img_after, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(f'After Filtering: {len(faces_filtered)} faces', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 深度學習方法預覽\n",
    "\n",
    "#### 現代深度學習人臉檢測\n",
    "\n",
    "傳統方法的局限性促使深度學習方法的發展：\n",
    "\n",
    "1. **OpenCV DNN 模組**\n",
    "   - 使用預訓練的 Caffe/TensorFlow 模型\n",
    "   - SSD (Single Shot Detector)\n",
    "   - ResNet 基礎網絡\n",
    "\n",
    "2. **MTCNN (Multi-task Cascaded CNN)**\n",
    "   - 三階段級聯網絡\n",
    "   - 同時檢測人臉和關鍵點\n",
    "   - 速度與準確度平衡\n",
    "\n",
    "3. **RetinaFace**\n",
    "   - SOTA 性能\n",
    "   - 處理極小人臉\n",
    "   - 多任務學習\n",
    "\n",
    "4. **YOLOv5-Face / YOLOv8-Face**\n",
    "   - 實時性能\n",
    "   - 易於部署\n",
    "   - 準確度高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV DNN 人臉檢測示例（如果有模型）\n",
    "dnn_model_path = '../assets/models/res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "dnn_config_path = '../assets/models/deploy.prototxt'\n",
    "\n",
    "if Path(dnn_model_path).exists() and Path(dnn_config_path).exists():\n",
    "    print(\"OpenCV DNN face detection model found\")\n",
    "    \n",
    "    # Load DNN model\n",
    "    net = cv2.dnn.readNetFromCaffe(dnn_config_path, dnn_model_path)\n",
    "    \n",
    "    def detect_faces_dnn(image: np.ndarray, \n",
    "                         net,\n",
    "                         confidence_threshold: float = 0.5) -> Tuple[List, float]:\n",
    "        \"\"\"\n",
    "        Detect faces using OpenCV DNN\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image\n",
    "        net : cv2.dnn.Net\n",
    "            DNN model\n",
    "        confidence_threshold : float\n",
    "            Minimum confidence (0.0-1.0)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        faces : list\n",
    "            Detected faces [(x, y, w, h), ...]\n",
    "        elapsed_time : float\n",
    "            Detection time\n",
    "        \"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        # Preprocess\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            cv2.resize(image, (300, 300)),\n",
    "            1.0,\n",
    "            (300, 300),\n",
    "            (104.0, 177.0, 123.0)\n",
    "        )\n",
    "        \n",
    "        # Detect\n",
    "        start_time = time.time()\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        faces = []\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            \n",
    "            if confidence > confidence_threshold:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                \n",
    "                # Convert to (x, y, w, h)\n",
    "                x = max(0, x1)\n",
    "                y = max(0, y1)\n",
    "                w = min(w, x2) - x\n",
    "                h = min(h, y2) - y\n",
    "                \n",
    "                faces.append((x, y, w, h))\n",
    "        \n",
    "        return faces, elapsed_time\n",
    "    \n",
    "    # 執行 DNN 檢測\n",
    "    faces_dnn, time_dnn = detect_faces_dnn(img, net, confidence_threshold=0.5)\n",
    "    img_result_dnn = draw_faces(img, faces_dnn, color=(0, 255, 255))\n",
    "    \n",
    "    # 四種方法比較\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    methods = [\n",
    "        (\"Haar Cascade\", img_result, len(faces_haar), time_haar),\n",
    "        (\"LBP Cascade\", img_result_lbp if LBP_AVAILABLE else img, len(faces_lbp) if LBP_AVAILABLE else 0, time_lbp if LBP_AVAILABLE else 0),\n",
    "        (\"HOG + SVM (dlib)\", img_result_hog if DLIB_AVAILABLE else img, len(faces_hog) if DLIB_AVAILABLE else 0, time_hog if DLIB_AVAILABLE else 0),\n",
    "        (\"DNN (Deep Learning)\", img_result_dnn, len(faces_dnn), time_dnn)\n",
    "    ]\n",
    "    \n",
    "    for idx, (name, result_img, n_faces, elapsed) in enumerate(methods):\n",
    "        axes[idx].imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(f'{name}\\nFaces: {n_faces}, Time: {elapsed*1000:.2f}ms', fontsize=12)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDeep Learning Comparison:\")\n",
    "    print(\"DNN method typically offers:\")\n",
    "    print(\"  + Higher accuracy (especially for challenging poses)\")\n",
    "    print(\"  + Better handling of occlusions\")\n",
    "    print(\"  + More robust to lighting variations\")\n",
    "    print(\"  - Slower than traditional methods (but still real-time capable)\")\n",
    "    print(\"  - Requires model files (larger storage)\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nDNN models not found.\")\n",
    "    print(\"For deep learning face detection, you need:\")\n",
    "    print(\"1. res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "    print(\"2. deploy.prototxt\")\n",
    "    print(\"\\nThese are typically included in the assets/models/ directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度學習 vs 傳統方法對比\n",
    "\n",
    "| 特性 | 傳統方法 (Haar/LBP/HOG) | 深度學習 (CNN/DNN) |\n",
    "|-----|------------------------|-------------------|\n",
    "| 準確度 | 中等 (85-90%) | 高 (95-99%) |\n",
    "| 速度 | 快 (10-50ms) | 中等 (20-100ms) |\n",
    "| 側臉檢測 | 差 | 優秀 |\n",
    "| 遮擋處理 | 差 | 良好 |\n",
    "| 光照魯棒性 | 中等 | 優秀 |\n",
    "| 訓練難度 | 高 | 中等（有預訓練模型） |\n",
    "| 資源需求 | 低 | 中-高 |\n",
    "| 部署難度 | 簡單 | 中等 |\n",
    "| 模型大小 | 小 (KB-MB) | 大 (MB-GB) |\n",
    "\n",
    "### 選擇建議\n",
    "\n",
    "- **嵌入式/移動設備**: 傳統方法 (Haar/LBP)\n",
    "- **高準確度要求**: 深度學習\n",
    "- **實時性要求**: 取決於硬件，現代 GPU 可支持 DNN 實時\n",
    "- **開發成本**: 傳統方法更易上手\n",
    "- **長期維護**: 深度學習模型更易更新和改進"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 練習題\n",
    "\n",
    "### 練習 1: 參數調優實驗\n",
    "\n",
    "使用不同參數組合，找到最佳的檢測設置：\n",
    "- 測試 scaleFactor: 1.05, 1.1, 1.2, 1.3\n",
    "- 測試 minNeighbors: 3, 4, 5, 6\n",
    "- 記錄檢測數量和時間\n",
    "- 找到速度與準確度的最佳平衡點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實作參數調優實驗\n",
    "# 提示：\n",
    "# 1. 創建嵌套循環遍歷所有參數組合\n",
    "# 2. 記錄每個組合的結果\n",
    "# 3. 創建熱力圖顯示性能\n",
    "# 4. 分析最佳參數\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 2: 多檢測器融合\n",
    "\n",
    "結合 Haar 和 LBP 檢測器，提高檢測可靠性：\n",
    "- 使用兩個檢測器分別檢測\n",
    "- 只保留兩者都檢測到的人臉（交集）\n",
    "- 比較融合前後的誤檢率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實作多檢測器融合\n",
    "# 提示：\n",
    "# 1. 定義 IoU (Intersection over Union) 函數\n",
    "# 2. 匹配兩個檢測器的結果\n",
    "# 3. 只保留高 IoU 的檢測\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 3: 視訊人臉檢測與統計\n",
    "\n",
    "處理一段視訊，統計人臉出現情況：\n",
    "- 檢測每一幀的人臉\n",
    "- 追蹤人臉 ID\n",
    "- 統計出現次數\n",
    "- 繪製人臉數量隨時間變化的曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實作視訊人臉統計\n",
    "# 提示：\n",
    "# 1. 讀取視訊文件\n",
    "# 2. 逐幀檢測並追蹤\n",
    "# 3. 記錄統計數據\n",
    "# 4. 繪製統計圖表\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 4: 人臉質量評分\n",
    "\n",
    "為檢測到的人臉評分（適合做人臉識別的程度）：\n",
    "- 檢查清晰度（邊緣強度）\n",
    "- 檢查正臉程度（眼睛檢測）\n",
    "- 檢查光照均勻度（直方圖）\n",
    "- 綜合評分 0-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實作人臉質量評分\n",
    "# 提示：\n",
    "# 1. 提取人臉區域\n",
    "# 2. 計算各項質量指標\n",
    "# 3. 加權平均得到總分\n",
    "# 4. 只保留高分人臉\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 總結\n",
    "\n",
    "### 關鍵要點\n",
    "\n",
    "1. **三種經典方法**\n",
    "   - Haar Cascade: 平衡速度與準確度\n",
    "   - LBP Cascade: 最快速度\n",
    "   - HOG + SVM: 最高準確度（傳統方法中）\n",
    "\n",
    "2. **參數調優重要性**\n",
    "   - scaleFactor: 控制檢測細緻度\n",
    "   - minNeighbors: 控制誤檢率\n",
    "   - 需根據應用場景調整\n",
    "\n",
    "3. **預處理技巧**\n",
    "   - 灰階化 + 直方圖均衡化\n",
    "   - 縮放到合適尺寸\n",
    "   - 可選的模糊降噪\n",
    "\n",
    "4. **實戰考慮**\n",
    "   - 速度 vs 準確度權衡\n",
    "   - 誤檢與漏檢處理\n",
    "   - 實時性能優化\n",
    "   - 多人臉追蹤\n",
    "\n",
    "5. **未來趨勢**\n",
    "   - 深度學習方法主流化\n",
    "   - 端側部署優化\n",
    "   - 多任務聯合學習\n",
    "   - 隱私保護檢測\n",
    "\n",
    "### 性能基準\n",
    "\n",
    "在標準測試圖像上（640x480 像素）：\n",
    "- Haar Cascade: ~15-30ms\n",
    "- LBP Cascade: ~8-15ms\n",
    "- HOG + SVM: ~50-150ms\n",
    "- DNN (CPU): ~30-80ms\n",
    "- DNN (GPU): ~5-15ms\n",
    "\n",
    "### 延伸學習\n",
    "\n",
    "1. **人臉對齊** (Face Alignment)\n",
    "   - 68 點關鍵點檢測\n",
    "   - Affine 變換標準化\n",
    "\n",
    "2. **人臉識別** (Face Recognition)\n",
    "   - 特徵提取（FaceNet, ArcFace）\n",
    "   - 相似度計算\n",
    "   - 1:1 驗證與 1:N 識別\n",
    "\n",
    "3. **人臉屬性分析**\n",
    "   - 年齡估計\n",
    "   - 性別識別\n",
    "   - 表情識別\n",
    "   - 種族預測\n",
    "\n",
    "4. **3D 人臉重建**\n",
    "   - 深度估計\n",
    "   - 姿態估計\n",
    "   - 3D Mesh 生成\n",
    "\n",
    "### 參考資源\n",
    "\n",
    "- OpenCV Face Detection Tutorial: https://docs.opencv.org/4.x/db/d28/tutorial_cascade_classifier.html\n",
    "- Viola-Jones Paper: https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf\n",
    "- dlib Documentation: http://dlib.net/face_detector.py.html\n",
    "- OpenCV DNN Module: https://docs.opencv.org/4.x/d2/d58/tutorial_table_of_content_dnn.html\n",
    "- Face Detection Benchmark: http://vis-www.cs.umass.edu/fddb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 下一步\n",
    "\n",
    "完成本模組後，建議繼續學習：\n",
    "- **5.1.2 人臉對齊** - 關鍵點檢測與標準化\n",
    "- **5.1.3 人臉識別** - 特徵提取與相似度計算\n",
    "- **5.2.1 物體檢測基礎** - YOLO 與 SSD\n",
    "\n",
    "**實戰項目建議**:\n",
    "1. 智能相冊：自動標記照片中的人臉\n",
    "2. 人流統計：視訊監控中的人數統計\n",
    "3. 注意力檢測：學生課堂專注度監測\n",
    "4. 智能門禁：人臉檢測 + 識別系統\n",
    "\n",
    "---\n",
    "\n",
    "**模組完成標記**: ✅ WBS 5.1.1 Face Detection Complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
