{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.2 物體分類 (Object Classification)\n",
    "\n",
    "**WBS 5.1.2**: HOG特徵提取與SVM分類器\n",
    "\n",
    "本模組深入探討傳統機器學習在電腦視覺中的應用，從特徵工程到模型訓練的完整pipeline。\n",
    "\n",
    "## 學習目標\n",
    "- 理解HOG (Histogram of Oriented Gradients) 特徵提取原理\n",
    "- 掌握SVM (Support Vector Machine) 分類器訓練\n",
    "- 實作完整的機器學習工作流程\n",
    "- 學習模型評估與優化技巧\n",
    "- 應用於實際物體分類問題\n",
    "\n",
    "## 前置知識\n",
    "- 圖像處理基礎 (Stage 2 & 3)\n",
    "- 特徵檢測概念 (Stage 4)\n",
    "- Python機器學習基礎\n",
    "- NumPy與Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_recall_fscore_support, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import joblib\n",
    "\n",
    "# Configure matplotlib for Chinese display\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Disable warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\u2705 Libraries imported successfully\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HOG特徵提取基礎\n",
    "\n",
    "### 什麼是HOG？\n",
    "\n",
    "**Histogram of Oriented Gradients (HOG)** 是一種用於物體檢測的特徵描述器，由Dalal和Triggs於2005年提出。\n",
    "\n",
    "### HOG原理\n",
    "\n",
    "1. **梯度計算**: 計算圖像的梯度強度和方向\n",
    "2. **細胞劃分**: 將圖像分割為小的細胞(cells)\n",
    "3. **方向直方圖**: 計算每個細胞的梯度方向直方圖\n",
    "4. **區塊歸一化**: 對相鄰細胞組成的區塊進行歸一化\n",
    "5. **特徵向量**: 串聯所有區塊的直方圖形成最終特徵\n",
    "\n",
    "### HOG關鍵參數\n",
    "\n",
    "- **orientations**: 梯度方向的bin數量 (通常為9)\n",
    "- **pixels_per_cell**: 每個細胞的像素大小 (如8x8)\n",
    "- **cells_per_block**: 每個區塊的細胞數量 (如2x2)\n",
    "- **block_norm**: 歸一化方法 ('L1', 'L2', 'L2-Hys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare a sample image for HOG demonstration\n",
    "def load_sample_image():\n",
    "    \"\"\"\n",
    "    Load sample image from dataset\n",
    "    \n",
    "    Returns:\n",
    "        image: grayscale image\n",
    "    \"\"\"\n",
    "    dataset_path = Path('../assets/datasets/dlib_ObjectCategories10')\n",
    "    \n",
    "    # Try to load from dataset\n",
    "    if dataset_path.exists():\n",
    "        categories = [d for d in dataset_path.iterdir() if d.is_dir()]\n",
    "        if categories:\n",
    "            images = list(categories[0].glob('*.jpg'))\n",
    "            if images:\n",
    "                img = cv2.imread(str(images[0]))\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                return cv2.resize(img_gray, (128, 128))\n",
    "    \n",
    "    # Fallback: create synthetic image\n",
    "    print(\"Dataset not found, creating synthetic image...\")\n",
    "    img = np.zeros((128, 128), dtype=np.uint8)\n",
    "    cv2.rectangle(img, (30, 30), (98, 98), 255, 2)\n",
    "    cv2.circle(img, (64, 64), 20, 200, -1)\n",
    "    return img\n",
    "\n",
    "# Load sample image\n",
    "sample_img = load_sample_image()\n",
    "\n",
    "# Extract HOG features with visualization\n",
    "features, hog_image = hog(\n",
    "    sample_img,\n",
    "    orientations=9,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2),\n",
    "    block_norm='L2-Hys',\n",
    "    visualize=True,\n",
    "    feature_vector=True\n",
    ")\n",
    "\n",
    "# Rescale HOG image for better visualization\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "# Display original image and HOG visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].imshow(sample_img, cmap='gray')\n",
    "axes[0].set_title('Original Image (128x128)', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(hog_image_rescaled, cmap='hot')\n",
    "axes[1].set_title('HOG Feature Visualization', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"HOG feature vector dimension: {features.shape[0]}\")\n",
    "print(f\"Feature vector range: [{features.min():.4f}, {features.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG參數影響分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different HOG parameter configurations\n",
    "configs = [\n",
    "    {'orientations': 9, 'pixels_per_cell': (8, 8), 'cells_per_block': (2, 2)},\n",
    "    {'orientations': 9, 'pixels_per_cell': (16, 16), 'cells_per_block': (2, 2)},\n",
    "    {'orientations': 12, 'pixels_per_cell': (8, 8), 'cells_per_block': (2, 2)},\n",
    "    {'orientations': 9, 'pixels_per_cell': (8, 8), 'cells_per_block': (3, 3)},\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, config in enumerate(configs):\n",
    "    features, hog_img = hog(\n",
    "        sample_img,\n",
    "        visualize=True,\n",
    "        feature_vector=True,\n",
    "        block_norm='L2-Hys',\n",
    "        **config\n",
    "    )\n",
    "    \n",
    "    hog_img_rescaled = exposure.rescale_intensity(hog_img, in_range=(0, 10))\n",
    "    \n",
    "    axes[idx].imshow(hog_img_rescaled, cmap='hot')\n",
    "    axes[idx].set_title(\n",
    "        f\"Orient={config['orientations']}, \"\n",
    "        f\"Cell={config['pixels_per_cell']}, \"\n",
    "        f\"Block={config['cells_per_block']}\\n\"\n",
    "        f\"Dim={features.shape[0]}\",\n",
    "        fontsize=9\n",
    "    )\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nParameter impact summary:\")\n",
    "print(\"- More orientations → Higher angular resolution, larger feature vector\")\n",
    "print(\"- Larger cells → Lower spatial resolution, smaller feature vector\")\n",
    "print(\"- Larger blocks → More context, better normalization, larger overlap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 數據集準備與載入\n",
    "\n",
    "### 數據集結構\n",
    "\n",
    "我們使用dlib的ObjectCategories10數據集：\n",
    "```\n",
    "dlib_ObjectCategories10/\n",
    "├── accordion/\n",
    "│   ├── image_0001.jpg\n",
    "│   ├── image_0002.jpg\n",
    "│   └── ...\n",
    "├── camera/\n",
    "│   ├── image_0001.jpg\n",
    "│   └── ...\n",
    "└── .../\n",
    "```\n",
    "\n",
    "### 數據載入策略\n",
    "\n",
    "1. **圖像讀取**: 使用OpenCV讀取圖像\n",
    "2. **預處理**: 灰階轉換、大小調整\n",
    "3. **標籤編碼**: 將類別名稱轉換為數字\n",
    "4. **數據分割**: 訓練集/測試集劃分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path, img_size=(64, 128), max_samples_per_class=None):\n",
    "    \"\"\"\n",
    "    Load image dataset from directory structure\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_path : str or Path\n",
    "        Path to dataset root directory\n",
    "    img_size : tuple\n",
    "        Target image size (width, height)\n",
    "    max_samples_per_class : int, optional\n",
    "        Maximum samples to load per class (for quick testing)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    images : list\n",
    "        List of processed images\n",
    "    labels : list\n",
    "        List of corresponding labels\n",
    "    class_names : list\n",
    "        List of class names\n",
    "    \"\"\"\n",
    "    dataset_path = Path(dataset_path)\n",
    "    \n",
    "    if not dataset_path.exists():\n",
    "        raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = []\n",
    "    \n",
    "    # Get all category directories\n",
    "    categories = sorted([d for d in dataset_path.iterdir() if d.is_dir()])\n",
    "    \n",
    "    print(f\"Found {len(categories)} categories:\")\n",
    "    \n",
    "    for label_idx, category_dir in enumerate(categories):\n",
    "        class_name = category_dir.name\n",
    "        class_names.append(class_name)\n",
    "        \n",
    "        # Get all images in category\n",
    "        image_files = list(category_dir.glob('*.jpg')) + list(category_dir.glob('*.png'))\n",
    "        \n",
    "        # Limit samples if specified\n",
    "        if max_samples_per_class:\n",
    "            image_files = image_files[:max_samples_per_class]\n",
    "        \n",
    "        print(f\"  - {class_name}: {len(image_files)} images\")\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            # Read image\n",
    "            img = cv2.imread(str(img_path))\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Resize to standard size\n",
    "            img_resized = cv2.resize(img_gray, img_size)\n",
    "            \n",
    "            images.append(img_resized)\n",
    "            labels.append(label_idx)\n",
    "    \n",
    "    print(f\"\\nTotal samples loaded: {len(images)}\")\n",
    "    \n",
    "    return images, labels, class_names\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "DATASET_PATH = '../assets/datasets/dlib_ObjectCategories10'\n",
    "IMG_SIZE = (64, 128)  # Standard HOG size (width, height)\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "images, labels, class_names = load_dataset(\n",
    "    DATASET_PATH, \n",
    "    img_size=IMG_SIZE,\n",
    "    max_samples_per_class=None  # Set to 20 for quick testing\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(f\"  Number of classes: {len(class_names)}\")\n",
    "print(f\"  Class names: {', '.join(class_names)}\")\n",
    "print(f\"  Image shape: {images[0].shape}\")\n",
    "print(f\"  Total samples: {len(images)}\")\n",
    "\n",
    "# Check class distribution\n",
    "label_counts = Counter(labels)\n",
    "print(\"\\nClass distribution:\")\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    print(f\"  {class_name}: {label_counts[idx]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數據可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "def visualize_samples(images, labels, class_names, samples_per_class=5):\n",
    "    \"\"\"\n",
    "    Visualize sample images from each class\n",
    "    \"\"\"\n",
    "    n_classes = len(class_names)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_classes, samples_per_class, figsize=(15, 3 * n_classes))\n",
    "    \n",
    "    if n_classes == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        # Get indices of this class\n",
    "        class_indices = [i for i, label in enumerate(labels) if label == class_idx]\n",
    "        \n",
    "        # Randomly sample\n",
    "        sample_indices = np.random.choice(\n",
    "            class_indices, \n",
    "            min(samples_per_class, len(class_indices)), \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        for col_idx, img_idx in enumerate(sample_indices):\n",
    "            if col_idx < samples_per_class:\n",
    "                axes[class_idx, col_idx].imshow(images[img_idx], cmap='gray')\n",
    "                axes[class_idx, col_idx].axis('off')\n",
    "                \n",
    "                if col_idx == 0:\n",
    "                    axes[class_idx, col_idx].set_ylabel(\n",
    "                        class_name, \n",
    "                        fontsize=12, \n",
    "                        rotation=0, \n",
    "                        labelpad=40,\n",
    "                        va='center'\n",
    "                    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples\n",
    "visualize_samples(images, labels, class_names, samples_per_class=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HOG特徵提取Pipeline\n",
    "\n",
    "### 批量特徵提取\n",
    "\n",
    "將所有圖像轉換為HOG特徵向量，形成特徵矩陣用於機器學習訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(images, orientations=9, pixels_per_cell=(8, 8), \n",
    "                         cells_per_block=(2, 2), block_norm='L2-Hys'):\n",
    "    \"\"\"\n",
    "    Extract HOG features from multiple images\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : list\n",
    "        List of grayscale images\n",
    "    orientations : int\n",
    "        Number of orientation bins\n",
    "    pixels_per_cell : tuple\n",
    "        Size of a cell (in pixels)\n",
    "    cells_per_block : tuple\n",
    "        Number of cells in each block\n",
    "    block_norm : str\n",
    "        Block normalization method\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    features : numpy.ndarray\n",
    "        Feature matrix (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    print(f\"Extracting HOG features from {len(images)} images...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for idx, img in enumerate(images):\n",
    "        # Extract HOG features\n",
    "        features = hog(\n",
    "            img,\n",
    "            orientations=orientations,\n",
    "            pixels_per_cell=pixels_per_cell,\n",
    "            cells_per_block=cells_per_block,\n",
    "            block_norm=block_norm,\n",
    "            visualize=False,\n",
    "            feature_vector=True\n",
    "        )\n",
    "        \n",
    "        features_list.append(features)\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (idx + 1) % 20 == 0:\n",
    "            print(f\"  Processed {idx + 1}/{len(images)} images...\", end='\\r')\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n  Completed in {elapsed:.2f}s ({elapsed/len(images)*1000:.2f}ms per image)\")\n",
    "    \n",
    "    features_array = np.array(features_list)\n",
    "    print(f\"  Feature matrix shape: {features_array.shape}\")\n",
    "    \n",
    "    return features_array\n",
    "\n",
    "\n",
    "# Extract HOG features from all images\n",
    "X = extract_hog_features(\n",
    "    images,\n",
    "    orientations=9,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2, 2),\n",
    "    block_norm='L2-Hys'\n",
    ")\n",
    "\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"\\nFeature extraction complete:\")\n",
    "print(f\"  X shape: {X.shape} (samples × features)\")\n",
    "print(f\"  y shape: {y.shape}\")\n",
    "print(f\"  Feature range: [{X.min():.4f}, {X.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數據預處理\n",
    "\n",
    "**標準化 (Standardization)**: SVM對特徵尺度敏感，需要進行標準化。\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "其中 $\\mu$ 是均值，$\\sigma$ 是標準差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(\"Dataset split:\")\n",
    "print(f\"  Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"  Testing set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Check class distribution in splits\n",
    "print(\"\\nClass distribution:\")\n",
    "print(f\"  Training: {Counter(y_train)}\")\n",
    "print(f\"  Testing: {Counter(y_test)}\")\n",
    "\n",
    "# Feature standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeature standardization:\")\n",
    "print(f\"  Before: mean={X_train.mean():.4f}, std={X_train.std():.4f}\")\n",
    "print(f\"  After: mean={X_train_scaled.mean():.4f}, std={X_train_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SVM分類器訓練\n",
    "\n",
    "### SVM基礎\n",
    "\n",
    "**Support Vector Machine (SVM)** 是一種強大的監督式學習算法，尋找最優超平面將不同類別分開。\n",
    "\n",
    "### SVM核函數\n",
    "\n",
    "1. **Linear**: $K(x, y) = x^T y$\n",
    "   - 適用於線性可分問題\n",
    "   - 訓練速度快\n",
    "\n",
    "2. **RBF (Radial Basis Function)**: $K(x, y) = e^{-\\gamma ||x-y||^2}$\n",
    "   - 最常用的核函數\n",
    "   - 適用於非線性問題\n",
    "\n",
    "3. **Polynomial**: $K(x, y) = (\\gamma x^T y + r)^d$\n",
    "   - 適用於特定非線性問題\n",
    "\n",
    "### 關鍵參數\n",
    "\n",
    "- **C**: 懲罰參數，控制對誤分類的容忍度\n",
    "  - 大C → 低偏差、高方差 (overfitting)\n",
    "  - 小C → 高偏差、低方差 (underfitting)\n",
    "\n",
    "- **gamma**: RBF核的參數\n",
    "  - 大gamma → 影響範圍小，複雜邊界\n",
    "  - 小gamma → 影響範圍大，平滑邊界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline SVM with default parameters\n",
    "print(\"Training baseline SVM classifier...\")\n",
    "\n",
    "# Use LinearSVC for faster training on large datasets\n",
    "baseline_svm = LinearSVC(random_state=42, max_iter=1000)\n",
    "\n",
    "start_time = time.time()\n",
    "baseline_svm.fit(X_train_scaled, y_train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Evaluate on training and testing sets\n",
    "train_acc = baseline_svm.score(X_train_scaled, y_train)\n",
    "test_acc = baseline_svm.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"\\nBaseline SVM Results:\")\n",
    "print(f\"  Training time: {train_time:.2f}s\")\n",
    "print(f\"  Training accuracy: {train_acc:.4f}\")\n",
    "print(f\"  Testing accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = baseline_svm.predict(X_test_scaled)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混淆矩陣 (Confusion Matrix)\n",
    "\n",
    "混淆矩陣展示了模型在各類別上的表現細節。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names, normalize=False):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_pred : array-like\n",
    "        Predicted labels\n",
    "    class_names : list\n",
    "        List of class names\n",
    "    normalize : bool\n",
    "        Whether to normalize the matrix\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    # Configure ticks\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=class_names,\n",
    "           yticklabels=class_names,\n",
    "           ylabel='True Label',\n",
    "           xlabel='Predicted Label')\n",
    "    \n",
    "    # Rotate x labels\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Add text annotations\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                   ha=\"center\", va=\"center\",\n",
    "                   color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    title = 'Normalized Confusion Matrix' if normalize else 'Confusion Matrix'\n",
    "    ax.set_title(title, fontsize=14, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrix(y_test, y_pred, class_names, normalize=False)\n",
    "plot_confusion_matrix(y_test, y_pred, class_names, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 超參數調整 (Hyperparameter Tuning)\n",
    "\n",
    "### Grid Search\n",
    "\n",
    "使用網格搜索結合交叉驗證尋找最優超參數組合。\n",
    "\n",
    "**GridSearchCV** 會嘗試所有參數組合，並使用k-fold交叉驗證評估每組參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for SVM with RBF kernel\n",
    "print(\"Starting hyperparameter tuning with GridSearchCV...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Create SVM classifier\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    svm, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "tuning_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nHyperparameter tuning completed in {tuning_time:.2f}s\")\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model on test set\n",
    "best_svm = grid_search.best_estimator_\n",
    "test_acc_tuned = best_svm.score(X_test_scaled, y_test)\n",
    "print(f\"Test accuracy (tuned): {test_acc_tuned:.4f}\")\n",
    "\n",
    "# Compare with baseline\n",
    "print(f\"\\nImprovement over baseline: {(test_acc_tuned - test_acc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch結果可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid search results\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Extract C and gamma values\n",
    "C_values = [params['C'] for params in results['params']]\n",
    "gamma_values = [params['gamma'] for params in results['params']]\n",
    "mean_scores = results['mean_test_score']\n",
    "\n",
    "# Create pivot table for heatmap\n",
    "C_unique = sorted(set(C_values))\n",
    "gamma_unique = sorted(set(gamma_values))\n",
    "\n",
    "score_matrix = np.zeros((len(gamma_unique), len(C_unique)))\n",
    "\n",
    "for c, g, score in zip(C_values, gamma_values, mean_scores):\n",
    "    c_idx = C_unique.index(c)\n",
    "    g_idx = gamma_unique.index(g)\n",
    "    score_matrix[g_idx, c_idx] = score\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "im = ax.imshow(score_matrix, cmap='YlOrRd', aspect='auto')\n",
    "\n",
    "ax.set_xticks(np.arange(len(C_unique)))\n",
    "ax.set_yticks(np.arange(len(gamma_unique)))\n",
    "ax.set_xticklabels(C_unique)\n",
    "ax.set_yticklabels(gamma_unique)\n",
    "\n",
    "ax.set_xlabel('C (Regularization)', fontsize=12)\n",
    "ax.set_ylabel('Gamma (Kernel coefficient)', fontsize=12)\n",
    "ax.set_title('Grid Search Results: Cross-Validation Accuracy', fontsize=14, pad=20)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Accuracy', fontsize=12)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(gamma_unique)):\n",
    "    for j in range(len(C_unique)):\n",
    "        text = ax.text(j, i, f'{score_matrix[i, j]:.3f}',\n",
    "                      ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型評估與分析\n",
    "\n",
    "### 交叉驗證 (Cross-Validation)\n",
    "\n",
    "K-fold交叉驗證可以更可靠地評估模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-fold cross-validation\n",
    "print(\"Performing 10-fold cross-validation...\")\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    best_svm, \n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    cv=10,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nCross-validation results:\")\n",
    "print(f\"  Individual fold scores: {cv_scores}\")\n",
    "print(f\"  Mean accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"  Standard deviation: {cv_scores.std():.4f}\")\n",
    "print(f\"  95% confidence interval: [{cv_scores.mean() - 1.96*cv_scores.std():.4f}, \"\n",
    "      f\"{cv_scores.mean() + 1.96*cv_scores.std():.4f}]\")\n",
    "\n",
    "# Visualize CV scores\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.bar(range(1, len(cv_scores) + 1), cv_scores, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax.axhline(y=cv_scores.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {cv_scores.mean():.4f}')\n",
    "ax.axhline(y=cv_scores.mean() + cv_scores.std(), color='orange', linestyle=':', linewidth=1, label=f'+1 std')\n",
    "ax.axhline(y=cv_scores.mean() - cv_scores.std(), color='orange', linestyle=':', linewidth=1, label=f'-1 std')\n",
    "\n",
    "ax.set_xlabel('Fold', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('10-Fold Cross-Validation Results', fontsize=14, pad=20)\n",
    "ax.set_ylim([0, 1])\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 學習曲線 (Learning Curve)\n",
    "\n",
    "學習曲線展示了訓練集大小對模型性能的影響，幫助診斷偏差/方差問題。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute learning curve\n",
    "print(\"Computing learning curve...\")\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_svm,\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Calculate mean and std\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "ax.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score', linewidth=2)\n",
    "ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "\n",
    "ax.plot(train_sizes, val_mean, 'o-', color='red', label='Cross-validation score', linewidth=2)\n",
    "ax.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2, color='red')\n",
    "\n",
    "ax.set_xlabel('Training Set Size', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Learning Curve', fontsize=14, pad=20)\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Diagnose bias/variance\n",
    "final_train_score = train_mean[-1]\n",
    "final_val_score = val_mean[-1]\n",
    "gap = final_train_score - final_val_score\n",
    "\n",
    "print(\"\\nLearning curve analysis:\")\n",
    "print(f\"  Final training score: {final_train_score:.4f}\")\n",
    "print(f\"  Final validation score: {final_val_score:.4f}\")\n",
    "print(f\"  Gap: {gap:.4f}\")\n",
    "\n",
    "if gap > 0.1:\n",
    "    print(\"  \\u26a0\\ufe0f High variance detected - model may be overfitting\")\n",
    "    print(\"  Suggestions: regularization, more data, reduce model complexity\")\n",
    "elif final_val_score < 0.7:\n",
    "    print(\"  \\u26a0\\ufe0f High bias detected - model may be underfitting\")\n",
    "    print(\"  Suggestions: more features, more complex model, reduce regularization\")\n",
    "else:\n",
    "    print(\"  \\u2705 Good bias-variance tradeoff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 錯誤分析 (Error Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassified examples\n",
    "y_pred_tuned = best_svm.predict(X_test_scaled)\n",
    "misclassified_idx = np.where(y_pred_tuned != y_test)[0]\n",
    "\n",
    "print(f\"Total misclassified samples: {len(misclassified_idx)}\")\n",
    "print(f\"Misclassification rate: {len(misclassified_idx) / len(y_test):.2%}\")\n",
    "\n",
    "# Visualize some misclassified examples\n",
    "if len(misclassified_idx) > 0:\n",
    "    n_examples = min(8, len(misclassified_idx))\n",
    "    sample_idx = np.random.choice(misclassified_idx, n_examples, replace=False)\n",
    "    \n",
    "    # Get original test indices\n",
    "    test_indices = np.arange(len(labels))\n",
    "    _, test_indices_split = train_test_split(\n",
    "        test_indices, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, idx in enumerate(sample_idx):\n",
    "        img_idx = test_indices_split[idx]\n",
    "        \n",
    "        axes[i].imshow(images[img_idx], cmap='gray')\n",
    "        axes[i].set_title(\n",
    "            f\"True: {class_names[y_test[idx]]}\\n\"\n",
    "            f\"Pred: {class_names[y_pred_tuned[idx]]}\",\n",
    "            fontsize=10,\n",
    "            color='red'\n",
    "        )\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Misclassified Examples', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\u2705 Perfect classification - no errors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 模型保存與載入\n",
    "\n",
    "### 保存完整Pipeline\n",
    "\n",
    "保存預處理器(scaler)和模型，以便後續使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and scaler\n",
    "MODEL_DIR = Path('../assets/models/object_classification')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = MODEL_DIR / 'hog_svm_classifier.pkl'\n",
    "scaler_path = MODEL_DIR / 'feature_scaler.pkl'\n",
    "config_path = MODEL_DIR / 'model_config.pkl'\n",
    "\n",
    "# Save model\n",
    "joblib.dump(best_svm, model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    'class_names': class_names,\n",
    "    'img_size': IMG_SIZE,\n",
    "    'hog_params': {\n",
    "        'orientations': 9,\n",
    "        'pixels_per_cell': (8, 8),\n",
    "        'cells_per_block': (2, 2),\n",
    "        'block_norm': 'L2-Hys'\n",
    "    },\n",
    "    'test_accuracy': test_acc_tuned,\n",
    "    'best_params': grid_search.best_params_\n",
    "}\n",
    "\n",
    "joblib.dump(config, config_path)\n",
    "print(f\"Configuration saved to: {config_path}\")\n",
    "\n",
    "print(f\"\\nTotal model size: {(model_path.stat().st_size + scaler_path.stat().st_size) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入並測試模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "loaded_svm = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "loaded_config = joblib.load(config_path)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  Classes: {loaded_config['class_names']}\")\n",
    "print(f\"  Image size: {loaded_config['img_size']}\")\n",
    "print(f\"  HOG params: {loaded_config['hog_params']}\")\n",
    "print(f\"  Test accuracy: {loaded_config['test_accuracy']:.4f}\")\n",
    "\n",
    "# Verify model works\n",
    "test_acc_loaded = loaded_svm.score(X_test_scaled, y_test)\n",
    "print(f\"\\nVerification: loaded model accuracy = {test_acc_loaded:.4f}\")\n",
    "assert test_acc_loaded == test_acc_tuned, \"Model mismatch!\"\n",
    "print(\"\\u2705 Model verification passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 實時分類應用\n",
    "\n",
    "### 完整推理Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img_path, model, scaler, config):\n",
    "    \"\"\"\n",
    "    Classify a single image using trained model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    img_path : str or Path\n",
    "        Path to input image\n",
    "    model : sklearn model\n",
    "        Trained SVM classifier\n",
    "    scaler : sklearn scaler\n",
    "        Fitted StandardScaler\n",
    "    config : dict\n",
    "        Model configuration\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    prediction : str\n",
    "        Predicted class name\n",
    "    confidence : float\n",
    "        Confidence score (if available)\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_resized = cv2.resize(img_gray, config['img_size'])\n",
    "    \n",
    "    # Extract HOG features\n",
    "    features = hog(\n",
    "        img_resized,\n",
    "        visualize=False,\n",
    "        feature_vector=True,\n",
    "        **config['hog_params']\n",
    "    )\n",
    "    \n",
    "    # Standardize features\n",
    "    features_scaled = scaler.transform(features.reshape(1, -1))\n",
    "    \n",
    "    # Predict\n",
    "    pred_label = model.predict(features_scaled)[0]\n",
    "    pred_class = config['class_names'][pred_label]\n",
    "    \n",
    "    # Get confidence if model supports decision_function\n",
    "    confidence = None\n",
    "    if hasattr(model, 'decision_function'):\n",
    "        decision_scores = model.decision_function(features_scaled)[0]\n",
    "        # Convert to probability-like scores\n",
    "        exp_scores = np.exp(decision_scores - np.max(decision_scores))\n",
    "        confidence = exp_scores / exp_scores.sum()\n",
    "    \n",
    "    return pred_class, confidence, img, img_resized\n",
    "\n",
    "\n",
    "# Test classification on random images\n",
    "print(\"Testing real-time classification...\\n\")\n",
    "\n",
    "# Get some test images\n",
    "test_image_paths = []\n",
    "for class_dir in (Path(DATASET_PATH)).iterdir():\n",
    "    if class_dir.is_dir():\n",
    "        imgs = list(class_dir.glob('*.jpg'))[:1]\n",
    "        test_image_paths.extend(imgs)\n",
    "\n",
    "n_display = min(6, len(test_image_paths))\n",
    "sample_paths = np.random.choice(test_image_paths, n_display, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, img_path in enumerate(sample_paths):\n",
    "    pred_class, confidence, img_orig, img_processed = classify_image(\n",
    "        img_path, loaded_svm, loaded_scaler, loaded_config\n",
    "    )\n",
    "    \n",
    "    true_class = img_path.parent.name\n",
    "    \n",
    "    # Display original image\n",
    "    axes[idx].imshow(cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Title with prediction\n",
    "    title = f\"True: {true_class}\\nPred: {pred_class}\"\n",
    "    color = 'green' if true_class == pred_class else 'red'\n",
    "    axes[idx].set_title(title, fontsize=11, color=color, weight='bold')\n",
    "    \n",
    "    # Add confidence bar if available\n",
    "    if confidence is not None:\n",
    "        conf_text = f\"Conf: {confidence.max():.2%}\"\n",
    "        axes[idx].text(0.5, 0.95, conf_text, \n",
    "                      transform=axes[idx].transAxes,\n",
    "                      ha='center', va='top',\n",
    "                      bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "                      fontsize=9)\n",
    "    \n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Real-time Classification Results', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 進階技巧與優化\n",
    "\n",
    "### 數據增強 (Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img):\n",
    "    \"\"\"\n",
    "    Apply random augmentation to image\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    img : numpy.ndarray\n",
    "        Input grayscale image\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    augmented : numpy.ndarray\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "    # Random flip\n",
    "    if np.random.random() > 0.5:\n",
    "        img = cv2.flip(img, 1)\n",
    "    \n",
    "    # Random rotation (-15 to +15 degrees)\n",
    "    angle = np.random.uniform(-15, 15)\n",
    "    h, w = img.shape\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "    img = cv2.warpAffine(img, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "    \n",
    "    # Random brightness adjustment\n",
    "    brightness = np.random.uniform(0.8, 1.2)\n",
    "    img = np.clip(img * brightness, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Random noise\n",
    "    if np.random.random() > 0.7:\n",
    "        noise = np.random.normal(0, 5, img.shape)\n",
    "        img = np.clip(img + noise, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Demonstrate augmentation\n",
    "sample_img = images[0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].imshow(sample_img, cmap='gray')\n",
    "axes[0].set_title('Original', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i in range(1, 8):\n",
    "    aug_img = augment_image(sample_img.copy())\n",
    "    axes[i].imshow(aug_img, cmap='gray')\n",
    "    axes[i].set_title(f'Augmented {i}', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Data augmentation techniques:\")\n",
    "print(\"  1. Horizontal flip (50% probability)\")\n",
    "print(\"  2. Random rotation (-15° to +15°)\")\n",
    "print(\"  3. Brightness adjustment (0.8x to 1.2x)\")\n",
    "print(\"  4. Gaussian noise (30% probability)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集成學習 (Ensemble Learning)\n",
    "\n",
    "使用Bagging和Boosting提升模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging Classifier\n",
    "print(\"Training Bagging ensemble...\")\n",
    "bagging_clf = BaggingClassifier(\n",
    "    estimator=LinearSVC(random_state=42),\n",
    "    n_estimators=10,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bagging_clf.fit(X_train_scaled, y_train)\n",
    "bagging_acc = bagging_clf.score(X_test_scaled, y_test)\n",
    "print(f\"Bagging accuracy: {bagging_acc:.4f}\")\n",
    "\n",
    "# Compare with base model\n",
    "print(f\"\\nModel comparison:\")\n",
    "print(f\"  Baseline SVM: {test_acc:.4f}\")\n",
    "print(f\"  Tuned SVM: {test_acc_tuned:.4f}\")\n",
    "print(f\"  Bagging SVM: {bagging_acc:.4f}\")\n",
    "print(f\"  Improvement: {(bagging_acc - test_acc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能優化總結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "models = ['Baseline', 'Tuned', 'Ensemble']\n",
    "accuracies = [test_acc, test_acc_tuned, bagging_acc]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bars = ax.bar(models, accuracies, color=['lightblue', 'lightgreen', 'lightcoral'], \n",
    "              edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "           f'{acc:.4f}',\n",
    "           ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Model Performance Comparison', fontsize=14, pad=20)\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nOptimization strategies summary:\")\n",
    "print(\"  1. Hyperparameter tuning → Improved by\", f\"{(test_acc_tuned - test_acc):.4f}\")\n",
    "print(\"  2. Ensemble learning → Improved by\", f\"{(bagging_acc - test_acc):.4f}\")\n",
    "print(\"  3. Data augmentation → Can further improve with more data\")\n",
    "print(\"  4. Feature engineering → Try different feature descriptors (SIFT, SURF, ORB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 總結與延伸\n",
    "\n",
    "### 關鍵要點\n",
    "\n",
    "1. **HOG特徵**\n",
    "   - 強大的傳統特徵描述器\n",
    "   - 對形狀和輪廓敏感\n",
    "   - 計算效率高\n",
    "   - 參數選擇影響特徵維度和性能\n",
    "\n",
    "2. **SVM分類器**\n",
    "   - 適合中小型數據集\n",
    "   - 核函數選擇重要\n",
    "   - 需要特徵標準化\n",
    "   - 超參數調整關鍵\n",
    "\n",
    "3. **機器學習流程**\n",
    "   - 數據準備 → 特徵提取 → 模型訓練 → 評估 → 優化\n",
    "   - 交叉驗證確保可靠性\n",
    "   - 學習曲線診斷問題\n",
    "   - 錯誤分析指導改進\n",
    "\n",
    "4. **實戰技巧**\n",
    "   - 數據增強提升泛化\n",
    "   - 集成學習提高性能\n",
    "   - 模型保存便於部署\n",
    "   - Pipeline化便於維護\n",
    "\n",
    "### 其他特徵方法對比\n",
    "\n",
    "| 特徵方法 | 優點 | 缺點 | 適用場景 |\n",
    "|---------|------|------|----------|\n",
    "| **HOG** | 對形狀敏感、快速、穩定 | 對紋理不敏感、固定窗口 | 行人檢測、物體分類 |\n",
    "| **SIFT** | 尺度不變、旋轉不變 | 計算慢、專利保護 | 圖像匹配、全景拼接 |\n",
    "| **SURF** | 比SIFT快、類似性能 | 專利保護 | 實時應用 |\n",
    "| **ORB** | 極快、無專利 | 精度略低 | 移動設備、實時追蹤 |\n",
    "| **LBP** | 極快、對光照魯棒 | 對旋轉敏感 | 紋理分類、人臉識別 |\n",
    "\n",
    "### 何時使用HOG+SVM？\n",
    "\n",
    "**適合**:\n",
    "- 中小型數據集（<10萬樣本）\n",
    "- 需要可解釋性\n",
    "- 計算資源有限\n",
    "- 需要快速部署\n",
    "- 物體形狀特徵明顯\n",
    "\n",
    "**不適合**:\n",
    "- 大規模數據集（深度學習更好）\n",
    "- 複雜場景理解\n",
    "- 需要端到端學習\n",
    "- 強紋理依賴的任務\n",
    "\n",
    "### 延伸學習方向\n",
    "\n",
    "1. **深度學習方法**\n",
    "   - CNN分類器 (LeNet, VGG, ResNet)\n",
    "   - Transfer Learning\n",
    "   - Fine-tuning預訓練模型\n",
    "\n",
    "2. **進階特徵**\n",
    "   - Fisher Vector\n",
    "   - Bag of Visual Words\n",
    "   - Deep Features (CNN中間層)\n",
    "\n",
    "3. **其他應用**\n",
    "   - 物體檢測 (R-CNN, YOLO)\n",
    "   - 語義分割\n",
    "   - 實例分割\n",
    "\n",
    "### 實戰項目建議\n",
    "\n",
    "1. **行人檢測系統**\n",
    "   - HOG+SVM經典應用\n",
    "   - 結合滑動窗口\n",
    "   - 多尺度檢測\n",
    "\n",
    "2. **車輛分類器**\n",
    "   - 多類別分類\n",
    "   - 實時推理\n",
    "   - 部署到邊緣設備\n",
    "\n",
    "3. **醫療影像分類**\n",
    "   - 結合領域知識\n",
    "   - 數據增強策略\n",
    "   - 類別不平衡處理\n",
    "\n",
    "### 參考資源\n",
    "\n",
    "- **論文**:\n",
    "  - Dalal & Triggs (2005): \"Histograms of Oriented Gradients for Human Detection\"\n",
    "  - Cortes & Vapnik (1995): \"Support-Vector Networks\"\n",
    "\n",
    "- **文檔**:\n",
    "  - Scikit-learn SVM Guide: https://scikit-learn.org/stable/modules/svm.html\n",
    "  - Scikit-image HOG: https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_hog.html\n",
    "\n",
    "- **數據集**:\n",
    "  - MNIST: 手寫數字分類\n",
    "  - CIFAR-10: 通用物體分類\n",
    "  - Caltech 101: 物體識別\n",
    "  - INRIA Person: 行人檢測\n",
    "\n",
    "---\n",
    "\n",
    "## 下一步\n",
    "\n",
    "完成本模組後，建議繼續學習：\n",
    "- **5.1.3 深度學習入門** - CNN基礎與實作\n",
    "- **5.2.1 物體檢測** - YOLO/SSD實戰\n",
    "- **5.2.2 遷移學習** - 預訓練模型應用\n",
    "\n",
    "**練習建議**: \n",
    "1. 在自己的數據集上訓練分類器\n",
    "2. 實作滑動窗口物體檢測\n",
    "3. 比較不同特徵方法的性能\n",
    "4. 嘗試深度學習方法並對比結果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
