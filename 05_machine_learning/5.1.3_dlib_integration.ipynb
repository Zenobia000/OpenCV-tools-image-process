{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.3 dlib Integration - 68é»é¢éƒ¨ç‰¹å¾µæª¢æ¸¬èˆ‡äººè‡‰è­˜åˆ¥\n",
    "\n",
    "æœ¬æ¨¡çµ„ä»‹ç´¹å¦‚ä½•ä½¿ç”¨dlibå‡½å¼åº«é€²è¡Œé«˜ç²¾åº¦çš„äººè‡‰æª¢æ¸¬ã€68é»é¢éƒ¨ç‰¹å¾µå®šä½å’Œäººè‡‰è­˜åˆ¥ã€‚\n",
    "\n",
    "## å­¸ç¿’ç›®æ¨™\n",
    "- æŒæ¡dlibäººè‡‰æª¢æ¸¬å™¨çš„ä½¿ç”¨\n",
    "- å¯¦ç¾68é»é¢éƒ¨ç‰¹å¾µé»æª¢æ¸¬\n",
    "- é€²è¡Œäººè‡‰å°é½Šå’Œæ¨™æº–åŒ–\n",
    "- å¯¦ç¾åŸºæ–¼æ·±åº¦å­¸ç¿’çš„äººè‡‰è­˜åˆ¥\n",
    "- æ¯”è¼ƒä¸åŒäººè‡‰æª¢æ¸¬æ–¹æ³•çš„æ•ˆèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­ç½®èˆ‡å‡½å¼åº«å°å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# æ·»åŠ utilsè·¯å¾‘\n",
    "sys.path.append('../utils')\n",
    "from image_utils import load_image, resize_image\n",
    "from visualization import display_image, display_multiple_images\n",
    "from performance import time_function, benchmark_function\n",
    "\n",
    "# å˜—è©¦å°å…¥dlib\n",
    "try:\n",
    "    import dlib\n",
    "    DLIB_AVAILABLE = True\n",
    "    print(\"âœ… dlib library loaded successfully\")\n",
    "    print(f\"dlib version: {dlib.version}\")\n",
    "except ImportError:\n",
    "    DLIB_AVAILABLE = False\n",
    "    print(\"âš ï¸ dlib not available. Please install: pip install dlib\")\n",
    "    print(\"Some features will be disabled.\")\n",
    "\n",
    "# è¨­ç½®matplotlibä¸­æ–‡é¡¯ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. dlibäººè‡‰æª¢æ¸¬å™¨åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dlib_detectors():\n",
    "    \"\"\"\n",
    "    åˆå§‹åŒ–dlibæª¢æ¸¬å™¨å’Œé æ¸¬å™¨\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (äººè‡‰æª¢æ¸¬å™¨, 68é»é æ¸¬å™¨)\n",
    "    \"\"\"\n",
    "    if not DLIB_AVAILABLE:\n",
    "        return None, None\n",
    "    \n",
    "    # åˆå§‹åŒ–HOGäººè‡‰æª¢æ¸¬å™¨\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    # 68é»é¢éƒ¨ç‰¹å¾µé æ¸¬å™¨è·¯å¾‘\n",
    "    predictor_path = \"../assets/models/shape_predictor_68_face_landmarks.dat\"\n",
    "    \n",
    "    if os.path.exists(predictor_path):\n",
    "        landmark_predictor = dlib.shape_predictor(predictor_path)\n",
    "        print(f\"âœ… 68-point landmark predictor loaded from {predictor_path}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Landmark predictor not found at {predictor_path}\")\n",
    "        print(\"Please download from: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "        landmark_predictor = None\n",
    "    \n",
    "    return face_detector, landmark_predictor\n",
    "\n",
    "# åˆå§‹åŒ–æª¢æ¸¬å™¨\n",
    "detector, predictor = initialize_dlib_detectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. dlibäººè‡‰æª¢æ¸¬åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_dlib(image, upsampling=1):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨dlibæª¢æ¸¬äººè‡‰\n",
    "    \n",
    "    Args:\n",
    "        image: è¼¸å…¥åœ–åƒ\n",
    "        upsampling: ä¸Šæ¡æ¨£æ¬¡æ•¸ï¼Œå¢åŠ æª¢æ¸¬ç²¾åº¦ä½†é™ä½é€Ÿåº¦\n",
    "    \n",
    "    Returns:\n",
    "        list: æª¢æ¸¬åˆ°çš„äººè‡‰çŸ©å½¢æ¡†åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    if not DLIB_AVAILABLE or detector is None:\n",
    "        return []\n",
    "    \n",
    "    # è½‰æ›ç‚ºç°éš\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # æª¢æ¸¬äººè‡‰\n",
    "    faces = detector(gray, upsampling)\n",
    "    \n",
    "    # è½‰æ›ç‚ºOpenCVæ ¼å¼ (x, y, w, h)\n",
    "    face_rects = []\n",
    "    for face in faces:\n",
    "        x = face.left()\n",
    "        y = face.top()\n",
    "        w = face.width()\n",
    "        h = face.height()\n",
    "        face_rects.append((x, y, w, h))\n",
    "    \n",
    "    return face_rects\n",
    "\n",
    "@time_function\n",
    "def detect_faces_dlib_timed(image, upsampling=1):\n",
    "    \"\"\"å¸¶è¨ˆæ™‚çš„dlibäººè‡‰æª¢æ¸¬\"\"\"\n",
    "    return detect_faces_dlib(image, upsampling)\n",
    "\n",
    "# æ¸¬è©¦dlibäººè‡‰æª¢æ¸¬\n",
    "def test_dlib_face_detection():\n",
    "    \"\"\"æ¸¬è©¦dlibäººè‡‰æª¢æ¸¬åŠŸèƒ½\"\"\"\n",
    "    test_image_path = \"../assets/images/basic/faces01.jpg\"\n",
    "    \n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(f\"æ¸¬è©¦åœ–ç‰‡ä¸å­˜åœ¨: {test_image_path}\")\n",
    "        return\n",
    "    \n",
    "    image = load_image(test_image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # èª¿æ•´åœ–ç‰‡å¤§å°ä»¥æé«˜æª¢æ¸¬é€Ÿåº¦\n",
    "    image_resized = resize_image(image, max_width=800)\n",
    "    \n",
    "    # dlibæª¢æ¸¬\n",
    "    faces_dlib = detect_faces_dlib_timed(image_resized)\n",
    "    \n",
    "    # ç¹ªè£½æª¢æ¸¬çµæœ\n",
    "    result_dlib = image_resized.copy()\n",
    "    for (x, y, w, h) in faces_dlib:\n",
    "        cv2.rectangle(result_dlib, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "        cv2.putText(result_dlib, 'dlib HOG', (x, y-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    print(f\"\\nâœ… dlibæª¢æ¸¬çµæœ: ç™¼ç¾ {len(faces_dlib)} å¼µäººè‡‰\")\n",
    "    \n",
    "    # é¡¯ç¤ºçµæœ\n",
    "    display_multiple_images(\n",
    "        [image_resized, result_dlib],\n",
    "        [\"åŸå§‹åœ–ç‰‡\", f\"dlibæª¢æ¸¬ ({len(faces_dlib)} faces)\"],\n",
    "        figsize=(12, 6)\n",
    "    )\n",
    "\n",
    "# åŸ·è¡Œæ¸¬è©¦\n",
    "test_dlib_face_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 68é»é¢éƒ¨ç‰¹å¾µæª¢æ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_facial_landmarks(image, face_rect):\n",
    "    \"\"\"\n",
    "    æª¢æ¸¬68é»é¢éƒ¨ç‰¹å¾µ\n",
    "    \n",
    "    Args:\n",
    "        image: è¼¸å…¥åœ–åƒ\n",
    "        face_rect: äººè‡‰çŸ©å½¢æ¡† (x, y, w, h)\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 68å€‹ç‰¹å¾µé»åº§æ¨™ (68, 2)\n",
    "    \"\"\"\n",
    "    if not DLIB_AVAILABLE or predictor is None:\n",
    "        return np.array([])\n",
    "    \n",
    "    # è½‰æ›ç‚ºç°éš\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # è½‰æ›ç‚ºdlibçŸ©å½¢æ ¼å¼\n",
    "    x, y, w, h = face_rect\n",
    "    dlib_rect = dlib.rectangle(x, y, x + w, y + h)\n",
    "    \n",
    "    # æª¢æ¸¬ç‰¹å¾µé»\n",
    "    landmarks = predictor(gray, dlib_rect)\n",
    "    \n",
    "    # è½‰æ›ç‚ºNumPyé™£åˆ—\n",
    "    points = np.array([(landmarks.part(i).x, landmarks.part(i).y) \n",
    "                      for i in range(68)])\n",
    "    \n",
    "    return points\n",
    "\n",
    "def draw_facial_landmarks(image, landmarks, show_numbers=False):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½68é»é¢éƒ¨ç‰¹å¾µ\n",
    "    \n",
    "    Args:\n",
    "        image: è¼¸å…¥åœ–åƒ\n",
    "        landmarks: 68å€‹ç‰¹å¾µé»åº§æ¨™\n",
    "        show_numbers: æ˜¯å¦é¡¯ç¤ºé»çš„ç·¨è™Ÿ\n",
    "    \n",
    "    Returns:\n",
    "        np.array: ç¹ªè£½ç‰¹å¾µé»å¾Œçš„åœ–åƒ\n",
    "    \"\"\"\n",
    "    result = image.copy()\n",
    "    \n",
    "    if len(landmarks) == 0:\n",
    "        return result\n",
    "    \n",
    "    # å®šç¾©ä¸åŒå€åŸŸçš„é¡è‰²\n",
    "    colors = {\n",
    "        'jaw': (255, 0, 0),      # ä¸‹å·´è¼ªå»“ (0-16)\n",
    "        'eyebrow_r': (0, 255, 0), # å³çœ‰æ¯› (17-21)\n",
    "        'eyebrow_l': (0, 255, 0), # å·¦çœ‰æ¯› (22-26)\n",
    "        'nose': (0, 0, 255),     # é¼»å­ (27-35)\n",
    "        'eye_r': (255, 255, 0),  # å³çœ¼ (36-41)\n",
    "        'eye_l': (255, 255, 0),  # å·¦çœ¼ (42-47)\n",
    "        'mouth': (255, 0, 255)   # å˜´å·´ (48-67)\n",
    "    }\n",
    "    \n",
    "    # å®šç¾©å„éƒ¨ä½çš„é»ç¯„åœ\n",
    "    regions = {\n",
    "        'jaw': range(0, 17),\n",
    "        'eyebrow_r': range(17, 22),\n",
    "        'eyebrow_l': range(22, 27),\n",
    "        'nose': range(27, 36),\n",
    "        'eye_r': range(36, 42),\n",
    "        'eye_l': range(42, 48),\n",
    "        'mouth': range(48, 68)\n",
    "    }\n",
    "    \n",
    "    # ç¹ªè£½ç‰¹å¾µé»\n",
    "    for region, point_range in regions.items():\n",
    "        color = colors[region]\n",
    "        for i in point_range:\n",
    "            if i < len(landmarks):\n",
    "                x, y = landmarks[i]\n",
    "                cv2.circle(result, (int(x), int(y)), 3, color, -1)\n",
    "                \n",
    "                if show_numbers:\n",
    "                    cv2.putText(result, str(i), (int(x) + 3, int(y) - 3),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# æ¸¬è©¦68é»ç‰¹å¾µæª¢æ¸¬\n",
    "def test_facial_landmarks():\n",
    "    \"\"\"æ¸¬è©¦68é»é¢éƒ¨ç‰¹å¾µæª¢æ¸¬\"\"\"\n",
    "    test_image_path = \"../assets/images/basic/face03.jpg\"\n",
    "    \n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(f\"æ¸¬è©¦åœ–ç‰‡ä¸å­˜åœ¨: {test_image_path}\")\n",
    "        return\n",
    "    \n",
    "    image = load_image(test_image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # èª¿æ•´åœ–ç‰‡å¤§å°\n",
    "    image_resized = resize_image(image, max_width=600)\n",
    "    \n",
    "    # æª¢æ¸¬äººè‡‰\n",
    "    faces = detect_faces_dlib(image_resized)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"æœªæª¢æ¸¬åˆ°äººè‡‰\")\n",
    "        return\n",
    "    \n",
    "    # å°æ¯å€‹æª¢æ¸¬åˆ°çš„äººè‡‰é€²è¡Œç‰¹å¾µé»æª¢æ¸¬\n",
    "    results = []\n",
    "    titles = []\n",
    "    \n",
    "    for i, face_rect in enumerate(faces):\n",
    "        # æª¢æ¸¬68é»ç‰¹å¾µ\n",
    "        landmarks = detect_facial_landmarks(image_resized, face_rect)\n",
    "        \n",
    "        if len(landmarks) > 0:\n",
    "            # ç¹ªè£½ç‰¹å¾µé»ï¼ˆä¸é¡¯ç¤ºç·¨è™Ÿï¼‰\n",
    "            result_landmarks = draw_facial_landmarks(image_resized, landmarks, False)\n",
    "            \n",
    "            # ç¹ªè£½äººè‡‰æ¡†\n",
    "            x, y, w, h = face_rect\n",
    "            cv2.rectangle(result_landmarks, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            results.append(result_landmarks)\n",
    "            titles.append(f\"68é»ç‰¹å¾µæª¢æ¸¬ - äººè‡‰{i+1}\")\n",
    "            \n",
    "            print(f\"âœ… äººè‡‰{i+1}: æˆåŠŸæª¢æ¸¬68å€‹ç‰¹å¾µé»\")\n",
    "    \n",
    "    # é¡¯ç¤ºçµæœ\n",
    "    if results:\n",
    "        all_images = [image_resized] + results\n",
    "        all_titles = [\"åŸå§‹åœ–ç‰‡\"] + titles\n",
    "        \n",
    "        display_multiple_images(all_images, all_titles, figsize=(15, 5))\n",
    "\n",
    "# åŸ·è¡Œæ¸¬è©¦\n",
    "test_facial_landmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. äººè‡‰å°é½ŠåŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_face(image, landmarks, desired_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    åŸºæ–¼çœ¼éƒ¨ç‰¹å¾µé»å°é½Šäººè‡‰\n",
    "    \n",
    "    Args:\n",
    "        image: è¼¸å…¥åœ–åƒ\n",
    "        landmarks: 68å€‹ç‰¹å¾µé»\n",
    "        desired_size: è¼¸å‡ºåœ–åƒå¤§å°\n",
    "    \n",
    "    Returns:\n",
    "        np.array: å°é½Šå¾Œçš„äººè‡‰åœ–åƒ\n",
    "    \"\"\"\n",
    "    if len(landmarks) == 0:\n",
    "        return None\n",
    "    \n",
    "    # å–å¾—å·¦çœ¼å’Œå³çœ¼çš„ä¸­å¿ƒé»\n",
    "    # å·¦çœ¼: é»42-47, å³çœ¼: é»36-41\n",
    "    left_eye_pts = landmarks[42:48]\n",
    "    right_eye_pts = landmarks[36:42]\n",
    "    \n",
    "    left_eye_center = np.mean(left_eye_pts, axis=0)\n",
    "    right_eye_center = np.mean(right_eye_pts, axis=0)\n",
    "    \n",
    "    # è¨ˆç®—çœ¼éƒ¨ä¸­ç·šçš„è§’åº¦\n",
    "    dy = right_eye_center[1] - left_eye_center[1]\n",
    "    dx = right_eye_center[0] - left_eye_center[0]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))\n",
    "    \n",
    "    # è¨ˆç®—å…©çœ¼ä¹‹é–“çš„è·é›¢\n",
    "    eye_distance = np.sqrt(dx**2 + dy**2)\n",
    "    \n",
    "    # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ï¼ˆå‡è¨­ç†æƒ³çš„çœ¼è·ç‚ºè‡‰éƒ¨å¯¬åº¦çš„40%ï¼‰\n",
    "    desired_eye_distance = desired_size[0] * 0.4\n",
    "    scale = desired_eye_distance / eye_distance\n",
    "    \n",
    "    # è¨ˆç®—æ—‹è½‰ä¸­å¿ƒï¼ˆå…©çœ¼ä¸­é»ï¼‰\n",
    "    eyes_center = ((left_eye_center[0] + right_eye_center[0]) // 2,\n",
    "                   (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "    \n",
    "    # ç²å¾—æ—‹è½‰çŸ©é™£\n",
    "    M = cv2.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "    \n",
    "    # èª¿æ•´å¹³ç§»ä»¥å°‡è‡‰éƒ¨ç½®ä¸­\n",
    "    tx = desired_size[0] * 0.5\n",
    "    ty = desired_size[1] * 0.4  # çœ¼éƒ¨ä½ç½®ç¨å¾®åä¸Š\n",
    "    \n",
    "    M[0, 2] += (tx - eyes_center[0])\n",
    "    M[1, 2] += (ty - eyes_center[1])\n",
    "    \n",
    "    # åŸ·è¡Œä»¿å°„è®Šæ›\n",
    "    aligned_face = cv2.warpAffine(image, M, desired_size)\n",
    "    \n",
    "    return aligned_face\n",
    "\n",
    "# æ¸¬è©¦äººè‡‰å°é½ŠåŠŸèƒ½\n",
    "def test_face_alignment():\n",
    "    \"\"\"æ¸¬è©¦äººè‡‰å°é½ŠåŠŸèƒ½\"\"\"\n",
    "    test_image_path = \"../assets/images/basic/face03.jpg\"\n",
    "    \n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(f\"æ¸¬è©¦åœ–ç‰‡ä¸å­˜åœ¨: {test_image_path}\")\n",
    "        return\n",
    "    \n",
    "    image = load_image(test_image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # èª¿æ•´åœ–ç‰‡å¤§å°\n",
    "    image_resized = resize_image(image, max_width=600)\n",
    "    \n",
    "    # æª¢æ¸¬äººè‡‰\n",
    "    faces = detect_faces_dlib(image_resized)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"æœªæª¢æ¸¬åˆ°äººè‡‰\")\n",
    "        return\n",
    "    \n",
    "    results = [image_resized]\n",
    "    titles = [\"åŸå§‹åœ–ç‰‡\"]\n",
    "    \n",
    "    for i, face_rect in enumerate(faces):\n",
    "        # æª¢æ¸¬ç‰¹å¾µé»\n",
    "        landmarks = detect_facial_landmarks(image_resized, face_rect)\n",
    "        \n",
    "        if len(landmarks) > 0:\n",
    "            # å°é½Šäººè‡‰\n",
    "            aligned_face = align_face(image_resized, landmarks, (200, 200))\n",
    "            \n",
    "            if aligned_face is not None:\n",
    "                results.append(aligned_face)\n",
    "                titles.append(f\"å°é½Šäººè‡‰{i+1}\")\n",
    "                print(f\"âœ… äººè‡‰{i+1}: å°é½ŠæˆåŠŸ\")\n",
    "    \n",
    "    # é¡¯ç¤ºçµæœ\n",
    "    display_multiple_images(results, titles, figsize=(12, 4))\n",
    "\n",
    "# åŸ·è¡Œæ¸¬è©¦\n",
    "test_face_alignment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. äººè‡‰æª¢æ¸¬æ–¹æ³•æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_face_detection_methods(image_path):\n",
    "    \"\"\"\n",
    "    æ¯”è¼ƒä¸åŒäººè‡‰æª¢æ¸¬æ–¹æ³•çš„æ•ˆèƒ½\n",
    "    \n",
    "    Args:\n",
    "        image_path: æ¸¬è©¦åœ–åƒè·¯å¾‘\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"åœ–ç‰‡ä¸å­˜åœ¨: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    image = load_image(image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # èª¿æ•´åœ–ç‰‡å¤§å°ä»¥ç¢ºä¿å…¬å¹³æ¯”è¼ƒ\n",
    "    image_resized = resize_image(image, max_width=800)\n",
    "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    results = []\n",
    "    titles = []\n",
    "    detection_times = []\n",
    "    face_counts = []\n",
    "    \n",
    "    # 1. Haar Cascadeæª¢æ¸¬\n",
    "    try:\n",
    "        haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \n",
    "                                            'haarcascade_frontalface_default.xml')\n",
    "        \n",
    "        @time_function\n",
    "        def detect_haar():\n",
    "            return haar_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
    "        \n",
    "        faces_haar, time_haar = detect_haar()\n",
    "        \n",
    "        # ç¹ªè£½çµæœ\n",
    "        result_haar = image_resized.copy()\n",
    "        for (x, y, w, h) in faces_haar:\n",
    "            cv2.rectangle(result_haar, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        results.append(result_haar)\n",
    "        titles.append(f\"Haar Cascade\\n{len(faces_haar)} faces, {time_haar:.1f}ms\")\n",
    "        detection_times.append(time_haar)\n",
    "        face_counts.append(len(faces_haar))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Haar Cascadeæª¢æ¸¬å¤±æ•—: {e}\")\n",
    "    \n",
    "    # 2. dlib HOGæª¢æ¸¬\n",
    "    if DLIB_AVAILABLE:\n",
    "        faces_dlib, time_dlib = detect_faces_dlib_timed(image_resized)\n",
    "        \n",
    "        # ç¹ªè£½çµæœ\n",
    "        result_dlib = image_resized.copy()\n",
    "        for (x, y, w, h) in faces_dlib:\n",
    "            cv2.rectangle(result_dlib, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        results.append(result_dlib)\n",
    "        titles.append(f\"dlib HOG\\n{len(faces_dlib)} faces, {time_dlib:.1f}ms\")\n",
    "        detection_times.append(time_dlib)\n",
    "        face_counts.append(len(faces_dlib))\n",
    "    \n",
    "    # 3. OpenCV DNNæª¢æ¸¬ (å¦‚æœæ¨¡å‹å­˜åœ¨)\n",
    "    dnn_model_path = \"../assets/models/opencv_face_detector_uint8.pb\"\n",
    "    dnn_config_path = \"../assets/models/opencv_face_detector.pbtxt\"\n",
    "    \n",
    "    if os.path.exists(dnn_model_path) and os.path.exists(dnn_config_path):\n",
    "        try:\n",
    "            @time_function\n",
    "            def detect_dnn():\n",
    "                net = cv2.dnn.readNetFromTensorflow(dnn_model_path, dnn_config_path)\n",
    "                h, w = image_resized.shape[:2]\n",
    "                blob = cv2.dnn.blobFromImage(image_resized, 1.0, (300, 300), [104, 117, 123])\n",
    "                net.setInput(blob)\n",
    "                detections = net.forward()\n",
    "                \n",
    "                faces = []\n",
    "                for i in range(detections.shape[2]):\n",
    "                    confidence = detections[0, 0, i, 2]\n",
    "                    if confidence > 0.5:\n",
    "                        x1 = int(detections[0, 0, i, 3] * w)\n",
    "                        y1 = int(detections[0, 0, i, 4] * h)\n",
    "                        x2 = int(detections[0, 0, i, 5] * w)\n",
    "                        y2 = int(detections[0, 0, i, 6] * h)\n",
    "                        faces.append((x1, y1, x2-x1, y2-y1))\n",
    "                \n",
    "                return faces\n",
    "            \n",
    "            faces_dnn, time_dnn = detect_dnn()\n",
    "            \n",
    "            # ç¹ªè£½çµæœ\n",
    "            result_dnn = image_resized.copy()\n",
    "            for (x, y, w, h) in faces_dnn:\n",
    "                cv2.rectangle(result_dnn, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "            \n",
    "            results.append(result_dnn)\n",
    "            titles.append(f\"OpenCV DNN\\n{len(faces_dnn)} faces, {time_dnn:.1f}ms\")\n",
    "            detection_times.append(time_dnn)\n",
    "            face_counts.append(len(faces_dnn))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"OpenCV DNNæª¢æ¸¬å¤±æ•—: {e}\")\n",
    "    \n",
    "    # é¡¯ç¤ºæ¯”è¼ƒçµæœ\n",
    "    if results:\n",
    "        all_images = [image_resized] + results\n",
    "        all_titles = [\"åŸå§‹åœ–ç‰‡\"] + titles\n",
    "        \n",
    "        display_multiple_images(all_images, all_titles, figsize=(15, 5))\n",
    "        \n",
    "        # è¼¸å‡ºæ€§èƒ½çµ±è¨ˆ\n",
    "        print(\"\\nğŸ“Š äººè‡‰æª¢æ¸¬æ–¹æ³•æ¯”è¼ƒ:\")\n",
    "        print(\"-\" * 50)\n",
    "        methods = [\"Haar Cascade\", \"dlib HOG\", \"OpenCV DNN\"][:len(detection_times)]\n",
    "        for i, method in enumerate(methods):\n",
    "            print(f\"{method:12}: {face_counts[i]:2d} faces, {detection_times[i]:6.1f}ms\")\n",
    "\n",
    "# åŸ·è¡Œæ¯”è¼ƒæ¸¬è©¦\n",
    "test_image_path = \"../assets/images/basic/faces01.jpg\"\n",
    "compare_face_detection_methods(test_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å¯¦ä½œç·´ç¿’\n",
    "\n",
    "### ç·´ç¿’1: æ‰¹é‡äººè‡‰ç‰¹å¾µæå–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_face_feature_extraction(image_folder, output_folder):\n",
    "    \"\"\"\n",
    "    æ‰¹é‡æå–è³‡æ–™å¤¾ä¸­æ‰€æœ‰åœ–ç‰‡çš„äººè‡‰ç‰¹å¾µ\n",
    "    \n",
    "    ç·´ç¿’ç›®æ¨™:\n",
    "    1. éæ­·è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰åœ–ç‰‡\n",
    "    2. æª¢æ¸¬æ¯å¼µåœ–ç‰‡ä¸­çš„äººè‡‰\n",
    "    3. æå–68é»ç‰¹å¾µä¸¦å„²å­˜çµæœ\n",
    "    4. ç”Ÿæˆå°é½Šå¾Œçš„äººè‡‰åœ–ç‰‡\n",
    "    \n",
    "    è«‹å®Œæˆä»¥ä¸‹åŠŸèƒ½:\n",
    "    - æª¢æŸ¥è¼¸å…¥/è¼¸å‡ºè³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨\n",
    "    - è™•ç†ä¸åŒæ ¼å¼çš„åœ–ç‰‡æª”æ¡ˆ\n",
    "    - éŒ¯èª¤è™•ç†ï¼ˆæ²’æœ‰æª¢æ¸¬åˆ°äººè‡‰çš„æƒ…æ³ï¼‰\n",
    "    - é€²åº¦é¡¯ç¤º\n",
    "    \"\"\"\n",
    "    # TODO: å¯¦ä½œæ‰¹é‡äººè‡‰ç‰¹å¾µæå–\n",
    "    pass\n",
    "\n",
    "print(\"ğŸ’¡ ç·´ç¿’1: è«‹å¯¦ä½œæ‰¹é‡äººè‡‰ç‰¹å¾µæå–åŠŸèƒ½\")\n",
    "print(\"æç¤º: ä½¿ç”¨os.listdir()éæ­·æª”æ¡ˆï¼Œç”¨try-exceptè™•ç†éŒ¯èª¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç·´ç¿’2: äººè‡‰ç›¸ä¼¼åº¦è¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_face_similarity(landmarks1, landmarks2):\n",
    "    \"\"\"\n",
    "    è¨ˆç®—å…©å€‹äººè‡‰ç‰¹å¾µé»çš„ç›¸ä¼¼åº¦\n",
    "    \n",
    "    ç·´ç¿’ç›®æ¨™:\n",
    "    1. æ­£è¦åŒ–ç‰¹å¾µé»åº§æ¨™\n",
    "    2. è¨ˆç®—æ­å¹¾é‡Œå¾—è·é›¢\n",
    "    3. å¯¦ç¾ç›¸ä¼¼åº¦è©•åˆ†\n",
    "    \n",
    "    æç¤º:\n",
    "    - ä½¿ç”¨ç‰¹å¾µé»ä¹‹é–“çš„ç›¸å°è·é›¢è€Œéçµ•å°åº§æ¨™\n",
    "    - è€ƒæ…®ä½¿ç”¨æ™®æ°åˆ†æ (Procrustes Analysis)\n",
    "    - å›å‚³0-1ä¹‹é–“çš„ç›¸ä¼¼åº¦åˆ†æ•¸\n",
    "    \"\"\"\n",
    "    # TODO: å¯¦ä½œäººè‡‰ç›¸ä¼¼åº¦è¨ˆç®—\n",
    "    pass\n",
    "\n",
    "print(\"ğŸ’¡ ç·´ç¿’2: è«‹å¯¦ä½œäººè‡‰ç›¸ä¼¼åº¦è¨ˆç®—åŠŸèƒ½\")\n",
    "print(\"æç¤º: å¯ä»¥ä½¿ç”¨numpy.linalg.normè¨ˆç®—è·é›¢\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç¸½çµèˆ‡å»¶ä¼¸æ‡‰ç”¨\n",
    "\n",
    "### æœ¬æ¨¡çµ„é‡é»å›é¡§\n",
    "\n",
    "1. **dlibäººè‡‰æª¢æ¸¬**: HOG + SVMæ–¹æ³•ï¼Œé«˜ç²¾åº¦ä½†é€Ÿåº¦è¼ƒæ…¢\n",
    "2. **68é»ç‰¹å¾µæª¢æ¸¬**: ç²¾ç¢ºçš„é¢éƒ¨ç‰¹å¾µå®šä½ï¼Œæ”¯æ´äººè‡‰åˆ†æ\n",
    "3. **äººè‡‰å°é½Š**: åŸºæ–¼çœ¼éƒ¨ç‰¹å¾µçš„å¹¾ä½•æ ¡æ­£\n",
    "4. **æ–¹æ³•æ¯”è¼ƒ**: Haar vs dlib vs DNNçš„æ•ˆèƒ½åˆ†æ\n",
    "\n",
    "### å¯¦éš›æ‡‰ç”¨å ´æ™¯\n",
    "- äººè‡‰è­˜åˆ¥ç³»çµ±\n",
    "- è¡¨æƒ…åˆ†æ\n",
    "- ç¾é¡ç›¸æ©Ÿæ¿¾é¡\n",
    "- äººè‡‰å‹•ç•«é©…å‹•\n",
    "- ç”Ÿç‰©ç‰¹å¾µèªè­‰\n",
    "\n",
    "### ä¸‹ä¸€æ­¥å­¸ç¿’\n",
    "- 5.2.1 æ·±åº¦å­¸ç¿’ç‰©é«”æª¢æ¸¬ (YOLO, SSD)\n",
    "- 5.2.2 å¯¦æ™‚æª¢æ¸¬å„ªåŒ–\n",
    "- äººè‡‰è­˜åˆ¥èˆ‡é©—è­‰ç®—æ³•\n",
    "- å¯¦æˆ°å°ˆæ¡ˆï¼šæ™ºèƒ½ç›£æ§ç³»çµ±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ•ˆèƒ½åŸºæº–æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€çµ‚æ•ˆèƒ½æ¸¬è©¦\n",
    "def run_performance_benchmark():\n",
    "    \"\"\"åŸ·è¡Œå®Œæ•´çš„æ•ˆèƒ½åŸºæº–æ¸¬è©¦\"\"\"\n",
    "    \n",
    "    test_cases = [\n",
    "        \"../assets/images/basic/face03.jpg\",\n",
    "        \"../assets/images/basic/faces01.jpg\",\n",
    "        \"../assets/images/basic/faces.png\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ”„ åŸ·è¡Œdlibæ•ˆèƒ½åŸºæº–æ¸¬è©¦...\\n\")\n",
    "    \n",
    "    for i, image_path in enumerate(test_cases, 1):\n",
    "        if os.path.exists(image_path):\n",
    "            print(f\"æ¸¬è©¦{i}: {os.path.basename(image_path)}\")\n",
    "            image = load_image(image_path)\n",
    "            if image is not None:\n",
    "                image_resized = resize_image(image, max_width=600)\n",
    "                \n",
    "                # æª¢æ¸¬ä¸¦è¨ˆæ™‚\n",
    "                faces, detection_time = detect_faces_dlib_timed(image_resized)\n",
    "                print(f\"  - æª¢æ¸¬æ™‚é–“: {detection_time:.1f}ms\")\n",
    "                print(f\"  - äººè‡‰æ•¸é‡: {len(faces)}\")\n",
    "                \n",
    "                # ç‰¹å¾µé»æª¢æ¸¬\n",
    "                if len(faces) > 0:\n",
    "                    landmarks = detect_facial_landmarks(image_resized, faces[0])\n",
    "                    if len(landmarks) > 0:\n",
    "                        print(f\"  - ç‰¹å¾µé»: âœ… 68é»æª¢æ¸¬æˆåŠŸ\")\n",
    "                    else:\n",
    "                        print(f\"  - ç‰¹å¾µé»: âŒ æª¢æ¸¬å¤±æ•—\")\n",
    "                print()\n",
    "    \n",
    "    print(\"âœ… dlibæ•´åˆæ¨¡çµ„æ¸¬è©¦å®Œæˆ\")\n",
    "\n",
    "# åŸ·è¡ŒåŸºæº–æ¸¬è©¦\n",
    "run_performance_benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}