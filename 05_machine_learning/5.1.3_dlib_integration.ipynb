{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# 5.1.3 dlib Integration - 68點面部特徵檢測與人臉識別\n",
    "\n",
    "本模組介紹如何使用dlib函式庫進行高精度的人臉檢測、68點面部特徵定位和人臉識別。\n",
    "\n",
    "## 學習目標\n",
    "- 掌握dlib人臉檢測器的使用\n",
    "- 實現68點面部特徵點檢測\n",
    "- 進行人臉對齊和標準化\n",
    "- 實現基於深度學習的人臉識別\n",
    "- 比較不同人臉檢測方法的效能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設置與函式庫導入"
=======
    "# 5.1.3 dlib 整合與人臉特徵檢測 (dlib Integration & Facial Landmarks)\n",
    "\n",
    "**WBS 5.1.3**: dlib 機器學習庫整合 - 從人臉檢測到人臉識別\n",
    "\n",
    "本模組深入探討 dlib 機器學習庫在計算機視覺中的應用，涵蓋人臉檢測、68點面部特徵檢測、人臉對齊、人臉編碼與識別的完整流程。\n",
    "\n",
    "## 學習目標\n",
    "- 理解 dlib 的核心功能與優勢\n",
    "- 掌握 HOG 人臉檢測器的使用\n",
    "- 學習 68 點面部特徵檢測與標註\n",
    "- 實作人臉對齊技術（Face Alignment）\n",
    "- 理解人臉編碼與相似度計算\n",
    "- 建立完整的人臉識別系統\n",
    "- 整合 OpenCV 與 dlib 工作流\n",
    "\n",
    "## 前置知識\n",
    "- Python 基礎與 NumPy 操作\n",
    "- OpenCV 圖像處理基礎\n",
    "- 了解人臉檢測基本概念（WBS 5.1.1）\n",
    "- 基礎機器學習概念\n",
    "\n",
    "## 課程大綱\n",
    "1. dlib 簡介與安裝 (5%)\n",
    "2. dlib 人臉檢測基礎 (10%)\n",
    "3. 68 點面部特徵檢測 (20%)\n",
    "4. 人臉對齊技術 (15%)\n",
    "5. 人臉識別基礎 (15%)\n",
    "6. 人臉編碼與比對 (15%)\n",
    "7. 實時人臉識別系統 (10%)\n",
    "8. 與 OpenCV 整合 (5%)\n",
    "9. 實戰練習 (5%)\n",
    "10. 總結與延伸 (5%)"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 添加utils路徑\n",
    "sys.path.append('../utils')\n",
    "from image_utils import load_image, resize_image\n",
    "from visualization import display_image, display_multiple_images\n",
    "from performance import time_function, benchmark_function\n",
    "\n",
    "# 嘗試導入dlib\n",
    "try:\n",
    "    import dlib\n",
    "    DLIB_AVAILABLE = True\n",
    "    print(\"✅ dlib library loaded successfully\")\n",
    "    print(f\"dlib version: {dlib.version}\")\n",
    "except ImportError:\n",
    "    DLIB_AVAILABLE = False\n",
    "    print(\"⚠️ dlib not available. Please install: pip install dlib\")\n",
    "    print(\"Some features will be disabled.\")\n",
    "\n",
    "# 設置matplotlib中文顯示\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
=======
    "# 導入必要的庫\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import List, Tuple, Dict\n",
    "import pickle\n",
    "\n",
    "# 設置中文顯示\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 設置圖像顯示大小\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "\n",
    "# 導入 dlib\n",
    "try:\n",
    "    import dlib\n",
    "    DLIB_AVAILABLE = True\n",
    "    print(\"dlib version:\", dlib.__version__ if hasattr(dlib, '__version__') else \"available\")\n",
    "    print(\"✅ dlib successfully imported\")\n",
    "except ImportError:\n",
    "    DLIB_AVAILABLE = False\n",
    "    print(\"❌ dlib not available\")\n",
    "    print(\"\\nInstallation instructions:\")\n",
    "    print(\"  pip install dlib\")\n",
    "    print(\"  or\")\n",
    "    print(\"  conda install -c conda-forge dlib\")\n",
    "    print(\"\\nNote: dlib requires CMake and a C++ compiler\")"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## 2. dlib人臉檢測器初始化"
=======
    "## 1. dlib 簡介與安裝 (5%)\n",
    "\n",
    "### 什麼是 dlib？\n",
    "\n",
    "**dlib** 是一個現代化的 C++ 機器學習工具包，提供 Python 綁定，廣泛用於計算機視覺和機器學習應用。\n",
    "\n",
    "### dlib 核心功能\n",
    "\n",
    "1. **人臉檢測** - HOG + Linear SVM\n",
    "2. **面部特徵點檢測** - 5 點、68 點、194 點\n",
    "3. **人臉識別** - ResNet-based face embeddings\n",
    "4. **物體追蹤** - Correlation tracker\n",
    "5. **機器學習工具** - SVM, 決策樹, 神經網絡\n",
    "\n",
    "### dlib vs OpenCV\n",
    "\n",
    "| 特性 | dlib | OpenCV |\n",
    "|-----|------|--------|\n",
    "| 人臉檢測準確度 | 高 | 中等 |\n",
    "| 速度 | 中等 | 快 |\n",
    "| 面部特徵點 | 68/194 點 | 需外部模型 |\n",
    "| 人臉識別 | 內建 ResNet | 需額外實作 |\n",
    "| 易用性 | 高 | 高 |\n",
    "| 社群支持 | 良好 | 非常好 |\n",
    "\n",
    "### 安裝驗證"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def initialize_dlib_detectors():\n",
    "    \"\"\"\n",
    "    初始化dlib檢測器和預測器\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (人臉檢測器, 68點預測器)\n",
    "    \"\"\"\n",
    "    if not DLIB_AVAILABLE:\n",
    "        return None, None\n",
    "    \n",
    "    # 初始化HOG人臉檢測器\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "    # 68點面部特徵預測器路徑\n",
    "    predictor_path = \"../assets/models/shape_predictor_68_face_landmarks.dat\"\n",
    "    \n",
    "    if os.path.exists(predictor_path):\n",
    "        landmark_predictor = dlib.shape_predictor(predictor_path)\n",
    "        print(f\"✅ 68-point landmark predictor loaded from {predictor_path}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Landmark predictor not found at {predictor_path}\")\n",
    "        print(\"Please download from: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "        landmark_predictor = None\n",
    "    \n",
    "    return face_detector, landmark_predictor\n",
    "\n",
    "# 初始化檢測器\n",
    "detector, predictor = initialize_dlib_detectors()"
=======
    "if DLIB_AVAILABLE:\n",
    "    # 檢查 dlib 功能\n",
    "    print(\"dlib Functions Available:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check face detector\n",
    "    try:\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        print(\"✅ HOG Face Detector: Available\")\n",
    "    except:\n",
    "        print(\"❌ HOG Face Detector: Not available\")\n",
    "    \n",
    "    # Check if CUDA is available (GPU acceleration)\n",
    "    try:\n",
    "        cuda_available = dlib.DLIB_USE_CUDA\n",
    "        print(f\"✅ CUDA Support: {cuda_available}\")\n",
    "    except:\n",
    "        print(\"❌ CUDA Support: Not available (CPU only)\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nNote: GPU acceleration requires dlib compiled with CUDA\")\n",
    "else:\n",
    "    print(\"Please install dlib to continue with this module\")"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## 3. dlib人臉檢測功能"
=======
    "## 2. dlib 人臉檢測基礎 (10%)\n",
    "\n",
    "### HOG + Linear SVM 檢測器\n",
    "\n",
    "dlib 的人臉檢測器使用 **HOG (Histogram of Oriented Gradients)** 特徵配合 **Linear SVM** 分類器。\n",
    "\n",
    "#### 核心原理\n",
    "\n",
    "1. **HOG 特徵提取**\n",
    "   - 計算圖像梯度\n",
    "   - 梯度方向直方圖\n",
    "   - 區塊歸一化\n",
    "\n",
    "2. **滑動窗口檢測**\n",
    "   - 多尺度圖像金字塔\n",
    "   - 滑動窗口掃描\n",
    "   - SVM 分類每個窗口\n",
    "\n",
    "3. **非極大值抑制 (NMS)**\n",
    "   - 移除重疊檢測\n",
    "   - 保留最高置信度\n",
    "\n",
    "#### 優勢\n",
    "\n",
    "- 準確度高於 Haar Cascade\n",
    "- 誤檢率低\n",
    "- 對光照變化魯棒\n",
    "- 可處理一定角度的側臉\n",
    "\n",
    "#### 劣勢\n",
    "\n",
    "- 速度比 Haar Cascade 慢 (約 5-10 倍)\n",
    "- 不適合大分辨率圖像\n",
    "- 對極端姿態效果差"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def detect_faces_dlib(image, upsampling=1):\n",
    "    \"\"\"\n",
    "    使用dlib檢測人臉\n",
    "    \n",
    "    Args:\n",
    "        image: 輸入圖像\n",
    "        upsampling: 上採樣次數，增加檢測精度但降低速度\n",
    "    \n",
    "    Returns:\n",
    "        list: 檢測到的人臉矩形框列表\n",
    "    \"\"\"\n",
    "    if not DLIB_AVAILABLE or detector is None:\n",
    "        return []\n",
    "    \n",
    "    # 轉換為灰階\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # 檢測人臉\n",
    "    faces = detector(gray, upsampling)\n",
    "    \n",
    "    # 轉換為OpenCV格式 (x, y, w, h)\n",
    "    face_rects = []\n",
    "    for face in faces:\n",
    "        x = face.left()\n",
    "        y = face.top()\n",
    "        w = face.width()\n",
    "        h = face.height()\n",
    "        face_rects.append((x, y, w, h))\n",
    "    \n",
    "    return face_rects\n",
    "\n",
    "@time_function\n",
    "def detect_faces_dlib_timed(image, upsampling=1):\n",
    "    \"\"\"帶計時的dlib人臉檢測\"\"\"\n",
    "    return detect_faces_dlib(image, upsampling)\n",
    "\n",
    "# 測試dlib人臉檢測\n",
    "def test_dlib_face_detection():\n",
    "    \"\"\"測試dlib人臉檢測功能\"\"\"\n",
    "    test_image_path = \"../assets/images/basic/faces01.jpg\"\n",
    "    \n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(f\"測試圖片不存在: {test_image_path}\")\n",
    "        return\n",
    "    \n",
    "    image = load_image(test_image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # 調整圖片大小以提高檢測速度\n",
    "    image_resized = resize_image(image, max_width=800)\n",
    "    \n",
    "    # dlib檢測\n",
    "    faces_dlib = detect_faces_dlib_timed(image_resized)\n",
    "    \n",
    "    # 繪製檢測結果\n",
    "    result_dlib = image_resized.copy()\n",
    "    for (x, y, w, h) in faces_dlib:\n",
    "        cv2.rectangle(result_dlib, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "        cv2.putText(result_dlib, 'dlib HOG', (x, y-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    print(f\"\\n✅ dlib檢測結果: 發現 {len(faces_dlib)} 張人臉\")\n",
    "    \n",
    "    # 顯示結果\n",
    "    display_multiple_images(\n",
    "        [image_resized, result_dlib],\n",
    "        [\"原始圖片\", f\"dlib檢測 ({len(faces_dlib)} faces)\"],\n",
    "        figsize=(12, 6)\n",
    "    )\n",
    "\n",
    "# 執行測試\n",
    "test_dlib_face_detection()"
=======
    "if DLIB_AVAILABLE:\n",
    "    # 初始化 dlib 人臉檢測器\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    print(\"dlib HOG face detector initialized\")\n",
    "    \n",
    "    # 載入測試圖像\n",
    "    test_image_path = '../assets/images/basic/faces.jpg'\n",
    "    \n",
    "    if not Path(test_image_path).exists():\n",
    "        print(f\"Warning: {test_image_path} not found\")\n",
    "        # 創建示範圖像\n",
    "        img = np.ones((400, 600, 3), dtype=np.uint8) * 200\n",
    "        cv2.putText(img, \"Place test face image at:\", (50, 150), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        cv2.putText(img, test_image_path, (50, 200), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1)\n",
    "    else:\n",
    "        img = cv2.imread(test_image_path)\n",
    "    \n",
    "    # 顯示原始圖像\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(f\"Image size: {img.shape[1]} x {img.shape[0]} pixels\")\n",
    "else:\n",
    "    print(\"dlib not available, skipping face detection demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DLIB_AVAILABLE:\n",
    "    def detect_faces_dlib(image: np.ndarray,\n",
    "                          detector,\n",
    "                          upsample_num: int = 1) -> Tuple[List, float]:\n",
    "        \"\"\"\n",
    "        Detect faces using dlib HOG detector\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image (BGR format)\n",
    "        detector : dlib.fhog_object_detector\n",
    "            dlib face detector\n",
    "        upsample_num : int\n",
    "            Number of times to upsample image before detection\n",
    "            0: fastest (no upsampling)\n",
    "            1: balanced (default)\n",
    "            2: highest accuracy (slow)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        faces : list\n",
    "            List of dlib rectangles\n",
    "        elapsed_time : float\n",
    "            Detection time in seconds\n",
    "        \"\"\"\n",
    "        # Convert to RGB (dlib expects RGB)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        start_time = time.time()\n",
    "        faces = detector(rgb, upsample_num)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        return faces, elapsed_time\n",
    "    \n",
    "    \n",
    "    def dlib_rect_to_bbox(rect) -> Tuple[int, int, int, int]:\n",
    "        \"\"\"\n",
    "        Convert dlib rectangle to (x, y, w, h) format\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        rect : dlib.rectangle\n",
    "            dlib rectangle object\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        bbox : tuple\n",
    "            (x, y, w, h) format\n",
    "        \"\"\"\n",
    "        x = rect.left()\n",
    "        y = rect.top()\n",
    "        w = rect.right() - x\n",
    "        h = rect.bottom() - y\n",
    "        return (x, y, w, h)\n",
    "    \n",
    "    \n",
    "    def draw_dlib_faces(image: np.ndarray, \n",
    "                        faces: List,\n",
    "                        color: Tuple[int, int, int] = (0, 255, 0),\n",
    "                        thickness: int = 2) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Draw rectangles around detected faces\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image\n",
    "        faces : list\n",
    "            List of dlib rectangles\n",
    "        color : tuple\n",
    "            Rectangle color (BGR)\n",
    "        thickness : int\n",
    "            Line thickness\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        output : np.ndarray\n",
    "            Image with drawn rectangles\n",
    "        \"\"\"\n",
    "        output = image.copy()\n",
    "        \n",
    "        for i, rect in enumerate(faces):\n",
    "            x, y, w, h = dlib_rect_to_bbox(rect)\n",
    "            \n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(output, (x, y), (x+w, y+h), color, thickness)\n",
    "            \n",
    "            # Draw face number\n",
    "            label = f\"Face {i+1}\"\n",
    "            cv2.putText(output, label, (x, y-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    # 執行人臉檢測\n",
    "    faces_dlib, time_dlib = detect_faces_dlib(img, detector, upsample_num=1)\n",
    "    \n",
    "    # 繪製檢測結果\n",
    "    img_result = draw_dlib_faces(img, faces_dlib, color=(0, 255, 0))\n",
    "    \n",
    "    # 顯示結果\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Image', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(f'dlib HOG Detection: {len(faces_dlib)} faces\\nTime: {time_dlib*1000:.2f}ms', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 輸出詳細信息\n",
    "    print(f\"\\nDetection Results:\")\n",
    "    print(f\"Number of faces detected: {len(faces_dlib)}\")\n",
    "    print(f\"Detection time: {time_dlib*1000:.2f} ms\")\n",
    "    print(f\"\\nFace coordinates (x, y, w, h):\")\n",
    "    for i, rect in enumerate(faces_dlib, 1):\n",
    "        x, y, w, h = dlib_rect_to_bbox(rect)\n",
    "        print(f\"Face {i}: ({x}, {y}, {w}, {h})\")\n",
    "else:\n",
    "    print(\"dlib not available\")"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## 4. 68點面部特徵檢測"
=======
    "### upsample 參數影響\n",
    "\n",
    "`upsample_num` 參數控制圖像上採樣次數，影響檢測準確度和速度：\n",
    "\n",
    "- **upsample_num = 0**: 不上採樣，最快速度，可能漏檢小臉\n",
    "- **upsample_num = 1**: 上採樣 1 次（放大 2 倍），平衡選擇\n",
    "- **upsample_num = 2**: 上採樣 2 次（放大 4 倍），最高準確度，但速度慢 4 倍"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def detect_facial_landmarks(image, face_rect):\n",
    "    \"\"\"\n",
    "    檢測68點面部特徵\n",
    "    \n",
    "    Args:\n",
    "        image: 輸入圖像\n",
    "        face_rect: 人臉矩形框 (x, y, w, h)\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 68個特徵點座標 (68, 2)\n",
    "    \"\"\"\n",
    "    if not DLIB_AVAILABLE or predictor is None:\n",
    "        return np.array([])\n",
    "    \n",
    "    # 轉換為灰階\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # 轉換為dlib矩形格式\n",
    "    x, y, w, h = face_rect\n",
    "    dlib_rect = dlib.rectangle(x, y, x + w, y + h)\n",
    "    \n",
    "    # 檢測特徵點\n",
    "    landmarks = predictor(gray, dlib_rect)\n",
    "    \n",
    "    # 轉換為NumPy陣列\n",
    "    points = np.array([(landmarks.part(i).x, landmarks.part(i).y) \n",
    "                      for i in range(68)])\n",
    "    \n",
    "    return points\n",
    "\n",
    "def draw_facial_landmarks(image, landmarks, show_numbers=False):\n",
    "    \"\"\"\n",
    "    繪製68點面部特徵\n",
    "    \n",
    "    Args:\n",
    "        image: 輸入圖像\n",
    "        landmarks: 68個特徵點座標\n",
    "        show_numbers: 是否顯示點的編號\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 繪製特徵點後的圖像\n",
    "    \"\"\"\n",
    "    result = image.copy()\n",
    "    \n",
    "    if len(landmarks) == 0:\n",
    "        return result\n",
    "    \n",
    "    # 定義不同區域的顏色\n",
    "    colors = {\n",
    "        'jaw': (255, 0, 0),      # 下巴輪廓 (0-16)\n",
    "        'eyebrow_r': (0, 255, 0), # 右眉毛 (17-21)\n",
    "        'eyebrow_l': (0, 255, 0), # 左眉毛 (22-26)\n",
    "        'nose': (0, 0, 255),     # 鼻子 (27-35)\n",
    "        'eye_r': (255, 255, 0),  # 右眼 (36-41)\n",
    "        'eye_l': (255, 255, 0),  # 左眼 (42-47)\n",
    "        'mouth': (255, 0, 255)   # 嘴巴 (48-67)\n",
    "    }\n",
    "    \n",
    "    # 定義各部位的點範圍\n",
    "    regions = {\n",
    "        'jaw': range(0, 17),\n",
    "        'eyebrow_r': range(17, 22),\n",
    "        'eyebrow_l': range(22, 27),\n",
    "        'nose': range(27, 36),\n",
    "        'eye_r': range(36, 42),\n",
    "        'eye_l': range(42, 48),\n",
    "        'mouth': range(48, 68)\n",
    "    }\n",
    "    \n",
    "    # 繪製特徵點\n",
    "    for region, point_range in regions.items():\n",
    "        color = colors[region]\n",
    "        for i in point_range:\n",
    "            if i < len(landmarks):\n",
    "                x, y = landmarks[i]\n",
    "                cv2.circle(result, (int(x), int(y)), 3, color, -1)\n",
    "                \n",
    "                if show_numbers:\n",
    "                    cv2.putText(result, str(i), (int(x) + 3, int(y) - 3),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 測試68點特徵檢測\n",
    "def test_facial_landmarks():\n",
    "    \"\"\"測試68點面部特徵檢測\"\"\"\n",
    "    test_image_path = \"../assets/images/basic/face03.jpg\"\n",
    "    \n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(f\"測試圖片不存在: {test_image_path}\")\n",
    "        return\n",
    "    \n",
    "    image = load_image(test_image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # 調整圖片大小\n",
    "    image_resized = resize_image(image, max_width=600)\n",
    "    \n",
    "    # 檢測人臉\n",
    "    faces = detect_faces_dlib(image_resized)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"未檢測到人臉\")\n",
    "        return\n",
    "    \n",
    "    # 對每個檢測到的人臉進行特徵點檢測\n",
    "    results = []\n",
    "    titles = []\n",
    "    \n",
    "    for i, face_rect in enumerate(faces):\n",
    "        # 檢測68點特徵\n",
    "        landmarks = detect_facial_landmarks(image_resized, face_rect)\n",
    "        \n",
    "        if len(landmarks) > 0:\n",
    "            # 繪製特徵點（不顯示編號）\n",
    "            result_landmarks = draw_facial_landmarks(image_resized, landmarks, False)\n",
    "            \n",
    "            # 繪製人臉框\n",
    "            x, y, w, h = face_rect\n",
    "            cv2.rectangle(result_landmarks, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            results.append(result_landmarks)\n",
    "            titles.append(f\"68點特徵檢測 - 人臉{i+1}\")\n",
    "            \n",
    "            print(f\"✅ 人臉{i+1}: 成功檢測68個特徵點\")\n",
    "    \n",
    "    # 顯示結果\n",
    "    if results:\n",
    "        all_images = [image_resized] + results\n",
    "        all_titles = [\"原始圖片\"] + titles\n",
    "        \n",
    "        display_multiple_images(all_images, all_titles, figsize=(15, 5))\n",
    "\n",
    "# 執行測試\n",
    "test_facial_landmarks()"
=======
    "if DLIB_AVAILABLE:\n",
    "    # 測試不同 upsample 參數\n",
    "    upsample_values = [0, 1, 2]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    results = []\n",
    "    \n",
    "    for idx, upsample in enumerate(upsample_values):\n",
    "        # 檢測\n",
    "        faces, elapsed = detect_faces_dlib(img, detector, upsample_num=upsample)\n",
    "        \n",
    "        # 繪製\n",
    "        img_result = draw_dlib_faces(img, faces)\n",
    "        \n",
    "        # 顯示\n",
    "        axes[idx].imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
    "        axes[idx].set_title(\n",
    "            f'upsample_num = {upsample}\\n'\n",
    "            f'Faces: {len(faces)}, Time: {elapsed*1000:.2f}ms',\n",
    "            fontsize=12\n",
    "        )\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        results.append({\n",
    "            'upsample': upsample,\n",
    "            'faces': len(faces),\n",
    "            'time_ms': elapsed * 1000\n",
    "        })\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 輸出比較\n",
    "    print(\"\\nUpsample Parameter Comparison:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Upsample':<15} {'Faces':<10} {'Time (ms)':<15} {'Relative Speed':<15}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    base_time = results[0]['time_ms']\n",
    "    for result in results:\n",
    "        relative_speed = base_time / result['time_ms']\n",
    "        print(f\"{result['upsample']:<15} {result['faces']:<10} \"\n",
    "              f\"{result['time_ms']:<15.2f} {relative_speed:<15.2f}x\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nRecommendation:\")\n",
    "    print(\"  - Use upsample_num=0 for real-time applications\")\n",
    "    print(\"  - Use upsample_num=1 for general use (balanced)\")\n",
    "    print(\"  - Use upsample_num=2 for highest accuracy (offline processing)\")\n",
    "else:\n",
    "    print(\"dlib not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 68 點面部特徵檢測 (20%)\n",
    "\n",
    "### 什麼是面部特徵點 (Facial Landmarks)？\n",
    "\n",
    "面部特徵點是人臉上的關鍵點位置，用於描述人臉的幾何結構。dlib 提供預訓練的 **68 點檢測模型**。\n",
    "\n",
    "### 68 點分布\n",
    "\n",
    "```\n",
    "下巴輪廓 (Jaw):         0-16   (17 points)\n",
    "右眉毛 (Right Eyebrow): 17-21  (5 points)\n",
    "左眉毛 (Left Eyebrow):  22-26  (5 points)\n",
    "鼻樑 (Nose Bridge):     27-30  (4 points)\n",
    "鼻尖 (Nose Tip):        31-35  (5 points)\n",
    "右眼 (Right Eye):       36-41  (6 points)\n",
    "左眼 (Left Eye):        42-47  (6 points)\n",
    "外嘴唇 (Outer Lip):     48-59  (12 points)\n",
    "內嘴唇 (Inner Lip):     60-67  (8 points)\n",
    "```\n",
    "\n",
    "### 應用場景\n",
    "\n",
    "1. **人臉對齊** - 標準化人臉姿態\n",
    "2. **表情識別** - 分析面部變化\n",
    "3. **AR 濾鏡** - 貼紙、特效\n",
    "4. **疲勞檢測** - 眼睛開合度\n",
    "5. **注視方向** - 眼球追蹤\n",
    "6. **唇讀** - 嘴型分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DLIB_AVAILABLE:\n",
    "    # 載入 68 點面部特徵檢測器\n",
    "    predictor_path = '../assets/models/dlib/shape_predictor_68_face_landmarks.dat'\n",
    "    \n",
    "    if Path(predictor_path).exists():\n",
    "        predictor = dlib.shape_predictor(predictor_path)\n",
    "        print(f\"✅ 68-point predictor loaded from {predictor_path}\")\n",
    "        PREDICTOR_AVAILABLE = True\n",
    "    else:\n",
    "        print(f\"❌ Predictor model not found at {predictor_path}\")\n",
    "        print(\"\\nDownload instructions:\")\n",
    "        print(\"1. Download from: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "        print(\"2. Extract the .dat file\")\n",
    "        print(\"3. Place in: ../assets/models/dlib/\")\n",
    "        print(\"\\nAlternative (using dlib.get_shape_predictor_5_face_landmarks() for 5-point):\")\n",
    "        try:\n",
    "            predictor = dlib.shape_predictor(dlib.get_shape_predictor_5_face_landmarks())\n",
    "            print(\"✅ Using built-in 5-point predictor instead\")\n",
    "            PREDICTOR_AVAILABLE = True\n",
    "        except:\n",
    "            PREDICTOR_AVAILABLE = False\n",
    "else:\n",
    "    PREDICTOR_AVAILABLE = False\n",
    "    print(\"dlib not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DLIB_AVAILABLE and PREDICTOR_AVAILABLE:\n",
    "    def detect_landmarks(image: np.ndarray,\n",
    "                        face_rect,\n",
    "                        predictor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Detect 68 facial landmarks\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image (BGR or RGB)\n",
    "        face_rect : dlib.rectangle\n",
    "            Face bounding box\n",
    "        predictor : dlib.shape_predictor\n",
    "            68-point predictor\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        landmarks : np.ndarray\n",
    "            Array of shape (68, 2) containing (x, y) coordinates\n",
    "        \"\"\"\n",
    "        # Convert to RGB if needed\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            rgb = image\n",
    "        \n",
    "        # Detect landmarks\n",
    "        shape = predictor(rgb, face_rect)\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        landmarks = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        \n",
    "        return landmarks\n",
    "    \n",
    "    \n",
    "    def draw_landmarks(image: np.ndarray,\n",
    "                      landmarks: np.ndarray,\n",
    "                      draw_numbers: bool = False,\n",
    "                      color: Tuple[int, int, int] = (0, 255, 0),\n",
    "                      radius: int = 2) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Draw facial landmarks on image\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image\n",
    "        landmarks : np.ndarray\n",
    "            Array of shape (N, 2) with (x, y) coordinates\n",
    "        draw_numbers : bool\n",
    "            Whether to draw landmark numbers\n",
    "        color : tuple\n",
    "            Point color (BGR)\n",
    "        radius : int\n",
    "            Point radius\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        output : np.ndarray\n",
    "            Image with landmarks\n",
    "        \"\"\"\n",
    "        output = image.copy()\n",
    "        \n",
    "        for i, (x, y) in enumerate(landmarks):\n",
    "            # Draw point\n",
    "            cv2.circle(output, (int(x), int(y)), radius, color, -1)\n",
    "            \n",
    "            # Draw number (optional)\n",
    "            if draw_numbers:\n",
    "                cv2.putText(output, str(i), (int(x)+5, int(y)-5),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 0), 1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def draw_landmarks_styled(image: np.ndarray,\n",
    "                             landmarks: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Draw facial landmarks with different colors for different parts\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image\n",
    "        landmarks : np.ndarray\n",
    "            68 facial landmarks\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        output : np.ndarray\n",
    "            Styled image\n",
    "        \"\"\"\n",
    "        output = image.copy()\n",
    "        \n",
    "        # Define facial part ranges and colors\n",
    "        parts = {\n",
    "            'jaw': (range(0, 17), (0, 255, 0)),          # Green\n",
    "            'right_eyebrow': (range(17, 22), (0, 0, 255)),  # Red\n",
    "            'left_eyebrow': (range(22, 27), (0, 0, 255)),   # Red\n",
    "            'nose_bridge': (range(27, 31), (255, 0, 0)),    # Blue\n",
    "            'nose_tip': (range(31, 36), (255, 255, 0)),     # Cyan\n",
    "            'right_eye': (range(36, 42), (255, 0, 255)),    # Magenta\n",
    "            'left_eye': (range(42, 48), (255, 0, 255)),     # Magenta\n",
    "            'outer_lip': (range(48, 60), (0, 255, 255)),    # Yellow\n",
    "            'inner_lip': (range(60, 68), (128, 128, 0))     # Teal\n",
    "        }\n",
    "        \n",
    "        # Draw each part\n",
    "        for part_name, (indices, color) in parts.items():\n",
    "            points = landmarks[list(indices)]\n",
    "            \n",
    "            # Draw points\n",
    "            for (x, y) in points:\n",
    "                cv2.circle(output, (int(x), int(y)), 2, color, -1)\n",
    "            \n",
    "            # Draw lines for closed regions\n",
    "            if part_name in ['jaw', 'right_eyebrow', 'left_eyebrow', \n",
    "                            'nose_bridge', 'right_eye', 'left_eye',\n",
    "                            'outer_lip', 'inner_lip']:\n",
    "                pts = points.astype(np.int32)\n",
    "                \n",
    "                if part_name in ['right_eye', 'left_eye', 'outer_lip', 'inner_lip']:\n",
    "                    # Closed contour\n",
    "                    cv2.polylines(output, [pts], True, color, 1)\n",
    "                else:\n",
    "                    # Open contour\n",
    "                    cv2.polylines(output, [pts], False, color, 1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    # 檢測並繪製第一張臉的特徵點\n",
    "    if len(faces_dlib) > 0:\n",
    "        # 取第一張臉\n",
    "        face = faces_dlib[0]\n",
    "        \n",
    "        # 檢測特徵點\n",
    "        landmarks = detect_landmarks(img, face, predictor)\n",
    "        \n",
    "        # 繪製結果\n",
    "        img_landmarks_simple = draw_landmarks(img, landmarks, draw_numbers=False)\n",
    "        img_landmarks_numbered = draw_landmarks(img, landmarks, draw_numbers=True)\n",
    "        img_landmarks_styled = draw_landmarks_styled(img, landmarks)\n",
    "        \n",
    "        # 顯示\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[0].set_title('Original Image', fontsize=12)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(cv2.cvtColor(img_landmarks_simple, cv2.COLOR_BGR2RGB))\n",
    "        axes[1].set_title('68 Facial Landmarks', fontsize=12)\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(cv2.cvtColor(img_landmarks_numbered, cv2.COLOR_BGR2RGB))\n",
    "        axes[2].set_title('Landmarks with Numbers', fontsize=12)\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        axes[3].imshow(cv2.cvtColor(img_landmarks_styled, cv2.COLOR_BGR2RGB))\n",
    "        axes[3].set_title('Styled Landmarks (Color-coded by Part)', fontsize=12)\n",
    "        axes[3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nLandmark Detection Results:\")\n",
    "        print(f\"Number of landmarks: {len(landmarks)}\")\n",
    "        print(f\"Landmark shape: {landmarks.shape}\")\n",
    "        print(f\"\\nSample landmark coordinates:\")\n",
    "        print(f\"  Nose tip (point 30): ({landmarks[30][0]:.1f}, {landmarks[30][1]:.1f})\")\n",
    "        print(f\"  Left eye center (point 39): ({landmarks[39][0]:.1f}, {landmarks[39][1]:.1f})\")\n",
    "        print(f\"  Right eye center (point 42): ({landmarks[42][0]:.1f}, {landmarks[42][1]:.1f})\")\n",
    "        print(f\"  Mouth center (point 62): ({landmarks[62][0]:.1f}, {landmarks[62][1]:.1f})\")\n",
    "    else:\n",
    "        print(\"No faces detected to show landmarks\")\n",
    "else:\n",
    "    print(\"dlib or predictor not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 面部特徵點的應用\n",
    "\n",
    "#### 1. 眼睛長寬比 (Eye Aspect Ratio, EAR)\n",
    "\n",
    "用於檢測眨眼、疲勞駕駛等應用。\n",
    "\n",
    "```\n",
    "EAR = (||p2-p6|| + ||p3-p5||) / (2 * ||p1-p4||)\n",
    "```\n",
    "\n",
    "其中 p1-p6 是眼睛的 6 個特徵點。\n",
    "\n",
    "- EAR > 0.2: 眼睛睜開\n",
    "- EAR < 0.2: 眼睛閉合/半閉\n",
    "\n",
    "#### 2. 嘴巴長寬比 (Mouth Aspect Ratio, MAR)\n",
    "\n",
    "用於檢測打哈欠、說話等。\n",
    "\n",
    "```\n",
    "MAR = (||p2-p8|| + ||p3-p7|| + ||p4-p6||) / (2 * ||p1-p5||)\n",
    "```\n",
    "\n",
    "#### 3. 頭部姿態估計\n",
    "\n",
    "通過特徵點與 3D 模型匹配，估計俯仰角、偏航角、翻滾角。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DLIB_AVAILABLE and PREDICTOR_AVAILABLE and len(faces_dlib) > 0:\n",
    "    def calculate_ear(eye_landmarks: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Eye Aspect Ratio\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        eye_landmarks : np.ndarray\n",
    "            6 eye landmarks (clockwise from left corner)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        ear : float\n",
    "            Eye Aspect Ratio\n",
    "        \"\"\"\n",
    "        # Compute vertical distances\n",
    "        v1 = np.linalg.norm(eye_landmarks[1] - eye_landmarks[5])\n",
    "        v2 = np.linalg.norm(eye_landmarks[2] - eye_landmarks[4])\n",
    "        \n",
    "        # Compute horizontal distance\n",
    "        h = np.linalg.norm(eye_landmarks[0] - eye_landmarks[3])\n",
    "        \n",
    "        # Compute EAR\n",
    "        ear = (v1 + v2) / (2.0 * h)\n",
    "        \n",
    "        return ear\n",
    "    \n",
    "    \n",
    "    def calculate_mar(mouth_landmarks: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Mouth Aspect Ratio\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        mouth_landmarks : np.ndarray\n",
    "            Mouth landmarks (outer lip: 48-59)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        mar : float\n",
    "            Mouth Aspect Ratio\n",
    "        \"\"\"\n",
    "        # Compute vertical distances\n",
    "        v1 = np.linalg.norm(mouth_landmarks[13] - mouth_landmarks[19])  # 61-67\n",
    "        v2 = np.linalg.norm(mouth_landmarks[14] - mouth_landmarks[18])  # 62-66\n",
    "        v3 = np.linalg.norm(mouth_landmarks[15] - mouth_landmarks[17])  # 63-65\n",
    "        \n",
    "        # Compute horizontal distance\n",
    "        h = np.linalg.norm(mouth_landmarks[0] - mouth_landmarks[6])  # 48-54\n",
    "        \n",
    "        # Compute MAR\n",
    "        mar = (v1 + v2 + v3) / (2.0 * h)\n",
    "        \n",
    "        return mar\n",
    "    \n",
    "    \n",
    "    # 計算 EAR 和 MAR\n",
    "    # 提取眼睛和嘴巴特徵點\n",
    "    left_eye = landmarks[42:48]   # 左眼 (42-47)\n",
    "    right_eye = landmarks[36:42]  # 右眼 (36-41)\n",
    "    mouth = landmarks[48:68]      # 嘴巴 (48-67)\n",
    "    \n",
    "    # 計算比率\n",
    "    left_ear = calculate_ear(left_eye)\n",
    "    right_ear = calculate_ear(right_eye)\n",
    "    avg_ear = (left_ear + right_ear) / 2.0\n",
    "    \n",
    "    mar = calculate_mar(mouth)\n",
    "    \n",
    "    # 可視化\n",
    "    img_ratios = img.copy()\n",
    "    \n",
    "    # 繪製特徵點\n",
    "    for (x, y) in left_eye:\n",
    "        cv2.circle(img_ratios, (int(x), int(y)), 3, (255, 0, 255), -1)\n",
    "    for (x, y) in right_eye:\n",
    "        cv2.circle(img_ratios, (int(x), int(y)), 3, (255, 0, 255), -1)\n",
    "    for (x, y) in mouth:\n",
    "        cv2.circle(img_ratios, (int(x), int(y)), 3, (0, 255, 255), -1)\n",
    "    \n",
    "    # 繪製比率資訊\n",
    "    y_offset = 30\n",
    "    cv2.putText(img_ratios, f\"Left EAR: {left_ear:.3f}\", (10, y_offset),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "    cv2.putText(img_ratios, f\"Right EAR: {right_ear:.3f}\", (10, y_offset + 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "    cv2.putText(img_ratios, f\"Avg EAR: {avg_ear:.3f}\", (10, y_offset + 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "    cv2.putText(img_ratios, f\"MAR: {mar:.3f}\", (10, y_offset + 90),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    \n",
    "    # 判斷狀態\n",
    "    eye_status = \"Open\" if avg_ear > 0.2 else \"Closed/Blinking\"\n",
    "    mouth_status = \"Open\" if mar > 0.5 else \"Closed\"\n",
    "    \n",
    "    cv2.putText(img_ratios, f\"Eyes: {eye_status}\", (10, y_offset + 130),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.putText(img_ratios, f\"Mouth: {mouth_status}\", (10, y_offset + 160),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # 顯示\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(img_ratios, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Eye Aspect Ratio (EAR) and Mouth Aspect Ratio (MAR)', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nFacial Ratio Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Left Eye EAR:  {left_ear:.4f}\")\n",
    "    print(f\"Right Eye EAR: {right_ear:.4f}\")\n",
    "    print(f\"Average EAR:   {avg_ear:.4f}\")\n",
    "    print(f\"Mouth MAR:     {mar:.4f}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Eye Status:    {eye_status}\")\n",
    "    print(f\"Mouth Status:  {mouth_status}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nThresholds:\")\n",
    "    print(\"  EAR < 0.2: Eyes closed/blinking\")\n",
    "    print(\"  EAR > 0.2: Eyes open\")\n",
    "    print(\"  MAR < 0.5: Mouth closed\")\n",
    "    print(\"  MAR > 0.5: Mouth open\")\n",
    "else:\n",
    "    print(\"Prerequisites not met for ratio calculation\")"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## 5. 人臉對齊功能"
=======
    "## 4. 人臉對齊 (Face Alignment) (15%)\n",
    "\n",
    "### 什麼是人臉對齊？\n",
    "\n",
    "人臉對齊是將檢測到的人臉轉換為標準姿態的過程，消除姿態、角度的影響。\n",
    "\n",
    "### 對齊步驟\n",
    "\n",
    "1. **檢測面部特徵點** - 找到眼睛、鼻子、嘴巴位置\n",
    "2. **計算變換矩陣** - 根據特徵點計算仿射變換\n",
    "3. **應用變換** - 將人臉旋轉、縮放到標準位置\n",
    "\n",
    "### 對齊方法\n",
    "\n",
    "1. **基於眼睛的對齊** (2 點)\n",
    "   - 僅使用兩眼中心點\n",
    "   - 簡單但不夠準確\n",
    "\n",
    "2. **基於 5 點的對齊**\n",
    "   - 兩眼中心 + 鼻尖 + 兩個嘴角\n",
    "   - 平衡準確度和速度\n",
    "\n",
    "3. **基於 68 點的對齊**\n",
    "   - 使用全部特徵點\n",
    "   - 最高準確度\n",
    "\n",
    "### 應用\n",
    "\n",
    "- 人臉識別前處理\n",
    "- 提高識別準確度\n",
    "- 標準化數據集"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def align_face(image, landmarks, desired_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    基於眼部特徵點對齊人臉\n",
    "    \n",
    "    Args:\n",
    "        image: 輸入圖像\n",
    "        landmarks: 68個特徵點\n",
    "        desired_size: 輸出圖像大小\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 對齊後的人臉圖像\n",
    "    \"\"\"\n",
    "    if len(landmarks) == 0:\n",
    "        return None\n",
    "    \n",
    "    # 取得左眼和右眼的中心點\n",
    "    # 左眼: 點42-47, 右眼: 點36-41\n",
    "    left_eye_pts = landmarks[42:48]\n",
    "    right_eye_pts = landmarks[36:42]\n",
    "    \n",
    "    left_eye_center = np.mean(left_eye_pts, axis=0)\n",
    "    right_eye_center = np.mean(right_eye_pts, axis=0)\n",
    "    \n",
    "    # 計算眼部中線的角度\n",
    "    dy = right_eye_center[1] - left_eye_center[1]\n",
    "    dx = right_eye_center[0] - left_eye_center[0]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))\n",
    "    \n",
    "    # 計算兩眼之間的距離\n",
    "    eye_distance = np.sqrt(dx**2 + dy**2)\n",
    "    \n",
    "    # 計算縮放比例（假設理想的眼距為臉部寬度的40%）\n",
    "    desired_eye_distance = desired_size[0] * 0.4\n",
    "    scale = desired_eye_distance / eye_distance\n",
    "    \n",
    "    # 計算旋轉中心（兩眼中點）\n",
    "    eyes_center = ((left_eye_center[0] + right_eye_center[0]) // 2,\n",
    "                   (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "    \n",
    "    # 獲得旋轉矩陣\n",
    "    M = cv2.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "    \n",
    "    # 調整平移以將臉部置中\n",
    "    tx = desired_size[0] * 0.5\n",
    "    ty = desired_size[1] * 0.4  # 眼部位置稍微偏上\n",
    "    \n",
    "    M[0, 2] += (tx - eyes_center[0])\n",
    "    M[1, 2] += (ty - eyes_center[1])\n",
    "    \n",
    "    # 執行仿射變換\n",
    "    aligned_face = cv2.warpAffine(image, M, desired_size)\n",
    "    \n",
    "    return aligned_face\n",
    "\n",
    "# 測試人臉對齊功能\n",
    "def test_face_alignment():\n",
    "    \"\"\"測試人臉對齊功能\"\"\"\n",
    "    test_image_path = \"../assets/images/basic/face03.jpg\"\n",
    "    \n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(f\"測試圖片不存在: {test_image_path}\")\n",
    "        return\n",
    "    \n",
    "    image = load_image(test_image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # 調整圖片大小\n",
    "    image_resized = resize_image(image, max_width=600)\n",
    "    \n",
    "    # 檢測人臉\n",
    "    faces = detect_faces_dlib(image_resized)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"未檢測到人臉\")\n",
    "        return\n",
    "    \n",
    "    results = [image_resized]\n",
    "    titles = [\"原始圖片\"]\n",
    "    \n",
    "    for i, face_rect in enumerate(faces):\n",
    "        # 檢測特徵點\n",
    "        landmarks = detect_facial_landmarks(image_resized, face_rect)\n",
    "        \n",
    "        if len(landmarks) > 0:\n",
    "            # 對齊人臉\n",
    "            aligned_face = align_face(image_resized, landmarks, (200, 200))\n",
    "            \n",
    "            if aligned_face is not None:\n",
    "                results.append(aligned_face)\n",
    "                titles.append(f\"對齊人臉{i+1}\")\n",
    "                print(f\"✅ 人臉{i+1}: 對齊成功\")\n",
    "    \n",
    "    # 顯示結果\n",
    "    display_multiple_images(results, titles, figsize=(12, 4))\n",
    "\n",
    "# 執行測試\n",
    "test_face_alignment()"
=======
    "if DLIB_AVAILABLE and PREDICTOR_AVAILABLE and len(faces_dlib) > 0:\n",
    "    def align_face_2point(image: np.ndarray,\n",
    "                          landmarks: np.ndarray,\n",
    "                          output_size: Tuple[int, int] = (256, 256)) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Align face using 2 eye centers\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image\n",
    "        landmarks : np.ndarray\n",
    "            68 facial landmarks\n",
    "        output_size : tuple\n",
    "            Output face size (width, height)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        aligned : np.ndarray\n",
    "            Aligned face image\n",
    "        \"\"\"\n",
    "        # Extract eye centers\n",
    "        left_eye_center = landmarks[42:48].mean(axis=0).astype(int)\n",
    "        right_eye_center = landmarks[36:42].mean(axis=0).astype(int)\n",
    "        \n",
    "        # Compute angle\n",
    "        dY = right_eye_center[1] - left_eye_center[1]\n",
    "        dX = right_eye_center[0] - left_eye_center[0]\n",
    "        angle = np.degrees(np.arctan2(dY, dX))\n",
    "        \n",
    "        # Compute desired eye positions\n",
    "        desired_left_eye = (0.35 * output_size[0], 0.35 * output_size[1])\n",
    "        desired_right_eye = (0.65 * output_size[0], 0.35 * output_size[1])\n",
    "        \n",
    "        # Compute scale\n",
    "        desired_dist = desired_right_eye[0] - desired_left_eye[0]\n",
    "        actual_dist = np.linalg.norm(right_eye_center - left_eye_center)\n",
    "        scale = desired_dist / actual_dist\n",
    "        \n",
    "        # Compute eye center\n",
    "        eyes_center = ((left_eye_center[0] + right_eye_center[0]) // 2,\n",
    "                      (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "        \n",
    "        # Get rotation matrix\n",
    "        M = cv2.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "        \n",
    "        # Update translation component\n",
    "        tX = output_size[0] * 0.5\n",
    "        tY = output_size[1] * 0.35\n",
    "        M[0, 2] += (tX - eyes_center[0])\n",
    "        M[1, 2] += (tY - eyes_center[1])\n",
    "        \n",
    "        # Apply transformation\n",
    "        aligned = cv2.warpAffine(image, M, output_size, flags=cv2.INTER_CUBIC)\n",
    "        \n",
    "        return aligned\n",
    "    \n",
    "    \n",
    "    def align_face_5point(image: np.ndarray,\n",
    "                          landmarks: np.ndarray,\n",
    "                          output_size: Tuple[int, int] = (256, 256)) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Align face using 5 key points\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image\n",
    "        landmarks : np.ndarray\n",
    "            68 facial landmarks\n",
    "        output_size : tuple\n",
    "            Output face size\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        aligned : np.ndarray\n",
    "            Aligned face\n",
    "        \"\"\"\n",
    "        # Extract 5 key points\n",
    "        left_eye = landmarks[42:48].mean(axis=0)\n",
    "        right_eye = landmarks[36:42].mean(axis=0)\n",
    "        nose = landmarks[30]\n",
    "        left_mouth = landmarks[48]\n",
    "        right_mouth = landmarks[54]\n",
    "        \n",
    "        src_points = np.array([left_eye, right_eye, nose, left_mouth, right_mouth], \n",
    "                             dtype=np.float32)\n",
    "        \n",
    "        # Define target 5 points (standard face template)\n",
    "        dst_points = np.array([\n",
    "            [0.35 * output_size[0], 0.35 * output_size[1]],  # Left eye\n",
    "            [0.65 * output_size[0], 0.35 * output_size[1]],  # Right eye\n",
    "            [0.50 * output_size[0], 0.55 * output_size[1]],  # Nose\n",
    "            [0.35 * output_size[0], 0.75 * output_size[1]],  # Left mouth\n",
    "            [0.65 * output_size[0], 0.75 * output_size[1]]   # Right mouth\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        # Compute transformation matrix (similarity transform)\n",
    "        M = cv2.estimateAffinePartial2D(src_points, dst_points)[0]\n",
    "        \n",
    "        # Apply transformation\n",
    "        aligned = cv2.warpAffine(image, M, output_size, flags=cv2.INTER_CUBIC)\n",
    "        \n",
    "        return aligned\n",
    "    \n",
    "    \n",
    "    # 執行對齊\n",
    "    aligned_2point = align_face_2point(img, landmarks, output_size=(256, 256))\n",
    "    aligned_5point = align_face_5point(img, landmarks, output_size=(256, 256))\n",
    "    \n",
    "    # 提取原始人臉區域（用於比較）\n",
    "    x, y, w, h = dlib_rect_to_bbox(faces_dlib[0])\n",
    "    face_crop = img[y:y+h, x:x+w]\n",
    "    face_crop_resized = cv2.resize(face_crop, (256, 256))\n",
    "    \n",
    "    # 顯示對比\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(cv2.cvtColor(face_crop_resized, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title('Original Face Crop', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cv2.cvtColor(aligned_2point, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title('2-Point Alignment (Eyes)', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(cv2.cvtColor(aligned_5point, cv2.COLOR_BGR2RGB))\n",
    "    axes[2].set_title('5-Point Alignment (Eyes, Nose, Mouth)', fontsize=12)\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nFace Alignment Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Original face size: {face_crop.shape[:2]}\")\n",
    "    print(f\"Aligned face size: {aligned_2point.shape[:2]}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nAlignment Benefits:\")\n",
    "    print(\"  ✓ Standardized face position\")\n",
    "    print(\"  ✓ Corrected rotation\")\n",
    "    print(\"  ✓ Consistent scale\")\n",
    "    print(\"  ✓ Improved recognition accuracy\")\n",
    "else:\n",
    "    print(\"Prerequisites not met for face alignment\")"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## 6. 人臉檢測方法比較"
=======
    "## 5. 人臉識別基礎 (15%)\n",
    "\n",
    "### 人臉識別 vs 人臉驗證\n",
    "\n",
    "| 任務 | 輸入 | 輸出 | 典型應用 |\n",
    "|-----|------|------|--------|\n",
    "| 人臉驗證 (1:1) | 兩張人臉 | 是否同一人 | 手機解鎖 |\n",
    "| 人臉識別 (1:N) | 一張人臉 + 數據庫 | 身份ID | 門禁系統 |\n",
    "\n",
    "### dlib 人臉識別流程\n",
    "\n",
    "1. **人臉檢測** - 定位人臉位置\n",
    "2. **特徵點檢測** - 找到 68 個關鍵點\n",
    "3. **人臉對齊** - 標準化姿態\n",
    "4. **特徵提取** - 生成 128 維人臉編碼 (Face Embedding)\n",
    "5. **相似度比較** - 計算歐氏距離\n",
    "\n",
    "### 人臉編碼 (Face Embedding)\n",
    "\n",
    "dlib 使用 **ResNet-34** 深度學習模型將人臉轉換為 **128 維向量**。\n",
    "\n",
    "- 同一人的不同照片：距離 < 0.6\n",
    "- 不同人的照片：距離 > 0.6\n",
    "\n",
    "### 模型要求\n",
    "\n",
    "需要下載 `dlib_face_recognition_resnet_model_v1.dat` 模型文件。"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def compare_face_detection_methods(image_path):\n",
    "    \"\"\"\n",
    "    比較不同人臉檢測方法的效能\n",
    "    \n",
    "    Args:\n",
    "        image_path: 測試圖像路徑\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"圖片不存在: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    image = load_image(image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # 調整圖片大小以確保公平比較\n",
    "    image_resized = resize_image(image, max_width=800)\n",
    "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    results = []\n",
    "    titles = []\n",
    "    detection_times = []\n",
    "    face_counts = []\n",
    "    \n",
    "    # 1. Haar Cascade檢測\n",
    "    try:\n",
    "        haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \n",
    "                                            'haarcascade_frontalface_default.xml')\n",
    "        \n",
    "        @time_function\n",
    "        def detect_haar():\n",
    "            return haar_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
    "        \n",
    "        faces_haar, time_haar = detect_haar()\n",
    "        \n",
    "        # 繪製結果\n",
    "        result_haar = image_resized.copy()\n",
    "        for (x, y, w, h) in faces_haar:\n",
    "            cv2.rectangle(result_haar, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        results.append(result_haar)\n",
    "        titles.append(f\"Haar Cascade\\n{len(faces_haar)} faces, {time_haar:.1f}ms\")\n",
    "        detection_times.append(time_haar)\n",
    "        face_counts.append(len(faces_haar))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Haar Cascade檢測失敗: {e}\")\n",
    "    \n",
    "    # 2. dlib HOG檢測\n",
    "    if DLIB_AVAILABLE:\n",
    "        faces_dlib, time_dlib = detect_faces_dlib_timed(image_resized)\n",
    "        \n",
    "        # 繪製結果\n",
    "        result_dlib = image_resized.copy()\n",
    "        for (x, y, w, h) in faces_dlib:\n",
    "            cv2.rectangle(result_dlib, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        results.append(result_dlib)\n",
    "        titles.append(f\"dlib HOG\\n{len(faces_dlib)} faces, {time_dlib:.1f}ms\")\n",
    "        detection_times.append(time_dlib)\n",
    "        face_counts.append(len(faces_dlib))\n",
    "    \n",
    "    # 3. OpenCV DNN檢測 (如果模型存在)\n",
    "    dnn_model_path = \"../assets/models/opencv_face_detector_uint8.pb\"\n",
    "    dnn_config_path = \"../assets/models/opencv_face_detector.pbtxt\"\n",
    "    \n",
    "    if os.path.exists(dnn_model_path) and os.path.exists(dnn_config_path):\n",
    "        try:\n",
    "            @time_function\n",
    "            def detect_dnn():\n",
    "                net = cv2.dnn.readNetFromTensorflow(dnn_model_path, dnn_config_path)\n",
    "                h, w = image_resized.shape[:2]\n",
    "                blob = cv2.dnn.blobFromImage(image_resized, 1.0, (300, 300), [104, 117, 123])\n",
    "                net.setInput(blob)\n",
    "                detections = net.forward()\n",
    "                \n",
    "                faces = []\n",
    "                for i in range(detections.shape[2]):\n",
    "                    confidence = detections[0, 0, i, 2]\n",
    "                    if confidence > 0.5:\n",
    "                        x1 = int(detections[0, 0, i, 3] * w)\n",
    "                        y1 = int(detections[0, 0, i, 4] * h)\n",
    "                        x2 = int(detections[0, 0, i, 5] * w)\n",
    "                        y2 = int(detections[0, 0, i, 6] * h)\n",
    "                        faces.append((x1, y1, x2-x1, y2-y1))\n",
    "                \n",
    "                return faces\n",
    "            \n",
    "            faces_dnn, time_dnn = detect_dnn()\n",
    "            \n",
    "            # 繪製結果\n",
    "            result_dnn = image_resized.copy()\n",
    "            for (x, y, w, h) in faces_dnn:\n",
    "                cv2.rectangle(result_dnn, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "            \n",
    "            results.append(result_dnn)\n",
    "            titles.append(f\"OpenCV DNN\\n{len(faces_dnn)} faces, {time_dnn:.1f}ms\")\n",
    "            detection_times.append(time_dnn)\n",
    "            face_counts.append(len(faces_dnn))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"OpenCV DNN檢測失敗: {e}\")\n",
    "    \n",
    "    # 顯示比較結果\n",
    "    if results:\n",
    "        all_images = [image_resized] + results\n",
    "        all_titles = [\"原始圖片\"] + titles\n",
    "        \n",
    "        display_multiple_images(all_images, all_titles, figsize=(15, 5))\n",
    "        \n",
    "        # 輸出性能統計\n",
    "        print(\"\\n📊 人臉檢測方法比較:\")\n",
    "        print(\"-\" * 50)\n",
    "        methods = [\"Haar Cascade\", \"dlib HOG\", \"OpenCV DNN\"][:len(detection_times)]\n",
    "        for i, method in enumerate(methods):\n",
    "            print(f\"{method:12}: {face_counts[i]:2d} faces, {detection_times[i]:6.1f}ms\")\n",
    "\n",
    "# 執行比較測試\n",
    "test_image_path = \"../assets/images/basic/faces01.jpg\"\n",
    "compare_face_detection_methods(test_image_path)"
=======
    "if DLIB_AVAILABLE:\n",
    "    # 載入人臉識別模型\n",
    "    face_rec_model_path = '../assets/models/dlib/dlib_face_recognition_resnet_model_v1.dat'\n",
    "    \n",
    "    if Path(face_rec_model_path).exists():\n",
    "        face_encoder = dlib.face_recognition_model_v1(face_rec_model_path)\n",
    "        print(f\"✅ Face recognition model loaded from {face_rec_model_path}\")\n",
    "        FACE_REC_AVAILABLE = True\n",
    "    else:\n",
    "        print(f\"❌ Face recognition model not found at {face_rec_model_path}\")\n",
    "        print(\"\\nDownload instructions:\")\n",
    "        print(\"1. Download from: http://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2\")\n",
    "        print(\"2. Extract the .dat file\")\n",
    "        print(\"3. Place in: ../assets/models/dlib/\")\n",
    "        print(\"\\nModel details:\")\n",
    "        print(\"  - Architecture: ResNet-34\")\n",
    "        print(\"  - Output: 128-dimensional face embedding\")\n",
    "        print(\"  - Training: 3 million faces\")\n",
    "        print(\"  - Accuracy: 99.38% on LFW benchmark\")\n",
    "        FACE_REC_AVAILABLE = False\n",
    "else:\n",
    "    FACE_REC_AVAILABLE = False\n",
    "    print(\"dlib not available\")"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## 7. 實作練習\n",
    "\n",
    "### 練習1: 批量人臉特徵提取"
=======
    "## 6. 人臉編碼與比對 (15%)\n",
    "\n",
    "### 生成人臉編碼\n",
    "\n",
    "將對齊後的人臉通過深度學習模型轉換為 128 維向量。"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def batch_face_feature_extraction(image_folder, output_folder):\n",
    "    \"\"\"\n",
    "    批量提取資料夾中所有圖片的人臉特徵\n",
    "    \n",
    "    練習目標:\n",
    "    1. 遍歷資料夾中的所有圖片\n",
    "    2. 檢測每張圖片中的人臉\n",
    "    3. 提取68點特徵並儲存結果\n",
    "    4. 生成對齊後的人臉圖片\n",
    "    \n",
    "    請完成以下功能:\n",
    "    - 檢查輸入/輸出資料夾是否存在\n",
    "    - 處理不同格式的圖片檔案\n",
    "    - 錯誤處理（沒有檢測到人臉的情況）\n",
    "    - 進度顯示\n",
    "    \"\"\"\n",
    "    # TODO: 實作批量人臉特徵提取\n",
    "    pass\n",
    "\n",
    "print(\"💡 練習1: 請實作批量人臉特徵提取功能\")\n",
    "print(\"提示: 使用os.listdir()遍歷檔案，用try-except處理錯誤\")"
=======
    "if DLIB_AVAILABLE and PREDICTOR_AVAILABLE and FACE_REC_AVAILABLE:\n",
    "    def get_face_encoding(image: np.ndarray,\n",
    "                          face_rect,\n",
    "                          predictor,\n",
    "                          face_encoder) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get 128-dimensional face encoding\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image : np.ndarray\n",
    "            Input image (BGR)\n",
    "        face_rect : dlib.rectangle\n",
    "            Face bounding box\n",
    "        predictor : dlib.shape_predictor\n",
    "            Landmark predictor\n",
    "        face_encoder : dlib.face_recognition_model_v1\n",
    "            Face encoding model\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        encoding : np.ndarray\n",
    "            128-dimensional face encoding\n",
    "        \"\"\"\n",
    "        # Convert to RGB\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get facial landmarks\n",
    "        shape = predictor(rgb, face_rect)\n",
    "        \n",
    "        # Compute face encoding\n",
    "        encoding = face_encoder.compute_face_descriptor(rgb, shape)\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        encoding = np.array(encoding)\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    \n",
    "    def face_distance(encoding1: np.ndarray, \n",
    "                     encoding2: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Compute Euclidean distance between two face encodings\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        encoding1, encoding2 : np.ndarray\n",
    "            Face encodings\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        distance : float\n",
    "            Euclidean distance\n",
    "        \"\"\"\n",
    "        return np.linalg.norm(encoding1 - encoding2)\n",
    "    \n",
    "    \n",
    "    def compare_faces(encoding1: np.ndarray,\n",
    "                     encoding2: np.ndarray,\n",
    "                     threshold: float = 0.6) -> Tuple[bool, float]:\n",
    "        \"\"\"\n",
    "        Compare two face encodings\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        encoding1, encoding2 : np.ndarray\n",
    "            Face encodings\n",
    "        threshold : float\n",
    "            Distance threshold (default: 0.6)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        is_match : bool\n",
    "            True if same person\n",
    "        distance : float\n",
    "            Face distance\n",
    "        \"\"\"\n",
    "        distance = face_distance(encoding1, encoding2)\n",
    "        is_match = distance < threshold\n",
    "        return is_match, distance\n",
    "    \n",
    "    \n",
    "    # 檢測第一張臉並生成編碼\n",
    "    if len(faces_dlib) > 0:\n",
    "        face = faces_dlib[0]\n",
    "        encoding = get_face_encoding(img, face, predictor, face_encoder)\n",
    "        \n",
    "        print(\"\\nFace Encoding Generated:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Encoding shape: {encoding.shape}\")\n",
    "        print(f\"Encoding type: {encoding.dtype}\")\n",
    "        print(f\"\\nFirst 10 dimensions: {encoding[:10]}\")\n",
    "        print(f\"Encoding norm (L2): {np.linalg.norm(encoding):.4f}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 如果有多張臉,比較前兩張\n",
    "        if len(faces_dlib) >= 2:\n",
    "            face2 = faces_dlib[1]\n",
    "            encoding2 = get_face_encoding(img, face2, predictor, face_encoder)\n",
    "            \n",
    "            is_match, distance = compare_faces(encoding, encoding2)\n",
    "            \n",
    "            print(\"\\nFace Comparison (Face 1 vs Face 2):\")\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"Distance: {distance:.4f}\")\n",
    "            print(f\"Threshold: 0.6\")\n",
    "            print(f\"Match: {is_match}\")\n",
    "            print(f\"Confidence: {(1 - distance / 1.0) * 100:.2f}%\")\n",
    "            print(\"=\" * 50)\n",
    "        else:\n",
    "            print(\"\\nNote: Only one face detected. Cannot perform comparison.\")\n",
    "            print(\"For face comparison demo, provide image with multiple faces.\")\n",
    "    else:\n",
    "        print(\"No faces detected for encoding\")\n",
    "else:\n",
    "    print(\"Prerequisites not met for face encoding\")"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "### 練習2: 人臉相似度計算"
=======
    "### 建立人臉數據庫\n",
    "\n",
    "實際人臉識別系統需要：\n",
    "\n",
    "1. **註冊階段** - 為每個人生成多張人臉編碼\n",
    "2. **存儲** - 保存編碼和身份信息\n",
    "3. **識別階段** - 將新人臉與數據庫比對"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def calculate_face_similarity(landmarks1, landmarks2):\n",
    "    \"\"\"\n",
    "    計算兩個人臉特徵點的相似度\n",
    "    \n",
    "    練習目標:\n",
    "    1. 正規化特徵點座標\n",
    "    2. 計算歐幾里得距離\n",
    "    3. 實現相似度評分\n",
    "    \n",
    "    提示:\n",
    "    - 使用特徵點之間的相對距離而非絕對座標\n",
    "    - 考慮使用普氏分析 (Procrustes Analysis)\n",
    "    - 回傳0-1之間的相似度分數\n",
    "    \"\"\"\n",
    "    # TODO: 實作人臉相似度計算\n",
    "    pass\n",
    "\n",
    "print(\"💡 練習2: 請實作人臉相似度計算功能\")\n",
    "print(\"提示: 可以使用numpy.linalg.norm計算距離\")"
=======
    "if DLIB_AVAILABLE and PREDICTOR_AVAILABLE and FACE_REC_AVAILABLE:\n",
    "    class FaceDatabase:\n",
    "        \"\"\"\n",
    "        Simple face recognition database\n",
    "        \"\"\"\n",
    "        def __init__(self):\n",
    "            self.encodings = []\n",
    "            self.names = []\n",
    "        \n",
    "        def add_face(self, encoding: np.ndarray, name: str):\n",
    "            \"\"\"\n",
    "            Add a face to the database\n",
    "            \n",
    "            Parameters:\n",
    "            -----------\n",
    "            encoding : np.ndarray\n",
    "                Face encoding\n",
    "            name : str\n",
    "                Person's name\n",
    "            \"\"\"\n",
    "            self.encodings.append(encoding)\n",
    "            self.names.append(name)\n",
    "        \n",
    "        def recognize_face(self, encoding: np.ndarray, \n",
    "                          threshold: float = 0.6) -> Tuple[str, float]:\n",
    "            \"\"\"\n",
    "            Recognize a face by comparing with database\n",
    "            \n",
    "            Parameters:\n",
    "            -----------\n",
    "            encoding : np.ndarray\n",
    "                Face encoding to recognize\n",
    "            threshold : float\n",
    "                Distance threshold\n",
    "                \n",
    "            Returns:\n",
    "            --------\n",
    "            name : str\n",
    "                Recognized name or \"Unknown\"\n",
    "            distance : float\n",
    "                Distance to closest match\n",
    "            \"\"\"\n",
    "            if len(self.encodings) == 0:\n",
    "                return \"Unknown\", float('inf')\n",
    "            \n",
    "            # Compute distances to all faces\n",
    "            distances = [face_distance(encoding, known_enc) \n",
    "                        for known_enc in self.encodings]\n",
    "            \n",
    "            # Find closest match\n",
    "            min_distance_idx = np.argmin(distances)\n",
    "            min_distance = distances[min_distance_idx]\n",
    "            \n",
    "            # Check if match is good enough\n",
    "            if min_distance < threshold:\n",
    "                return self.names[min_distance_idx], min_distance\n",
    "            else:\n",
    "                return \"Unknown\", min_distance\n",
    "        \n",
    "        def save(self, filepath: str):\n",
    "            \"\"\"\n",
    "            Save database to file\n",
    "            \"\"\"\n",
    "            data = {\n",
    "                'encodings': self.encodings,\n",
    "                'names': self.names\n",
    "            }\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "        \n",
    "        def load(self, filepath: str):\n",
    "            \"\"\"\n",
    "            Load database from file\n",
    "            \"\"\"\n",
    "            with open(filepath, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            self.encodings = data['encodings']\n",
    "            self.names = data['names']\n",
    "    \n",
    "    \n",
    "    # 創建示範數據庫\n",
    "    print(\"\\nFace Database System:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    db = FaceDatabase()\n",
    "    \n",
    "    # 添加檢測到的人臉\n",
    "    for i, face in enumerate(faces_dlib):\n",
    "        enc = get_face_encoding(img, face, predictor, face_encoder)\n",
    "        db.add_face(enc, f\"Person_{i+1}\")\n",
    "        print(f\"✓ Added Person_{i+1} to database\")\n",
    "    \n",
    "    print(f\"\\nDatabase size: {len(db.encodings)} faces\")\n",
    "    print(f\"Registered names: {', '.join(db.names)}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 測試識別\n",
    "    if len(faces_dlib) > 0:\n",
    "        test_enc = get_face_encoding(img, faces_dlib[0], predictor, face_encoder)\n",
    "        recognized_name, distance = db.recognize_face(test_enc)\n",
    "        \n",
    "        print(f\"\\nRecognition Test:\")\n",
    "        print(f\"Recognized as: {recognized_name}\")\n",
    "        print(f\"Distance: {distance:.4f}\")\n",
    "        print(f\"Confidence: {(1 - distance) * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"Prerequisites not met for face database demo\")"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## 8. 總結與延伸應用\n",
    "\n",
    "### 本模組重點回顧\n",
    "\n",
    "1. **dlib人臉檢測**: HOG + SVM方法，高精度但速度較慢\n",
    "2. **68點特徵檢測**: 精確的面部特徵定位，支援人臉分析\n",
    "3. **人臉對齊**: 基於眼部特徵的幾何校正\n",
    "4. **方法比較**: Haar vs dlib vs DNN的效能分析\n",
    "\n",
    "### 實際應用場景\n",
    "- 人臉識別系統\n",
    "- 表情分析\n",
    "- 美顏相機濾鏡\n",
    "- 人臉動畫驅動\n",
    "- 生物特徵認證\n",
    "\n",
    "### 下一步學習\n",
    "- 5.2.1 深度學習物體檢測 (YOLO, SSD)\n",
    "- 5.2.2 實時檢測優化\n",
    "- 人臉識別與驗證算法\n",
    "- 實戰專案：智能監控系統"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 效能基準測試"
=======
    "## 7. 實時人臉識別系統 (10%)\n",
    "\n",
    "### 實時識別流程\n",
    "\n",
    "1. 從攝像頭讀取視訊幀\n",
    "2. 檢測人臉\n",
    "3. 提取人臉編碼\n",
    "4. 與數據庫比對\n",
    "5. 顯示識別結果\n",
    "\n",
    "### 性能優化\n",
    "\n",
    "- 降低處理幀率（隔幀處理）\n",
    "- 縮小圖像分辨率\n",
    "- 使用多線程\n",
    "- GPU 加速（需要 CUDA 編譯的 dlib）"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# 最終效能測試\n",
    "def run_performance_benchmark():\n",
    "    \"\"\"執行完整的效能基準測試\"\"\"\n",
    "    \n",
    "    test_cases = [\n",
    "        \"../assets/images/basic/face03.jpg\",\n",
    "        \"../assets/images/basic/faces01.jpg\",\n",
    "        \"../assets/images/basic/faces.png\"\n",
    "    ]\n",
    "    \n",
    "    print(\"🔄 執行dlib效能基準測試...\\n\")\n",
    "    \n",
    "    for i, image_path in enumerate(test_cases, 1):\n",
    "        if os.path.exists(image_path):\n",
    "            print(f\"測試{i}: {os.path.basename(image_path)}\")\n",
    "            image = load_image(image_path)\n",
    "            if image is not None:\n",
    "                image_resized = resize_image(image, max_width=600)\n",
    "                \n",
    "                # 檢測並計時\n",
    "                faces, detection_time = detect_faces_dlib_timed(image_resized)\n",
    "                print(f\"  - 檢測時間: {detection_time:.1f}ms\")\n",
    "                print(f\"  - 人臉數量: {len(faces)}\")\n",
    "                \n",
    "                # 特徵點檢測\n",
    "                if len(faces) > 0:\n",
    "                    landmarks = detect_facial_landmarks(image_resized, faces[0])\n",
    "                    if len(landmarks) > 0:\n",
    "                        print(f\"  - 特徵點: ✅ 68點檢測成功\")\n",
    "                    else:\n",
    "                        print(f\"  - 特徵點: ❌ 檢測失敗\")\n",
    "                print()\n",
    "    \n",
    "    print(\"✅ dlib整合模組測試完成\")\n",
    "\n",
    "# 執行基準測試\n",
    "run_performance_benchmark()"
=======
    "if DLIB_AVAILABLE and PREDICTOR_AVAILABLE and FACE_REC_AVAILABLE:\n",
    "    def realtime_face_recognition_demo():\n",
    "        \"\"\"\n",
    "        Real-time face recognition demo (code template)\n",
    "        \n",
    "        Note: This is a code template. Run as standalone script for actual demo.\n",
    "        \"\"\"\n",
    "        print(\"Real-Time Face Recognition System\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"This function demonstrates real-time face recognition.\")\n",
    "        print(\"\\nTo run actual system:\")\n",
    "        print(\"1. Save code below to face_recognition_realtime.py\")\n",
    "        print(\"2. Run: python face_recognition_realtime.py\")\n",
    "        print(\"3. Press 'q' to quit, 'r' to register new face\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        demo_code = '''import cv2\nimport dlib\nimport numpy as np\nimport time\nfrom pathlib import Path\n\n# Initialize dlib\ndetector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\nface_encoder = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n\n# Initialize face database\nclass FaceDatabase:\n    def __init__(self):\n        self.encodings = []\n        self.names = []\n    \n    def add_face(self, encoding, name):\n        self.encodings.append(encoding)\n        self.names.append(name)\n    \n    def recognize_face(self, encoding, threshold=0.6):\n        if len(self.encodings) == 0:\n            return \"Unknown\", float('inf')\n        \n        distances = [np.linalg.norm(encoding - known_enc) \n                    for known_enc in self.encodings]\n        \n        min_idx = np.argmin(distances)\n        min_dist = distances[min_idx]\n        \n        if min_dist < threshold:\n            return self.names[min_idx], min_dist\n        else:\n            return \"Unknown\", min_dist\n\ndb = FaceDatabase()\n\n# Open webcam\ncap = cv2.VideoCapture(0)\ncap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\ncap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n\nframe_count = 0\nprocess_every_n_frames = 5  # Process every 5 frames for performance\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    frame_count += 1\n    \n    # Resize for faster detection\n    small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n    rgb_small = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n    \n    # Detect and recognize faces (every N frames)\n    if frame_count % process_every_n_frames == 0:\n        faces = detector(rgb_small, 0)\n        \n        for face in faces:\n            # Scale back to original size\n            x, y, w, h = face.left()*2, face.top()*2, face.width()*2, face.height()*2\n            \n            # Get encoding\n            shape = predictor(rgb_small, face)\n            encoding = np.array(face_encoder.compute_face_descriptor(rgb_small, shape))\n            \n            # Recognize\n            name, distance = db.recognize_face(encoding)\n            \n            # Draw results\n            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n            \n            label = f\"{name} ({distance:.2f})\"\n            cv2.putText(frame, label, (x, y-10),\n                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n    \n    # Display FPS\n    cv2.putText(frame, f\"Faces: {len(db.encodings)}\", (10, 30),\n               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n    \n    # Show frame\n    cv2.imshow('Face Recognition', frame)\n    \n    # Handle key press\n    key = cv2.waitKey(1) & 0xFF\n    if key == ord('q'):\n        break\n    elif key == ord('r'):\n        # Register new face\n        if len(faces) > 0:\n            name = input(\"Enter name: \")\n            face = faces[0]\n            shape = predictor(rgb_small, face)\n            encoding = np.array(face_encoder.compute_face_descriptor(rgb_small, shape))\n            db.add_face(encoding, name)\n            print(f\"Registered {name}\")\n\ncap.release()\ncv2.destroyAllWindows()\n        '''\n",
    "        \n",
    "        print(\"\\nExample Code:\")\n",
    "        print(demo_code)\n",
    "    \n",
    "    # 顯示 demo\n",
    "    realtime_face_recognition_demo()\n",
    "else:\n",
    "    print(\"Prerequisites not met for real-time demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 與 OpenCV 整合 (5%)\n",
    "\n",
    "### 整合優勢\n",
    "\n",
    "**dlib** 和 **OpenCV** 各有優勢，結合使用可以發揮最大效用：\n",
    "\n",
    "| 功能 | 推薦庫 | 原因 |\n",
    "|-----|--------|------|\n",
    "| 圖像讀寫 | OpenCV | 更快、支持更多格式 |\n",
    "| 圖像預處理 | OpenCV | 豐富的濾波、變換函數 |\n",
    "| 人臉檢測（速度優先） | OpenCV | Haar/LBP 更快 |\n",
    "| 人臉檢測（準確度優先） | dlib | HOG 更準確 |\n",
    "| 面部特徵點 | dlib | 內建68點模型 |\n",
    "| 人臉識別 | dlib | 內建 ResNet 模型 |\n",
    "| 視訊處理 | OpenCV | 更好的視訊 API |\n",
    "| 繪圖標註 | OpenCV | 更豐富的繪圖函數 |\n",
    "\n",
    "### 最佳實踐\n",
    "\n",
    "```python\n",
    "# 使用 OpenCV 讀取和預處理\n",
    "img = cv2.imread('face.jpg')\n",
    "img = cv2.resize(img, (640, 480))\n",
    "\n",
    "# 使用 dlib 檢測和識別\n",
    "faces = dlib_detector(img, 1)\n",
    "for face in faces:\n",
    "    landmarks = predictor(img, face)\n",
    "    encoding = face_encoder.compute_face_descriptor(img, landmarks)\n",
    "\n",
    "# 使用 OpenCV 顯示結果\n",
    "cv2.rectangle(img, ...)\n",
    "cv2.imshow('Result', img)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 實戰練習 (5%)\n",
    "\n",
    "### 練習 1: 疲勞駕駛檢測\n",
    "\n",
    "實作基於 EAR (Eye Aspect Ratio) 的疲勞檢測：\n",
    "- 持續監測 EAR 值\n",
    "- 如果 EAR < 0.2 持續 3 秒以上，發出警報\n",
    "- 統計眨眼次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實作疲勞駕駛檢測\n",
    "# 提示：\n",
    "# 1. 計算連續幀的 EAR\n",
    "# 2. 維護一個時間窗口\n",
    "# 3. 檢測閉眼時間\n",
    "# 4. 觸發警報\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 2: 人臉相似度矩陣\n",
    "\n",
    "給定多張人臉圖像，計算兩兩相似度：\n",
    "- 檢測所有人臉\n",
    "- 生成編碼\n",
    "- 計算距離矩陣\n",
    "- 可視化熱力圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實作人臉相似度矩陣\n",
    "# 提示：\n",
    "# 1. 批量處理多張圖像\n",
    "# 2. 計算所有編碼對的距離\n",
    "# 3. 構建距離矩陣\n",
    "# 4. 使用 seaborn 繪製熱力圖\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 3: AR 濾鏡應用\n",
    "\n",
    "使用面部特徵點實作簡單 AR 特效：\n",
    "- 在眼睛位置添加眼鏡\n",
    "- 在嘴巴位置添加鬍子\n",
    "- 根據頭部姿態調整貼圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 實作 AR 濾鏡\n",
    "# 提示：\n",
    "# 1. 載入貼圖素材（眼鏡、鬍子 PNG）\n",
    "# 2. 根據特徵點計算位置和大小\n",
    "# 3. 使用 Alpha 通道合成\n",
    "# 4. 處理旋轉和縮放\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 總結與延伸 (5%)\n",
    "\n",
    "### 關鍵要點\n",
    "\n",
    "1. **dlib 核心優勢**\n",
    "   - HOG 人臉檢測：準確度高\n",
    "   - 68 點面部特徵檢測：精確定位\n",
    "   - ResNet 人臉編碼：128 維向量\n",
    "   - 易於使用：Python API 簡潔\n",
    "\n",
    "2. **面部特徵點應用**\n",
    "   - 人臉對齊：提高識別準確度\n",
    "   - 表情分析：EAR, MAR 計算\n",
    "   - AR 特效：貼紙、濾鏡\n",
    "   - 頭部姿態：注視方向\n",
    "\n",
    "3. **人臉識別流程**\n",
    "   - 檢測 → 特徵點 → 對齊 → 編碼 → 比對\n",
    "   - 相似度閾值：0.6 (典型值)\n",
    "   - 數據庫管理：註冊、識別、更新\n",
    "\n",
    "4. **性能優化**\n",
    "   - 圖像縮放：加速檢測\n",
    "   - 隔幀處理：降低計算量\n",
    "   - GPU 加速：CUDA 版本\n",
    "   - 多線程：並行處理\n",
    "\n",
    "5. **實用技巧**\n",
    "   - 結合 OpenCV：發揮各自優勢\n",
    "   - 模型管理：正確路徑配置\n",
    "   - 錯誤處理：檢測失敗的情況\n",
    "   - 數據持久化：保存人臉數據庫\n",
    "\n",
    "### 性能基準\n",
    "\n",
    "在標準配置（Intel i5, 640x480 圖像）：\n",
    "\n",
    "| 操作 | 時間 (CPU) | 備註 |\n",
    "|-----|-----------|------|\n",
    "| HOG 人臉檢測 | 50-150ms | upsample=1 |\n",
    "| 68點檢測 | 10-30ms | 每張臉 |\n",
    "| 人臉編碼 | 30-60ms | ResNet forward |\n",
    "| 人臉比對 | <1ms | 歐氏距離計算 |\n",
    "| 完整識別流程 | 100-250ms | 檢測+編碼+比對 |\n",
    "\n",
    "### 延伸學習\n",
    "\n",
    "1. **進階 dlib 功能**\n",
    "   - CNN 人臉檢測器（更準確）\n",
    "   - 194 點面部特徵（更精細）\n",
    "   - 物體追蹤（correlation tracker）\n",
    "   - 自定義模型訓練\n",
    "\n",
    "2. **深度學習人臉識別**\n",
    "   - FaceNet（Google）\n",
    "   - ArcFace（InsightFace）\n",
    "   - SphereFace\n",
    "   - VGGFace\n",
    "\n",
    "3. **3D 人臉分析**\n",
    "   - 3D 人臉重建\n",
    "   - 深度估計\n",
    "   - 姿態估計（Pitch, Yaw, Roll）\n",
    "\n",
    "4. **人臉屬性分析**\n",
    "   - 年齡估計\n",
    "   - 性別識別\n",
    "   - 表情識別（7種基本表情）\n",
    "   - 種族預測\n",
    "\n",
    "5. **實際應用場景**\n",
    "   - 考勤系統\n",
    "   - 門禁控制\n",
    "   - 疲勞駕駛檢測\n",
    "   - 視訊會議人臉追蹤\n",
    "   - 社交媒體濾鏡\n",
    "\n",
    "### 參考資源\n",
    "\n",
    "- dlib 官方網站: http://dlib.net/\n",
    "- dlib GitHub: https://github.com/davisking/dlib\n",
    "- Face Recognition Library: https://github.com/ageitgey/face_recognition\n",
    "- LFW Benchmark: http://vis-www.cs.umass.edu/lfw/\n",
    "- dlib 模型下載: http://dlib.net/files/\n",
    "\n",
    "### 常見問題\n",
    "\n",
    "**Q1: dlib 安裝失敗？**\n",
    "\n",
    "A: dlib 需要 C++ 編譯器和 CMake：\n",
    "```bash\n",
    "# Ubuntu/Debian\n",
    "sudo apt-get install build-essential cmake\n",
    "\n",
    "# macOS\n",
    "brew install cmake\n",
    "\n",
    "# Windows\n",
    "# 安裝 Visual Studio Build Tools\n",
    "# 或使用預編譯包\n",
    "pip install dlib-binary\n",
    "```\n",
    "\n",
    "**Q2: 模型文件太大？**\n",
    "\n",
    "A: 可以使用較小的模型：\n",
    "- 5點檢測器（<1MB）代替 68點（100MB）\n",
    "- CNN 檢測器選用 quantized 版本\n",
    "\n",
    "**Q3: 檢測速度太慢？**\n",
    "\n",
    "A: 優化策略：\n",
    "- 降低 upsample_num (0 最快)\n",
    "- 縮小輸入圖像\n",
    "- 使用 OpenCV Haar 初步過濾\n",
    "- 編譯 CUDA 版本 dlib\n",
    "\n",
    "**Q4: 側臉檢測效果差？**\n",
    "\n",
    "A: dlib HOG 檢測器主要針對正臉：\n",
    "- 使用 CNN 檢測器（更魯棒）\n",
    "- 或使用 MTCNN、RetinaFace\n",
    "\n",
    "---\n",
    "\n",
    "## 下一步\n",
    "\n",
    "完成本模組後，建議繼續學習：\n",
    "- **5.2.1 深度學習物體檢測** - YOLO、SSD、Faster R-CNN\n",
    "- **5.2.2 實時檢測系統** - 優化實時性能\n",
    "- **7.1 智能門禁系統** - 實戰項目\n",
    "\n",
    "---\n",
    "\n",
    "**模組完成標記**: ✅ WBS 5.1.3 dlib Integration Complete"
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
<<<<<<< HEAD
}
=======
}
>>>>>>> 276946a5fc26de299734b6d6b2af372c2813694f
