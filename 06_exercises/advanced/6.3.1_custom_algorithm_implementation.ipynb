{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3.1 è‡ªå®šç¾©ç®—æ³•å¯¦ä½œæŒ‘æˆ° - é«˜ç´šç·´ç¿’\n",
    "\n",
    "æœ¬ç·´ç¿’æŒ‘æˆ°ä½ å¾é›¶é–‹å§‹å¯¦ç¾ç¶“å…¸çš„é›»è…¦è¦–è¦ºç®—æ³•ï¼Œæ·±å…¥ç†è§£ç®—æ³•åŸç†ä¸¦æŒæ¡å„ªåŒ–æŠ€å·§ã€‚\n",
    "\n",
    "## ç·´ç¿’ç›®æ¨™\n",
    "- å¾ç†è«–åˆ°å¯¦ä½œï¼šæ·±å…¥ç†è§£ç®—æ³•æ•¸å­¸åŸºç¤\n",
    "- æ€§èƒ½å„ªåŒ–ï¼šå¯¦ç¾æ¥è¿‘OpenCVå®˜æ–¹å¯¦ç¾çš„æ•ˆèƒ½\n",
    "- ä»£ç¢¼å“è³ªï¼šæ’°å¯«å¯ç¶­è­·ã€å¯æ“´å±•çš„é«˜è³ªé‡ä»£ç¢¼\n",
    "- æ¸¬è©¦é©—è­‰ï¼šå»ºç«‹å®Œæ•´çš„æ¸¬è©¦å’Œé©—è­‰æµç¨‹\n",
    "- å‰µæ–°æ‡‰ç”¨ï¼šåœ¨ç¶“å…¸ç®—æ³•åŸºç¤ä¸Šé€²è¡Œå‰µæ–°æ”¹é€²\n",
    "\n",
    "## é›£åº¦ç­‰ç´š: â­â­â­â­â­ (å°ˆå®¶ç´š)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç’°å¢ƒè¨­ç½®èˆ‡å°å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from typing import List, Tuple, Optional, Union\n",
    "from numba import jit, prange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# æ·»åŠ utilsè·¯å¾‘\n",
    "sys.path.append('../../utils')\n",
    "from image_utils import load_image, resize_image\n",
    "from visualization import display_image, display_multiple_images\n",
    "from performance import time_function, benchmark_function\n",
    "\n",
    "# è¨­ç½®matplotlib\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ç’°å¢ƒè¨­ç½®å®Œæˆ\")\n",
    "print(f\"OpenCVç‰ˆæœ¬: {cv2.__version__}\")\n",
    "print(f\"NumPyç‰ˆæœ¬: {np.__version__}\")\n",
    "try:\n",
    "    import numba\n",
    "    print(f\"Numbaç‰ˆæœ¬: {numba.__version__} (åŠ é€Ÿè¨ˆç®—å¯ç”¨)\")\nexcept:\n    print(\"âš ï¸ Numbaæœªå®‰è£ï¼ŒæŸäº›å„ªåŒ–åŠŸèƒ½ä¸å¯ç”¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°1: è‡ªå®šç¾©Cannyé‚Šç·£æª¢æ¸¬ç®—æ³•\n",
    "\n",
    "### ä»»å‹™æè¿°\n",
    "å¾é›¶å¯¦ç¾å®Œæ•´çš„Cannyé‚Šç·£æª¢æ¸¬ç®—æ³•ï¼ŒåŒ…æ‹¬é«˜æ–¯æ¿¾æ³¢ã€æ¢¯åº¦è¨ˆç®—ã€éæ¥µå¤§å€¼æŠ‘åˆ¶ã€é›™é–¾å€¼è™•ç†å’Œé‚Šç·£é€£æ¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCannyDetector:\n",
    "    \"\"\"\n",
    "    è‡ªå®šç¾©Cannyé‚Šç·£æª¢æ¸¬å™¨å¯¦ç¾\n",
    "    \n",
    "    å¯¦ç¾æ­¥é©Ÿï¼š\n",
    "    1. é«˜æ–¯æ¨¡ç³Šå»å™ª\n",
    "    2. è¨ˆç®—åœ–åƒæ¢¯åº¦\n",
    "    3. éæ¥µå¤§å€¼æŠ‘åˆ¶\n",
    "    4. é›™é–¾å€¼è™•ç†\n",
    "    5. é‚Šç·£é€£æ¥\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gaussian_kernel_size=5, gaussian_sigma=1.4):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–Cannyæª¢æ¸¬å™¨\n",
    "        \n",
    "        Args:\n",
    "            gaussian_kernel_size: é«˜æ–¯æ ¸å¤§å°\n",
    "            gaussian_sigma: é«˜æ–¯æ¨™æº–å·®\n",
    "        \"\"\"\n",
    "        self.kernel_size = gaussian_kernel_size\n",
    "        self.sigma = gaussian_sigma\n",
    "        self.gaussian_kernel = self._create_gaussian_kernel(gaussian_kernel_size, gaussian_sigma)\n",
    "        \n",
    "        # Sobelç®—å­\n",
    "        self.sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "        self.sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32)\n",
    "    \n",
    "    def _create_gaussian_kernel(self, size, sigma):\n",
    "        \"\"\"\n",
    "        å‰µå»ºé«˜æ–¯å·ç©æ ¸\n",
    "        \n",
    "        Args:\n",
    "            size: æ ¸å¤§å°\n",
    "            sigma: æ¨™æº–å·®\n",
    "        \n",
    "        Returns:\n",
    "            np.array: é«˜æ–¯æ ¸\n",
    "        \"\"\"\n",
    "        kernel = np.zeros((size, size))\n",
    "        center = size // 2\n",
    "        \n",
    "        # è¨ˆç®—é«˜æ–¯æ¬Šé‡\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                x, y = i - center, j - center\n",
    "                kernel[i, j] = np.exp(-(x*x + y*y) / (2 * sigma * sigma))\n",
    "        \n",
    "        # æ­£è¦åŒ–\n",
    "        kernel = kernel / np.sum(kernel)\n",
    "        return kernel\n",
    "    \n",
    "    @jit(nopython=True)\n",
    "    def _apply_convolution(self, image, kernel):\n",
    "        \"\"\"\n",
    "        æ‡‰ç”¨å·ç©æ“ä½œï¼ˆNumbaåŠ é€Ÿï¼‰\n",
    "        \n",
    "        Args:\n",
    "            image: è¼¸å…¥åœ–åƒ\n",
    "            kernel: å·ç©æ ¸\n",
    "        \n",
    "        Returns:\n",
    "            np.array: å·ç©çµæœ\n",
    "        \"\"\"\n",
    "        h, w = image.shape\n",
    "        kh, kw = kernel.shape\n",
    "        pad_h, pad_w = kh // 2, kw // 2\n",
    "        \n",
    "        result = np.zeros((h, w), dtype=np.float32)\n",
    "        \n",
    "        for i in range(pad_h, h - pad_h):\n",
    "            for j in range(pad_w, w - pad_w):\n",
    "                conv_sum = 0.0\n",
    "                for ki in range(kh):\n",
    "                    for kj in range(kw):\n",
    "                        conv_sum += image[i - pad_h + ki, j - pad_w + kj] * kernel[ki, kj]\n",
    "                result[i, j] = conv_sum\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _gaussian_blur(self, image):\n",
    "        \"\"\"\n",
    "        æ‡‰ç”¨é«˜æ–¯æ¨¡ç³Š\n",
    "        \n",
    "        Args:\n",
    "            image: è¼¸å…¥åœ–åƒ\n",
    "        \n",
    "        Returns:\n",
    "            np.array: æ¨¡ç³Šå¾Œçš„åœ–åƒ\n",
    "        \"\"\"\n",
    "        return self._apply_convolution(image.astype(np.float32), self.gaussian_kernel)\n",
    "    \n",
    "    def _compute_gradients(self, image):\n",
    "        \"\"\"\n",
    "        è¨ˆç®—åœ–åƒæ¢¯åº¦\n",
    "        \n",
    "        Args:\n",
    "            image: è¼¸å…¥åœ–åƒ\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (æ¢¯åº¦å¹…å€¼, æ¢¯åº¦æ–¹å‘)\n",
    "        \"\"\"\n",
    "        # è¨ˆç®—xå’Œyæ–¹å‘çš„æ¢¯åº¦\n",
    "        grad_x = self._apply_convolution(image, self.sobel_x)\n",
    "        grad_y = self._apply_convolution(image, self.sobel_y)\n",
    "        \n",
    "        # è¨ˆç®—æ¢¯åº¦å¹…å€¼å’Œæ–¹å‘\n",
    "        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        gradient_direction = np.arctan2(grad_y, grad_x)\n",
    "        \n",
    "        return gradient_magnitude, gradient_direction\n",
    "    \n",
    "    @jit(nopython=True)\n",
    "    def _non_maximum_suppression(self, magnitude, direction):\n",
    "        \"\"\"\n",
    "        éæ¥µå¤§å€¼æŠ‘åˆ¶ï¼ˆNumbaåŠ é€Ÿï¼‰\n",
    "        \n",
    "        Args:\n",
    "            magnitude: æ¢¯åº¦å¹…å€¼\n",
    "            direction: æ¢¯åº¦æ–¹å‘\n",
    "        \n",
    "        Returns:\n",
    "            np.array: æŠ‘åˆ¶å¾Œçš„é‚Šç·£åœ–åƒ\n",
    "        \"\"\"\n",
    "        h, w = magnitude.shape\n",
    "        suppressed = np.zeros((h, w), dtype=np.float32)\n",
    "        \n",
    "        for i in range(1, h - 1):\n",
    "            for j in range(1, w - 1):\n",
    "                angle = direction[i, j]\n",
    "                \n",
    "                # å°‡è§’åº¦è½‰æ›åˆ°0-180åº¦\n",
    "                angle = angle * 180.0 / np.pi\n",
    "                if angle < 0:\n",
    "                    angle += 180\n",
    "                \n",
    "                # æ ¹æ“šæ¢¯åº¦æ–¹å‘ç¢ºå®šç›¸é„°åƒç´ \n",
    "                if (0 <= angle < 22.5) or (157.5 <= angle <= 180):\n",
    "                    # æ°´å¹³æ–¹å‘\n",
    "                    neighbor1 = magnitude[i, j-1]\n",
    "                    neighbor2 = magnitude[i, j+1]\n",
    "                elif 22.5 <= angle < 67.5:\n",
    "                    # 45åº¦æ–¹å‘\n",
    "                    neighbor1 = magnitude[i-1, j+1]\n",
    "                    neighbor2 = magnitude[i+1, j-1]\n",
    "                elif 67.5 <= angle < 112.5:\n",
    "                    # å‚ç›´æ–¹å‘\n",
    "                    neighbor1 = magnitude[i-1, j]\n",
    "                    neighbor2 = magnitude[i+1, j]\n",
    "                else:  # 112.5 <= angle < 157.5\n",
    "                    # 135åº¦æ–¹å‘\n",
    "                    neighbor1 = magnitude[i-1, j-1]\n",
    "                    neighbor2 = magnitude[i+1, j+1]\n",
    "                \n",
    "                # éæ¥µå¤§å€¼æŠ‘åˆ¶\n",
    "                if magnitude[i, j] >= neighbor1 and magnitude[i, j] >= neighbor2:\n",
    "                    suppressed[i, j] = magnitude[i, j]\n",
    "        \n",
    "        return suppressed\n",
    "    \n",
    "    def _double_threshold(self, image, low_threshold, high_threshold):\n",
    "        \"\"\"\n",
    "        é›™é–¾å€¼è™•ç†\n",
    "        \n",
    "        Args:\n",
    "            image: éæ¥µå¤§å€¼æŠ‘åˆ¶å¾Œçš„åœ–åƒ\n",
    "            low_threshold: ä½é–¾å€¼\n",
    "            high_threshold: é«˜é–¾å€¼\n",
    "        \n",
    "        Returns:\n",
    "            np.array: åˆ†é¡å¾Œçš„é‚Šç·£åœ–åƒ\n",
    "        \"\"\"\n",
    "        # å‰µå»ºä¸‰ç¨®åƒç´ é¡å‹ï¼šå¼·é‚Šç·£ã€å¼±é‚Šç·£ã€éé‚Šç·£\n",
    "        strong_edges = 255\n",
    "        weak_edges = 75\n",
    "        \n",
    "        result = np.zeros_like(image, dtype=np.uint8)\n",
    "        \n",
    "        # å¼·é‚Šç·£\n",
    "        strong_mask = image >= high_threshold\n",
    "        result[strong_mask] = strong_edges\n",
    "        \n",
    "        # å¼±é‚Šç·£\n",
    "        weak_mask = (image >= low_threshold) & (image < high_threshold)\n",
    "        result[weak_mask] = weak_edges\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @jit(nopython=True)\n",
    "    def _edge_tracking_by_hysteresis(self, image):\n",
    "        \"\"\"\n",
    "        é€šéæ»¯å¾Œé–¾å€¼é€²è¡Œé‚Šç·£é€£æ¥ï¼ˆNumbaåŠ é€Ÿï¼‰\n",
    "        \n",
    "        Args:\n",
    "            image: é›™é–¾å€¼è™•ç†å¾Œçš„åœ–åƒ\n",
    "        \n",
    "        Returns:\n",
    "            np.array: æœ€çµ‚çš„é‚Šç·£åœ–åƒ\n",
    "        \"\"\"\n",
    "        h, w = image.shape\n",
    "        result = image.copy()\n",
    "        \n",
    "        # å¤šæ¬¡è¿­ä»£ä»¥ç¢ºä¿æ‰€æœ‰é€£æ¥çš„å¼±é‚Šç·£éƒ½è¢«ä¿ç•™\n",
    "        for _ in range(10):  # é™åˆ¶è¿­ä»£æ¬¡æ•¸é¿å…ç„¡é™å¾ªç’°\n",
    "            changed = False\n",
    "            \n",
    "            for i in range(1, h - 1):\n",
    "                for j in range(1, w - 1):\n",
    "                    if result[i, j] == 75:  # å¼±é‚Šç·£\n",
    "                        # æª¢æŸ¥8é„°åŸŸæ˜¯å¦æœ‰å¼·é‚Šç·£\n",
    "                        has_strong_neighbor = False\n",
    "                        for di in range(-1, 2):\n",
    "                            for dj in range(-1, 2):\n",
    "                                if di == 0 and dj == 0:\n",
    "                                    continue\n",
    "                                if result[i + di, j + dj] == 255:\n",
    "                                    has_strong_neighbor = True\n",
    "                                    break\n",
    "                            if has_strong_neighbor:\n",
    "                                break\n",
    "                        \n",
    "                        if has_strong_neighbor:\n",
    "                            result[i, j] = 255  # æå‡ç‚ºå¼·é‚Šç·£\n",
    "                            changed = True\n",
    "            \n",
    "            if not changed:\n",
    "                break\n",
    "        \n",
    "        # ç§»é™¤å‰©é¤˜çš„å¼±é‚Šç·£\n",
    "        result[result == 75] = 0\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def detect_edges(self, image, low_threshold=50, high_threshold=150):\n",
    "        \"\"\"\n",
    "        åŸ·è¡Œå®Œæ•´çš„Cannyé‚Šç·£æª¢æ¸¬\n",
    "        \n",
    "        Args:\n",
    "            image: è¼¸å…¥åœ–åƒ\n",
    "            low_threshold: ä½é–¾å€¼\n",
    "            high_threshold: é«˜é–¾å€¼\n",
    "        \n",
    "        Returns:\n",
    "            dict: åŒ…å«æ‰€æœ‰ä¸­é–“çµæœçš„å­—å…¸\n",
    "        \"\"\"\n",
    "        # è½‰æ›ç‚ºç°éš\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        print(\"ğŸ”„ åŸ·è¡Œè‡ªå®šç¾©Cannyé‚Šç·£æª¢æ¸¬...\")\n",
    "        \n",
    "        # æ­¥é©Ÿ1: é«˜æ–¯æ¨¡ç³Š\n",
    "        print(\"  1. é«˜æ–¯æ¨¡ç³Šå»å™ª...\")\n",
    "        start_time = time.time()\n",
    "        blurred = self._gaussian_blur(gray)\n",
    "        blur_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # æ­¥é©Ÿ2: è¨ˆç®—æ¢¯åº¦\n",
    "        print(\"  2. è¨ˆç®—åœ–åƒæ¢¯åº¦...\")\n",
    "        start_time = time.time()\n",
    "        magnitude, direction = self._compute_gradients(blurred)\n",
    "        gradient_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # æ­¥é©Ÿ3: éæ¥µå¤§å€¼æŠ‘åˆ¶\n",
    "        print(\"  3. éæ¥µå¤§å€¼æŠ‘åˆ¶...\")\n",
    "        start_time = time.time()\n",
    "        suppressed = self._non_maximum_suppression(magnitude, direction)\n",
    "        nms_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # æ­¥é©Ÿ4: é›™é–¾å€¼è™•ç†\n",
    "        print(\"  4. é›™é–¾å€¼è™•ç†...\")\n",
    "        start_time = time.time()\n",
    "        thresholded = self._double_threshold(suppressed, low_threshold, high_threshold)\n",
    "        threshold_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # æ­¥é©Ÿ5: é‚Šç·£é€£æ¥\n",
    "        print(\"  5. é‚Šç·£é€£æ¥...\")\n",
    "        start_time = time.time()\n",
    "        final_edges = self._edge_tracking_by_hysteresis(thresholded)\n",
    "        hysteresis_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        total_time = blur_time + gradient_time + nms_time + threshold_time + hysteresis_time\n",
    "        \n",
    "        print(f\"  âœ… å®Œæˆï¼ç¸½æ™‚é–“: {total_time:.1f}ms\")\n",
    "        \n",
    "        return {\n",
    "            'original': gray,\n",
    "            'blurred': blurred.astype(np.uint8),\n",
    "            'magnitude': (magnitude / np.max(magnitude) * 255).astype(np.uint8),\n",
    "            'suppressed': (suppressed / np.max(suppressed) * 255).astype(np.uint8) if np.max(suppressed) > 0 else suppressed.astype(np.uint8),\n",
    "            'thresholded': thresholded,\n",
    "            'final_edges': final_edges,\n",
    "            'processing_times': {\n",
    "                'gaussian_blur': blur_time,\n",
    "                'gradient_computation': gradient_time,\n",
    "                'non_maximum_suppression': nms_time,\n",
    "                'double_threshold': threshold_time,\n",
    "                'edge_tracking': hysteresis_time,\n",
    "                'total': total_time\n",
    "            }\n",
    "        }\n",
    "\n",
    "# å‰µå»ºè‡ªå®šç¾©Cannyæª¢æ¸¬å™¨\n",
    "custom_canny = CustomCannyDetector()\n",
    "print(\"âœ… è‡ªå®šç¾©Cannyé‚Šç·£æª¢æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ æŒ‘æˆ°ä»»å‹™ 1.1: æ¸¬è©¦è‡ªå®šç¾©Cannyç®—æ³•\n",
    "\n",
    "**ä»»å‹™**: ä½¿ç”¨è‡ªå®šç¾©å¯¦ç¾çš„Cannyç®—æ³•ä¸¦èˆ‡OpenCVå®˜æ–¹å¯¦ç¾é€²è¡Œæ¯”è¼ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_canny_implementations(image_path):\n",
    "    \"\"\"\n",
    "    æ¯”è¼ƒè‡ªå®šç¾©Cannyå¯¦ç¾èˆ‡OpenCVå®˜æ–¹å¯¦ç¾\n",
    "    \n",
    "    Args:\n",
    "        image_path: æ¸¬è©¦åœ–åƒè·¯å¾‘\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"åœ–åƒä¸å­˜åœ¨: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # è¼‰å…¥åœ–åƒ\n",
    "    image = load_image(image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # èª¿æ•´åœ–åƒå¤§å°ï¼ˆé¿å…è¨ˆç®—æ™‚é–“éé•·ï¼‰\n",
    "    image_resized = resize_image(image, max_width=400)\n",
    "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    print(f\"\\nğŸ” Cannyå¯¦ç¾æ¯”è¼ƒæ¸¬è©¦: {os.path.basename(image_path)}\")\n",
    "    print(f\"åœ–åƒå¤§å°: {gray.shape}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # æ¸¬è©¦è‡ªå®šç¾©å¯¦ç¾\n",
    "    print(\"\\nğŸ› ï¸  è‡ªå®šç¾©å¯¦ç¾:\")\n",
    "    start_time = time.time()\n",
    "    custom_result = custom_canny.detect_edges(gray, low_threshold=50, high_threshold=150)\n",
    "    custom_total_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    # æ¸¬è©¦OpenCVå¯¦ç¾\n",
    "    print(\"\\nğŸ“š OpenCVå¯¦ç¾:\")\n",
    "    start_time = time.time()\n",
    "    opencv_edges = cv2.Canny(gray, 50, 150)\n",
    "    opencv_time = (time.time() - start_time) * 1000\n",
    "    print(f\"  è™•ç†æ™‚é–“: {opencv_time:.1f}ms\")\n",
    "    \n",
    "    # é¡¯ç¤ºä¸­é–“æ­¥é©Ÿ\n",
    "    intermediate_images = [\n",
    "        custom_result['original'],\n",
    "        custom_result['blurred'],\n",
    "        custom_result['magnitude'],\n",
    "        custom_result['suppressed']\n",
    "    ]\n",
    "    \n",
    "    intermediate_titles = [\n",
    "        \"åŸå§‹åœ–åƒ\",\n",
    "        \"é«˜æ–¯æ¨¡ç³Š\",\n",
    "        \"æ¢¯åº¦å¹…å€¼\",\n",
    "        \"éæ¥µå¤§å€¼æŠ‘åˆ¶\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nğŸ“Š é¡¯ç¤ºä¸­é–“è™•ç†æ­¥é©Ÿ:\")\n",
    "    display_multiple_images(intermediate_images, intermediate_titles, figsize=(16, 8))\n",
    "    \n",
    "    # é¡¯ç¤ºæœ€çµ‚æ¯”è¼ƒçµæœ\n",
    "    final_images = [\n",
    "        custom_result['original'],\n",
    "        custom_result['final_edges'],\n",
    "        opencv_edges,\n",
    "        cv2.absdiff(custom_result['final_edges'], opencv_edges)\n",
    "    ]\n",
    "    \n",
    "    final_titles = [\n",
    "        \"åŸå§‹åœ–åƒ\",\n",
    "        f\"è‡ªå®šç¾©Canny\\n{custom_total_time:.1f}ms\",\n",
    "        f\"OpenCV Canny\\n{opencv_time:.1f}ms\",\n",
    "        \"å·®ç•°åœ–åƒ\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nğŸ† æœ€çµ‚çµæœæ¯”è¼ƒ:\")\n",
    "    display_multiple_images(final_images, final_titles, figsize=(16, 8))\n",
    "    \n",
    "    # æ€§èƒ½åˆ†æ\n",
    "    print(\"\\nğŸ“ˆ æ€§èƒ½åˆ†æ:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"è‡ªå®šç¾©å¯¦ç¾ç¸½æ™‚é–“: {custom_total_time:.1f}ms\")\n",
    "    print(f\"OpenCVå¯¦ç¾æ™‚é–“:   {opencv_time:.1f}ms\")\n",
    "    print(f\"æ€§èƒ½æ¯”å€¼:         {custom_total_time/opencv_time:.1f}x\")\n",
    "    \n",
    "    # è©³ç´°æ™‚é–“åˆ†è§£\n",
    "    print(\"\\nâ±ï¸  è‡ªå®šç¾©å¯¦ç¾æ™‚é–“åˆ†è§£:\")\n",
    "    for step, time_ms in custom_result['processing_times'].items():\n",
    "        if step != 'total':\n",
    "            percentage = (time_ms / custom_total_time) * 100\n",
    "            print(f\"  {step:20}: {time_ms:6.1f}ms ({percentage:4.1f}%)\")\n",
    "    \n",
    "    # è³ªé‡è©•ä¼°\n",
    "    print(\"\\nğŸ¯ è³ªé‡è©•ä¼°:\")\n",
    "    diff_pixels = np.sum(cv2.absdiff(custom_result['final_edges'], opencv_edges) > 0)\n",
    "    total_pixels = custom_result['final_edges'].shape[0] * custom_result['final_edges'].shape[1]\n",
    "    similarity = (1 - diff_pixels / total_pixels) * 100\n",
    "    \n",
    "    print(f\"  ç›¸ä¼¼åº¦:     {similarity:.1f}%\")\n",
    "    print(f\"  å·®ç•°åƒç´ :   {diff_pixels:,} / {total_pixels:,}\")\n",
    "    \n",
    "    if similarity >= 95:\n",
    "        quality_rating = \"å„ªç§€ â­â­â­â­â­\"\n",
    "    elif similarity >= 85:\n",
    "        quality_rating = \"è‰¯å¥½ â­â­â­â­\"\n",
    "    elif similarity >= 70:\n",
    "        quality_rating = \"ä¸€èˆ¬ â­â­â­\"\n",
    "    else:\n",
    "        quality_rating = \"éœ€æ”¹é€² â­â­\"\n",
    "    \n",
    "    print(f\"  è³ªé‡è©•ç´š:   {quality_rating}\")\n",
    "    \n",
    "    return custom_result, opencv_edges, {\n",
    "        'custom_time': custom_total_time,\n",
    "        'opencv_time': opencv_time,\n",
    "        'similarity': similarity\n",
    "    }\n",
    "\n",
    "# æ¸¬è©¦è‡ªå®šç¾©Cannyå¯¦ç¾\n",
    "test_images = [\n",
    "    \"../../assets/images/basic/face03.jpg\",\n",
    "    \"../../assets/images/basic/faces01.jpg\"\n",
    "]\n",
    "\n",
    "for image_path in test_images:\n",
    "    if os.path.exists(image_path):\n",
    "        custom_result, opencv_result, metrics = compare_canny_implementations(image_path)\n",
    "        break\n",
    "else:\n",
    "    print(\"âš ï¸ æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦åœ–åƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°2: è‡ªå®šç¾©Harrisè§’é»æª¢æ¸¬ç®—æ³•\n",
    "\n",
    "### ä»»å‹™æè¿°\n",
    "å¯¦ç¾å®Œæ•´çš„Harrisè§’é»æª¢æ¸¬ç®—æ³•ï¼ŒåŒ…æ‹¬çµæ§‹å¼µé‡è¨ˆç®—ã€HarriséŸ¿æ‡‰å‡½æ•¸ã€éæ¥µå¤§å€¼æŠ‘åˆ¶ç­‰æ­¥é©Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomHarrisDetector:\n",
    "    \"\"\"\n",
    "    è‡ªå®šç¾©Harrisè§’é»æª¢æ¸¬å™¨å¯¦ç¾\n",
    "    \n",
    "    Harrisè§’é»æª¢æ¸¬æ­¥é©Ÿï¼š\n",
    "    1. è¨ˆç®—åœ–åƒæ¢¯åº¦\n",
    "    2. è¨ˆç®—çµæ§‹å¼µé‡\n",
    "    3. è¨ˆç®—HarriséŸ¿æ‡‰å‡½æ•¸\n",
    "    4. éæ¥µå¤§å€¼æŠ‘åˆ¶\n",
    "    5. é–¾å€¼è™•ç†æå–è§’é»\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k=0.04, window_size=3, gaussian_sigma=1.0):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–Harrisæª¢æ¸¬å™¨\n",
    "        \n",
    "        Args:\n",
    "            k: Harrisåƒæ•¸\n",
    "            window_size: çª—å£å¤§å°\n",
    "            gaussian_sigma: é«˜æ–¯æ¨™æº–å·®\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.window_size = window_size\n",
    "        self.sigma = gaussian_sigma\n",
    "        \n",
    "        # å‰µå»ºé«˜æ–¯æ¬Šé‡çª—å£\n",
    "        self.gaussian_window = self._create_gaussian_window(window_size, gaussian_sigma)\n",
    "        \n",
    "        # Sobelç®—å­\n",
    "        self.sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "        self.sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32)\n",
    "    \n",
    "    def _create_gaussian_window(self, size, sigma):\n",
    "        \"\"\"\n",
    "        å‰µå»ºé«˜æ–¯æ¬Šé‡çª—å£\n",
    "        \n",
    "        Args:\n",
    "            size: çª—å£å¤§å°\n",
    "            sigma: æ¨™æº–å·®\n",
    "        \n",
    "        Returns:\n",
    "            np.array: é«˜æ–¯æ¬Šé‡çª—å£\n",
    "        \"\"\"\n",
    "        window = np.zeros((size, size))\n",
    "        center = size // 2\n",
    "        \n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                x, y = i - center, j - center\n",
    "                window[i, j] = np.exp(-(x*x + y*y) / (2 * sigma * sigma))\n",
    "        \n",
    "        return window / np.sum(window)\n",
    "    \n",
    "    def _compute_gradients(self, image):\n",
    "        \"\"\"\n",
    "        è¨ˆç®—åœ–åƒæ¢¯åº¦\n",
    "        \n",
    "        Args:\n",
    "            image: è¼¸å…¥åœ–åƒ\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (Ix, Iy) æ¢¯åº¦åœ–åƒ\n",
    "        \"\"\"\n",
    "        # ä½¿ç”¨Sobelç®—å­è¨ˆç®—æ¢¯åº¦\n",
    "        Ix = cv2.filter2D(image.astype(np.float32), -1, self.sobel_x)\n",
    "        Iy = cv2.filter2D(image.astype(np.float32), -1, self.sobel_y)\n",
    "        \n",
    "        return Ix, Iy\n",
    "    \n",
    "    @jit(nopython=True)\n",
    "    def _compute_structure_tensor(self, Ix, Iy, window):\n",
    "        \"\"\"\n",
    "        è¨ˆç®—çµæ§‹å¼µé‡ï¼ˆNumbaåŠ é€Ÿï¼‰\n",
    "        \n",
    "        Args:\n",
    "            Ix, Iy: æ¢¯åº¦åœ–åƒ\n",
    "            window: é«˜æ–¯æ¬Šé‡çª—å£\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (M11, M12, M22) çµæ§‹å¼µé‡å…ƒç´ \n",
    "        \"\"\"\n",
    "        h, w = Ix.shape\n",
    "        window_size = window.shape[0]\n",
    "        offset = window_size // 2\n",
    "        \n",
    "        M11 = np.zeros((h, w), dtype=np.float32)\n",
    "        M12 = np.zeros((h, w), dtype=np.float32)\n",
    "        M22 = np.zeros((h, w), dtype=np.float32)\n",
    "        \n",
    "        for i in range(offset, h - offset):\n",
    "            for j in range(offset, w - offset):\n",
    "                # è¨ˆç®—å±€éƒ¨å€åŸŸçš„åŠ æ¬Šæ¢¯åº¦ä¹˜ç©\n",
    "                sum_IxIx = 0.0\n",
    "                sum_IxIy = 0.0\n",
    "                sum_IyIy = 0.0\n",
    "                \n",
    "                for ki in range(window_size):\n",
    "                    for kj in range(window_size):\n",
    "                        pi, pj = i - offset + ki, j - offset + kj\n",
    "                        weight = window[ki, kj]\n",
    "                        \n",
    "                        ix_val = Ix[pi, pj]\n",
    "                        iy_val = Iy[pi, pj]\n",
    "                        \n",
    "                        sum_IxIx += weight * ix_val * ix_val\n",
    "                        sum_IxIy += weight * ix_val * iy_val\n",
    "                        sum_IyIy += weight * iy_val * iy_val\n",
    "                \n",
    "                M11[i, j] = sum_IxIx\n",
    "                M12[i, j] = sum_IxIy\n",
    "                M22[i, j] = sum_IyIy\n",
    "        \n",
    "        return M11, M12, M22\n",
    "    \n",
    "    def _compute_harris_response(self, M11, M12, M22):\n",
    "        \"\"\"\n",
    "        è¨ˆç®—HarriséŸ¿æ‡‰å‡½æ•¸\n",
    "        \n",
    "        Args:\n",
    "            M11, M12, M22: çµæ§‹å¼µé‡å…ƒç´ \n",
    "        \n",
    "        Returns:\n",
    "            np.array: HarriséŸ¿æ‡‰\n",
    "        \"\"\"\n",
    "        # è¨ˆç®—è¡Œåˆ—å¼å’Œè·¡\n",
    "        det_M = M11 * M22 - M12 * M12\n",
    "        trace_M = M11 + M22\n",
    "        \n",
    "        # HarriséŸ¿æ‡‰å‡½æ•¸: R = det(M) - k * trace(M)^2\n",
    "        R = det_M - self.k * (trace_M ** 2)\n",
    "        \n",
    "        return R\n",
    "    \n",
    "    @jit(nopython=True)\n",
    "    def _non_maximum_suppression(self, response, window_size=3):\n",
    "        \"\"\"\n",
    "        éæ¥µå¤§å€¼æŠ‘åˆ¶ï¼ˆNumbaåŠ é€Ÿï¼‰\n",
    "        \n",
    "        Args:\n",
    "            response: HarriséŸ¿æ‡‰åœ–åƒ\n",
    "            window_size: æŠ‘åˆ¶çª—å£å¤§å°\n",
    "        \n",
    "        Returns:\n",
    "            np.array: æŠ‘åˆ¶å¾Œçš„éŸ¿æ‡‰åœ–åƒ\n",
    "        \"\"\"\n",
    "        h, w = response.shape\n",
    "        suppressed = np.zeros((h, w), dtype=np.float32)\n",
    "        offset = window_size // 2\n",
    "        \n",
    "        for i in range(offset, h - offset):\n",
    "            for j in range(offset, w - offset):\n",
    "                center_val = response[i, j]\n",
    "                is_maximum = True\n",
    "                \n",
    "                # æª¢æŸ¥å±€éƒ¨çª—å£å…§æ˜¯å¦ç‚ºæœ€å¤§å€¼\n",
    "                for ki in range(-offset, offset + 1):\n",
    "                    for kj in range(-offset, offset + 1):\n",
    "                        if ki == 0 and kj == 0:\n",
    "                            continue\n",
    "                        if response[i + ki, j + kj] > center_val:\n",
    "                            is_maximum = False\n",
    "                            break\n",
    "                    if not is_maximum:\n",
    "                        break\n",
    "                \n",
    "                if is_maximum:\n",
    "                    suppressed[i, j] = center_val\n",
    "        \n",
    "        return suppressed\n",
    "    \n",
    "    def detect_corners(self, image, threshold=0.01, nms_window=5):\n",
    "        \"\"\"\n",
    "        åŸ·è¡Œå®Œæ•´çš„Harrisè§’é»æª¢æ¸¬\n",
    "        \n",
    "        Args:\n",
    "            image: è¼¸å…¥åœ–åƒ\n",
    "            threshold: éŸ¿æ‡‰é–¾å€¼\n",
    "            nms_window: éæ¥µå¤§å€¼æŠ‘åˆ¶çª—å£å¤§å°\n",
    "        \n",
    "        Returns:\n",
    "            dict: æª¢æ¸¬çµæœå’Œä¸­é–“æ•¸æ“š\n",
    "        \"\"\"\n",
    "        # è½‰æ›ç‚ºç°éš\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        print(\"ğŸ”„ åŸ·è¡Œè‡ªå®šç¾©Harrisè§’é»æª¢æ¸¬...\")\n",
    "        \n",
    "        # æ­¥é©Ÿ1: è¨ˆç®—æ¢¯åº¦\n",
    "        print(\"  1. è¨ˆç®—åœ–åƒæ¢¯åº¦...\")\n",
    "        start_time = time.time()\n",
    "        Ix, Iy = self._compute_gradients(gray)\n",
    "        gradient_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # æ­¥é©Ÿ2: è¨ˆç®—çµæ§‹å¼µé‡\n",
    "        print(\"  2. è¨ˆç®—çµæ§‹å¼µé‡...\")\n",
    "        start_time = time.time()\n",
    "        M11, M12, M22 = self._compute_structure_tensor(Ix, Iy, self.gaussian_window)\n",
    "        tensor_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # æ­¥é©Ÿ3: è¨ˆç®—HarriséŸ¿æ‡‰\n",
    "        print(\"  3. è¨ˆç®—HarriséŸ¿æ‡‰...\")\n",
    "        start_time = time.time()\n",
    "        response = self._compute_harris_response(M11, M12, M22)\n",
    "        response_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # æ­¥é©Ÿ4: éæ¥µå¤§å€¼æŠ‘åˆ¶\n",
    "        print(\"  4. éæ¥µå¤§å€¼æŠ‘åˆ¶...\")\n",
    "        start_time = time.time()\n",
    "        suppressed = self._non_maximum_suppression(response, nms_window)\n",
    "        nms_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # æ­¥é©Ÿ5: é–¾å€¼è™•ç†æå–è§’é»\n",
    "        print(\"  5. æå–è§’é»...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # è‡ªé©æ‡‰é–¾å€¼ï¼ˆç›¸å°æ–¼æœ€å¤§éŸ¿æ‡‰å€¼ï¼‰\n",
    "        max_response = np.max(suppressed)\n",
    "        adaptive_threshold = threshold * max_response\n",
    "        \n",
    "        # æå–è§’é»åº§æ¨™\n",
    "        corner_mask = suppressed > adaptive_threshold\n",
    "        corner_coords = np.where(corner_mask)\n",
    "        corners = list(zip(corner_coords[1], corner_coords[0]))  # (x, y) æ ¼å¼\n",
    "        \n",
    "        extraction_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        total_time = gradient_time + tensor_time + response_time + nms_time + extraction_time\n",
    "        \n",
    "        print(f\"  âœ… å®Œæˆï¼æª¢æ¸¬åˆ° {len(corners)} å€‹è§’é»ï¼Œç¸½æ™‚é–“: {total_time:.1f}ms\")\n",
    "        \n",
    "        return {\n",
    "            'original': gray,\n",
    "            'gradient_x': (np.abs(Ix) / np.max(np.abs(Ix)) * 255).astype(np.uint8),\n",
    "            'gradient_y': (np.abs(Iy) / np.max(np.abs(Iy)) * 255).astype(np.uint8),\n",
    "            'response': response,\n",
    "            'suppressed': suppressed,\n",
    "            'corners': corners,\n",
    "            'corner_mask': corner_mask,\n",
    "            'parameters': {\n",
    "                'k': self.k,\n",
    "                'threshold': threshold,\n",
    "                'adaptive_threshold': adaptive_threshold,\n",
    "                'max_response': max_response\n",
    "            },\n",
    "            'processing_times': {\n",
    "                'gradient_computation': gradient_time,\n",
    "                'structure_tensor': tensor_time,\n",
    "                'harris_response': response_time,\n",
    "                'non_maximum_suppression': nms_time,\n",
    "                'corner_extraction': extraction_time,\n",
    "                'total': total_time\n",
    "            }\n",
    "        }\n",
    "\n",
    "# å‰µå»ºè‡ªå®šç¾©Harrisæª¢æ¸¬å™¨\n",
    "custom_harris = CustomHarrisDetector(k=0.04, window_size=5, gaussian_sigma=1.2)\n",
    "print(\"âœ… è‡ªå®šç¾©Harrisè§’é»æª¢æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ æŒ‘æˆ°ä»»å‹™ 2.1: æ¸¬è©¦è‡ªå®šç¾©Harrisç®—æ³•\n",
    "\n",
    "**ä»»å‹™**: æ¸¬è©¦è‡ªå®šç¾©Harrisè§’é»æª¢æ¸¬ä¸¦èˆ‡OpenCVå¯¦ç¾æ¯”è¼ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_harris_implementations(image_path):\n",
    "    \"\"\"\n",
    "    æ¯”è¼ƒè‡ªå®šç¾©Harriså¯¦ç¾èˆ‡OpenCVå®˜æ–¹å¯¦ç¾\n",
    "    \n",
    "    Args:\n",
    "        image_path: æ¸¬è©¦åœ–åƒè·¯å¾‘\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"åœ–åƒä¸å­˜åœ¨: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # è¼‰å…¥åœ–åƒ\n",
    "    image = load_image(image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    \n",
    "    # èª¿æ•´åœ–åƒå¤§å°\n",
    "    image_resized = resize_image(image, max_width=400)\n",
    "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    print(f\"\\nğŸ” Harrisè§’é»æª¢æ¸¬æ¯”è¼ƒæ¸¬è©¦: {os.path.basename(image_path)}\")\n",
    "    print(f\"åœ–åƒå¤§å°: {gray.shape}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # æ¸¬è©¦è‡ªå®šç¾©å¯¦ç¾\n",
    "    print(\"\\nğŸ› ï¸  è‡ªå®šç¾©å¯¦ç¾:\")\n",
    "    custom_result = custom_harris.detect_corners(gray, threshold=0.01, nms_window=5)\n",
    "    \n",
    "    # æ¸¬è©¦OpenCVå¯¦ç¾\n",
    "    print(\"\\nğŸ“š OpenCVå¯¦ç¾:\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # OpenCV Harrisè§’é»æª¢æ¸¬\n",
    "    opencv_response = cv2.cornerHarris(gray, 5, 3, 0.04)\n",
    "    \n",
    "    # æ‡‰ç”¨ç›¸åŒçš„å¾Œè™•ç†\n",
    "    opencv_response_dilated = cv2.dilate(opencv_response, None)\n",
    "    threshold = 0.01 * opencv_response.max()\n",
    "    opencv_corners = np.where(opencv_response > threshold)\n",
    "    opencv_corner_list = list(zip(opencv_corners[1], opencv_corners[0]))\n",
    "    \n",
    "    opencv_time = (time.time() - start_time) * 1000\n",
    "    print(f\"  æª¢æ¸¬åˆ° {len(opencv_corner_list)} å€‹è§’é»ï¼Œè™•ç†æ™‚é–“: {opencv_time:.1f}ms\")\n",
    "    \n",
    "    # å‰µå»ºå¯è¦–åŒ–åœ–åƒ\n",
    "    def draw_corners(img, corners, color=(0, 255, 0), radius=3):\n",
    "        \"\"\"åœ¨åœ–åƒä¸Šç¹ªè£½è§’é»\"\"\"\n",
    "        result = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        for x, y in corners:\n",
    "            cv2.circle(result, (int(x), int(y)), radius, color, -1)\n",
    "        return result\n",
    "    \n",
    "    # ç¹ªè£½è§’é»æª¢æ¸¬çµæœ\n",
    "    custom_visualization = draw_corners(gray, custom_result['corners'], (0, 255, 0), 2)\n",
    "    opencv_visualization = draw_corners(gray, opencv_corner_list, (255, 0, 0), 2)\n",
    "    \n",
    "    # å‰µå»ºéŸ¿æ‡‰ç†±åœ–\n",
    "    custom_response_vis = cv2.applyColorMap(\n",
    "        (custom_result['response'] / np.max(custom_result['response']) * 255).astype(np.uint8),\n",
    "        cv2.COLORMAP_JET\n",
    "    )\n",
    "    \n",
    "    opencv_response_vis = cv2.applyColorMap(\n",
    "        (opencv_response / np.max(opencv_response) * 255).astype(np.uint8),\n",
    "        cv2.COLORMAP_JET\n",
    "    )\n",
    "    \n",
    "    # é¡¯ç¤ºä¸­é–“æ­¥é©Ÿ\n",
    "    intermediate_images = [\n",
    "        custom_result['original'],\n",
    "        custom_result['gradient_x'],\n",
    "        custom_result['gradient_y'],\n",
    "        custom_response_vis\n",
    "    ]\n",
    "    \n",
    "    intermediate_titles = [\n",
    "        \"åŸå§‹åœ–åƒ\",\n",
    "        \"Xæ–¹å‘æ¢¯åº¦\",\n",
    "        \"Yæ–¹å‘æ¢¯åº¦\",\n",
    "        \"HarriséŸ¿æ‡‰\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nğŸ“Š é¡¯ç¤ºä¸­é–“è™•ç†æ­¥é©Ÿ:\")\n",
    "    display_multiple_images(intermediate_images, intermediate_titles, figsize=(16, 8))\n",
    "    \n",
    "    # é¡¯ç¤ºæœ€çµ‚æ¯”è¼ƒçµæœ\n",
    "    final_images = [\n",
    "        cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR),\n",
    "        custom_visualization,\n",
    "        opencv_visualization,\n",
    "        np.hstack([custom_response_vis, opencv_response_vis])\n",
    "    ]\n",
    "    \n",
    "    final_titles = [\n",
    "        \"åŸå§‹åœ–åƒ\",\n",
    "        f\"è‡ªå®šç¾©Harris\\n{len(custom_result['corners'])} è§’é», {custom_result['processing_times']['total']:.1f}ms\",\n",
    "        f\"OpenCV Harris\\n{len(opencv_corner_list)} è§’é», {opencv_time:.1f}ms\",\n",
    "        \"éŸ¿æ‡‰æ¯”è¼ƒ\\n(å·¦:è‡ªå®šç¾©, å³:OpenCV)\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nğŸ† æœ€çµ‚çµæœæ¯”è¼ƒ:\")\n",
    "    display_multiple_images(final_images, final_titles, figsize=(16, 10))\n",
    "    \n",
    "    # æ€§èƒ½åˆ†æ\n",
    "    print(\"\\nğŸ“ˆ æ€§èƒ½åˆ†æ:\")\n",
    "    print(\"-\" * 40)\n",
    "    custom_time = custom_result['processing_times']['total']\n",
    "    print(f\"è‡ªå®šç¾©å¯¦ç¾:\")\n",
    "    print(f\"  è§’é»æ•¸é‡: {len(custom_result['corners'])}\")\n",
    "    print(f\"  è™•ç†æ™‚é–“: {custom_time:.1f}ms\")\n",
    "    print(f\"\\nOpenCVå¯¦ç¾:\")\n",
    "    print(f\"  è§’é»æ•¸é‡: {len(opencv_corner_list)}\")\n",
    "    print(f\"  è™•ç†æ™‚é–“: {opencv_time:.1f}ms\")\n",
    "    print(f\"\\næ€§èƒ½æ¯”å€¼: {custom_time/opencv_time:.1f}x\")\n",
    "    \n",
    "    # è©³ç´°æ™‚é–“åˆ†è§£\n",
    "    print(\"\\nâ±ï¸  è‡ªå®šç¾©å¯¦ç¾æ™‚é–“åˆ†è§£:\")\n",
    "    for step, time_ms in custom_result['processing_times'].items():\n",
    "        if step != 'total':\n",
    "            percentage = (time_ms / custom_time) * 100\n",
    "            print(f\"  {step:22}: {time_ms:6.1f}ms ({percentage:4.1f}%)\")\n",
    "    \n",
    "    # è³ªé‡è©•ä¼°\n",
    "    print(\"\\nğŸ¯ ç®—æ³•åƒæ•¸:\")\n",
    "    print(f\"  Harrisåƒæ•¸k:        {custom_result['parameters']['k']}\")\n",
    "    print(f\"  ç›¸å°é–¾å€¼:           {custom_result['parameters']['threshold']}\")\n",
    "    print(f\"  è‡ªé©æ‡‰é–¾å€¼:         {custom_result['parameters']['adaptive_threshold']:.2f}\")\n",
    "    print(f\"  æœ€å¤§éŸ¿æ‡‰å€¼:         {custom_result['parameters']['max_response']:.2f}\")\n",
    "    \n",
    "    return custom_result, {\n",
    "        'corners': opencv_corner_list,\n",
    "        'response': opencv_response,\n",
    "        'time': opencv_time\n",
    "    }\n",
    "\n",
    "# æ¸¬è©¦è‡ªå®šç¾©Harriså¯¦ç¾\n",
    "harris_test_images = [\n",
    "    \"../../assets/images/basic/face03.jpg\",\n",
    "    \"../../assets/images/basic/faces01.jpg\"\n",
    "]\n",
    "\n",
    "for image_path in harris_test_images:\n",
    "    if os.path.exists(image_path):\n",
    "        custom_result, opencv_result = compare_harris_implementations(image_path)\n",
    "        break\n",
    "else:\n",
    "    print(\"âš ï¸ æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦åœ–åƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°ç¸½çµèˆ‡è©•ä¼°\n",
    "\n",
    "### ğŸ† å®Œæˆæˆå°±è©•ä¼°\n",
    "\n",
    "è«‹æ ¹æ“šä½ çš„å®Œæˆæƒ…æ³é€²è¡Œè‡ªè©•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlgorithmImplementationAssessment:\n",
    "    \"\"\"è‡ªå®šç¾©ç®—æ³•å¯¦ä½œè©•ä¼°ç³»çµ±\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"åˆå§‹åŒ–è©•ä¼°ç³»çµ±\"\"\"\n",
    "        self.criteria = {\n",
    "            'correctness': {\n",
    "                'name': 'ç®—æ³•æ­£ç¢ºæ€§',\n",
    "                'weight': 0.3,\n",
    "                'description': 'å¯¦ç¾æ˜¯å¦ç¬¦åˆç®—æ³•ç†è«–'\n",
    "            },\n",
    "            'performance': {\n",
    "                'name': 'æ€§èƒ½æ•ˆç‡',\n",
    "                'weight': 0.25,\n",
    "                'description': 'èˆ‡æ¨™æº–å¯¦ç¾çš„é€Ÿåº¦æ¯”è¼ƒ'\n",
    "            },\n",
    "            'code_quality': {\n",
    "                'name': 'ä»£ç¢¼å“è³ª',\n",
    "                'weight': 0.2,\n",
    "                'description': 'ä»£ç¢¼çµæ§‹ã€è¨»è§£ã€å¯è®€æ€§'\n",
    "            },\n",
    "            'optimization': {\n",
    "                'name': 'å„ªåŒ–ç¨‹åº¦',\n",
    "                'weight': 0.15,\n",
    "                'description': 'ä½¿ç”¨äº†å“ªäº›å„ªåŒ–æŠ€è¡“'\n",
    "            },\n",
    "            'innovation': {\n",
    "                'name': 'å‰µæ–°æ”¹é€²',\n",
    "                'weight': 0.1,\n",
    "                'description': 'æ˜¯å¦æœ‰å‰µæ–°çš„æ”¹é€²æˆ–æ“´å±•'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def evaluate_implementation(self, algorithm_name, scores):\n",
    "        \"\"\"\n",
    "        è©•ä¼°ç®—æ³•å¯¦ç¾\n",
    "        \n",
    "        Args:\n",
    "            algorithm_name: ç®—æ³•åç¨±\n",
    "            scores: å„é …è©•åˆ†å­—å…¸ (0-10åˆ†)\n",
    "        \n",
    "        Returns:\n",
    "            dict: è©•ä¼°çµæœ\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ“Š {algorithm_name} å¯¦ç¾è©•ä¼°\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        total_score = 0\n",
    "        weighted_scores = {}\n",
    "        \n",
    "        for criterion, info in self.criteria.items():\n",
    "            if criterion in scores:\n",
    "                score = scores[criterion]\n",
    "                weighted_score = score * info['weight']\n",
    "                total_score += weighted_score\n",
    "                weighted_scores[criterion] = weighted_score\n",
    "                \n",
    "                print(f\"{info['name']:12}: {score:4.1f}/10 (æ¬Šé‡{info['weight']*100:3.0f}%) = {weighted_score:4.2f}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        print(f\"ç¸½åˆ†: {total_score:.2f}/10\")\n",
    "        \n",
    "        # ç­‰ç´šè©•å®š\n",
    "        if total_score >= 9.0:\n",
    "            grade = \"å°ˆå®¶ç´š â­â­â­â­â­\"\n",
    "            comment = \"å“è¶Šçš„å¯¦ç¾ï¼Œé”åˆ°ç”Ÿç”¢ç’°å¢ƒæ¨™æº–\"\n",
    "        elif total_score >= 8.0:\n",
    "            grade = \"é«˜ç´š â­â­â­â­\"\n",
    "            comment = \"å„ªç§€çš„å¯¦ç¾ï¼Œå…·æœ‰å¯¦ç”¨åƒ¹å€¼\"\n",
    "        elif total_score >= 7.0:\n",
    "            grade = \"ä¸­é«˜ç´š â­â­â­â­\"\n",
    "            comment = \"è‰¯å¥½çš„å¯¦ç¾ï¼Œç†è§£æ·±å…¥\"\n",
    "        elif total_score >= 6.0:\n",
    "            grade = \"ä¸­ç´š â­â­â­\"\n",
    "            comment = \"åŸºæœ¬æ­£ç¢ºçš„å¯¦ç¾\"\n",
    "        else:\n",
    "            grade = \"å…¥é–€ç´š â­â­\"\n",
    "            comment = \"éœ€è¦é€²ä¸€æ­¥æ”¹é€²\"\n",
    "        \n",
    "        print(f\"\\nğŸ† è©•ç´š: {grade}\")\n",
    "        print(f\"ğŸ’¬ è©•åƒ¹: {comment}\")\n",
    "        \n",
    "        return {\n",
    "            'total_score': total_score,\n",
    "            'weighted_scores': weighted_scores,\n",
    "            'grade': grade,\n",
    "            'comment': comment\n",
    "        }\n",
    "    \n",
    "    def generate_improvement_suggestions(self, scores):\n",
    "        \"\"\"\n",
    "        ç”Ÿæˆæ”¹é€²å»ºè­°\n",
    "        \n",
    "        Args:\n",
    "            scores: è©•åˆ†å­—å…¸\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ’¡ æ”¹é€²å»ºè­°:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        suggestions = []\n",
    "        \n",
    "        if scores.get('correctness', 10) < 8:\n",
    "            suggestions.append(\"â€¢ ä»”ç´°æª¢æŸ¥ç®—æ³•æ­¥é©Ÿï¼Œç¢ºä¿å¯¦ç¾ç¬¦åˆç†è«–\")\n",
    "            suggestions.append(\"â€¢ å¢åŠ æ›´å¤šæ¸¬è©¦ç”¨ä¾‹é©—è­‰æ­£ç¢ºæ€§\")\n",
    "        \n",
    "        if scores.get('performance', 10) < 7:\n",
    "            suggestions.append(\"â€¢ ä½¿ç”¨Numbaæˆ–Cythoné€²è¡ŒåŠ é€Ÿå„ªåŒ–\")\n",
    "            suggestions.append(\"â€¢ å„ªåŒ–æ•¸æ“šçµæ§‹å’Œå¾ªç’°çµæ§‹\")\n",
    "            suggestions.append(\"â€¢ è€ƒæ…®ä½¿ç”¨å‘é‡åŒ–æ“ä½œ\")\n",
    "        \n",
    "        if scores.get('code_quality', 10) < 8:\n",
    "            suggestions.append(\"â€¢ æ·»åŠ è©³ç´°çš„å‡½æ•¸æ–‡æª”å­—ç¬¦ä¸²\")\n",
    "            suggestions.append(\"â€¢ æ”¹é€²è®Šé‡å‘½åå’Œä»£ç¢¼çµæ§‹\")\n",
    "            suggestions.append(\"â€¢ å¢åŠ éŒ¯èª¤è™•ç†å’Œé‚Šç•Œæ¢ä»¶æª¢æŸ¥\")\n",
    "        \n",
    "        if scores.get('optimization', 10) < 7:\n",
    "            suggestions.append(\"â€¢ åˆ†æç®—æ³•ç“¶é ¸ä¸¦é€²è¡Œé‡å°æ€§å„ªåŒ–\")\n",
    "            suggestions.append(\"â€¢ è€ƒæ…®å…§å­˜è¨ªå•æ¨¡å¼å„ªåŒ–\")\n",
    "            suggestions.append(\"â€¢ å¯¦ç¾å¤šç·šç¨‹æˆ–GPUåŠ é€Ÿ\")\n",
    "        \n",
    "        if scores.get('innovation', 10) < 6:\n",
    "            suggestions.append(\"â€¢ å˜—è©¦æ”¹é€²ç®—æ³•åƒæ•¸æˆ–æ·»åŠ è‡ªé©æ‡‰æ©Ÿåˆ¶\")\n",
    "            suggestions.append(\"â€¢ çµåˆå…¶ä»–ç®—æ³•æˆ–æŠ€è¡“é€²è¡Œå‰µæ–°\")\n",
    "            suggestions.append(\"â€¢ é‡å°ç‰¹å®šæ‡‰ç”¨å ´æ™¯é€²è¡Œå„ªåŒ–\")\n",
    "        \n",
    "        if not suggestions:\n",
    "            suggestions.append(\"â€¢ å·²ç¶“æ˜¯å¾ˆå„ªç§€çš„å¯¦ç¾ï¼\")\n",
    "            suggestions.append(\"â€¢ å¯ä»¥è€ƒæ…®å°‡å¯¦ç¾è²¢ç»çµ¦é–‹æºç¤¾ç¾¤\")\n",
    "        \n",
    "        for suggestion in suggestions:\n",
    "            print(suggestion)\n",
    "\n",
    "# å‰µå»ºè©•ä¼°ç³»çµ±\n",
    "assessor = AlgorithmImplementationAssessment()\n",
    "\n",
    "# ç¤ºä¾‹è©•ä¼° - è«‹æ ¹æ“šä½ çš„å¯¦éš›å®Œæˆæƒ…æ³èª¿æ•´åˆ†æ•¸\n",
    "print(\"\\nğŸ¯ è‡ªå®šç¾©ç®—æ³•å¯¦ä½œæŒ‘æˆ° - æˆæœè©•ä¼°\")\n",
    "print(\"è«‹æ ¹æ“šä½ çš„å¯¦éš›å®Œæˆæƒ…æ³ï¼Œç‚ºä»¥ä¸‹æ–¹é¢æ‰“åˆ† (0-10åˆ†):\")\n",
    "\n",
    "# Cannyç®—æ³•è©•ä¼°ç¤ºä¾‹\n",
    "canny_scores = {\n",
    "    'correctness': 8.5,    # ç®—æ³•æ­¥é©Ÿå®Œæ•´ï¼Œèˆ‡OpenCVçµæœç›¸ä¼¼åº¦é«˜\n",
    "    'performance': 6.0,    # æ¯”OpenCVæ…¢ç´„3-5å€ï¼Œä½†å¯æ¥å—\n",
    "    'code_quality': 8.0,   # ä»£ç¢¼çµæ§‹æ¸…æ™°ï¼Œè¨»è§£å®Œæ•´\n",
    "    'optimization': 7.0,   # ä½¿ç”¨äº†NumbaåŠ é€Ÿ\n",
    "    'innovation': 5.0      # åŸºæœ¬å¯¦ç¾ï¼Œç„¡ç‰¹æ®Šå‰µæ–°\n",
    "}\n",
    "\n",
    "canny_result = assessor.evaluate_implementation(\"è‡ªå®šç¾©Cannyé‚Šç·£æª¢æ¸¬\", canny_scores)\n",
    "assessor.generate_improvement_suggestions(canny_scores)\n",
    "\n",
    "# Harrisç®—æ³•è©•ä¼°ç¤ºä¾‹\n",
    "harris_scores = {\n",
    "    'correctness': 8.0,    # è§’é»æª¢æ¸¬çµæœåˆç†\n",
    "    'performance': 5.5,    # æ€§èƒ½æœ‰å¾…å„ªåŒ–\n",
    "    'code_quality': 7.5,   # ä»£ç¢¼è³ªé‡è‰¯å¥½\n",
    "    'optimization': 6.5,   # éƒ¨åˆ†ä½¿ç”¨äº†åŠ é€ŸæŠ€è¡“\n",
    "    'innovation': 4.5      # æ¨™æº–å¯¦ç¾\n",
    "}\n",
    "\n",
    "harris_result = assessor.evaluate_implementation(\"è‡ªå®šç¾©Harrisè§’é»æª¢æ¸¬\", harris_scores)\n",
    "assessor.generate_improvement_suggestions(harris_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ é€²éšæŒ‘æˆ°æ–¹å‘\n",
    "\n",
    "å®ŒæˆåŸºæœ¬å¯¦ç¾å¾Œï¼Œä½ å¯ä»¥å˜—è©¦ä»¥ä¸‹é€²éšæŒ‘æˆ°ï¼š\n",
    "\n",
    "### 1. æ€§èƒ½æ¥µè‡´å„ªåŒ–\n",
    "- **SIMDæŒ‡ä»¤å„ªåŒ–**: ä½¿ç”¨NumPyçš„å‘é‡åŒ–æ“ä½œ\n",
    "- **è¨˜æ†¶é«”å„ªåŒ–**: æ¸›å°‘ä¸å¿…è¦çš„è¨˜æ†¶é«”åˆ†é…\n",
    "- **ä¸¦è¡Œè™•ç†**: ä½¿ç”¨å¤šç·šç¨‹æˆ–å¤šè™•ç†\n",
    "- **GPUåŠ é€Ÿ**: ä½¿ç”¨CuPyæˆ–OpenCVçš„CUDAåŠŸèƒ½\n",
    "\n",
    "### 2. ç®—æ³•å‰µæ–°æ”¹é€²\n",
    "- **è‡ªé©æ‡‰åƒæ•¸**: æ ¹æ“šåœ–åƒå…§å®¹è‡ªå‹•èª¿æ•´åƒæ•¸\n",
    "- **å¤šå°ºåº¦è™•ç†**: å¯¦ç¾é‡‘å­—å¡”çµæ§‹çš„å¤šå°ºåº¦æª¢æ¸¬\n",
    "- **é­¯æ£’æ€§å¢å¼·**: å°å™ªè²å’Œå…‰ç…§è®ŠåŒ–çš„é©æ‡‰æ€§\n",
    "- **æ··åˆç®—æ³•**: çµåˆå¤šç¨®ç®—æ³•çš„å„ªé»\n",
    "\n",
    "### 3. æ‡‰ç”¨å ´æ™¯ç‰¹åŒ–\n",
    "- **å¯¦æ™‚è™•ç†**: é‡å°å½±ç‰‡æµçš„å„ªåŒ–\n",
    "- **åµŒå…¥å¼å„ªåŒ–**: é©åˆç§»å‹•è¨­å‚™çš„è¼•é‡åŒ–\n",
    "- **ç‰¹å®šé ˜åŸŸ**: é†«å­¸å½±åƒã€é™æ„Ÿå½±åƒç­‰å°ˆç”¨ç‰ˆæœ¬\n",
    "\n",
    "### 4. å®Œæ•´ç³»çµ±æ•´åˆ\n",
    "- **ç®¡é“åŒ–è™•ç†**: å»ºç«‹å®Œæ•´çš„è¦–è¦ºè™•ç†ç®¡é“\n",
    "- **å¯è¦–åŒ–ç•Œé¢**: æ·»åŠ åƒæ•¸èª¿æ•´çš„GUI\n",
    "- **æ•ˆèƒ½åŸºæº–æ¸¬è©¦**: å»ºç«‹æ¨™æº–åŒ–çš„æ¸¬è©¦æ¡†æ¶\n",
    "\n",
    "## ğŸ“š å­¸ç¿’è³‡æºæ¨è–¦\n",
    "\n",
    "### ç¶“å…¸è«–æ–‡\n",
    "- **Canny Edge Detection**: \"A Computational Approach to Edge Detection\" - John Canny (1986)\n",
    "- **Harris Corner Detection**: \"A Combined Corner and Edge Detector\" - Harris & Stephens (1988)\n",
    "- **SIFT**: \"Distinctive Image Features from Scale-Invariant Keypoints\" - David Lowe (2004)\n",
    "\n",
    "### å¯¦ç¾åƒè€ƒ\n",
    "- OpenCV æºä»£ç¢¼ç ”ç©¶\n",
    "- scikit-image å¯¦ç¾åˆ†æ\n",
    "- å­¸è¡“ç•Œé–‹æºå¯¦ç¾\n",
    "\n",
    "### å„ªåŒ–æŠ€è¡“\n",
    "- Intel IPP (Integrated Performance Primitives)\n",
    "- NVIDIA NPP (NVIDIA Performance Primitives)\n",
    "- OpenMP ä¸¦è¡Œç·¨ç¨‹\n",
    "\n",
    "## ğŸ¯ æŒ‘æˆ°å®Œæˆæª¢æ ¸è¡¨\n",
    "\n",
    "### åŸºç¤è¦æ±‚ â­â­â­\n",
    "- [ ] å®Œæˆè‡³å°‘ä¸€å€‹å®Œæ•´ç®—æ³•çš„å¾é›¶å¯¦ç¾\n",
    "- [ ] å¯¦ç¾çµæœèˆ‡æ¨™æº–åº«åŸºæœ¬ä¸€è‡´\n",
    "- [ ] ä»£ç¢¼çµæ§‹æ¸…æ™°ï¼Œæœ‰é©ç•¶è¨»è§£\n",
    "\n",
    "### é€²éšè¦æ±‚ â­â­â­â­\n",
    "- [ ] å¯¦ç¾å¤šå€‹ç®—æ³•ä¸¦é€²è¡Œæ¯”è¼ƒ\n",
    "- [ ] ä½¿ç”¨äº†æ€§èƒ½å„ªåŒ–æŠ€è¡“\n",
    "- [ ] å»ºç«‹äº†å®Œæ•´çš„æ¸¬è©¦å’Œé©—è­‰æµç¨‹\n",
    "\n",
    "### å°ˆå®¶è¦æ±‚ â­â­â­â­â­\n",
    "- [ ] æ€§èƒ½æ¥è¿‘æˆ–è¶…è¶Šæ¨™æº–å¯¦ç¾\n",
    "- [ ] æœ‰å‰µæ–°çš„æ”¹é€²æˆ–æ‡‰ç”¨\n",
    "- [ ] ä»£ç¢¼è³ªé‡é”åˆ°ç”Ÿç”¢ç’°å¢ƒæ¨™æº–\n",
    "\n",
    "**å®ŒæˆåŸºç¤è¦æ±‚å³å¯é€²å…¥ä¸‹ä¸€å€‹é«˜ç´šç·´ç¿’ï¼** ğŸ‰\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¬ åæ€èˆ‡ç¸½çµ\n",
    "\n",
    "é€šéé€™å€‹æŒ‘æˆ°ï¼Œä½ æ‡‰è©²å·²ç¶“ï¼š\n",
    "1. **æ·±å…¥ç†è§£**äº†ç¶“å…¸é›»è…¦è¦–è¦ºç®—æ³•çš„æ•¸å­¸åŸç†\n",
    "2. **æŒæ¡äº†**å¾ç†è«–åˆ°å¯¦ä½œçš„å®Œæ•´æµç¨‹\n",
    "3. **å­¸æœƒäº†**æ€§èƒ½å„ªåŒ–å’Œä»£ç¢¼è³ªé‡æ§åˆ¶\n",
    "4. **å»ºç«‹äº†**ç®—æ³•è©•ä¼°å’Œæ¯”è¼ƒçš„æ–¹æ³•è«–\n",
    "\n",
    "é€™äº›æŠ€èƒ½å°‡ç‚ºä½ åœ¨é›»è…¦è¦–è¦ºé ˜åŸŸçš„æ·±å…¥ç ”ç©¶å’Œå·¥ç¨‹é–‹ç™¼å¥ å®šå …å¯¦åŸºç¤ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}