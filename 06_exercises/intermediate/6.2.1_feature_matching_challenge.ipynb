{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2.1 ç‰¹å¾µåŒ¹é…æŒ‘æˆ° - ä¸­ç´šç·´ç¿’\n",
    "\n",
    "æœ¬ç·´ç¿’å°ˆæ³¨æ–¼ç‰¹å¾µæª¢æ¸¬ã€æè¿°å­æå–å’Œç‰¹å¾µåŒ¹é…çš„å¯¦éš›æ‡‰ç”¨ã€‚é€šéè§£æ±ºå¯¦éš›å•é¡Œä¾†æ·±å…¥ç†è§£ç‰¹å¾µåŒ¹é…çš„åŸç†å’ŒæŠ€å·§ã€‚\n",
    "\n",
    "## ç·´ç¿’ç›®æ¨™\n",
    "- æŒæ¡å¤šç¨®ç‰¹å¾µæª¢æ¸¬å™¨çš„ä½¿ç”¨å’Œæ¯”è¼ƒ\n",
    "- å¯¦ç¾é­¯æ£’çš„ç‰¹å¾µåŒ¹é…ç®—æ³•\n",
    "- å­¸æœƒè™•ç†å…‰ç…§ã€è§’åº¦è®ŠåŒ–ç­‰æŒ‘æˆ°\n",
    "- æ‡‰ç”¨Homographyé€²è¡Œåœ–åƒé…æº–\n",
    "- è©•ä¼°ç‰¹å¾µåŒ¹é…çš„æ•ˆæœå’Œç²¾åº¦\n",
    "\n",
    "## é›£åº¦ç­‰ç´š: â­â­â­ (ä¸­ç´š)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç’°å¢ƒè¨­ç½®èˆ‡å°å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "# æ·»åŠ utilsè·¯å¾‘\n",
    "sys.path.append('../../utils')\n",
    "from image_utils import load_image, resize_image\n",
    "from visualization import display_image, display_multiple_images\n",
    "from performance import time_function, benchmark_function\n",
    "\n",
    "# è¨­ç½®matplotlib\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ç’°å¢ƒè¨­ç½®å®Œæˆ\")\n",
    "print(f\"OpenCVç‰ˆæœ¬: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°1: å¤šç‰¹å¾µæª¢æ¸¬å™¨æ¯”è¼ƒåˆ†æ\n",
    "\n",
    "### ä»»å‹™æè¿°\n",
    "å¯¦ç¾ä¸€å€‹ç‰¹å¾µæª¢æ¸¬å™¨æ¯”è¼ƒç³»çµ±ï¼Œèƒ½å¤ åŒæ™‚ä½¿ç”¨SIFTã€ORBã€BRISKç­‰å¤šç¨®æª¢æ¸¬å™¨ï¼Œä¸¦é€²è¡Œå®šé‡åˆ†æã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDetectorComparator:\n",
    "    \"\"\"ç‰¹å¾µæª¢æ¸¬å™¨æ¯”è¼ƒé¡\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"åˆå§‹åŒ–å„ç¨®ç‰¹å¾µæª¢æ¸¬å™¨\"\"\"\n",
    "        self.detectors = {}\n",
    "        self._initialize_detectors()\n",
    "    \n",
    "    def _initialize_detectors(self):\n",
    "        \"\"\"åˆå§‹åŒ–æ‰€æœ‰å¯ç”¨çš„ç‰¹å¾µæª¢æ¸¬å™¨\"\"\"\n",
    "        try:\n",
    "            # SIFTæª¢æ¸¬å™¨\n",
    "            self.detectors['SIFT'] = cv2.SIFT_create()\n",
    "            print(\"âœ… SIFTæª¢æ¸¬å™¨åˆå§‹åŒ–æˆåŠŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ SIFTåˆå§‹åŒ–å¤±æ•—: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # ORBæª¢æ¸¬å™¨\n",
    "            self.detectors['ORB'] = cv2.ORB_create(nfeatures=1000)\n",
    "            print(\"âœ… ORBæª¢æ¸¬å™¨åˆå§‹åŒ–æˆåŠŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ORBåˆå§‹åŒ–å¤±æ•—: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # BRISKæª¢æ¸¬å™¨\n",
    "            self.detectors['BRISK'] = cv2.BRISK_create()\n",
    "            print(\"âœ… BRISKæª¢æ¸¬å™¨åˆå§‹åŒ–æˆåŠŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ BRISKåˆå§‹åŒ–å¤±æ•—: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # AKAZEæª¢æ¸¬å™¨\n",
    "            self.detectors['AKAZE'] = cv2.AKAZE_create()\n",
    "            print(\"âœ… AKAZEæª¢æ¸¬å™¨åˆå§‹åŒ–æˆåŠŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ AKAZEåˆå§‹åŒ–å¤±æ•—: {e}\")\n",
    "        \n",
    "        print(f\"\\nğŸ”§ ç¸½å…±åˆå§‹åŒ–äº† {len(self.detectors)} å€‹æª¢æ¸¬å™¨\")\n",
    "    \n",
    "    def detect_and_compute(self, image, detector_name):\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨æŒ‡å®šæª¢æ¸¬å™¨é€²è¡Œç‰¹å¾µæª¢æ¸¬å’Œæè¿°å­è¨ˆç®—\n",
    "        \n",
    "        Args:\n",
    "            image: è¼¸å…¥åœ–åƒ\n",
    "            detector_name: æª¢æ¸¬å™¨åç¨±\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (é—œéµé», æè¿°å­, è™•ç†æ™‚é–“)\n",
    "        \"\"\"\n",
    "        if detector_name not in self.detectors:\n",
    "            return None, None, 0\n",
    "        \n",
    "        detector = self.detectors[detector_name]\n",
    "        \n",
    "        # è½‰æ›ç‚ºç°éšï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        \n",
    "        # æª¢æ¸¬ä¸¦è¨ˆç®—æè¿°å­\n",
    "        start_time = time.time()\n",
    "        keypoints, descriptors = detector.detectAndCompute(gray, None)\n",
    "        process_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        return keypoints, descriptors, process_time\n",
    "    \n",
    "    def compare_detectors(self, image_path):\n",
    "        \"\"\"\n",
    "        æ¯”è¼ƒæ‰€æœ‰æª¢æ¸¬å™¨åœ¨åŒä¸€åœ–åƒä¸Šçš„è¡¨ç¾\n",
    "        \n",
    "        Args:\n",
    "            image_path: åœ–åƒè·¯å¾‘\n",
    "        \"\"\"\n",
    "        # è¼‰å…¥åœ–åƒ\n",
    "        image = load_image(image_path)\n",
    "        if image is None:\n",
    "            print(f\"ç„¡æ³•è¼‰å…¥åœ–åƒ: {image_path}\")\n",
    "            return\n",
    "        \n",
    "        # èª¿æ•´åœ–åƒå¤§å°\n",
    "        image_resized = resize_image(image, max_width=640)\n",
    "        \n",
    "        results = []\n",
    "        titles = []\n",
    "        comparison_data = []\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ç‰¹å¾µæª¢æ¸¬å™¨æ¯”è¼ƒåˆ†æ: {os.path.basename(image_path)}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for detector_name in self.detectors.keys():\n",
    "            # æª¢æ¸¬ç‰¹å¾µ\n",
    "            keypoints, descriptors, process_time = self.detect_and_compute(\n",
    "                image_resized, detector_name\n",
    "            )\n",
    "            \n",
    "            if keypoints is not None:\n",
    "                # ç¹ªè£½é—œéµé»\n",
    "                img_with_kp = cv2.drawKeypoints(\n",
    "                    image_resized, keypoints, None, \n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "                )\n",
    "                \n",
    "                results.append(img_with_kp)\n",
    "                titles.append(f\"{detector_name}\\n{len(keypoints)} kpts, {process_time:.1f}ms\")\n",
    "                \n",
    "                # æ”¶é›†æ¯”è¼ƒæ•¸æ“š\n",
    "                desc_size = descriptors.shape[1] if descriptors is not None else 0\n",
    "                comparison_data.append({\n",
    "                    'name': detector_name,\n",
    "                    'keypoints': len(keypoints),\n",
    "                    'time': process_time,\n",
    "                    'descriptor_size': desc_size\n",
    "                })\n",
    "                \n",
    "                print(f\"{detector_name:6}: {len(keypoints):4d} ç‰¹å¾µé», \"\n",
    "                      f\"{process_time:6.1f}ms, æè¿°å­ç¶­åº¦: {desc_size}\")\n",
    "        \n",
    "        # é¡¯ç¤ºæ¯”è¼ƒçµæœ\n",
    "        if results:\n",
    "            all_images = [image_resized] + results\n",
    "            all_titles = [\"åŸå§‹åœ–åƒ\"] + titles\n",
    "            \n",
    "            display_multiple_images(all_images, all_titles, figsize=(15, 10))\n",
    "        \n",
    "        # è¼¸å‡ºè©³ç´°çµ±è¨ˆ\n",
    "        self._print_detailed_statistics(comparison_data)\n",
    "        \n",
    "        return comparison_data\n",
    "    \n",
    "    def _print_detailed_statistics(self, data):\n",
    "        \"\"\"è¼¸å‡ºè©³ç´°çµ±è¨ˆä¿¡æ¯\"\"\"\n",
    "        if not data:\n",
    "            return\n",
    "        \n",
    "        print(\"\\nğŸ“ˆ è©³ç´°çµ±è¨ˆåˆ†æ:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # æŒ‰ç‰¹å¾µé»æ•¸é‡æ’åº\n",
    "        sorted_by_features = sorted(data, key=lambda x: x['keypoints'], reverse=True)\n",
    "        print(\"ç‰¹å¾µé»æ•¸é‡æ’å:\")\n",
    "        for i, item in enumerate(sorted_by_features, 1):\n",
    "            print(f\"  {i}. {item['name']:6}: {item['keypoints']:4d} ç‰¹å¾µé»\")\n",
    "        \n",
    "        # æŒ‰é€Ÿåº¦æ’åº\n",
    "        sorted_by_speed = sorted(data, key=lambda x: x['time'])\n",
    "        print(\"\\nè™•ç†é€Ÿåº¦æ’å:\")\n",
    "        for i, item in enumerate(sorted_by_speed, 1):\n",
    "            print(f\"  {i}. {item['name']:6}: {item['time']:6.1f}ms\")\n",
    "        \n",
    "        # æ¨è–¦ä½¿ç”¨å ´æ™¯\n",
    "        print(\"\\nğŸ’¡ ä½¿ç”¨å ´æ™¯æ¨è–¦:\")\n",
    "        fastest = sorted_by_speed[0]['name']\n",
    "        most_features = sorted_by_features[0]['name']\n",
    "        \n",
    "        print(f\"  â€¢ å¯¦æ™‚æ‡‰ç”¨: {fastest} (æœ€å¿«)\")\n",
    "        print(f\"  â€¢ é«˜ç²¾åº¦åŒ¹é…: {most_features} (ç‰¹å¾µé»æœ€å¤š)\")\n",
    "        print(\"  â€¢ ç§»å‹•è¨­å‚™: ORB (å¹³è¡¡é€Ÿåº¦å’Œæ•ˆæœ)\")\n",
    "        print(\"  â€¢ å­¸è¡“ç ”ç©¶: SIFT (ç¶“å…¸ç®—æ³•)\")\n",
    "\n",
    "# åˆå§‹åŒ–æ¯”è¼ƒå™¨\n",
    "comparator = FeatureDetectorComparator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ ç·´ç¿’ä»»å‹™ 1.1: åŸ·è¡Œç‰¹å¾µæª¢æ¸¬å™¨æ¯”è¼ƒ\n",
    "\n",
    "**ä»»å‹™**: ä½¿ç”¨ä¸åŒçš„æ¸¬è©¦åœ–åƒä¾†æ¯”è¼ƒå„ç¨®ç‰¹å¾µæª¢æ¸¬å™¨çš„æ•ˆèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ä¸åŒé¡å‹çš„åœ–åƒ\n",
    "test_images = [\n",
    "    \"../../assets/images/basic/faces01.jpg\",  # äººè‡‰åœ–åƒ\n",
    "    \"../../assets/images/basic/faces.png\",    # è¤‡é›œå ´æ™¯\n",
    "    \"../../assets/images/basic/face03.jpg\"    # å–®ä¸€ç‰©é«”\n",
    "]\n",
    "\n",
    "# ä¾æ¬¡æ¸¬è©¦æ¯å€‹åœ–åƒ\n",
    "for image_path in test_images:\n",
    "    if os.path.exists(image_path):\n",
    "        print(f\"\\nğŸ” æ¸¬è©¦åœ–åƒ: {os.path.basename(image_path)}\")\n",
    "        comparison_results = comparator.compare_detectors(image_path)\n",
    "    else:\n",
    "        print(f\"âš ï¸ åœ–åƒä¸å­˜åœ¨: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°2: é­¯æ£’ç‰¹å¾µåŒ¹é…ç³»çµ±\n",
    "\n",
    "### ä»»å‹™æè¿°\n",
    "å¯¦ç¾ä¸€å€‹èƒ½è™•ç†å…‰ç…§è®ŠåŒ–ã€å°ºåº¦è®Šæ›ã€æ—‹è½‰ç­‰æŒ‘æˆ°çš„é­¯æ£’ç‰¹å¾µåŒ¹é…ç³»çµ±ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustFeatureMatcher:\n",
    "    \"\"\"é­¯æ£’ç‰¹å¾µåŒ¹é…å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, detector_name='SIFT', matcher_type='FLANN'):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–é­¯æ£’ç‰¹å¾µåŒ¹é…å™¨\n",
    "        \n",
    "        Args:\n",
    "            detector_name: ç‰¹å¾µæª¢æ¸¬å™¨åç¨±\n",
    "            matcher_type: åŒ¹é…å™¨é¡å‹ ('FLANN' or 'BF')\n",
    "        \"\"\"\n",
    "        self.detector_name = detector_name\n",
    "        self.matcher_type = matcher_type\n",
    "        self.detector = self._create_detector(detector_name)\n",
    "        self.matcher = self._create_matcher(matcher_type, detector_name)\n",
    "        \n",
    "    def _create_detector(self, name):\n",
    "        \"\"\"å‰µå»ºç‰¹å¾µæª¢æ¸¬å™¨\"\"\"\n",
    "        detectors = {\n",
    "            'SIFT': lambda: cv2.SIFT_create(),\n",
    "            'ORB': lambda: cv2.ORB_create(nfeatures=1000),\n",
    "            'BRISK': lambda: cv2.BRISK_create(),\n",
    "            'AKAZE': lambda: cv2.AKAZE_create()\n",
    "        }\n",
    "        \n",
    "        if name in detectors:\n",
    "            return detectors[name]()\n",
    "        else:\n",
    "            print(f\"æœªçŸ¥æª¢æ¸¬å™¨: {name}, ä½¿ç”¨SIFT\")\n",
    "            return cv2.SIFT_create()\n",
    "    \n",
    "    def _create_matcher(self, matcher_type, detector_name):\n",
    "        \"\"\"å‰µå»ºç‰¹å¾µåŒ¹é…å™¨\"\"\"\n",
    "        if matcher_type == 'FLANN':\n",
    "            if detector_name in ['SIFT', 'SURF']:\n",
    "                # åŸºæ–¼æ¨¹çš„ç´¢å¼•\n",
    "                FLANN_INDEX_KDTREE = 1\n",
    "                index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "            else:\n",
    "                # LSHç´¢å¼•ç”¨æ–¼äºŒé€²åˆ¶æè¿°å­\n",
    "                FLANN_INDEX_LSH = 6\n",
    "                index_params = dict(algorithm=FLANN_INDEX_LSH,\n",
    "                                  table_number=6,\n",
    "                                  key_size=12,\n",
    "                                  multi_probe_level=1)\n",
    "            \n",
    "            search_params = dict(checks=50)\n",
    "            return cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        \n",
    "        else:  # BruteForce\n",
    "            if detector_name in ['ORB', 'BRISK', 'AKAZE']:\n",
    "                return cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            else:\n",
    "                return cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    \n",
    "    def match_features(self, img1, img2, ratio_threshold=0.75, min_matches=10):\n",
    "        \"\"\"\n",
    "        åŸ·è¡Œç‰¹å¾µåŒ¹é…\n",
    "        \n",
    "        Args:\n",
    "            img1, img2: è¼¸å…¥åœ–åƒ\n",
    "            ratio_threshold: Lowe's ratio testé–¾å€¼\n",
    "            min_matches: æœ€å°‘åŒ¹é…é»æ•¸é‡\n",
    "        \n",
    "        Returns:\n",
    "            dict: åŒ¹é…çµæœ\n",
    "        \"\"\"\n",
    "        # æª¢æ¸¬ç‰¹å¾µé»å’Œæè¿°å­\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2\n",
    "        \n",
    "        kp1, desc1 = self.detector.detectAndCompute(gray1, None)\n",
    "        kp2, desc2 = self.detector.detectAndCompute(gray2, None)\n",
    "        \n",
    "        if desc1 is None or desc2 is None or len(desc1) < min_matches or len(desc2) < min_matches:\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'reason': 'insufficient_features',\n",
    "                'keypoints1': kp1,\n",
    "                'keypoints2': kp2\n",
    "            }\n",
    "        \n",
    "        # ç‰¹å¾µåŒ¹é…\n",
    "        if self.matcher_type == 'FLANN' or not hasattr(self.matcher, 'match'):\n",
    "            # ä½¿ç”¨KNNåŒ¹é…\n",
    "            matches = self.matcher.knnMatch(desc1, desc2, k=2)\n",
    "            \n",
    "            # Lowe's ratio test\n",
    "            good_matches = []\n",
    "            for match_pair in matches:\n",
    "                if len(match_pair) == 2:\n",
    "                    m, n = match_pair\n",
    "                    if m.distance < ratio_threshold * n.distance:\n",
    "                        good_matches.append(m)\n",
    "        else:\n",
    "            # ç›´æ¥åŒ¹é…\n",
    "            matches = self.matcher.match(desc1, desc2)\n",
    "            good_matches = sorted(matches, key=lambda x: x.distance)\n",
    "        \n",
    "        if len(good_matches) < min_matches:\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'reason': 'insufficient_matches',\n",
    "                'matches_found': len(good_matches),\n",
    "                'keypoints1': kp1,\n",
    "                'keypoints2': kp2\n",
    "            }\n",
    "        \n",
    "        # æå–åŒ¹é…é»åº§æ¨™\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        # è¨ˆç®—Homography\n",
    "        homography = None\n",
    "        inliers_mask = None\n",
    "        \n",
    "        if len(good_matches) >= 4:\n",
    "            homography, inliers_mask = cv2.findHomography(\n",
    "                src_pts, dst_pts, cv2.RANSAC, 5.0\n",
    "            )\n",
    "        \n",
    "        inliers_count = np.sum(inliers_mask) if inliers_mask is not None else 0\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'keypoints1': kp1,\n",
    "            'keypoints2': kp2,\n",
    "            'matches': good_matches,\n",
    "            'homography': homography,\n",
    "            'inliers_mask': inliers_mask,\n",
    "            'inliers_count': inliers_count,\n",
    "            'total_matches': len(good_matches),\n",
    "            'match_ratio': inliers_count / len(good_matches) if len(good_matches) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    def visualize_matches(self, img1, img2, match_result, max_matches=50):\n",
    "        \"\"\"\n",
    "        è¦–è¦ºåŒ–åŒ¹é…çµæœ\n",
    "        \n",
    "        Args:\n",
    "            img1, img2: è¼¸å…¥åœ–åƒ\n",
    "            match_result: åŒ¹é…çµæœ\n",
    "            max_matches: æœ€å¤§é¡¯ç¤ºåŒ¹é…æ•¸\n",
    "        \n",
    "        Returns:\n",
    "            np.array: åŒ¹é…è¦–è¦ºåŒ–åœ–åƒ\n",
    "        \"\"\"\n",
    "        if match_result['status'] != 'success':\n",
    "            # åªé¡¯ç¤ºç‰¹å¾µé»\n",
    "            img1_kp = cv2.drawKeypoints(img1, match_result['keypoints1'], None)\n",
    "            img2_kp = cv2.drawKeypoints(img2, match_result['keypoints2'], None)\n",
    "            return np.hstack([img1_kp, img2_kp])\n",
    "        \n",
    "        # ç¹ªè£½åŒ¹é…çµæœ\n",
    "        matches_to_draw = match_result['matches'][:max_matches]\n",
    "        \n",
    "        if match_result['inliers_mask'] is not None:\n",
    "            # åˆ†åˆ¥ç¹ªè£½å…§é»å’Œå¤–é»\n",
    "            mask = match_result['inliers_mask'].ravel()[:len(matches_to_draw)]\n",
    "            \n",
    "            # ç¹ªè£½æ‰€æœ‰åŒ¹é…ï¼ˆå¤–é»ç‚ºç´…è‰²ï¼‰\n",
    "            img_matches = cv2.drawMatches(\n",
    "                img1, match_result['keypoints1'],\n",
    "                img2, match_result['keypoints2'],\n",
    "                matches_to_draw, None,\n",
    "                matchColor=(0, 0, 255),  # ç´…è‰²\n",
    "                flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "            )\n",
    "            \n",
    "            # è¦†è“‹ç¹ªè£½å…§é»ï¼ˆç¶ è‰²ï¼‰\n",
    "            inlier_matches = [m for i, m in enumerate(matches_to_draw) if i < len(mask) and mask[i]]\n",
    "            if inlier_matches:\n",
    "                img_matches = cv2.drawMatches(\n",
    "                    img1, match_result['keypoints1'],\n",
    "                    img2, match_result['keypoints2'],\n",
    "                    inlier_matches, img_matches,\n",
    "                    matchColor=(0, 255, 0),  # ç¶ è‰²\n",
    "                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS | cv2.DrawMatchesFlags_DRAW_OVER_OUTIMG\n",
    "                )\n",
    "        else:\n",
    "            # ç°¡å–®ç¹ªè£½æ‰€æœ‰åŒ¹é…\n",
    "            img_matches = cv2.drawMatches(\n",
    "                img1, match_result['keypoints1'],\n",
    "                img2, match_result['keypoints2'],\n",
    "                matches_to_draw, None,\n",
    "                matchColor=(0, 255, 0),\n",
    "                flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "            )\n",
    "        \n",
    "        return img_matches\n",
    "\n",
    "# å‰µå»ºé­¯æ£’åŒ¹é…å™¨\n",
    "robust_matcher = RobustFeatureMatcher(detector_name='SIFT', matcher_type='FLANN')\n",
    "print(\"âœ… é­¯æ£’ç‰¹å¾µåŒ¹é…å™¨åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ ç·´ç¿’ä»»å‹™ 2.1: æ¸¬è©¦é­¯æ£’ç‰¹å¾µåŒ¹é…\n",
    "\n",
    "**ä»»å‹™**: ä½¿ç”¨åŒä¸€ç‰©é«”çš„ä¸åŒè¦–è§’åœ–åƒä¾†æ¸¬è©¦ç‰¹å¾µåŒ¹é…çš„é­¯æ£’æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_robust_matching(img1_path, img2_path, detector_name='SIFT'):\n",
    "    \"\"\"\n",
    "    æ¸¬è©¦é­¯æ£’ç‰¹å¾µåŒ¹é…\n",
    "    \n",
    "    Args:\n",
    "        img1_path, img2_path: åœ–åƒè·¯å¾‘\n",
    "        detector_name: æª¢æ¸¬å™¨åç¨±\n",
    "    \"\"\"\n",
    "    # è¼‰å…¥åœ–åƒ\n",
    "    img1 = load_image(img1_path)\n",
    "    img2 = load_image(img2_path)\n",
    "    \n",
    "    if img1 is None or img2 is None:\n",
    "        print(\"ç„¡æ³•è¼‰å…¥åœ–åƒ\")\n",
    "        return\n",
    "    \n",
    "    # èª¿æ•´åœ–åƒå¤§å°\n",
    "    img1 = resize_image(img1, max_width=500)\n",
    "    img2 = resize_image(img2, max_width=500)\n",
    "    \n",
    "    # å‰µå»ºåŒ¹é…å™¨\n",
    "    matcher = RobustFeatureMatcher(detector_name=detector_name)\n",
    "    \n",
    "    # åŸ·è¡ŒåŒ¹é…\n",
    "    print(f\"\\nğŸ” ä½¿ç”¨ {detector_name} é€²è¡Œç‰¹å¾µåŒ¹é…...\")\n",
    "    start_time = time.time()\n",
    "    result = matcher.match_features(img1, img2)\n",
    "    match_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    # è¼¸å‡ºçµæœ\n",
    "    print(f\"åŒ¹é…ç‹€æ…‹: {result['status']}\")\n",
    "    print(f\"è™•ç†æ™‚é–“: {match_time:.1f}ms\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(f\"ç¸½åŒ¹é…é»: {result['total_matches']}\")\n",
    "        print(f\"å…§é»æ•¸é‡: {result['inliers_count']}\")\n",
    "        print(f\"åŒ¹é…ç²¾åº¦: {result['match_ratio']:.2%}\")\n",
    "        \n",
    "        # è¦–è¦ºåŒ–åŒ¹é…çµæœ\n",
    "        img_matches = matcher.visualize_matches(img1, img2, result)\n",
    "        \n",
    "        title = (f\"{detector_name} åŒ¹é…çµæœ\\n\"\n",
    "                f\"åŒ¹é…é»: {result['total_matches']}, \"\n",
    "                f\"å…§é»: {result['inliers_count']}, \"\n",
    "                f\"ç²¾åº¦: {result['match_ratio']:.1%}\")\n",
    "        \n",
    "        display_image(img_matches, title, figsize=(15, 8))\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        print(f\"åŒ¹é…å¤±æ•—: {result.get('reason', 'æœªçŸ¥åŸå› ')}\")\n",
    "        if 'matches_found' in result:\n",
    "            print(f\"æ‰¾åˆ°çš„åŒ¹é…é»: {result['matches_found']}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "# æ¸¬è©¦åœ–åƒåŒ¹é…ï¼ˆä½¿ç”¨ç›¸åŒå ´æ™¯çš„ä¸åŒåœ–åƒï¼‰\n",
    "test_pairs = [\n",
    "    (\"../../assets/images/basic/face03.jpg\", \"../../assets/images/basic/faces01.jpg\"),\n",
    "    (\"../../assets/images/basic/faces.png\", \"../../assets/images/basic/faces01.jpg\")\n",
    "]\n",
    "\n",
    "for img1_path, img2_path in test_pairs:\n",
    "    if os.path.exists(img1_path) and os.path.exists(img2_path):\n",
    "        print(f\"\\nğŸ“· æ¸¬è©¦é…å°: {os.path.basename(img1_path)} <-> {os.path.basename(img2_path)}\")\n",
    "        test_robust_matching(img1_path, img2_path, 'SIFT')\n",
    "    else:\n",
    "        print(f\"âš ï¸ æ¸¬è©¦åœ–åƒä¸å­˜åœ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°3: åœ–åƒé…æº–èˆ‡æ‹¼æ¥\n",
    "\n",
    "### ä»»å‹™æè¿°\n",
    "åŸºæ–¼ç‰¹å¾µåŒ¹é…å¯¦ç¾åœ–åƒé…æº–å’Œç°¡å–®çš„åœ–åƒæ‹¼æ¥åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRegistration:\n",
    "    \"\"\"åœ–åƒé…æº–å’Œæ‹¼æ¥é¡\"\"\"\n",
    "    \n",
    "    def __init__(self, matcher=None):\n",
    "        \"\"\"åˆå§‹åŒ–åœ–åƒé…æº–å™¨\"\"\"\n",
    "        self.matcher = matcher or RobustFeatureMatcher()\n",
    "    \n",
    "    def register_images(self, img1, img2):\n",
    "        \"\"\"\n",
    "        é…æº–å…©å¼µåœ–åƒ\n",
    "        \n",
    "        Args:\n",
    "            img1: åƒè€ƒåœ–åƒ\n",
    "            img2: å¾…é…æº–åœ–åƒ\n",
    "        \n",
    "        Returns:\n",
    "            dict: é…æº–çµæœ\n",
    "        \"\"\"\n",
    "        # åŸ·è¡Œç‰¹å¾µåŒ¹é…\n",
    "        match_result = self.matcher.match_features(img1, img2)\n",
    "        \n",
    "        if match_result['status'] != 'success':\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'reason': 'ç‰¹å¾µåŒ¹é…å¤±æ•—',\n",
    "                'match_result': match_result\n",
    "            }\n",
    "        \n",
    "        if match_result['homography'] is None:\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'reason': 'Homographyè¨ˆç®—å¤±æ•—',\n",
    "                'match_result': match_result\n",
    "            }\n",
    "        \n",
    "        # æ‡‰ç”¨Homographyè®Šæ›\n",
    "        h, w = img1.shape[:2]\n",
    "        registered_img = cv2.warpPerspective(\n",
    "            img2, match_result['homography'], (w, h)\n",
    "        )\n",
    "        \n",
    "        # è¨ˆç®—é…æº–èª¤å·®ï¼ˆä½¿ç”¨RMSEï¼‰\n",
    "        registration_error = self._calculate_registration_error(\n",
    "            img1, registered_img\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'registered_image': registered_img,\n",
    "            'homography': match_result['homography'],\n",
    "            'registration_error': registration_error,\n",
    "            'match_result': match_result\n",
    "        }\n",
    "    \n",
    "    def _calculate_registration_error(self, img1, img2):\n",
    "        \"\"\"\n",
    "        è¨ˆç®—é…æº–èª¤å·®\n",
    "        \n",
    "        Args:\n",
    "            img1, img2: è¼¸å…¥åœ–åƒ\n",
    "        \n",
    "        Returns:\n",
    "            float: RMSEèª¤å·®\n",
    "        \"\"\"\n",
    "        # è½‰æ›ç‚ºç°éš\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2\n",
    "        \n",
    "        # è¨ˆç®—RMSE\n",
    "        diff = (gray1.astype(np.float32) - gray2.astype(np.float32)) ** 2\n",
    "        rmse = np.sqrt(np.mean(diff))\n",
    "        \n",
    "        return rmse\n",
    "    \n",
    "    def create_panorama(self, images):\n",
    "        \"\"\"\n",
    "        å‰µå»ºå…¨æ™¯åœ–åƒï¼ˆç°¡åŒ–ç‰ˆï¼‰\n",
    "        \n",
    "        Args:\n",
    "            images: åœ–åƒåˆ—è¡¨\n",
    "        \n",
    "        Returns:\n",
    "            np.array: å…¨æ™¯åœ–åƒ\n",
    "        \"\"\"\n",
    "        if len(images) < 2:\n",
    "            return images[0] if images else None\n",
    "        \n",
    "        # ä½¿ç”¨ç¬¬ä¸€å¼µåœ–åƒä½œç‚ºåŸºæº–\n",
    "        panorama = images[0].copy()\n",
    "        \n",
    "        print(f\"ğŸ“¸ é–‹å§‹å‰µå»ºå…¨æ™¯åœ–ï¼Œå…± {len(images)} å¼µåœ–åƒ\")\n",
    "        \n",
    "        for i in range(1, len(images)):\n",
    "            print(f\"æ­£åœ¨è™•ç†ç¬¬ {i+1} å¼µåœ–åƒ...\")\n",
    "            \n",
    "            # é…æº–ç•¶å‰åœ–åƒåˆ°å…¨æ™¯åœ–\n",
    "            result = self.register_images(panorama, images[i])\n",
    "            \n",
    "            if result['status'] == 'success':\n",
    "                # ç°¡å–®çš„åœ–åƒèåˆï¼ˆå¹³å‡å€¼ï¼‰\n",
    "                registered = result['registered_image']\n",
    "                \n",
    "                # å‰µå»ºé®ç½©æ‰¾åˆ°é‡ç–Šå€åŸŸ\n",
    "                mask = cv2.cvtColor(registered, cv2.COLOR_BGR2GRAY) > 0\n",
    "                \n",
    "                # åœ¨é‡ç–Šå€åŸŸé€²è¡Œèåˆ\n",
    "                panorama_float = panorama.astype(np.float32)\n",
    "                registered_float = registered.astype(np.float32)\n",
    "                \n",
    "                # ç°¡å–®å¹³å‡èåˆ\n",
    "                overlap_mask = mask[:, :, np.newaxis]\n",
    "                panorama_float[overlap_mask] = (\n",
    "                    panorama_float[overlap_mask] + registered_float[overlap_mask]\n",
    "                ) / 2.0\n",
    "                \n",
    "                panorama = panorama_float.astype(np.uint8)\n",
    "                \n",
    "                print(f\"  âœ… åœ–åƒ {i+1} èåˆæˆåŠŸï¼Œé…æº–èª¤å·®: {result['registration_error']:.2f}\")\n",
    "            else:\n",
    "                print(f\"  âŒ åœ–åƒ {i+1} é…æº–å¤±æ•—: {result['reason']}\")\n",
    "        \n",
    "        return panorama\n",
    "\n",
    "# åˆå§‹åŒ–é…æº–å™¨\n",
    "registration = ImageRegistration()\n",
    "print(\"âœ… åœ–åƒé…æº–å™¨åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ ç·´ç¿’ä»»å‹™ 3.1: å¯¦ç¾åœ–åƒé…æº–\n",
    "\n",
    "**ä»»å‹™**: æ¸¬è©¦åœ–åƒé…æº–åŠŸèƒ½ï¼Œä¸¦è©•ä¼°é…æº–ç²¾åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_registration(img1_path, img2_path):\n",
    "    \"\"\"\n",
    "    æ¸¬è©¦åœ–åƒé…æº–åŠŸèƒ½\n",
    "    \n",
    "    Args:\n",
    "        img1_path: åƒè€ƒåœ–åƒè·¯å¾‘\n",
    "        img2_path: å¾…é…æº–åœ–åƒè·¯å¾‘\n",
    "    \"\"\"\n",
    "    # è¼‰å…¥åœ–åƒ\n",
    "    img1 = load_image(img1_path)\n",
    "    img2 = load_image(img2_path)\n",
    "    \n",
    "    if img1 is None or img2 is None:\n",
    "        print(\"ç„¡æ³•è¼‰å…¥åœ–åƒ\")\n",
    "        return\n",
    "    \n",
    "    # èª¿æ•´åœ–åƒå¤§å°\n",
    "    img1 = resize_image(img1, max_width=400)\n",
    "    img2 = resize_image(img2, max_width=400)\n",
    "    \n",
    "    print(f\"\\nğŸ”§ åœ–åƒé…æº–æ¸¬è©¦\")\n",
    "    print(f\"åƒè€ƒåœ–åƒ: {os.path.basename(img1_path)}\")\n",
    "    print(f\"å¾…é…æº–åœ–åƒ: {os.path.basename(img2_path)}\")\n",
    "    \n",
    "    # åŸ·è¡Œé…æº–\n",
    "    start_time = time.time()\n",
    "    result = registration.register_images(img1, img2)\n",
    "    registration_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    print(f\"é…æº–è™•ç†æ™‚é–“: {registration_time:.1f}ms\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(f\"âœ… é…æº–æˆåŠŸ\")\n",
    "        print(f\"é…æº–èª¤å·® (RMSE): {result['registration_error']:.2f}\")\n",
    "        print(f\"ç‰¹å¾µåŒ¹é…é»: {result['match_result']['total_matches']}\")\n",
    "        print(f\"å…§é»æ•¸é‡: {result['match_result']['inliers_count']}\")\n",
    "        \n",
    "        # é¡¯ç¤ºé…æº–çµæœ\n",
    "        registered_img = result['registered_image']\n",
    "        \n",
    "        # å‰µå»ºå°æ¯”åœ–\n",
    "        diff_img = cv2.absdiff(img1, registered_img)\n",
    "        \n",
    "        images = [img1, img2, registered_img, diff_img]\n",
    "        titles = [\n",
    "            \"åƒè€ƒåœ–åƒ\",\n",
    "            \"åŸå§‹åœ–åƒ\", \n",
    "            f\"é…æº–çµæœ\\nRMSE: {result['registration_error']:.2f}\",\n",
    "            \"å·®ç•°åœ–åƒ\"\n",
    "        ]\n",
    "        \n",
    "        display_multiple_images(images, titles, figsize=(16, 8))\n",
    "        \n",
    "        # è©•ä¼°é…æº–è³ªé‡\n",
    "        if result['registration_error'] < 20:\n",
    "            quality = \"å„ªç§€\"\n",
    "        elif result['registration_error'] < 40:\n",
    "            quality = \"è‰¯å¥½\"\n",
    "        elif result['registration_error'] < 60:\n",
    "            quality = \"ä¸€èˆ¬\"\n",
    "        else:\n",
    "            quality = \"éœ€æ”¹å–„\"\n",
    "        \n",
    "        print(f\"ğŸ† é…æº–è³ªé‡è©•ç´š: {quality}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ é…æº–å¤±æ•—: {result['reason']}\")\n",
    "        \n",
    "        # é¡¯ç¤ºåŸå§‹åœ–åƒ\n",
    "        display_multiple_images(\n",
    "            [img1, img2], \n",
    "            [\"åƒè€ƒåœ–åƒ\", \"å¾…é…æº–åœ–åƒ\"], \n",
    "            figsize=(10, 5)\n",
    "        )\n",
    "\n",
    "# æ¸¬è©¦é…æº–åŠŸèƒ½\n",
    "registration_test_pairs = [\n",
    "    (\"../../assets/images/basic/face03.jpg\", \"../../assets/images/basic/faces01.jpg\")\n",
    "]\n",
    "\n",
    "for img1_path, img2_path in registration_test_pairs:\n",
    "    if os.path.exists(img1_path) and os.path.exists(img2_path):\n",
    "        test_image_registration(img1_path, img2_path)\n",
    "    else:\n",
    "        print(\"âš ï¸ æ¸¬è©¦åœ–åƒä¸å­˜åœ¨ï¼Œè·³éé…æº–æ¸¬è©¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°4: ç¶œåˆè©•ä¼°ç³»çµ±\n",
    "\n",
    "### ä»»å‹™æè¿°\n",
    "å‰µå»ºä¸€å€‹ç¶œåˆè©•ä¼°ç³»çµ±ï¼Œèƒ½å¤ è‡ªå‹•è©•ä¼°ä¸åŒç‰¹å¾µåŒ¹é…æ–¹æ³•åœ¨å„ç¨®å ´æ™¯ä¸‹çš„è¡¨ç¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMatchingEvaluator:\n",
    "    \"\"\"ç‰¹å¾µåŒ¹é…ç¶œåˆè©•ä¼°å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"åˆå§‹åŒ–è©•ä¼°å™¨\"\"\"\n",
    "        self.test_results = []\n",
    "        \n",
    "    def evaluate_method(self, detector_name, test_images, challenges=None):\n",
    "        \"\"\"\n",
    "        è©•ä¼°ç‰¹å®šæª¢æ¸¬æ–¹æ³•\n",
    "        \n",
    "        Args:\n",
    "            detector_name: æª¢æ¸¬å™¨åç¨±\n",
    "            test_images: æ¸¬è©¦åœ–åƒå°åˆ—è¡¨\n",
    "            challenges: æŒ‘æˆ°é¡å‹åˆ—è¡¨\n",
    "        \n",
    "        Returns:\n",
    "            dict: è©•ä¼°çµæœ\n",
    "        \"\"\"\n",
    "        if challenges is None:\n",
    "            challenges = ['normal', 'scale', 'rotation', 'illumination']\n",
    "        \n",
    "        matcher = RobustFeatureMatcher(detector_name=detector_name)\n",
    "        \n",
    "        results = {\n",
    "            'detector': detector_name,\n",
    "            'challenges': {},\n",
    "            'overall_score': 0,\n",
    "            'processing_times': [],\n",
    "            'match_counts': [],\n",
    "            'success_rate': 0\n",
    "        }\n",
    "        \n",
    "        successful_tests = 0\n",
    "        total_tests = 0\n",
    "        \n",
    "        print(f\"\\nğŸ“Š è©•ä¼° {detector_name} æª¢æ¸¬å™¨\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for challenge in challenges:\n",
    "            challenge_results = []\n",
    "            \n",
    "            for img1_path, img2_path in test_images:\n",
    "                if not (os.path.exists(img1_path) and os.path.exists(img2_path)):\n",
    "                    continue\n",
    "                \n",
    "                # è¼‰å…¥ä¸¦é è™•ç†åœ–åƒ\n",
    "                img1, img2 = self._load_and_preprocess(\n",
    "                    img1_path, img2_path, challenge\n",
    "                )\n",
    "                \n",
    "                if img1 is None or img2 is None:\n",
    "                    continue\n",
    "                \n",
    "                # åŸ·è¡ŒåŒ¹é…\n",
    "                start_time = time.time()\n",
    "                match_result = matcher.match_features(img1, img2)\n",
    "                process_time = (time.time() - start_time) * 1000\n",
    "                \n",
    "                total_tests += 1\n",
    "                \n",
    "                if match_result['status'] == 'success':\n",
    "                    successful_tests += 1\n",
    "                    \n",
    "                    # æ”¶é›†æ€§èƒ½æŒ‡æ¨™\n",
    "                    challenge_results.append({\n",
    "                        'success': True,\n",
    "                        'matches': match_result['total_matches'],\n",
    "                        'inliers': match_result['inliers_count'],\n",
    "                        'ratio': match_result['match_ratio'],\n",
    "                        'time': process_time\n",
    "                    })\n",
    "                    \n",
    "                    results['processing_times'].append(process_time)\n",
    "                    results['match_counts'].append(match_result['total_matches'])\n",
    "                    \n",
    "                else:\n",
    "                    challenge_results.append({\n",
    "                        'success': False,\n",
    "                        'time': process_time\n",
    "                    })\n",
    "            \n",
    "            # è¨ˆç®—æŒ‘æˆ°æ€§èƒ½çµ±è¨ˆ\n",
    "            if challenge_results:\n",
    "                success_count = sum(1 for r in challenge_results if r['success'])\n",
    "                challenge_success_rate = success_count / len(challenge_results)\n",
    "                \n",
    "                avg_matches = np.mean([r['matches'] for r in challenge_results if r['success']]) if success_count > 0 else 0\n",
    "                avg_ratio = np.mean([r['ratio'] for r in challenge_results if r['success']]) if success_count > 0 else 0\n",
    "                avg_time = np.mean([r['time'] for r in challenge_results])\n",
    "                \n",
    "                results['challenges'][challenge] = {\n",
    "                    'success_rate': challenge_success_rate,\n",
    "                    'avg_matches': avg_matches,\n",
    "                    'avg_ratio': avg_ratio,\n",
    "                    'avg_time': avg_time\n",
    "                }\n",
    "                \n",
    "                print(f\"{challenge:12}: {challenge_success_rate:.1%} æˆåŠŸç‡, \"\n",
    "                      f\"{avg_matches:5.1f} å¹³å‡åŒ¹é…é», {avg_time:6.1f}ms\")\n",
    "        \n",
    "        # è¨ˆç®—ç¸½é«”å¾—åˆ†\n",
    "        results['success_rate'] = successful_tests / total_tests if total_tests > 0 else 0\n",
    "        \n",
    "        # ç¶œåˆè©•åˆ†ï¼ˆ0-100ï¼‰\n",
    "        score_components = {\n",
    "            'success_rate': results['success_rate'] * 40,  # 40%æ¬Šé‡\n",
    "            'match_quality': np.mean([c['avg_ratio'] for c in results['challenges'].values()]) * 30,  # 30%æ¬Šé‡\n",
    "            'speed': min(100, 1000 / np.mean(results['processing_times'])) if results['processing_times'] else 0  # 30%æ¬Šé‡ï¼ˆé€Ÿåº¦å€’æ•¸ï¼‰\n",
    "        }\n",
    "        \n",
    "        results['overall_score'] = sum(score_components.values())\n",
    "        results['score_breakdown'] = score_components\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ {detector_name} ç¸½é«”è©•ä¼°:\")\n",
    "        print(f\"æˆåŠŸç‡: {results['success_rate']:.1%}\")\n",
    "        print(f\"å¹³å‡è™•ç†æ™‚é–“: {np.mean(results['processing_times']):.1f}ms\" if results['processing_times'] else \"N/A\")\n",
    "        print(f\"ç¶œåˆå¾—åˆ†: {results['overall_score']:.1f}/100\")\n",
    "        \n",
    "        self.test_results.append(results)\n",
    "        return results\n",
    "    \n",
    "    def _load_and_preprocess(self, img1_path, img2_path, challenge):\n",
    "        \"\"\"\n",
    "        è¼‰å…¥ä¸¦æ ¹æ“šæŒ‘æˆ°é¡å‹é è™•ç†åœ–åƒ\n",
    "        \n",
    "        Args:\n",
    "            img1_path, img2_path: åœ–åƒè·¯å¾‘\n",
    "            challenge: æŒ‘æˆ°é¡å‹\n",
    "        \n",
    "        Returns:\n",
    "            tuple: è™•ç†å¾Œçš„åœ–åƒå°\n",
    "        \"\"\"\n",
    "        img1 = load_image(img1_path)\n",
    "        img2 = load_image(img2_path)\n",
    "        \n",
    "        if img1 is None or img2 is None:\n",
    "            return None, None\n",
    "        \n",
    "        # åŸºæœ¬å¤§å°èª¿æ•´\n",
    "        img1 = resize_image(img1, max_width=400)\n",
    "        img2 = resize_image(img2, max_width=400)\n",
    "        \n",
    "        # æ ¹æ“šæŒ‘æˆ°é¡å‹é€²è¡Œè®Šæ›\n",
    "        if challenge == 'scale':\n",
    "            # ç¸®æ”¾è®Šæ›\n",
    "            scale_factor = 0.7\n",
    "            h, w = img2.shape[:2]\n",
    "            img2 = cv2.resize(img2, (int(w * scale_factor), int(h * scale_factor)))\n",
    "            \n",
    "        elif challenge == 'rotation':\n",
    "            # æ—‹è½‰è®Šæ›\n",
    "            angle = 15\n",
    "            h, w = img2.shape[:2]\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            img2 = cv2.warpAffine(img2, M, (w, h))\n",
    "            \n",
    "        elif challenge == 'illumination':\n",
    "            # å…‰ç…§è®Šæ›\n",
    "            img2 = cv2.convertScaleAbs(img2, alpha=1.3, beta=20)\n",
    "        \n",
    "        return img1, img2\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"\n",
    "        ç”Ÿæˆç¶œåˆè©•ä¼°å ±å‘Š\n",
    "        \"\"\"\n",
    "        if not self.test_results:\n",
    "            print(\"æ²’æœ‰æ¸¬è©¦çµæœå¯å ±å‘Š\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“Š ç‰¹å¾µåŒ¹é…æ–¹æ³•ç¶œåˆè©•ä¼°å ±å‘Š\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # æŒ‰ç¸½åˆ†æ’åº\n",
    "        sorted_results = sorted(self.test_results, key=lambda x: x['overall_score'], reverse=True)\n",
    "        \n",
    "        print(\"\\nğŸ† ç¶œåˆæ€§èƒ½æ’å:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, result in enumerate(sorted_results, 1):\n",
    "            print(f\"{i}. {result['detector']:6} - å¾—åˆ†: {result['overall_score']:5.1f}/100\")\n",
    "            print(f\"   æˆåŠŸç‡: {result['success_rate']:5.1%}, \"\n",
    "                  f\"å¹³å‡æ™‚é–“: {np.mean(result['processing_times']):5.1f}ms\" if result['processing_times'] else \"N/A\")\n",
    "        \n",
    "        # å„é …æŒ‡æ¨™åˆ†æ\n",
    "        print(\"\\nğŸ“ˆ è©³ç´°æ€§èƒ½åˆ†æ:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for category in ['success_rate', 'speed', 'match_quality']:\n",
    "            best_detector = max(sorted_results, \n",
    "                              key=lambda x: x['score_breakdown'][category])['detector']\n",
    "            category_names = {\n",
    "                'success_rate': 'æˆåŠŸç‡',\n",
    "                'speed': 'è™•ç†é€Ÿåº¦',\n",
    "                'match_quality': 'åŒ¹é…è³ªé‡'\n",
    "            }\n",
    "            print(f\"{category_names[category]:8}: {best_detector} è¡¨ç¾æœ€ä½³\")\n",
    "        \n",
    "        # ä½¿ç”¨å»ºè­°\n",
    "        print(\"\\nğŸ’¡ ä½¿ç”¨å»ºè­°:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        best_overall = sorted_results[0]['detector']\n",
    "        fastest = min(sorted_results, \n",
    "                     key=lambda x: np.mean(x['processing_times']) if x['processing_times'] else float('inf'))['detector']\n",
    "        \n",
    "        print(f\"â€¢ é€šç”¨æ‡‰ç”¨: {best_overall} (ç¶œåˆè¡¨ç¾æœ€ä½³)\")\n",
    "        print(f\"â€¢ å¯¦æ™‚æ‡‰ç”¨: {fastest} (è™•ç†é€Ÿåº¦æœ€å¿«)\")\n",
    "        print(f\"â€¢ ç²¾ç¢ºåŒ¹é…: SIFT (ç¶“å…¸ç©©å®šç®—æ³•)\")\n",
    "        print(f\"â€¢ ç§»å‹•è¨­å‚™: ORB (è³‡æºæ¶ˆè€—ä½)\")\n",
    "\n",
    "# å‰µå»ºè©•ä¼°å™¨\n",
    "evaluator = FeatureMatchingEvaluator()\n",
    "print(\"âœ… ç‰¹å¾µåŒ¹é…è©•ä¼°å™¨åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ ç·´ç¿’ä»»å‹™ 4.1: åŸ·è¡Œç¶œåˆè©•ä¼°\n",
    "\n",
    "**ä»»å‹™**: å°ä¸åŒçš„ç‰¹å¾µæª¢æ¸¬å™¨é€²è¡Œç¶œåˆè©•ä¼°ä¸¦ç”Ÿæˆå ±å‘Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æº–å‚™æ¸¬è©¦åœ–åƒå°\n",
    "evaluation_test_pairs = [\n",
    "    (\"../../assets/images/basic/face03.jpg\", \"../../assets/images/basic/faces01.jpg\"),\n",
    "    (\"../../assets/images/basic/faces.png\", \"../../assets/images/basic/faces01.jpg\")\n",
    "]\n",
    "\n",
    "# éæ¿¾å­˜åœ¨çš„åœ–åƒå°\n",
    "valid_pairs = [(p1, p2) for p1, p2 in evaluation_test_pairs \n",
    "               if os.path.exists(p1) and os.path.exists(p2)]\n",
    "\n",
    "if valid_pairs:\n",
    "    print(f\"ğŸ” æ‰¾åˆ° {len(valid_pairs)} å°æœ‰æ•ˆæ¸¬è©¦åœ–åƒ\")\n",
    "    \n",
    "    # æ¸¬è©¦ä¸åŒçš„æª¢æ¸¬å™¨\n",
    "    detectors_to_test = ['SIFT', 'ORB', 'BRISK', 'AKAZE']\n",
    "    \n",
    "    for detector in detectors_to_test:\n",
    "        try:\n",
    "            evaluator.evaluate_method(\n",
    "                detector_name=detector,\n",
    "                test_images=valid_pairs,\n",
    "                challenges=['normal', 'scale', 'rotation']\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {detector} è©•ä¼°å¤±æ•—: {e}\")\n",
    "    \n",
    "    # ç”Ÿæˆç¶œåˆå ±å‘Š\n",
    "    evaluator.generate_report()\n",
    "    \nelse:\n",
    "    print(\"âš ï¸ æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¸¬è©¦åœ–åƒå°\")\n",
    "    print(\"è«‹ç¢ºä¿ä»¥ä¸‹åœ–åƒå­˜åœ¨:\")\n",
    "    for p1, p2 in evaluation_test_pairs:\n",
    "        print(f\"  - {p1}\")\n",
    "        print(f\"  - {p2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°ç¸½çµèˆ‡å»¶ä¼¸ç·´ç¿’\n",
    "\n",
    "### ğŸ¯ æœ¬ç·´ç¿’å®Œæˆçš„æŠ€èƒ½\n",
    "\n",
    "1. **å¤šç‰¹å¾µæª¢æ¸¬å™¨æ¯”è¼ƒ**: æŒæ¡SIFTã€ORBã€BRISKã€AKAZEç­‰æª¢æ¸¬å™¨çš„ä½¿ç”¨\n",
    "2. **é­¯æ£’ç‰¹å¾µåŒ¹é…**: å¯¦ç¾è™•ç†å„ç¨®è®Šæ›çš„ç©©å®šåŒ¹é…ç®—æ³•\n",
    "3. **åœ–åƒé…æº–**: åŸºæ–¼Homographyçš„åœ–åƒå°é½ŠæŠ€è¡“\n",
    "4. **ç¶œåˆè©•ä¼°**: å»ºç«‹å®Œæ•´çš„æ€§èƒ½è©•ä¼°é«”ç³»\n",
    "\n",
    "### ğŸ“Š æ•ˆèƒ½æŒ‡æ¨™ç†è§£\n",
    "\n",
    "- **ç‰¹å¾µé»æ•¸é‡**: æ›´å¤šä¸ä¸€å®šæ›´å¥½ï¼Œé—œéµæ˜¯è³ªé‡\n",
    "- **åŒ¹é…ç²¾åº¦**: å…§é»æ¯”ä¾‹åæ˜ åŒ¹é…çš„å¯é æ€§\n",
    "- **è™•ç†é€Ÿåº¦**: å¯¦æ™‚æ‡‰ç”¨çš„é—œéµæŒ‡æ¨™\n",
    "- **é­¯æ£’æ€§**: å°è®Šæ›çš„é©æ‡‰èƒ½åŠ›\n",
    "\n",
    "### ğŸš€ é€²éšæŒ‘æˆ°æ–¹å‘\n",
    "\n",
    "1. **è‡ªå®šç¾©æè¿°å­**: è¨­è¨ˆé‡å°ç‰¹å®šå ´æ™¯çš„ç‰¹å¾µæè¿°å­\n",
    "2. **æ·±åº¦å­¸ç¿’ç‰¹å¾µ**: æ•´åˆæ·±åº¦å­¸ç¿’ç‰¹å¾µæª¢æ¸¬æ–¹æ³•\n",
    "3. **å¯¦æ™‚å„ªåŒ–**: å¯¦ç¾ç§»å‹•è¨­å‚™ä¸Šçš„å¯¦æ™‚ç‰¹å¾µåŒ¹é…\n",
    "4. **å¤šè¦–è§’åŒ¹é…**: è™•ç†3Dé‡å»ºä¸­çš„å¤šè¦–è§’åŒ¹é…å•é¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“š å»¶ä¼¸å­¸ç¿’è³‡æº\n",
    "\n",
    "#### ç›¸é—œè«–æ–‡\n",
    "- SIFT: \"Distinctive Image Features from Scale-Invariant Keypoints\" - David Lowe\n",
    "- ORB: \"ORB: an efficient alternative to SIFT or SURF\" - Rublee et al.\n",
    "- BRISK: \"BRISK: Binary Robust invariant scalable keypoints\" - Leutenegger et al.\n",
    "\n",
    "#### å¯¦éš›æ‡‰ç”¨\n",
    "- è¦–è¦ºSLAM\n",
    "- 3Dé‡å»º\n",
    "- åœ–åƒæª¢ç´¢\n",
    "- æ“´å¢å¯¦å¢ƒ\n",
    "- æ–‡æª”é…æº–\n",
    "\n",
    "#### ä¸‹ä¸€æ­¥å­¸ç¿’\n",
    "- 6.2.2 åœ–åƒæ‹¼æ¥å°ˆæ¡ˆ\n",
    "- 6.2.3 å½±ç‰‡åˆ†æä»»å‹™\n",
    "- 7.1 å¯¦æˆ°å°ˆæ¡ˆé–‹ç™¼\n",
    "\n",
    "### ğŸ† æŒ‘æˆ°å®Œæˆåº¦è‡ªè©•\n",
    "\n",
    "è«‹æ ¹æ“šå®Œæˆæƒ…æ³å‹¾é¸ï¼š\n",
    "\n",
    "- [ ] æˆåŠŸæ¯”è¼ƒäº†è‡³å°‘3ç¨®ä¸åŒçš„ç‰¹å¾µæª¢æ¸¬å™¨\n",
    "- [ ] å¯¦ç¾äº†é­¯æ£’çš„ç‰¹å¾µåŒ¹é…ï¼ˆè™•ç†å°ºåº¦ã€æ—‹è½‰è®ŠåŒ–ï¼‰\n",
    "- [ ] å®Œæˆäº†åœ–åƒé…æº–ä¸¦è©•ä¼°äº†ç²¾åº¦\n",
    "- [ ] å»ºç«‹äº†ç¶œåˆè©•ä¼°ç³»çµ±ä¸¦ç”Ÿæˆäº†å ±å‘Š\n",
    "- [ ] ç†è§£äº†ä¸åŒæ–¹æ³•çš„å„ªç¼ºé»å’Œé©ç”¨å ´æ™¯\n",
    "\n",
    "**å®Œæˆ3é …ä»¥ä¸Šå³å¯é€²å…¥ä¸‹ä¸€å€‹ä¸­ç´šç·´ç¿’ï¼** ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}