#!/usr/bin/env python3
"""
7.4.1 æ“´å¢å¯¦å¢ƒç³»çµ± - æ¨™è¨˜æª¢æ¸¬æ¨¡çµ„

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†æ“´å¢å¯¦å¢ƒä¸­çš„æ¨™è¨˜æª¢æ¸¬èˆ‡è¿½è¹¤åŠŸèƒ½ï¼Œæ”¯æ´ArUcoæ¨™è¨˜ã€
è‡ªå®šç¾©æ¨™è¨˜ã€ä»¥åŠåŸºæ–¼ç‰¹å¾µçš„æ¨™è¨˜æª¢æ¸¬ã€‚

åŠŸèƒ½ç‰¹è‰²ï¼š
- ArUcoæ¨™è¨˜æª¢æ¸¬èˆ‡è­˜åˆ¥
- è‡ªå®šç¾©æ¨™è¨˜æ¨¡æ¿åŒ¹é…
- æ¨™è¨˜å§¿æ…‹ä¼°è¨ˆ (ä½ç½®èˆ‡æ—‹è½‰)
- 3Dåº§æ¨™ç³»çµ±å»ºç«‹
- å¯¦æ™‚è¿½è¹¤èˆ‡ç©©å®š
- å¤šæ¨™è¨˜åŒæ™‚æª¢æ¸¬
- ç›¸æ©Ÿæ¨™å®šæ•´åˆ
- è™›æ“¬ç‰©é«”æŠ•å½±æº–å‚™

ä½œè€…: OpenCV Computer Vision Toolkit
æ—¥æœŸ: 2024-10-14
ç‰ˆæœ¬: 1.0
"""

import cv2
import numpy as np
import os
import sys
import time
import json
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, asdict
from enum import Enum
import math

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('../../utils')
try:
    from image_utils import load_image, resize_image
    from visualization import display_image, display_multiple_images
    from performance import time_function
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥å·¥å…·æ¨¡çµ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MarkerType(Enum):
    """æ¨™è¨˜é¡å‹æšèˆ‰"""
    ARUCO = "ArUco"                    # ArUcoæ¨™è¨˜
    CUSTOM_TEMPLATE = "CustomTemplate" # è‡ªå®šç¾©æ¨¡æ¿
    QR_CODE = "QRCode"                 # QRç¢¼
    FEATURE_BASED = "FeatureBased"     # åŸºæ–¼ç‰¹å¾µçš„æ¨™è¨˜

@dataclass
class MarkerInfo:
    """æ¨™è¨˜ä¿¡æ¯æ•¸æ“šçµæ§‹"""
    marker_id: int
    marker_type: MarkerType
    corners: np.ndarray              # 4å€‹è§’é»åº§æ¨™
    center: Tuple[float, float]      # ä¸­å¿ƒé»
    rotation_vector: np.ndarray      # æ—‹è½‰å‘é‡ (rvec)
    translation_vector: np.ndarray   # å¹³ç§»å‘é‡ (tvec)
    pose_matrix: np.ndarray          # 4x4å§¿æ…‹çŸ©é™£
    confidence: float                # æª¢æ¸¬ç½®ä¿¡åº¦
    size: float                      # æ¨™è¨˜å¤§å° (åƒç´ )

@dataclass
class CameraParameters:
    """ç›¸æ©Ÿåƒæ•¸"""
    camera_matrix: np.ndarray        # å…§åƒçŸ©é™£
    distortion_coeffs: np.ndarray    # ç•¸è®Šä¿‚æ•¸
    image_size: Tuple[int, int]      # åœ–åƒå°ºå¯¸
    is_calibrated: bool = False

class ARMarkerDetector:
    """æ“´å¢å¯¦å¢ƒæ¨™è¨˜æª¢æ¸¬å™¨"""

    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–ARæ¨™è¨˜æª¢æ¸¬å™¨"""
        self.config = self._load_config(config_file)
        self.camera_params = None
        self.aruco_dict = None
        self.aruco_params = None
        self.custom_templates = {}
        self.detection_history = {}  # ç”¨æ–¼è¿½è¹¤ç©©å®šæ€§

        # åˆå§‹åŒ–ArUcoæª¢æ¸¬å™¨
        self._initialize_aruco_detector()

        # è¼‰å…¥è‡ªå®šç¾©æ¨¡æ¿
        self._load_custom_templates()

        logger.info("ARæ¨™è¨˜æª¢æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        default_config = {
            "aruco": {
                "dictionary": "DICT_6X6_250",      # ArUcoå­—å…¸é¡å‹
                "marker_size": 0.1,                # æ¨™è¨˜å¯¦éš›å¤§å° (ç±³)
                "adaptive_thresh_win_size": 7,      # è‡ªé©æ‡‰é–¾å€¼çª—å£å¤§å°
                "adaptive_thresh_constant": 7,      # è‡ªé©æ‡‰é–¾å€¼å¸¸æ•¸
                "min_marker_perimeter": 80,         # æœ€å°æ¨™è¨˜å‘¨é•·
                "max_marker_perimeter": 4000,       # æœ€å¤§æ¨™è¨˜å‘¨é•·
                "accuracy_rate": 0.6,               # æº–ç¢ºç‡é–¾å€¼
                "corner_refinement": True,          # è§’é»ç²¾ç´°åŒ–
                "error_correction_rate": 0.6        # éŒ¯èª¤æ ¡æ­£ç‡
            },
            "custom_template": {
                "template_dir": "templates",        # æ¨¡æ¿ç›®éŒ„
                "match_threshold": 0.8,             # åŒ¹é…é–¾å€¼
                "scale_range": [0.5, 2.0],          # ç¸®æ”¾ç¯„åœ
                "rotation_range": [-30, 30]         # æ—‹è½‰è§’åº¦ç¯„åœ
            },
            "tracking": {
                "enable_tracking": True,            # å•Ÿç”¨è¿½è¹¤
                "tracking_smoothing": 0.7,          # è¿½è¹¤å¹³æ»‘ä¿‚æ•¸
                "max_tracking_frames": 10,          # æœ€å¤§è¿½è¹¤å¹€æ•¸
                "position_threshold": 50,           # ä½ç½®è®ŠåŒ–é–¾å€¼
                "angle_threshold": 30               # è§’åº¦è®ŠåŒ–é–¾å€¼
            },
            "pose_estimation": {
                "enable_pose": True,                # å•Ÿç”¨å§¿æ…‹ä¼°è¨ˆ
                "coordinate_system": "opencv",      # åº§æ¨™ç³»çµ± opencv/opengl
                "axis_length": 0.05,                # åº§æ¨™è»¸é•·åº¦
                "use_pnp_ransac": True              # ä½¿ç”¨RANSAC PnP
            },
            "camera": {
                "auto_calibration": False,          # è‡ªå‹•æ¨™å®š
                "calibration_file": "camera_calibration.json",
                "default_focal_length": 800,       # é è¨­ç„¦è·
                "default_center": [320, 240]       # é è¨­ä¸»é»
            }
        }

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                self._deep_update(default_config, user_config)
                logger.info(f"å·²è¼‰å…¥é…ç½®æ–‡ä»¶: {config_file}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥é…ç½®æ–‡ä»¶: {e}ï¼Œä½¿ç”¨é è¨­é…ç½®")

        return default_config

    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if isinstance(value, dict) and key in base_dict:
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def _initialize_aruco_detector(self):
        """åˆå§‹åŒ–ArUcoæª¢æ¸¬å™¨"""
        try:
            # ç²å–ArUcoå­—å…¸
            dict_name = self.config["aruco"]["dictionary"]
            if hasattr(cv2.aruco, dict_name):
                self.aruco_dict = cv2.aruco.Dictionary_get(getattr(cv2.aruco, dict_name))
            else:
                # å˜—è©¦æ–°ç‰ˆæœ¬OpenCVçš„æ–¹æ³•
                self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)

            # å‰µå»ºæª¢æ¸¬å™¨åƒæ•¸
            if hasattr(cv2.aruco, 'DetectorParameters_create'):
                self.aruco_params = cv2.aruco.DetectorParameters_create()
            else:
                # æ–°ç‰ˆæœ¬OpenCV
                self.aruco_params = cv2.aruco.DetectorParameters()

            # è¨­ç½®åƒæ•¸
            config = self.config["aruco"]
            self.aruco_params.adaptiveThreshWinSizeMin = config["adaptive_thresh_win_size"]
            self.aruco_params.adaptiveThreshWinSizeMax = config["adaptive_thresh_win_size"] * 3
            self.aruco_params.adaptiveThreshConstant = config["adaptive_thresh_constant"]
            self.aruco_params.minMarkerPerimeterRate = config["min_marker_perimeter"] / 1000.0
            self.aruco_params.maxMarkerPerimeterRate = config["max_marker_perimeter"] / 1000.0

            if config["corner_refinement"]:
                self.aruco_params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX

            logger.info("ArUcoæª¢æ¸¬å™¨åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logger.error(f"ArUcoæª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
            self.aruco_dict = None
            self.aruco_params = None

    def _load_custom_templates(self):
        """è¼‰å…¥è‡ªå®šç¾©æ¨™è¨˜æ¨¡æ¿"""
        template_dir = self.config["custom_template"]["template_dir"]

        if os.path.exists(template_dir):
            for filename in os.listdir(template_dir):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                    template_path = os.path.join(template_dir, filename)
                    template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)

                    if template is not None:
                        template_id = os.path.splitext(filename)[0]
                        self.custom_templates[template_id] = template
                        logger.info(f"è¼‰å…¥è‡ªå®šç¾©æ¨¡æ¿: {template_id}")
        else:
            logger.info(f"è‡ªå®šç¾©æ¨¡æ¿ç›®éŒ„ä¸å­˜åœ¨: {template_dir}")

    def load_camera_calibration(self, calibration_file: str = None) -> bool:
        """è¼‰å…¥ç›¸æ©Ÿæ¨™å®šåƒæ•¸"""
        if calibration_file is None:
            calibration_file = self.config["camera"]["calibration_file"]

        try:
            if os.path.exists(calibration_file):
                with open(calibration_file, 'r') as f:
                    calib_data = json.load(f)

                self.camera_params = CameraParameters(
                    camera_matrix=np.array(calib_data["camera_matrix"]),
                    distortion_coeffs=np.array(calib_data["distortion_coeffs"]),
                    image_size=tuple(calib_data["image_size"]),
                    is_calibrated=True
                )

                logger.info("ç›¸æ©Ÿæ¨™å®šåƒæ•¸è¼‰å…¥æˆåŠŸ")
                return True

        except Exception as e:
            logger.warning(f"ç›¸æ©Ÿæ¨™å®šåƒæ•¸è¼‰å…¥å¤±æ•—: {e}")

        # ä½¿ç”¨é è¨­åƒæ•¸
        config = self.config["camera"]
        self.camera_params = CameraParameters(
            camera_matrix=np.array([[config["default_focal_length"], 0, config["default_center"][0]],
                                   [0, config["default_focal_length"], config["default_center"][1]],
                                   [0, 0, 1]], dtype=np.float32),
            distortion_coeffs=np.zeros(5, dtype=np.float32),
            image_size=(640, 480),
            is_calibrated=False
        )

        logger.info("ä½¿ç”¨é è¨­ç›¸æ©Ÿåƒæ•¸")
        return False

    def detect_aruco_markers(self, image: np.ndarray) -> List[MarkerInfo]:
        """æª¢æ¸¬ArUcoæ¨™è¨˜"""
        if self.aruco_dict is None or self.aruco_params is None:
            return []

        try:
            # è½‰æ›ç‚ºç°éš
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            # æª¢æ¸¬æ¨™è¨˜
            if hasattr(cv2.aruco, 'detectMarkers'):
                corners, ids, _ = cv2.aruco.detectMarkers(
                    gray, self.aruco_dict, parameters=self.aruco_params
                )
            else:
                # æ–°ç‰ˆæœ¬OpenCV
                detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.aruco_params)
                corners, ids, _ = detector.detectMarkers(gray)

            markers = []

            if ids is not None and len(ids) > 0:
                for i, marker_id in enumerate(ids.flatten()):
                    corner_points = corners[i][0]

                    # è¨ˆç®—ä¸­å¿ƒé»
                    center = np.mean(corner_points, axis=0)

                    # è¨ˆç®—æ¨™è¨˜å¤§å°
                    size = np.linalg.norm(corner_points[1] - corner_points[0])

                    # å§¿æ…‹ä¼°è¨ˆ
                    rvec, tvec, pose_matrix = self._estimate_pose(corner_points)

                    marker_info = MarkerInfo(
                        marker_id=int(marker_id),
                        marker_type=MarkerType.ARUCO,
                        corners=corner_points,
                        center=(float(center[0]), float(center[1])),
                        rotation_vector=rvec,
                        translation_vector=tvec,
                        pose_matrix=pose_matrix,
                        confidence=1.0,  # ArUcoæª¢æ¸¬é€šå¸¸å¾ˆå¯é 
                        size=float(size)
                    )

                    markers.append(marker_info)

            return markers

        except Exception as e:
            logger.error(f"ArUcoæ¨™è¨˜æª¢æ¸¬å¤±æ•—: {e}")
            return []

    def detect_custom_template_markers(self, image: np.ndarray) -> List[MarkerInfo]:
        """æª¢æ¸¬è‡ªå®šç¾©æ¨¡æ¿æ¨™è¨˜"""
        if not self.custom_templates:
            return []

        markers = []

        try:
            # è½‰æ›ç‚ºç°éš
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            config = self.config["custom_template"]
            threshold = config["match_threshold"]

            for template_id, template in self.custom_templates.items():
                # å¤šå°ºåº¦æ¨¡æ¿åŒ¹é…
                best_match = None
                best_confidence = 0

                scale_range = config["scale_range"]
                for scale in np.arange(scale_range[0], scale_range[1], 0.1):
                    # ç¸®æ”¾æ¨¡æ¿
                    scaled_template = cv2.resize(
                        template,
                        (int(template.shape[1] * scale), int(template.shape[0] * scale))
                    )

                    if (scaled_template.shape[0] > gray.shape[0] or
                        scaled_template.shape[1] > gray.shape[1]):
                        continue

                    # æ¨¡æ¿åŒ¹é…
                    result = cv2.matchTemplate(gray, scaled_template, cv2.TM_CCOEFF_NORMED)
                    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)

                    if max_val > best_confidence:
                        best_confidence = max_val
                        best_match = {
                            'location': max_loc,
                            'scale': scale,
                            'template_size': scaled_template.shape
                        }

                # å¦‚æœæ‰¾åˆ°è¶³å¤ å¥½çš„åŒ¹é…
                if best_match and best_confidence >= threshold:
                    x, y = best_match['location']
                    w, h = best_match['template_size']

                    # æ§‹å»ºè§’é»
                    corners = np.array([
                        [x, y],
                        [x + w, y],
                        [x + w, y + h],
                        [x, y + h]
                    ], dtype=np.float32)

                    # è¨ˆç®—ä¸­å¿ƒé»
                    center = (x + w/2, y + h/2)

                    # å§¿æ…‹ä¼°è¨ˆ
                    rvec, tvec, pose_matrix = self._estimate_pose(corners)

                    marker_info = MarkerInfo(
                        marker_id=hash(template_id) % 1000,  # ç°¡å–®çš„IDæ˜ å°„
                        marker_type=MarkerType.CUSTOM_TEMPLATE,
                        corners=corners,
                        center=center,
                        rotation_vector=rvec,
                        translation_vector=tvec,
                        pose_matrix=pose_matrix,
                        confidence=float(best_confidence),
                        size=float(max(w, h))
                    )

                    markers.append(marker_info)

        except Exception as e:
            logger.error(f"è‡ªå®šç¾©æ¨¡æ¿æª¢æ¸¬å¤±æ•—: {e}")

        return markers

    def _estimate_pose(self, corners: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """ä¼°è¨ˆæ¨™è¨˜å§¿æ…‹"""
        if self.camera_params is None:
            self.load_camera_calibration()

        try:
            # å®šç¾©3Dç‰©ä»¶é»ï¼ˆå‡è¨­æ¨™è¨˜åœ¨XYå¹³é¢ï¼ŒZ=0ï¼‰
            marker_size = self.config["aruco"]["marker_size"]
            object_points = np.array([
                [-marker_size/2, -marker_size/2, 0],
                [ marker_size/2, -marker_size/2, 0],
                [ marker_size/2,  marker_size/2, 0],
                [-marker_size/2,  marker_size/2, 0]
            ], dtype=np.float32)

            # åœ–åƒé»
            image_points = corners.astype(np.float32)

            # ä½¿ç”¨PnPæ±‚è§£å§¿æ…‹
            if self.config["pose_estimation"]["use_pnp_ransac"]:
                success, rvec, tvec, _ = cv2.solvePnPRansac(
                    object_points, image_points,
                    self.camera_params.camera_matrix,
                    self.camera_params.distortion_coeffs
                )
            else:
                success, rvec, tvec = cv2.solvePnP(
                    object_points, image_points,
                    self.camera_params.camera_matrix,
                    self.camera_params.distortion_coeffs
                )

            if success:
                # æ§‹å»º4x4å§¿æ…‹çŸ©é™£
                rotation_matrix, _ = cv2.Rodrigues(rvec)
                pose_matrix = np.eye(4)
                pose_matrix[:3, :3] = rotation_matrix
                pose_matrix[:3, 3] = tvec.flatten()

                return rvec, tvec, pose_matrix
            else:
                # è¿”å›å–®ä½çŸ©é™£ä½œç‚ºé è¨­å€¼
                return (np.zeros(3), np.zeros(3), np.eye(4))

        except Exception as e:
            logger.warning(f"å§¿æ…‹ä¼°è¨ˆå¤±æ•—: {e}")
            return (np.zeros(3), np.zeros(3), np.eye(4))

    def apply_tracking_smoothing(self, current_markers: List[MarkerInfo]) -> List[MarkerInfo]:
        """æ‡‰ç”¨è¿½è¹¤å¹³æ»‘"""
        if not self.config["tracking"]["enable_tracking"]:
            return current_markers

        smoothing_factor = self.config["tracking"]["tracking_smoothing"]
        smoothed_markers = []

        for current_marker in current_markers:
            marker_id = current_marker.marker_id

            if marker_id in self.detection_history:
                # ç²å–æ­·å²æ•¸æ“š
                history = self.detection_history[marker_id]
                last_marker = history[-1]

                # è¨ˆç®—ä½ç½®è®ŠåŒ–
                pos_diff = np.linalg.norm(
                    np.array(current_marker.center) - np.array(last_marker.center)
                )

                # å¦‚æœè®ŠåŒ–ä¸å¤§ï¼Œæ‡‰ç”¨å¹³æ»‘
                if pos_diff < self.config["tracking"]["position_threshold"]:
                    # ä½ç½®å¹³æ»‘
                    smoothed_center = (
                        smoothing_factor * np.array(last_marker.center) +
                        (1 - smoothing_factor) * np.array(current_marker.center)
                    )

                    # å§¿æ…‹å¹³æ»‘ï¼ˆç°¡åŒ–ç‰ˆï¼‰
                    smoothed_rvec = (
                        smoothing_factor * last_marker.rotation_vector +
                        (1 - smoothing_factor) * current_marker.rotation_vector
                    )

                    smoothed_tvec = (
                        smoothing_factor * last_marker.translation_vector +
                        (1 - smoothing_factor) * current_marker.translation_vector
                    )

                    # æ›´æ–°æ¨™è¨˜ä¿¡æ¯
                    current_marker.center = tuple(smoothed_center)
                    current_marker.rotation_vector = smoothed_rvec
                    current_marker.translation_vector = smoothed_tvec

                # æ›´æ–°æ­·å²è¨˜éŒ„
                history.append(current_marker)
                if len(history) > self.config["tracking"]["max_tracking_frames"]:
                    history.pop(0)
            else:
                # ç¬¬ä¸€æ¬¡æª¢æ¸¬åˆ°æ­¤æ¨™è¨˜
                self.detection_history[marker_id] = [current_marker]

            smoothed_markers.append(current_marker)

        return smoothed_markers

    def detect_markers(self, image: np.ndarray) -> List[MarkerInfo]:
        """æª¢æ¸¬æ‰€æœ‰é¡å‹çš„æ¨™è¨˜"""
        all_markers = []

        # æª¢æ¸¬ArUcoæ¨™è¨˜
        aruco_markers = self.detect_aruco_markers(image)
        all_markers.extend(aruco_markers)

        # æª¢æ¸¬è‡ªå®šç¾©æ¨¡æ¿æ¨™è¨˜
        template_markers = self.detect_custom_template_markers(image)
        all_markers.extend(template_markers)

        # æ‡‰ç”¨è¿½è¹¤å¹³æ»‘
        smoothed_markers = self.apply_tracking_smoothing(all_markers)

        return smoothed_markers

    def draw_markers(self, image: np.ndarray, markers: List[MarkerInfo]) -> np.ndarray:
        """ç¹ªè£½æª¢æ¸¬åˆ°çš„æ¨™è¨˜"""
        result = image.copy()

        for marker in markers:
            # ç¹ªè£½æ¨™è¨˜é‚Šæ¡†
            corners = marker.corners.astype(int)

            # ä¸åŒé¡å‹ä½¿ç”¨ä¸åŒé¡è‰²
            if marker.marker_type == MarkerType.ARUCO:
                color = (0, 255, 0)  # ç¶ è‰²
            elif marker.marker_type == MarkerType.CUSTOM_TEMPLATE:
                color = (255, 0, 0)  # è—è‰²
            else:
                color = (0, 0, 255)  # ç´…è‰²

            # ç¹ªè£½é‚Šæ¡†
            cv2.polylines(result, [corners], True, color, 2)

            # ç¹ªè£½ä¸­å¿ƒé»
            center = tuple(map(int, marker.center))
            cv2.circle(result, center, 5, color, -1)

            # é¡¯ç¤ºæ¨™è¨˜ID
            cv2.putText(result, f"ID:{marker.marker_id}",
                       (center[0] + 10, center[1]),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

            # é¡¯ç¤ºç½®ä¿¡åº¦
            if marker.confidence < 1.0:
                cv2.putText(result, f"Conf:{marker.confidence:.2f}",
                           (center[0] + 10, center[1] + 20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            # ç¹ªè£½3Dåº§æ¨™è»¸ï¼ˆå¦‚æœå•Ÿç”¨å§¿æ…‹ä¼°è¨ˆï¼‰
            if (self.config["pose_estimation"]["enable_pose"] and
                self.camera_params is not None):
                self._draw_3d_axis(result, marker)

        return result

    def _draw_3d_axis(self, image: np.ndarray, marker: MarkerInfo):
        """ç¹ªè£½3Dåº§æ¨™è»¸"""
        try:
            axis_length = self.config["pose_estimation"]["axis_length"]

            # å®šç¾©åº§æ¨™è»¸ç«¯é»
            axis_points = np.array([
                [0, 0, 0],           # åŸé»
                [axis_length, 0, 0], # Xè»¸
                [0, axis_length, 0], # Yè»¸
                [0, 0, -axis_length] # Zè»¸
            ], dtype=np.float32)

            # æŠ•å½±åˆ°åœ–åƒå¹³é¢
            projected_points, _ = cv2.projectPoints(
                axis_points,
                marker.rotation_vector,
                marker.translation_vector,
                self.camera_params.camera_matrix,
                self.camera_params.distortion_coeffs
            )

            # è½‰æ›ç‚ºæ•´æ•¸åº§æ¨™
            points = projected_points.reshape(-1, 2).astype(int)
            origin = tuple(points[0])

            # ç¹ªè£½åº§æ¨™è»¸
            # Xè»¸ - ç´…è‰²
            cv2.line(image, origin, tuple(points[1]), (0, 0, 255), 3)
            # Yè»¸ - ç¶ è‰²
            cv2.line(image, origin, tuple(points[2]), (0, 255, 0), 3)
            # Zè»¸ - è—è‰²
            cv2.line(image, origin, tuple(points[3]), (255, 0, 0), 3)

        except Exception as e:
            logger.warning(f"3Dåº§æ¨™è»¸ç¹ªè£½å¤±æ•—: {e}")


def create_sample_aruco_markers():
    """å‰µå»ºç¯„ä¾‹ArUcoæ¨™è¨˜"""
    try:
        # ç²å–ArUcoå­—å…¸
        aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_250)

        # å‰µå»ºå¹¾å€‹æ¨™è¨˜
        marker_ids = [0, 1, 2, 3, 4]
        marker_size = 200

        print("ğŸ“„ å‰µå»ºç¯„ä¾‹ArUcoæ¨™è¨˜...")

        for marker_id in marker_ids:
            # ç”Ÿæˆæ¨™è¨˜
            marker_image = cv2.aruco.drawMarker(aruco_dict, marker_id, marker_size)

            # å„²å­˜æ¨™è¨˜
            filename = f"aruco_marker_{marker_id}.png"
            cv2.imwrite(filename, marker_image)
            print(f"  å‰µå»ºæ¨™è¨˜: {filename}")

        print("âœ… ArUcoæ¨™è¨˜å‰µå»ºå®Œæˆï¼")
        print("ğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
        print("  1. åˆ—å°é€™äº›æ¨™è¨˜åœ–ç‰‡")
        print("  2. å°‡æ¨™è¨˜æ”¾åœ¨æ”åƒé ­å‰")
        print("  3. é‹è¡Œæª¢æ¸¬æ¼”ç¤º")

    except Exception as e:
        print(f"âŒ ArUcoæ¨™è¨˜å‰µå»ºå¤±æ•—: {e}")


def demo_ar_marker_detection():
    """ARæ¨™è¨˜æª¢æ¸¬æ¼”ç¤º"""
    print("ğŸ¯ æ“´å¢å¯¦å¢ƒæ¨™è¨˜æª¢æ¸¬æ¼”ç¤º")
    print("=" * 50)

    # å‰µå»ºæª¢æ¸¬å™¨
    detector = ARMarkerDetector()

    # å‰µå»ºç¯„ä¾‹æ¨™è¨˜
    create_sample_aruco_markers()

    # å˜—è©¦è¼‰å…¥æ¸¬è©¦åœ–åƒ
    test_image_path = "../../assets/images/basic/faces01.jpg"

    if os.path.exists(test_image_path):
        print(f"\nğŸ–¼ï¸  æ¸¬è©¦éœæ…‹åœ–åƒ: {os.path.basename(test_image_path)}")

        # è¼‰å…¥åœ–åƒ
        test_image = load_image(test_image_path)
        test_image = resize_image(test_image, max_width=800)

        # æª¢æ¸¬æ¨™è¨˜
        markers = detector.detect_markers(test_image)

        print(f"ğŸ“Š æª¢æ¸¬çµæœ: æ‰¾åˆ° {len(markers)} å€‹æ¨™è¨˜")

        # ç¹ªè£½çµæœ
        result_image = detector.draw_markers(test_image, markers)

        # é¡¯ç¤ºçµæœ
        display_multiple_images(
            [test_image, result_image],
            ["åŸå§‹åœ–åƒ", f"æª¢æ¸¬çµæœ ({len(markers)} æ¨™è¨˜)"],
            figsize=(12, 6)
        )

    print("\nğŸ¥ æ”åƒé ­å¯¦æ™‚æª¢æ¸¬æ¼”ç¤º")
    print("æ“ä½œèªªæ˜:")
    print("  æŒ‰ 'q' æˆ– ESC é€€å‡º")
    print("  æŒ‰ 's' å„²å­˜ç•¶å‰å¹€")
    print("  æŒ‰ 'c' å‰µå»ºæ–°çš„ArUcoæ¨™è¨˜")
    print("  å°‡åˆ—å°çš„ArUcoæ¨™è¨˜æ”¾åœ¨æ”åƒé ­å‰é€²è¡Œæª¢æ¸¬")

    # å˜—è©¦é–‹å•Ÿæ”åƒé ­
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ç„¡æ³•é–‹å•Ÿæ”åƒé ­")
        return

    frame_count = 0

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("âŒ ç„¡æ³•è®€å–æ”åƒé ­å¹€")
                break

            frame_count += 1

            # æª¢æ¸¬æ¨™è¨˜
            start_time = time.time()
            markers = detector.detect_markers(frame)
            detection_time = (time.time() - start_time) * 1000

            # ç¹ªè£½çµæœ
            result_frame = detector.draw_markers(frame, markers)

            # æ·»åŠ ä¿¡æ¯é¡¯ç¤º
            info_text = [
                f"å¹€æ•¸: {frame_count}",
                f"æª¢æ¸¬æ™‚é–“: {detection_time:.1f}ms",
                f"æ¨™è¨˜æ•¸é‡: {len(markers)}"
            ]

            for i, text in enumerate(info_text):
                cv2.putText(result_frame, text, (10, 30 + i * 25),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            # é¡¯ç¤ºæª¢æ¸¬åˆ°çš„æ¨™è¨˜ä¿¡æ¯
            y_offset = 120
            for marker in markers:
                info = f"ID:{marker.marker_id} Type:{marker.marker_type.value}"
                cv2.putText(result_frame, info, (10, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
                y_offset += 20

            # é¡¯ç¤ºçµæœ
            cv2.imshow('AR Marker Detection', result_frame)

            # æŒ‰éµè™•ç†
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == 27:  # 'q' æˆ– ESC
                break
            elif key == ord('s'):  # å„²å­˜æˆªåœ–
                timestamp = time.strftime('%Y%m%d_%H%M%S')
                filename = f"ar_detection_{timestamp}.jpg"
                cv2.imwrite(filename, result_frame)
                print(f"ğŸ“¸ å·²å„²å­˜æˆªåœ–: {filename}")
            elif key == ord('c'):  # å‰µå»ºæ–°æ¨™è¨˜
                print("ğŸ”„ å‰µå»ºæ–°çš„ArUcoæ¨™è¨˜...")
                create_sample_aruco_markers()

    except KeyboardInterrupt:
        print("\nâš ï¸ æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿ")
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("ğŸ‘‹ ARæ¨™è¨˜æª¢æ¸¬æ¼”ç¤ºçµæŸ")

    # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
    print(f"\nğŸ“Š æœƒè©±çµ±è¨ˆ:")
    print(f"  ç¸½è™•ç†å¹€æ•¸: {frame_count}")
    print(f"  æ¨™è¨˜æª¢æ¸¬æ­·å²: {len(detector.detection_history)} å€‹æ¨™è¨˜")

    print("\nğŸ¯ ä¸‹ä¸€æ­¥å¯ä»¥å˜—è©¦:")
    print("â€¢ åˆ—å°å‰µå»ºçš„ArUcoæ¨™è¨˜ä¸¦é€²è¡Œæª¢æ¸¬")
    print("â€¢ æ·»åŠ è‡ªå®šç¾©æ¨™è¨˜æ¨¡æ¿")
    print("â€¢ æ•´åˆç›¸æ©Ÿæ¨™å®šä»¥ç²å¾—æ›´æº–ç¢ºçš„å§¿æ…‹ä¼°è¨ˆ")
    print("â€¢ åŸºæ–¼æª¢æ¸¬çµæœæ·»åŠ è™›æ“¬ç‰©é«”æ¸²æŸ“")


if __name__ == "__main__":
    demo_ar_marker_detection()