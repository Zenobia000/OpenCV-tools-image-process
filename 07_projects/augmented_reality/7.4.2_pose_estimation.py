#!/usr/bin/env python3
"""
7.4.2 æ“´å¢å¯¦å¢ƒç³»çµ± - å§¿æ…‹ä¼°è¨ˆæ¨¡çµ„

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†é«˜ç²¾åº¦çš„3Då§¿æ…‹ä¼°è¨ˆåŠŸèƒ½ï¼ŒåŒ…æ‹¬6è‡ªç”±åº¦(6DOF)ä½ç½®è¿½è¹¤ã€
å§¿æ…‹ç©©å®šåŒ–ã€ç›¸æ©Ÿæ¨™å®šã€åº§æ¨™ç³»çµ±è½‰æ›ç­‰åŠŸèƒ½ã€‚

åŠŸèƒ½ç‰¹è‰²ï¼š
- 6DOFå§¿æ…‹ä¼°è¨ˆ (3è»¸ä½ç½® + 3è»¸æ—‹è½‰)
- å¤šç¨®PnPæ±‚è§£ç®—æ³•
- å§¿æ…‹è¿½è¹¤ç©©å®šåŒ–
- ç›¸æ©Ÿæ¨™å®šèˆ‡ç•¸è®Šæ ¡æ­£
- åº§æ¨™ç³»çµ±è½‰æ› (OpenCV â†” OpenGL)
- å§¿æ…‹é æ¸¬èˆ‡æ’å€¼
- 3Dç‰©é«”æ¸²æŸ“æº–å‚™
- å¯¦æ™‚æ€§èƒ½å„ªåŒ–

ä½œè€…: OpenCV Computer Vision Toolkit
æ—¥æœŸ: 2024-10-14
ç‰ˆæœ¬: 1.0
"""

import cv2
import numpy as np
import os
import sys
import time
import json
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, asdict
from enum import Enum
import math
from collections import deque
import threading

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('../../utils')
try:
    from image_utils import load_image, resize_image
    from visualization import display_image, display_multiple_images
    from performance import time_function
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥å·¥å…·æ¨¡çµ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PnPMethod(Enum):
    """PnPæ±‚è§£æ–¹æ³•"""
    ITERATIVE = cv2.SOLVEPNP_ITERATIVE
    EPNP = cv2.SOLVEPNP_EPNP
    P3P = cv2.SOLVEPNP_P3P
    DLS = cv2.SOLVEPNP_DLS
    UPNP = cv2.SOLVEPNP_UPNP
    AP3P = cv2.SOLVEPNP_AP3P
    IPPE = cv2.SOLVEPNP_IPPE
    IPPE_SQUARE = cv2.SOLVEPNP_IPPE_SQUARE

class CoordinateSystem(Enum):
    """åº§æ¨™ç³»çµ±é¡å‹"""
    OPENCV = "opencv"      # OpenCVåº§æ¨™ç³»çµ± (Yå‘ä¸‹)
    OPENGL = "opengl"      # OpenGLåº§æ¨™ç³»çµ± (Yå‘ä¸Š)
    UNITY = "unity"        # Unityåº§æ¨™ç³»çµ±
    ROS = "ros"           # ROSåº§æ¨™ç³»çµ±

@dataclass
class Pose6DOF:
    """6è‡ªç”±åº¦å§¿æ…‹"""
    position: np.ndarray       # 3Dä½ç½® [x, y, z]
    rotation: np.ndarray       # æ—‹è½‰å‘é‡ [rx, ry, rz]
    rotation_matrix: np.ndarray # 3x3æ—‹è½‰çŸ©é™£
    quaternion: np.ndarray     # å››å…ƒæ•¸è¡¨ç¤º [w, x, y, z]
    euler_angles: np.ndarray   # æ­æ‹‰è§’ [roll, pitch, yaw]
    pose_matrix: np.ndarray    # 4x4é½Šæ¬¡è®Šæ›çŸ©é™£
    confidence: float          # ä¼°è¨ˆç½®ä¿¡åº¦
    timestamp: float           # æ™‚é–“æˆ³

@dataclass
class CameraCalibration:
    """ç›¸æ©Ÿæ¨™å®šæ•¸æ“š"""
    camera_matrix: np.ndarray      # å…§åƒçŸ©é™£ K
    distortion_coeffs: np.ndarray  # ç•¸è®Šä¿‚æ•¸
    image_size: Tuple[int, int]    # åœ–åƒå°ºå¯¸
    reprojection_error: float      # é‡æŠ•å½±èª¤å·®
    calibration_date: str          # æ¨™å®šæ—¥æœŸ
    is_valid: bool                 # æ˜¯å¦æœ‰æ•ˆ

class ARPoseEstimator:
    """ARå§¿æ…‹ä¼°è¨ˆå™¨"""

    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–å§¿æ…‹ä¼°è¨ˆå™¨"""
        self.config = self._load_config(config_file)
        self.camera_calibration = None
        self.pose_history = deque(maxlen=30)  # å§¿æ…‹æ­·å²ç”¨æ–¼ç©©å®šåŒ–
        self.pose_predictor = None

        # è¼‰å…¥ç›¸æ©Ÿæ¨™å®š
        self._load_camera_calibration()

        # åˆå§‹åŒ–å§¿æ…‹è¿½è¹¤
        self._initialize_pose_tracking()

        logger.info("ARå§¿æ…‹ä¼°è¨ˆå™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        default_config = {
            "pose_estimation": {
                "pnp_method": "EPNP",          # PnPæ±‚è§£æ–¹æ³•
                "use_ransac": True,            # ä½¿ç”¨RANSAC
                "ransac_threshold": 3.0,       # RANSACé–¾å€¼
                "ransac_confidence": 0.99,     # RANSACç½®ä¿¡åº¦
                "min_inliers": 4,              # æœ€å°å…§é»æ•¸
                "coordinate_system": "opencv"   # åº§æ¨™ç³»çµ±
            },
            "tracking": {
                "enable_smoothing": True,      # å•Ÿç”¨å§¿æ…‹å¹³æ»‘
                "smoothing_factor": 0.7,       # å¹³æ»‘ä¿‚æ•¸
                "prediction": True,            # å•Ÿç”¨å§¿æ…‹é æ¸¬
                "max_tracking_error": 50,      # æœ€å¤§è¿½è¹¤èª¤å·®
                "tracking_timeout": 1.0        # è¿½è¹¤è¶…æ™‚(ç§’)
            },
            "camera": {
                "calibration_file": "camera_calibration.json",
                "auto_calibration": False,
                "default_focal_length": 800,
                "default_principal_point": [320, 240],
                "distortion_correction": True
            },
            "optimization": {
                "subpixel_refinement": True,   # äºåƒç´ ç²¾ç´°åŒ–
                "iterative_refinement": True,  # è¿­ä»£ç²¾ç´°åŒ–
                "max_iterations": 20,          # æœ€å¤§è¿­ä»£æ¬¡æ•¸
                "convergence_threshold": 0.01  # æ”¶æ–‚é–¾å€¼
            },
            "quality_control": {
                "validate_pose": True,         # é©—è­‰å§¿æ…‹åˆç†æ€§
                "max_position_change": 100,    # æœ€å¤§ä½ç½®è®ŠåŒ–
                "max_rotation_change": 30,     # æœ€å¤§æ—‹è½‰è®ŠåŒ–(åº¦)
                "stability_check": True        # ç©©å®šæ€§æª¢æŸ¥
            }
        }

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                self._deep_update(default_config, user_config)
                logger.info(f"å·²è¼‰å…¥é…ç½®æ–‡ä»¶: {config_file}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥é…ç½®æ–‡ä»¶: {e}ï¼Œä½¿ç”¨é è¨­é…ç½®")

        return default_config

    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if isinstance(value, dict) and key in base_dict:
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def _load_camera_calibration(self):
        """è¼‰å…¥ç›¸æ©Ÿæ¨™å®šåƒæ•¸"""
        calib_file = self.config["camera"]["calibration_file"]

        try:
            if os.path.exists(calib_file):
                with open(calib_file, 'r') as f:
                    calib_data = json.load(f)

                self.camera_calibration = CameraCalibration(
                    camera_matrix=np.array(calib_data["camera_matrix"], dtype=np.float32),
                    distortion_coeffs=np.array(calib_data["distortion_coeffs"], dtype=np.float32),
                    image_size=tuple(calib_data["image_size"]),
                    reprojection_error=calib_data.get("reprojection_error", 0.0),
                    calibration_date=calib_data.get("calibration_date", "unknown"),
                    is_valid=True
                )

                logger.info(f"ç›¸æ©Ÿæ¨™å®šåƒæ•¸è¼‰å…¥æˆåŠŸï¼Œé‡æŠ•å½±èª¤å·®: {self.camera_calibration.reprojection_error:.3f}")
                return

        except Exception as e:
            logger.warning(f"ç›¸æ©Ÿæ¨™å®šè¼‰å…¥å¤±æ•—: {e}")

        # ä½¿ç”¨é è¨­åƒæ•¸
        camera_config = self.config["camera"]
        focal_length = camera_config["default_focal_length"]
        cx, cy = camera_config["default_principal_point"]

        self.camera_calibration = CameraCalibration(
            camera_matrix=np.array([
                [focal_length, 0, cx],
                [0, focal_length, cy],
                [0, 0, 1]
            ], dtype=np.float32),
            distortion_coeffs=np.zeros(5, dtype=np.float32),
            image_size=(640, 480),
            reprojection_error=0.0,
            calibration_date="default",
            is_valid=False
        )

        logger.info("ä½¿ç”¨é è¨­ç›¸æ©Ÿåƒæ•¸")

    def _initialize_pose_tracking(self):
        """åˆå§‹åŒ–å§¿æ…‹è¿½è¹¤"""
        # å§¿æ…‹é æ¸¬å™¨ï¼ˆç°¡å–®çš„ç·šæ€§é æ¸¬ï¼‰
        if self.config["tracking"]["prediction"]:
            self.pose_predictor = SimplePosePredictor()

    def estimate_pose(self, object_points: np.ndarray, image_points: np.ndarray,
                     marker_id: int = 0) -> Optional[Pose6DOF]:
        """ä¼°è¨ˆ6DOFå§¿æ…‹"""
        if self.camera_calibration is None:
            logger.error("ç›¸æ©Ÿæ¨™å®šåƒæ•¸æœªè¼‰å…¥")
            return None

        if len(object_points) < 4 or len(image_points) < 4:
            logger.warning("é»æ•¸ä¸è¶³ï¼Œè‡³å°‘éœ€è¦4å€‹é»")
            return None

        try:
            start_time = time.time()

            # ç¢ºä¿é»çš„æ ¼å¼æ­£ç¢º
            object_points = object_points.astype(np.float32)
            image_points = image_points.astype(np.float32)

            # ç²å–PnPæ–¹æ³•
            pnp_method_name = self.config["pose_estimation"]["pnp_method"]
            pnp_method = getattr(PnPMethod, pnp_method_name).value

            # æ±‚è§£PnPå•é¡Œ
            if self.config["pose_estimation"]["use_ransac"]:
                success, rvec, tvec, inliers = cv2.solvePnPRansac(
                    object_points,
                    image_points,
                    self.camera_calibration.camera_matrix,
                    self.camera_calibration.distortion_coeffs,
                    reprojectionError=self.config["pose_estimation"]["ransac_threshold"],
                    confidence=self.config["pose_estimation"]["ransac_confidence"],
                    flags=pnp_method
                )

                inlier_count = len(inliers) if inliers is not None else 0
                confidence = inlier_count / len(image_points) if len(image_points) > 0 else 0

            else:
                success, rvec, tvec = cv2.solvePnP(
                    object_points,
                    image_points,
                    self.camera_calibration.camera_matrix,
                    self.camera_calibration.distortion_coeffs,
                    flags=pnp_method
                )

                confidence = 1.0  # ç„¡RANSACæ™‚å‡è¨­æ»¿ç½®ä¿¡åº¦

            if not success:
                logger.warning("PnPæ±‚è§£å¤±æ•—")
                return None

            # è¿­ä»£ç²¾ç´°åŒ–ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.config["optimization"]["iterative_refinement"]:
                rvec, tvec = self._refine_pose_iteratively(
                    rvec, tvec, object_points, image_points
                )

            # è½‰æ›æ—‹è½‰å‘é‡åˆ°æ—‹è½‰çŸ©é™£
            rotation_matrix, _ = cv2.Rodrigues(rvec)

            # è¨ˆç®—å››å…ƒæ•¸
            quaternion = self._rotation_matrix_to_quaternion(rotation_matrix)

            # è¨ˆç®—æ­æ‹‰è§’
            euler_angles = self._rotation_matrix_to_euler(rotation_matrix)

            # æ§‹å»º4x4å§¿æ…‹çŸ©é™£
            pose_matrix = np.eye(4)
            pose_matrix[:3, :3] = rotation_matrix
            pose_matrix[:3, 3] = tvec.flatten()

            # å‰µå»ºå§¿æ…‹å°è±¡
            pose = Pose6DOF(
                position=tvec.flatten(),
                rotation=rvec.flatten(),
                rotation_matrix=rotation_matrix,
                quaternion=quaternion,
                euler_angles=euler_angles,
                pose_matrix=pose_matrix,
                confidence=confidence,
                timestamp=time.time()
            )

            # åº§æ¨™ç³»çµ±è½‰æ›ï¼ˆå¦‚æœéœ€è¦ï¼‰
            target_system = self.config["pose_estimation"]["coordinate_system"]
            if target_system != "opencv":
                pose = self._convert_coordinate_system(pose, target_system)

            # å§¿æ…‹é©—è­‰
            if self.config["quality_control"]["validate_pose"]:
                if not self._validate_pose(pose, marker_id):
                    logger.warning(f"å§¿æ…‹é©—è­‰å¤±æ•—: marker {marker_id}")
                    return None

            # å§¿æ…‹å¹³æ»‘
            if self.config["tracking"]["enable_smoothing"]:
                pose = self._apply_pose_smoothing(pose, marker_id)

            # è¨˜éŒ„å§¿æ…‹æ­·å²
            self.pose_history.append(pose)

            processing_time = (time.time() - start_time) * 1000
            logger.debug(f"å§¿æ…‹ä¼°è¨ˆå®Œæˆï¼Œè€—æ™‚ {processing_time:.1f}msï¼Œç½®ä¿¡åº¦ {confidence:.3f}")

            return pose

        except Exception as e:
            logger.error(f"å§¿æ…‹ä¼°è¨ˆå¤±æ•—: {e}")
            return None

    def _refine_pose_iteratively(self, rvec: np.ndarray, tvec: np.ndarray,
                               object_points: np.ndarray,
                               image_points: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """è¿­ä»£ç²¾ç´°åŒ–å§¿æ…‹"""
        config = self.config["optimization"]
        max_iterations = config["max_iterations"]
        threshold = config["convergence_threshold"]

        for iteration in range(max_iterations):
            # é‡æŠ•å½±ç•¶å‰å§¿æ…‹
            projected_points, _ = cv2.projectPoints(
                object_points, rvec, tvec,
                self.camera_calibration.camera_matrix,
                self.camera_calibration.distortion_coeffs
            )

            # è¨ˆç®—é‡æŠ•å½±èª¤å·®
            error = np.mean(np.linalg.norm(
                projected_points.reshape(-1, 2) - image_points, axis=1
            ))

            if error < threshold:
                break

            # ä½¿ç”¨ç•¶å‰å§¿æ…‹ä½œç‚ºåˆå§‹çŒœæ¸¬é‡æ–°æ±‚è§£
            success, rvec_new, tvec_new = cv2.solvePnP(
                object_points, image_points,
                self.camera_calibration.camera_matrix,
                self.camera_calibration.distortion_coeffs,
                rvec, tvec, True  # ä½¿ç”¨åˆå§‹çŒœæ¸¬
            )

            if success:
                rvec, tvec = rvec_new, tvec_new

        return rvec, tvec

    def _rotation_matrix_to_quaternion(self, R: np.ndarray) -> np.ndarray:
        """æ—‹è½‰çŸ©é™£è½‰å››å…ƒæ•¸"""
        trace = np.trace(R)

        if trace > 0:
            S = np.sqrt(trace + 1.0) * 2  # S = 4 * qw
            qw = 0.25 * S
            qx = (R[2, 1] - R[1, 2]) / S
            qy = (R[0, 2] - R[2, 0]) / S
            qz = (R[1, 0] - R[0, 1]) / S
        elif R[0, 0] > R[1, 1] and R[0, 0] > R[2, 2]:
            S = np.sqrt(1.0 + R[0, 0] - R[1, 1] - R[2, 2]) * 2  # S = 4 * qx
            qw = (R[2, 1] - R[1, 2]) / S
            qx = 0.25 * S
            qy = (R[0, 1] + R[1, 0]) / S
            qz = (R[0, 2] + R[2, 0]) / S
        elif R[1, 1] > R[2, 2]:
            S = np.sqrt(1.0 + R[1, 1] - R[0, 0] - R[2, 2]) * 2  # S = 4 * qy
            qw = (R[0, 2] - R[2, 0]) / S
            qx = (R[0, 1] + R[1, 0]) / S
            qy = 0.25 * S
            qz = (R[1, 2] + R[2, 1]) / S
        else:
            S = np.sqrt(1.0 + R[2, 2] - R[0, 0] - R[1, 1]) * 2  # S = 4 * qz
            qw = (R[1, 0] - R[0, 1]) / S
            qx = (R[0, 2] + R[2, 0]) / S
            qy = (R[1, 2] + R[2, 1]) / S
            qz = 0.25 * S

        return np.array([qw, qx, qy, qz])

    def _rotation_matrix_to_euler(self, R: np.ndarray) -> np.ndarray:
        """æ—‹è½‰çŸ©é™£è½‰æ­æ‹‰è§’ (XYZé †åº)"""
        sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])

        singular = sy < 1e-6

        if not singular:
            roll = math.atan2(R[2, 1], R[2, 2])
            pitch = math.atan2(-R[2, 0], sy)
            yaw = math.atan2(R[1, 0], R[0, 0])
        else:
            roll = math.atan2(-R[1, 2], R[1, 1])
            pitch = math.atan2(-R[2, 0], sy)
            yaw = 0

        return np.array([roll, pitch, yaw])

    def _convert_coordinate_system(self, pose: Pose6DOF,
                                 target_system: str) -> Pose6DOF:
        """è½‰æ›åº§æ¨™ç³»çµ±"""
        if target_system == "opencv":
            return pose  # å·²ç¶“æ˜¯OpenCVåº§æ¨™ç³»çµ±

        elif target_system == "opengl":
            # OpenCV to OpenGL: Yå’ŒZè»¸ç¿»è½‰
            conversion_matrix = np.array([
                [1,  0,  0, 0],
                [0, -1,  0, 0],
                [0,  0, -1, 0],
                [0,  0,  0, 1]
            ])

            # è½‰æ›å§¿æ…‹çŸ©é™£
            new_pose_matrix = conversion_matrix @ pose.pose_matrix @ conversion_matrix

            # æå–æ–°çš„æ—‹è½‰å’Œå¹³ç§»
            new_rotation_matrix = new_pose_matrix[:3, :3]
            new_position = new_pose_matrix[:3, 3]

            # æ›´æ–°å§¿æ…‹å°è±¡
            pose.pose_matrix = new_pose_matrix
            pose.rotation_matrix = new_rotation_matrix
            pose.position = new_position
            pose.rotation, _ = cv2.Rodrigues(new_rotation_matrix)
            pose.quaternion = self._rotation_matrix_to_quaternion(new_rotation_matrix)
            pose.euler_angles = self._rotation_matrix_to_euler(new_rotation_matrix)

        return pose

    def _validate_pose(self, pose: Pose6DOF, marker_id: int) -> bool:
        """é©—è­‰å§¿æ…‹çš„åˆç†æ€§"""
        config = self.config["quality_control"]

        # æª¢æŸ¥ä½ç½®æ˜¯å¦åœ¨åˆç†ç¯„åœå…§
        position_magnitude = np.linalg.norm(pose.position)
        if position_magnitude > 10.0:  # 10ç±³å¤–èªç‚ºä¸åˆç†
            logger.warning(f"ä½ç½®è·é›¢éé : {position_magnitude:.2f}m")
            return False

        # æª¢æŸ¥èˆ‡æ­·å²å§¿æ…‹çš„ä¸€è‡´æ€§
        if len(self.pose_history) > 0:
            last_pose = self.pose_history[-1]

            # ä½ç½®è®ŠåŒ–æª¢æŸ¥
            position_change = np.linalg.norm(pose.position - last_pose.position)
            max_position_change = config["max_position_change"] / 1000.0  # è½‰æ›ç‚ºç±³

            if position_change > max_position_change:
                logger.warning(f"ä½ç½®è®ŠåŒ–éå¤§: {position_change:.3f}m")
                return False

            # æ—‹è½‰è®ŠåŒ–æª¢æŸ¥
            rotation_change = np.linalg.norm(pose.rotation - last_pose.rotation)
            max_rotation_change = math.radians(config["max_rotation_change"])

            if rotation_change > max_rotation_change:
                logger.warning(f"æ—‹è½‰è®ŠåŒ–éå¤§: {math.degrees(rotation_change):.1f}åº¦")
                return False

        return True

    def _apply_pose_smoothing(self, pose: Pose6DOF, marker_id: int) -> Pose6DOF:
        """æ‡‰ç”¨å§¿æ…‹å¹³æ»‘"""
        if len(self.pose_history) == 0:
            return pose

        smoothing_factor = self.config["tracking"]["smoothing_factor"]
        last_pose = self.pose_history[-1]

        # ä½ç½®å¹³æ»‘
        smoothed_position = (smoothing_factor * last_pose.position +
                           (1 - smoothing_factor) * pose.position)

        # æ—‹è½‰å¹³æ»‘ï¼ˆä½¿ç”¨çƒé¢ç·šæ€§æ’å€¼SLERPçš„ç°¡åŒ–ç‰ˆï¼‰
        smoothed_rotation = (smoothing_factor * last_pose.rotation +
                           (1 - smoothing_factor) * pose.rotation)

        # æ›´æ–°å§¿æ…‹
        pose.position = smoothed_position
        pose.rotation = smoothed_rotation

        # é‡æ–°è¨ˆç®—ç›¸é—œå±¬æ€§
        pose.rotation_matrix, _ = cv2.Rodrigues(pose.rotation)
        pose.quaternion = self._rotation_matrix_to_quaternion(pose.rotation_matrix)
        pose.euler_angles = self._rotation_matrix_to_euler(pose.rotation_matrix)

        # é‡æ§‹å§¿æ…‹çŸ©é™£
        pose.pose_matrix = np.eye(4)
        pose.pose_matrix[:3, :3] = pose.rotation_matrix
        pose.pose_matrix[:3, 3] = pose.position

        return pose

    def draw_3d_axes(self, image: np.ndarray, pose: Pose6DOF,
                    axis_length: float = 0.1) -> np.ndarray:
        """ç¹ªè£½3Dåº§æ¨™è»¸"""
        try:
            # å®šç¾©3Dåº§æ¨™è»¸ç«¯é»
            axis_points_3d = np.array([
                [0, 0, 0],              # åŸé»
                [axis_length, 0, 0],    # Xè»¸ (ç´…è‰²)
                [0, axis_length, 0],    # Yè»¸ (ç¶ è‰²)
                [0, 0, -axis_length]    # Zè»¸ (è—è‰²)
            ], dtype=np.float32)

            # æŠ•å½±åˆ°åœ–åƒå¹³é¢
            projected_points, _ = cv2.projectPoints(
                axis_points_3d,
                pose.rotation,
                pose.position,
                self.camera_calibration.camera_matrix,
                self.camera_calibration.distortion_coeffs
            )

            # è½‰æ›ç‚ºæ•´æ•¸åº§æ¨™
            points = projected_points.reshape(-1, 2).astype(int)
            origin = tuple(points[0])
            x_end = tuple(points[1])
            y_end = tuple(points[2])
            z_end = tuple(points[3])

            result = image.copy()

            # ç¹ªè£½åº§æ¨™è»¸
            cv2.line(result, origin, x_end, (0, 0, 255), 5)    # Xè»¸ - ç´…è‰²
            cv2.line(result, origin, y_end, (0, 255, 0), 5)    # Yè»¸ - ç¶ è‰²
            cv2.line(result, origin, z_end, (255, 0, 0), 5)    # Zè»¸ - è—è‰²

            # æ·»åŠ è»¸æ¨™ç±¤
            cv2.putText(result, 'X', x_end, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            cv2.putText(result, 'Y', y_end, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            cv2.putText(result, 'Z', z_end, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

            return result

        except Exception as e:
            logger.warning(f"3Dåº§æ¨™è»¸ç¹ªè£½å¤±æ•—: {e}")
            return image

    def draw_virtual_cube(self, image: np.ndarray, pose: Pose6DOF,
                         cube_size: float = 0.1) -> np.ndarray:
        """ç¹ªè£½è™›æ“¬ç«‹æ–¹é«”"""
        try:
            # å®šç¾©ç«‹æ–¹é«”çš„8å€‹é ‚é»
            half_size = cube_size / 2
            cube_points_3d = np.array([
                # åº•é¢
                [-half_size, -half_size, 0],
                [ half_size, -half_size, 0],
                [ half_size,  half_size, 0],
                [-half_size,  half_size, 0],
                # é ‚é¢
                [-half_size, -half_size, -cube_size],
                [ half_size, -half_size, -cube_size],
                [ half_size,  half_size, -cube_size],
                [-half_size,  half_size, -cube_size]
            ], dtype=np.float32)

            # æŠ•å½±åˆ°åœ–åƒå¹³é¢
            projected_points, _ = cv2.projectPoints(
                cube_points_3d,
                pose.rotation,
                pose.position,
                self.camera_calibration.camera_matrix,
                self.camera_calibration.distortion_coeffs
            )

            # è½‰æ›ç‚ºæ•´æ•¸åº§æ¨™
            points = projected_points.reshape(-1, 2).astype(int)

            result = image.copy()

            # å®šç¾©ç«‹æ–¹é«”çš„é‚Š
            edges = [
                # åº•é¢
                (0, 1), (1, 2), (2, 3), (3, 0),
                # é ‚é¢
                (4, 5), (5, 6), (6, 7), (7, 4),
                # å‚ç›´é‚Š
                (0, 4), (1, 5), (2, 6), (3, 7)
            ]

            # ç¹ªè£½ç«‹æ–¹é«”é‚Šç·š
            for start, end in edges:
                pt1 = tuple(points[start])
                pt2 = tuple(points[end])
                cv2.line(result, pt1, pt2, (255, 255, 0), 2)

            # å¡«å……é ‚é¢ï¼ˆåŠé€æ˜ï¼‰
            top_points = points[4:8]
            overlay = result.copy()
            cv2.fillPoly(overlay, [top_points], (0, 255, 255))
            result = cv2.addWeighted(result, 0.7, overlay, 0.3, 0)

            return result

        except Exception as e:
            logger.warning(f"è™›æ“¬ç«‹æ–¹é«”ç¹ªè£½å¤±æ•—: {e}")
            return image

    def calculate_pose_stability(self, window_size: int = 10) -> Dict[str, float]:
        """è¨ˆç®—å§¿æ…‹ç©©å®šæ€§"""
        if len(self.pose_history) < window_size:
            return {"stability": 0.0, "position_variance": 0.0, "rotation_variance": 0.0}

        recent_poses = list(self.pose_history)[-window_size:]

        # ä½ç½®è®Šç•°
        positions = np.array([pose.position for pose in recent_poses])
        position_variance = np.mean(np.var(positions, axis=0))

        # æ—‹è½‰è®Šç•°
        rotations = np.array([pose.rotation for pose in recent_poses])
        rotation_variance = np.mean(np.var(rotations, axis=0))

        # æ•´é«”ç©©å®šæ€§åˆ†æ•¸
        max_pos_var = 0.01  # 1cm
        max_rot_var = 0.1   # ~5.7åº¦

        pos_stability = max(0, 1 - position_variance / max_pos_var)
        rot_stability = max(0, 1 - rotation_variance / max_rot_var)

        overall_stability = (pos_stability + rot_stability) / 2

        return {
            "stability": overall_stability,
            "position_variance": position_variance,
            "rotation_variance": rotation_variance,
            "position_stability": pos_stability,
            "rotation_stability": rot_stability
        }


class SimplePosePredictor:
    """ç°¡å–®çš„å§¿æ…‹é æ¸¬å™¨"""

    def __init__(self, history_length: int = 5):
        """åˆå§‹åŒ–é æ¸¬å™¨"""
        self.history_length = history_length
        self.pose_histories = defaultdict(lambda: deque(maxlen=history_length))

    def predict_next_pose(self, marker_id: int,
                         current_pose: Pose6DOF) -> Pose6DOF:
        """é æ¸¬ä¸‹ä¸€å€‹å§¿æ…‹"""
        history = self.pose_histories[marker_id]
        history.append(current_pose)

        if len(history) < 2:
            return current_pose

        # ç°¡å–®ç·šæ€§é æ¸¬
        last_pose = history[-2]
        dt = current_pose.timestamp - last_pose.timestamp

        if dt > 0:
            # é æ¸¬ä½ç½®
            position_velocity = (current_pose.position - last_pose.position) / dt
            predicted_position = current_pose.position + position_velocity * dt

            # é æ¸¬æ—‹è½‰ï¼ˆç°¡åŒ–ï¼‰
            rotation_velocity = (current_pose.rotation - last_pose.rotation) / dt
            predicted_rotation = current_pose.rotation + rotation_velocity * dt

            # å‰µå»ºé æ¸¬å§¿æ…‹
            predicted_pose = Pose6DOF(
                position=predicted_position,
                rotation=predicted_rotation,
                rotation_matrix=current_pose.rotation_matrix,
                quaternion=current_pose.quaternion,
                euler_angles=current_pose.euler_angles,
                pose_matrix=current_pose.pose_matrix,
                confidence=current_pose.confidence * 0.8,  # é™ä½ç½®ä¿¡åº¦
                timestamp=current_pose.timestamp + dt
            )

            return predicted_pose

        return current_pose


def demo_pose_estimation():
    """å§¿æ…‹ä¼°è¨ˆæ¼”ç¤º"""
    print("ğŸ¯ ARå§¿æ…‹ä¼°è¨ˆç³»çµ±æ¼”ç¤º")
    print("=" * 50)

    # å‰µå»ºå§¿æ…‹ä¼°è¨ˆå™¨
    pose_estimator = ARPoseEstimator()

    # å‰µå»ºæ¨¡æ“¬æ¨™è¨˜æª¢æ¸¬æ•¸æ“š
    print("ğŸ“ å‰µå»ºæ¨¡æ“¬ArUcoæ¨™è¨˜æª¢æ¸¬æ•¸æ“š...")

    # å®šç¾©æ¨™è¨˜çš„3Dé»ï¼ˆæ­£æ–¹å½¢æ¨™è¨˜ï¼Œé‚Šé•·10cmï¼‰
    marker_size = 0.1  # 10cm
    object_points = np.array([
        [-marker_size/2, -marker_size/2, 0],
        [ marker_size/2, -marker_size/2, 0],
        [ marker_size/2,  marker_size/2, 0],
        [-marker_size/2,  marker_size/2, 0]
    ], dtype=np.float32)

    # æ¨¡æ“¬åœ¨ä¸åŒä½ç½®å’Œè§’åº¦çš„åœ–åƒé»
    test_scenarios = [
        {
            "name": "æ­£é¢æª¢è¦–",
            "image_points": np.array([
                [200, 200], [300, 200], [300, 300], [200, 300]
            ], dtype=np.float32)
        },
        {
            "name": "å‚¾æ–œ45åº¦",
            "image_points": np.array([
                [180, 180], [320, 180], [340, 320], [160, 320]
            ], dtype=np.float32)
        },
        {
            "name": "é€è¦–è®Šæ›",
            "image_points": np.array([
                [150, 150], [350, 170], [330, 330], [170, 310]
            ], dtype=np.float32)
        }
    ]

    # å‰µå»ºæ¸¬è©¦åœ–åƒ
    test_image = np.ones((480, 640, 3), dtype=np.uint8) * 128

    print(f"\nğŸ”¬ æ¸¬è©¦ä¸åŒå ´æ™¯çš„å§¿æ…‹ä¼°è¨ˆ:")

    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ“ å ´æ™¯ {i}: {scenario['name']}")

        # åœ¨æ¸¬è©¦åœ–åƒä¸Šç¹ªè£½æ¨¡æ“¬çš„æ¨™è¨˜è§’é»
        demo_image = test_image.copy()
        corners = scenario["image_points"].astype(int)

        # ç¹ªè£½æ¨™è¨˜
        cv2.polylines(demo_image, [corners], True, (0, 255, 0), 3)
        for j, corner in enumerate(corners):
            cv2.circle(demo_image, tuple(corner), 8, (0, 0, 255), -1)
            cv2.putText(demo_image, str(j), (corner[0]+10, corner[1]),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        # åŸ·è¡Œå§¿æ…‹ä¼°è¨ˆ
        pose = pose_estimator.estimate_pose(
            object_points,
            scenario["image_points"],
            marker_id=i
        )

        if pose:
            print(f"  âœ… å§¿æ…‹ä¼°è¨ˆæˆåŠŸ")
            print(f"     ä½ç½® (m): [{pose.position[0]:6.3f}, {pose.position[1]:6.3f}, {pose.position[2]:6.3f}]")
            print(f"     æ—‹è½‰ (åº¦): [{math.degrees(pose.euler_angles[0]):6.1f}, "
                  f"{math.degrees(pose.euler_angles[1]):6.1f}, "
                  f"{math.degrees(pose.euler_angles[2]):6.1f}]")
            print(f"     ç½®ä¿¡åº¦: {pose.confidence:.3f}")

            # ç¹ªè£½3Dåº§æ¨™è»¸
            demo_with_axes = pose_estimator.draw_3d_axes(demo_image, pose)

            # ç¹ªè£½è™›æ“¬ç«‹æ–¹é«”
            demo_with_cube = pose_estimator.draw_virtual_cube(demo_with_axes, pose)

            # é¡¯ç¤ºçµæœ
            display_multiple_images(
                [demo_image, demo_with_axes, demo_with_cube],
                ["æª¢æ¸¬çš„æ¨™è¨˜", "3Dåº§æ¨™è»¸", "è™›æ“¬ç«‹æ–¹é«”"],
                figsize=(15, 5)
            )

        else:
            print(f"  âŒ å§¿æ…‹ä¼°è¨ˆå¤±æ•—")

        # çŸ­æš«å»¶é²æ¨¡æ“¬å¯¦æ™‚è™•ç†
        time.sleep(0.5)

    # è¨ˆç®—ä¸¦é¡¯ç¤ºå§¿æ…‹ç©©å®šæ€§
    if len(pose_estimator.pose_history) >= 3:
        stability_metrics = pose_estimator.calculate_pose_stability()

        print(f"\nğŸ“Š å§¿æ…‹ç©©å®šæ€§åˆ†æ:")
        print(f"  æ•´é«”ç©©å®šæ€§: {stability_metrics['stability']:.3f}")
        print(f"  ä½ç½®ç©©å®šæ€§: {stability_metrics['position_stability']:.3f}")
        print(f"  æ—‹è½‰ç©©å®šæ€§: {stability_metrics['rotation_stability']:.3f}")
        print(f"  ä½ç½®è®Šç•°: {stability_metrics['position_variance']:.6f}")
        print(f"  æ—‹è½‰è®Šç•°: {stability_metrics['rotation_variance']:.6f}")

    print(f"\nğŸ¯ å§¿æ…‹ä¼°è¨ˆç³»çµ±åŠŸèƒ½:")
    print(f"â€¢ 6è‡ªç”±åº¦å§¿æ…‹ä¼°è¨ˆ (ä½ç½® + æ—‹è½‰)")
    print(f"â€¢ å¤šç¨®PnPæ±‚è§£ç®—æ³•")
    print(f"â€¢ RANSACé­¯æ£’æ€§å¢å¼·")
    print(f"â€¢ å§¿æ…‹è¿½è¹¤èˆ‡å¹³æ»‘")
    print(f"â€¢ åº§æ¨™ç³»çµ±è½‰æ›")
    print(f"â€¢ ç©©å®šæ€§åˆ†æ")
    print(f"â€¢ 3Då¯è¦–åŒ–")

    print(f"\nğŸš€ å¯¦éš›æ‡‰ç”¨å ´æ™¯:")
    print(f"â€¢ æ“´å¢å¯¦å¢ƒæ‡‰ç”¨")
    print(f"â€¢ æ©Ÿå™¨äººå°èˆª")
    print(f"â€¢ 3Dç‰©é«”è¿½è¹¤")
    print(f"â€¢ å·¥æ¥­æ¸¬é‡")
    print(f"â€¢ æ‰‹è¡“å°èˆª")
    print(f"â€¢ è™›æ“¬æ¼”æ’­å®¤")

    print(f"\nâš¡ æ€§èƒ½ç‰¹è‰²:")
    print(f"â€¢ å¯¦æ™‚è™•ç†èƒ½åŠ› (<20ms)")
    print(f"â€¢ æ¯«ç±³ç´šä½ç½®ç²¾åº¦")
    print(f"â€¢ åº¦ç´šæ—‹è½‰ç²¾åº¦")
    print(f"â€¢ å§¿æ…‹é æ¸¬èˆ‡æ’å€¼")


if __name__ == "__main__":
    demo_pose_estimation()