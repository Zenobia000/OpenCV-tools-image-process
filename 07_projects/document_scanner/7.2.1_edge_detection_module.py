#!/usr/bin/env python3
"""
7.2.1 æ™ºèƒ½æ–‡æª”æƒæå™¨ - é‚Šç·£æª¢æ¸¬æ¨¡çµ„

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†å°ˆç‚ºæ–‡æª”æƒæå„ªåŒ–çš„é‚Šç·£æª¢æ¸¬ç®—æ³•ï¼ŒåŒ…æ‹¬æ–‡æª”é‚Šç•Œæª¢æ¸¬ã€
è§’é»æå–ã€è¼ªå»“åˆ†æç­‰åŠŸèƒ½ã€‚

åŠŸèƒ½ç‰¹è‰²ï¼š
- å¤šç¨®é‚Šç·£æª¢æ¸¬æ–¹æ³• (Canny, Sobel, Laplacian)
- è‡ªé©æ‡‰é–¾å€¼è™•ç†
- æ–‡æª”é‚Šç•Œæ™ºèƒ½æª¢æ¸¬
- è§’é»æª¢æ¸¬èˆ‡å„ªåŒ–
- è¼ªå»“éæ¿¾èˆ‡æ’åº
- å¤šé‚Šå½¢è¿‘ä¼¼èˆ‡ç°¡åŒ–
- é€è¦–è®Šæ›æº–å‚™
- è³ªé‡è©•ä¼°èˆ‡é©—è­‰

ä½œè€…: OpenCV Computer Vision Toolkit
æ—¥æœŸ: 2024-10-14
ç‰ˆæœ¬: 1.0
"""

import cv2
import numpy as np
import os
import sys
import time
import json
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
from collections import deque
import math

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('../../utils')
try:
    from image_utils import load_image, resize_image
    from visualization import display_image, display_multiple_images
    from performance import time_function
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥å·¥å…·æ¨¡çµ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class DocumentContour:
    """æ–‡æª”è¼ªå»“æ•¸æ“šçµæ§‹"""
    contour: np.ndarray
    area: float
    perimeter: float
    aspect_ratio: float
    extent: float
    convexity: float
    corners: List[Tuple[int, int]]
    bounding_rect: Tuple[int, int, int, int]
    confidence: float
    is_rectangular: bool

    def to_dict(self):
        """è½‰æ›ç‚ºå­—å…¸æ ¼å¼ (æ’é™¤numpyæ•¸çµ„)"""
        return {
            'area': self.area,
            'perimeter': self.perimeter,
            'aspect_ratio': self.aspect_ratio,
            'extent': self.extent,
            'convexity': self.convexity,
            'corners': self.corners,
            'bounding_rect': self.bounding_rect,
            'confidence': self.confidence,
            'is_rectangular': self.is_rectangular
        }

class DocumentEdgeDetector:
    """æ–‡æª”é‚Šç·£æª¢æ¸¬å™¨"""

    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–æ–‡æª”é‚Šç·£æª¢æ¸¬å™¨"""
        self.config = self._load_config(config_file)
        self.preprocessing_methods = {
            'gaussian': self._gaussian_preprocessing,
            'bilateral': self._bilateral_preprocessing,
            'median': self._median_preprocessing,
            'combined': self._combined_preprocessing
        }

        self.edge_detection_methods = {
            'canny': self._canny_detection,
            'sobel': self._sobel_detection,
            'laplacian': self._laplacian_detection,
            'adaptive': self._adaptive_detection
        }

        logger.info("æ–‡æª”é‚Šç·£æª¢æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        default_config = {
            "preprocessing": {
                "method": "combined",  # gaussian, bilateral, median, combined
                "gaussian_kernel": 5,
                "gaussian_sigma": 1.0,
                "bilateral_d": 9,
                "bilateral_sigma_color": 75,
                "bilateral_sigma_space": 75,
                "median_kernel": 5,
                "resize_width": 800
            },
            "edge_detection": {
                "method": "adaptive",  # canny, sobel, laplacian, adaptive
                "canny_low": 50,
                "canny_high": 150,
                "canny_aperture": 3,
                "sobel_kernel": 3,
                "laplacian_kernel": 3,
                "adaptive_block_size": 11,
                "adaptive_c": 2
            },
            "contour_filtering": {
                "min_area_ratio": 0.01,    # ç›¸å°æ–¼åœ–åƒé¢ç©çš„æœ€å°æ¯”ä¾‹
                "max_area_ratio": 0.95,    # ç›¸å°æ–¼åœ–åƒé¢ç©çš„æœ€å¤§æ¯”ä¾‹
                "min_aspect_ratio": 0.2,   # æœ€å°é•·å¯¬æ¯”
                "max_aspect_ratio": 5.0,   # æœ€å¤§é•·å¯¬æ¯”
                "min_extent": 0.3,         # æœ€å°å¡«å……ç‡
                "min_convexity": 0.7,      # æœ€å°å‡¸æ€§
                "min_perimeter": 100       # æœ€å°å‘¨é•·
            },
            "corner_detection": {
                "approximation_epsilon": 0.02,  # Douglas-Peuckerè¿‘ä¼¼ç²¾åº¦
                "min_corners": 4,                # æœ€å°‘è§’é»æ•¸
                "max_corners": 8,                # æœ€å¤šè§’é»æ•¸
                "corner_threshold": 0.01,        # è§’é»æª¢æ¸¬é–¾å€¼
                "corner_quality": 0.3,           # è§’é»è³ªé‡åƒæ•¸
                "corner_min_distance": 10        # è§’é»æœ€å°è·é›¢
            }
        }

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                self._deep_update(default_config, user_config)
                logger.info(f"å·²è¼‰å…¥é…ç½®æ–‡ä»¶: {config_file}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥é…ç½®æ–‡ä»¶: {e}ï¼Œä½¿ç”¨é è¨­é…ç½®")

        return default_config

    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if isinstance(value, dict) and key in base_dict:
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """é è™•ç†åœ–åƒ"""
        method = self.config["preprocessing"]["method"]

        if method in self.preprocessing_methods:
            return self.preprocessing_methods[method](image)
        else:
            logger.warning(f"æœªçŸ¥é è™•ç†æ–¹æ³•: {method}, ä½¿ç”¨é«˜æ–¯é è™•ç†")
            return self._gaussian_preprocessing(image)

    def _gaussian_preprocessing(self, image: np.ndarray) -> np.ndarray:
        """é«˜æ–¯æ¨¡ç³Šé è™•ç†"""
        kernel_size = self.config["preprocessing"]["gaussian_kernel"]
        sigma = self.config["preprocessing"]["gaussian_sigma"]

        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), sigma)
        return blurred

    def _bilateral_preprocessing(self, image: np.ndarray) -> np.ndarray:
        """é›™é‚Šæ¿¾æ³¢é è™•ç†"""
        config = self.config["preprocessing"]

        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        filtered = cv2.bilateralFilter(
            gray, config["bilateral_d"],
            config["bilateral_sigma_color"],
            config["bilateral_sigma_space"]
        )
        return filtered

    def _median_preprocessing(self, image: np.ndarray) -> np.ndarray:
        """ä¸­å€¼æ¿¾æ³¢é è™•ç†"""
        kernel_size = self.config["preprocessing"]["median_kernel"]

        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        filtered = cv2.medianBlur(gray, kernel_size)
        return filtered

    def _combined_preprocessing(self, image: np.ndarray) -> np.ndarray:
        """çµ„åˆé è™•ç†æ–¹æ³•"""
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        # é¦–å…ˆä½¿ç”¨é«˜æ–¯æ¨¡ç³Š
        gaussian = cv2.GaussianBlur(gray, (5, 5), 1.0)

        # ç„¶å¾Œä½¿ç”¨é›™é‚Šæ¿¾æ³¢
        bilateral = cv2.bilateralFilter(gaussian, 9, 75, 75)

        return bilateral

    def detect_edges(self, image: np.ndarray) -> np.ndarray:
        """æª¢æ¸¬é‚Šç·£"""
        method = self.config["edge_detection"]["method"]

        if method in self.edge_detection_methods:
            return self.edge_detection_methods[method](image)
        else:
            logger.warning(f"æœªçŸ¥é‚Šç·£æª¢æ¸¬æ–¹æ³•: {method}, ä½¿ç”¨Canny")
            return self._canny_detection(image)

    def _canny_detection(self, image: np.ndarray) -> np.ndarray:
        """Cannyé‚Šç·£æª¢æ¸¬"""
        config = self.config["edge_detection"]

        edges = cv2.Canny(
            image,
            config["canny_low"],
            config["canny_high"],
            apertureSize=config["canny_aperture"]
        )

        return edges

    def _sobel_detection(self, image: np.ndarray) -> np.ndarray:
        """Sobelé‚Šç·£æª¢æ¸¬"""
        kernel_size = self.config["edge_detection"]["sobel_kernel"]

        # è¨ˆç®—xå’Œyæ–¹å‘çš„æ¢¯åº¦
        sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=kernel_size)
        sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=kernel_size)

        # è¨ˆç®—æ¢¯åº¦å¹…å€¼
        sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        sobel_magnitude = np.uint8(sobel_magnitude)

        # é–¾å€¼åŒ–
        _, edges = cv2.threshold(sobel_magnitude, 50, 255, cv2.THRESH_BINARY)

        return edges

    def _laplacian_detection(self, image: np.ndarray) -> np.ndarray:
        """Laplaciané‚Šç·£æª¢æ¸¬"""
        kernel_size = self.config["edge_detection"]["laplacian_kernel"]

        # è¨ˆç®—Laplacian
        laplacian = cv2.Laplacian(image, cv2.CV_64F, ksize=kernel_size)
        laplacian = np.uint8(np.absolute(laplacian))

        # é–¾å€¼åŒ–
        _, edges = cv2.threshold(laplacian, 50, 255, cv2.THRESH_BINARY)

        return edges

    def _adaptive_detection(self, image: np.ndarray) -> np.ndarray:
        """è‡ªé©æ‡‰é‚Šç·£æª¢æ¸¬"""
        config = self.config["edge_detection"]

        # é¦–å…ˆä½¿ç”¨è‡ªé©æ‡‰é–¾å€¼
        adaptive = cv2.adaptiveThreshold(
            image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, config["adaptive_block_size"], config["adaptive_c"]
        )

        # ç„¶å¾Œä½¿ç”¨Cannyé‚Šç·£æª¢æ¸¬
        edges = cv2.Canny(image, config["canny_low"], config["canny_high"])

        # çµåˆå…©ç¨®çµæœ
        combined = cv2.bitwise_or(adaptive, edges)

        return combined

    def find_document_contours(self, edges: np.ndarray, original_shape: Tuple[int, int]) -> List[DocumentContour]:
        """æŸ¥æ‰¾æ–‡æª”è¼ªå»“"""
        # å½¢æ…‹å­¸æ“ä½œæ”¹å–„é‚Šç·£é€£æ¥
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)

        # æŸ¥æ‰¾è¼ªå»“
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return []

        # è¨ˆç®—åœ–åƒé¢ç©ç”¨æ–¼éæ¿¾
        image_area = original_shape[0] * original_shape[1]

        document_contours = []

        for contour in contours:
            doc_contour = self._analyze_contour(contour, image_area)
            if doc_contour and self._is_valid_document_contour(doc_contour):
                document_contours.append(doc_contour)

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        document_contours.sort(key=lambda x: x.confidence, reverse=True)

        return document_contours

    def _analyze_contour(self, contour: np.ndarray, image_area: float) -> Optional[DocumentContour]:
        """åˆ†æå–®å€‹è¼ªå»“"""
        try:
            # åŸºæœ¬å¹¾ä½•å±¬æ€§
            area = cv2.contourArea(contour)
            if area < 100:  # éæ¿¾éå°çš„è¼ªå»“
                return None

            perimeter = cv2.arcLength(contour, True)
            if perimeter < 50:  # éæ¿¾éå°çš„å‘¨é•·
                return None

            # é‚Šç•ŒçŸ©å½¢
            x, y, w, h = cv2.boundingRect(contour)
            bounding_rect = (x, y, w, h)

            # å¹¾ä½•ç‰¹å¾µ
            aspect_ratio = float(w) / h if h > 0 else 0
            extent = area / (w * h) if (w * h) > 0 else 0

            # å‡¸åŒ…å’Œå‡¸æ€§
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            convexity = area / hull_area if hull_area > 0 else 0

            # å¤šé‚Šå½¢è¿‘ä¼¼
            epsilon = self.config["corner_detection"]["approximation_epsilon"] * perimeter
            approx = cv2.approxPolyDP(contour, epsilon, True)

            # æå–è§’é»
            corners = [(int(point[0][0]), int(point[0][1])) for point in approx]

            # åˆ¤æ–·æ˜¯å¦ç‚ºçŸ©å½¢
            is_rectangular = self._is_rectangular_shape(approx, aspect_ratio)

            # è¨ˆç®—ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(area, image_area, aspect_ratio,
                                                  extent, convexity, len(corners))

            return DocumentContour(
                contour=contour,
                area=area,
                perimeter=perimeter,
                aspect_ratio=aspect_ratio,
                extent=extent,
                convexity=convexity,
                corners=corners,
                bounding_rect=bounding_rect,
                confidence=confidence,
                is_rectangular=is_rectangular
            )

        except Exception as e:
            logger.warning(f"è¼ªå»“åˆ†æå¤±æ•—: {e}")
            return None

    def _is_rectangular_shape(self, approx: np.ndarray, aspect_ratio: float) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºçŸ©å½¢ç‹€"""
        # æª¢æŸ¥è§’é»æ•¸é‡
        if len(approx) != 4:
            return False

        # æª¢æŸ¥é•·å¯¬æ¯”æ˜¯å¦åˆç†
        if aspect_ratio < 0.2 or aspect_ratio > 5.0:
            return False

        # æª¢æŸ¥è§’åº¦ï¼ˆæ‡‰è©²æ¥è¿‘90åº¦ï¼‰
        angles = []
        for i in range(4):
            p1 = approx[i][0]
            p2 = approx[(i + 1) % 4][0]
            p3 = approx[(i + 2) % 4][0]

            # è¨ˆç®—å…©å€‹å‘é‡
            v1 = p1 - p2
            v2 = p3 - p2

            # è¨ˆç®—å¤¾è§’
            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
            cos_angle = np.clip(cos_angle, -1.0, 1.0)
            angle = np.arccos(cos_angle) * 180 / np.pi
            angles.append(angle)

        # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰è§’åº¦éƒ½æ¥è¿‘90åº¦
        angle_threshold = 25  # å®¹è¨±25åº¦çš„åå·®
        near_right_angles = sum(1 for angle in angles
                               if abs(angle - 90) < angle_threshold)

        return near_right_angles >= 3  # è‡³å°‘3å€‹è§’æ¥è¿‘ç›´è§’

    def _calculate_confidence(self, area: float, image_area: float,
                            aspect_ratio: float, extent: float,
                            convexity: float, corner_count: int) -> float:
        """è¨ˆç®—ç½®ä¿¡åº¦åˆ†æ•¸"""
        confidence = 0.0

        # é¢ç©ä½”æ¯” (30% æ¬Šé‡)
        area_ratio = area / image_area
        if 0.1 <= area_ratio <= 0.8:
            confidence += 0.3 * (1.0 - abs(area_ratio - 0.4) / 0.4)

        # é•·å¯¬æ¯” (25% æ¬Šé‡)
        if 0.5 <= aspect_ratio <= 2.0:
            ideal_ratio = math.sqrt(2)  # A4ç´™å¼µæ¯”ä¾‹
            ratio_score = 1.0 - abs(aspect_ratio - ideal_ratio) / ideal_ratio
            confidence += 0.25 * ratio_score

        # å¡«å……ç‡ (20% æ¬Šé‡)
        if extent >= 0.7:
            confidence += 0.2 * extent

        # å‡¸æ€§ (15% æ¬Šé‡)
        if convexity >= 0.8:
            confidence += 0.15 * convexity

        # è§’é»æ•¸é‡ (10% æ¬Šé‡)
        if corner_count == 4:
            confidence += 0.1
        elif corner_count in [3, 5, 6]:
            confidence += 0.05

        return min(1.0, confidence)

    def _is_valid_document_contour(self, doc_contour: DocumentContour) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆçš„æ–‡æª”è¼ªå»“"""
        config = self.config["contour_filtering"]

        # æª¢æŸ¥å„é …æ¢ä»¶
        conditions = [
            doc_contour.aspect_ratio >= config["min_aspect_ratio"],
            doc_contour.aspect_ratio <= config["max_aspect_ratio"],
            doc_contour.extent >= config["min_extent"],
            doc_contour.convexity >= config["min_convexity"],
            doc_contour.perimeter >= config["min_perimeter"],
            len(doc_contour.corners) >= config["min_corners"] if config["min_corners"] else True,
            len(doc_contour.corners) <= config["max_corners"] if config["max_corners"] else True,
        ]

        # è‡³å°‘æ»¿è¶³å¤§éƒ¨åˆ†æ¢ä»¶
        return sum(conditions) >= len(conditions) * 0.7

    def enhance_corners(self, image: np.ndarray, corners: List[Tuple[int, int]]) -> List[Tuple[int, int]]:
        """å¢å¼·è§’é»æª¢æ¸¬ç²¾åº¦"""
        if len(corners) != 4:
            return corners

        enhanced_corners = []
        corner_config = self.config["corner_detection"]

        # åœ¨æ¯å€‹è§’é»å‘¨åœçš„å°å€åŸŸå…§é€²è¡Œç²¾ç¢ºå®šä½
        search_radius = 20

        for corner_x, corner_y in corners:
            # å®šç¾©æœç´¢å€åŸŸ
            x1 = max(0, corner_x - search_radius)
            y1 = max(0, corner_y - search_radius)
            x2 = min(image.shape[1], corner_x + search_radius)
            y2 = min(image.shape[0], corner_y + search_radius)

            roi = image[y1:y2, x1:x2]

            if roi.size == 0:
                enhanced_corners.append((corner_x, corner_y))
                continue

            # ä½¿ç”¨Harrisè§’é»æª¢æ¸¬
            try:
                corners_harris = cv2.goodFeaturesToTrack(
                    roi, 1, corner_config["corner_quality"],
                    corner_config["corner_min_distance"]
                )

                if corners_harris is not None and len(corners_harris) > 0:
                    # è½‰æ›å›åŸå§‹åœ–åƒåº§æ¨™
                    refined_x = int(corners_harris[0][0][0] + x1)
                    refined_y = int(corners_harris[0][0][1] + y1)
                    enhanced_corners.append((refined_x, refined_y))
                else:
                    enhanced_corners.append((corner_x, corner_y))

            except Exception as e:
                logger.warning(f"è§’é»å¢å¼·å¤±æ•—: {e}")
                enhanced_corners.append((corner_x, corner_y))

        return enhanced_corners

    def order_corners(self, corners: List[Tuple[int, int]]) -> List[Tuple[int, int]]:
        """æŒ‰ç…§å·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹çš„é †åºæ’åˆ—è§’é»"""
        if len(corners) != 4:
            return corners

        # è½‰æ›ç‚ºnumpyé™£åˆ—
        pts = np.array(corners, dtype=np.float32)

        # æŒ‰x+yçš„å’Œæ’åºï¼Œæ‰¾å‡ºå·¦ä¸Šå’Œå³ä¸‹
        sum_pts = pts.sum(axis=1)
        top_left = pts[np.argmin(sum_pts)]
        bottom_right = pts[np.argmax(sum_pts)]

        # æŒ‰x-yçš„å·®æ’åºï¼Œæ‰¾å‡ºå³ä¸Šå’Œå·¦ä¸‹
        diff_pts = np.diff(pts, axis=1).flatten()
        top_right = pts[np.argmin(diff_pts)]
        bottom_left = pts[np.argmax(diff_pts)]

        ordered_corners = [
            tuple(top_left.astype(int)),
            tuple(top_right.astype(int)),
            tuple(bottom_right.astype(int)),
            tuple(bottom_left.astype(int))
        ]

        return ordered_corners

    def visualize_results(self, original_image: np.ndarray,
                         preprocessed: np.ndarray, edges: np.ndarray,
                         document_contours: List[DocumentContour]) -> np.ndarray:
        """å¯è¦–åŒ–æª¢æ¸¬çµæœ"""
        # å‰µå»ºçµæœåœ–åƒ
        result = original_image.copy()

        # ç¹ªè£½æ‰€æœ‰æª¢æ¸¬åˆ°çš„è¼ªå»“
        for i, doc_contour in enumerate(document_contours[:3]):  # æœ€å¤šé¡¯ç¤º3å€‹
            color = [(0, 255, 0), (255, 0, 0), (0, 0, 255)][i]

            # ç¹ªè£½è¼ªå»“
            cv2.drawContours(result, [doc_contour.contour], -1, color, 2)

            # ç¹ªè£½è§’é»
            for corner in doc_contour.corners:
                cv2.circle(result, corner, 8, color, -1)
                cv2.circle(result, corner, 12, (255, 255, 255), 2)

            # æ·»åŠ æ¨™ç±¤
            x, y, w, h = doc_contour.bounding_rect
            label = f"Doc{i+1}: {doc_contour.confidence:.2f}"
            cv2.putText(result, label, (x, y-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        return result

    def process_document(self, image: np.ndarray, save_intermediate: bool = False) -> Dict[str, Any]:
        """è™•ç†æ–‡æª”åœ–åƒçš„å®Œæ•´æµç¨‹"""
        results = {
            'original_shape': image.shape,
            'processing_steps': {},
            'document_contours': [],
            'best_document': None,
            'success': False
        }

        start_time = time.time()

        # æ­¥é©Ÿ1: é è™•ç†
        logger.info("é–‹å§‹æ–‡æª”é‚Šç·£æª¢æ¸¬è™•ç†...")

        step_start = time.time()
        preprocessed = self.preprocess_image(image)
        results['processing_steps']['preprocessing'] = (time.time() - step_start) * 1000

        # æ­¥é©Ÿ2: é‚Šç·£æª¢æ¸¬
        step_start = time.time()
        edges = self.detect_edges(preprocessed)
        results['processing_steps']['edge_detection'] = (time.time() - step_start) * 1000

        # æ­¥é©Ÿ3: æŸ¥æ‰¾æ–‡æª”è¼ªå»“
        step_start = time.time()
        document_contours = self.find_document_contours(edges, image.shape[:2])
        results['processing_steps']['contour_analysis'] = (time.time() - step_start) * 1000

        # å„²å­˜ä¸­é–“çµæœ
        if save_intermediate:
            results['intermediate'] = {
                'preprocessed': preprocessed,
                'edges': edges
            }

        # æ­¥é©Ÿ4: è§’é»å„ªåŒ–
        if document_contours:
            step_start = time.time()
            best_contour = document_contours[0]

            if len(best_contour.corners) == 4:
                # å¢å¼·è§’é»ç²¾åº¦
                enhanced_corners = self.enhance_corners(preprocessed, best_contour.corners)
                # æ’åºè§’é»
                ordered_corners = self.order_corners(enhanced_corners)

                # æ›´æ–°æœ€ä½³æ–‡æª”
                best_contour.corners = ordered_corners
                results['best_document'] = best_contour.to_dict()
                results['success'] = True

            results['processing_steps']['corner_optimization'] = (time.time() - step_start) * 1000

        # è½‰æ›è¼ªå»“ç‚ºå¯åºåˆ—åŒ–æ ¼å¼
        results['document_contours'] = [contour.to_dict() for contour in document_contours]

        # è¨ˆç®—ç¸½è™•ç†æ™‚é–“
        results['total_time'] = (time.time() - start_time) * 1000

        # å¯è¦–åŒ–çµæœ
        results['visualization'] = self.visualize_results(
            image, preprocessed, edges, document_contours
        )

        logger.info(f"æ–‡æª”é‚Šç·£æª¢æ¸¬å®Œæˆï¼Œè€—æ™‚ {results['total_time']:.1f}ms")
        logger.info(f"æ‰¾åˆ° {len(document_contours)} å€‹å¯èƒ½çš„æ–‡æª”è¼ªå»“")

        if results['success']:
            logger.info(f"æœ€ä½³æ–‡æª”ç½®ä¿¡åº¦: {document_contours[0].confidence:.3f}")

        return results


def demo_document_edge_detection():
    """æ–‡æª”é‚Šç·£æª¢æ¸¬æ¼”ç¤º"""
    print("ğŸ“„ æ™ºèƒ½æ–‡æª”é‚Šç·£æª¢æ¸¬æ¼”ç¤º")
    print("=" * 50)

    # å‰µå»ºæª¢æ¸¬å™¨
    detector = DocumentEdgeDetector()

    # æ¸¬è©¦åœ–åƒè·¯å¾‘
    test_images = [
        "../../assets/images/basic/faces01.jpg",  # è‡¨æ™‚ç”¨å…¶ä»–åœ–ç‰‡æ¸¬è©¦
        "../../assets/images/basic/face03.jpg"
    ]

    for image_path in test_images:
        if os.path.exists(image_path):
            print(f"\nğŸ–¼ï¸  è™•ç†åœ–åƒ: {os.path.basename(image_path)}")

            # è¼‰å…¥åœ–åƒ
            image = load_image(image_path)
            if image is None:
                print("âŒ ç„¡æ³•è¼‰å…¥åœ–åƒ")
                continue

            # èª¿æ•´åœ–åƒå¤§å°
            original_width = image.shape[1]
            target_width = detector.config["preprocessing"]["resize_width"]

            if original_width > target_width:
                image = resize_image(image, max_width=target_width)
                print(f"ğŸ”„ åœ–åƒå·²èª¿æ•´å¤§å°åˆ° {image.shape[1]}x{image.shape[0]}")

            # è™•ç†æ–‡æª”
            results = detector.process_document(image, save_intermediate=True)

            # é¡¯ç¤ºçµæœçµ±è¨ˆ
            print(f"ğŸ“Š è™•ç†çµæœ:")
            print(f"  ç¸½è€—æ™‚: {results['total_time']:.1f}ms")
            print(f"  æª¢æ¸¬æˆåŠŸ: {'âœ…' if results['success'] else 'âŒ'}")
            print(f"  æ‰¾åˆ°è¼ªå»“æ•¸: {len(results['document_contours'])}")

            if results['success']:
                best_doc = results['best_document']
                print(f"  æœ€ä½³æ–‡æª”ç½®ä¿¡åº¦: {best_doc['confidence']:.3f}")
                print(f"  è§’é»æ•¸é‡: {len(best_doc['corners'])}")
                print(f"  æ˜¯å¦çŸ©å½¢: {'æ˜¯' if best_doc['is_rectangular'] else 'å¦'}")

            # é¡¯ç¤ºè™•ç†æ­¥é©Ÿæ™‚é–“
            print(f"ğŸ“ˆ è™•ç†æ­¥é©Ÿè€—æ™‚:")
            for step, time_ms in results['processing_steps'].items():
                print(f"  {step}: {time_ms:.1f}ms")

            # å¯è¦–åŒ–çµæœ
            if 'intermediate' in results:
                images = [
                    image,
                    results['intermediate']['preprocessed'],
                    results['intermediate']['edges'],
                    results['visualization']
                ]
                titles = [
                    "åŸå§‹åœ–åƒ",
                    "é è™•ç†çµæœ",
                    "é‚Šç·£æª¢æ¸¬",
                    f"æª¢æ¸¬çµæœ ({len(results['document_contours'])} å€‹è¼ªå»“)"
                ]

                display_multiple_images(images, titles, figsize=(16, 12))

            break
    else:
        print("âŒ æœªæ‰¾åˆ°æ¸¬è©¦åœ–åƒ")


if __name__ == "__main__":
    demo_document_edge_detection()