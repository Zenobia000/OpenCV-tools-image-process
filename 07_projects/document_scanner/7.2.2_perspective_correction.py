#!/usr/bin/env python3
"""
7.2.2 æ™ºèƒ½æ–‡æª”æƒæå™¨ - é€è¦–æ ¡æ­£æ¨¡çµ„

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†é«˜å“è³ªçš„é€è¦–è®Šæ›èˆ‡å¹¾ä½•æ ¡æ­£åŠŸèƒ½ï¼Œå°‡å‚¾æ–œæˆ–è®Šå½¢çš„æ–‡æª”
åœ–åƒæ ¡æ­£ç‚ºæ­£é¢å¹³æ•´çš„æƒææ•ˆæœã€‚

åŠŸèƒ½ç‰¹è‰²ï¼š
- å››é»é€è¦–è®Šæ›æ ¡æ­£
- è‡ªå‹•é€è¦–çŸ©é™£è¨ˆç®—
- ç•¸è®Šæ ¡æ­£èˆ‡å¹¾ä½•èª¿æ•´
- å¤šç¨®æ’å€¼æ–¹æ³•æ”¯æ´
- è¼¸å‡ºå°ºå¯¸è‡ªé©æ‡‰
- å“è³ªè©•ä¼°èˆ‡é©—è­‰
- å¾Œè™•ç†å„ªåŒ–
- æ‰¹é‡è™•ç†æ”¯æ´

ä½œè€…: OpenCV Computer Vision Toolkit
æ—¥æœŸ: 2024-10-14
ç‰ˆæœ¬: 1.0
"""

import cv2
import numpy as np
import os
import sys
import time
import json
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, asdict
from enum import Enum
import math

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('../../utils')
try:
    from image_utils import load_image, resize_image
    from visualization import display_image, display_multiple_images
    from performance import time_function
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥å·¥å…·æ¨¡çµ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PaperSize(Enum):
    """ç´™å¼µå°ºå¯¸æšèˆ‰"""
    A4 = (210, 297)      # mm
    A3 = (297, 420)      # mm
    A5 = (148, 210)      # mm
    LETTER = (216, 279)  # mm
    LEGAL = (216, 356)   # mm
    CUSTOM = (0, 0)      # è‡ªå®šç¾©

@dataclass
class PerspectiveTransform:
    """é€è¦–è®Šæ›æ•¸æ“šçµæ§‹"""
    source_corners: List[Tuple[int, int]]
    target_corners: List[Tuple[int, int]]
    transform_matrix: np.ndarray
    inverse_matrix: np.ndarray
    output_size: Tuple[int, int]
    paper_size: PaperSize
    confidence: float

class DocumentPerspectiveCorrector:
    """æ–‡æª”é€è¦–æ ¡æ­£å™¨"""

    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–é€è¦–æ ¡æ­£å™¨"""
        self.config = self._load_config(config_file)

        # æ¨™æº–ç´™å¼µæ¯”ä¾‹
        self.paper_ratios = {
            PaperSize.A4: 210 / 297,      # 0.707
            PaperSize.A3: 297 / 420,      # 0.707
            PaperSize.A5: 148 / 210,      # 0.705
            PaperSize.LETTER: 216 / 279,  # 0.774
            PaperSize.LEGAL: 216 / 356,   # 0.607
        }

        logger.info("æ–‡æª”é€è¦–æ ¡æ­£å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        default_config = {
            "correction": {
                "default_paper_size": "A4",        # A4, A3, A5, LETTER, LEGAL, AUTO
                "output_dpi": 300,                  # è¼¸å‡ºè§£æåº¦ DPI
                "interpolation_method": "cubic",    # linear, cubic, lanczos
                "border_removal": True,             # æ˜¯å¦ç§»é™¤é‚Šæ¡†
                "border_threshold": 0.02,           # é‚Šæ¡†æª¢æ¸¬é–¾å€¼
                "aspect_ratio_tolerance": 0.15      # é•·å¯¬æ¯”å®¹å·®
            },
            "quality_enhancement": {
                "auto_contrast": True,              # è‡ªå‹•å°æ¯”åº¦èª¿æ•´
                "noise_reduction": True,            # é™å™ªè™•ç†
                "sharpening": True,                 # éŠ³åŒ–è™•ç†
                "gamma_correction": 1.2,            # ä¼½é¦¬æ ¡æ­£å€¼
                "brightness_adjustment": 0,         # äº®åº¦èª¿æ•´ (-100 to 100)
                "contrast_adjustment": 10           # å°æ¯”åº¦èª¿æ•´ (-100 to 100)
            },
            "validation": {
                "min_area_ratio": 0.1,              # æœ€å°é¢ç©æ¯”ä¾‹
                "max_area_ratio": 0.95,             # æœ€å¤§é¢ç©æ¯”ä¾‹
                "min_corner_distance": 50,          # æœ€å°è§’é»è·é›¢
                "validate_corners": True,           # é©—è­‰è§’é»æœ‰æ•ˆæ€§
                "corner_angle_threshold": 30        # è§’é»è§’åº¦é–¾å€¼
            },
            "output": {
                "format": "png",                    # è¼¸å‡ºæ ¼å¼ png, jpg
                "quality": 95,                      # JPEGå“è³ª (1-100)
                "preserve_aspect_ratio": True,      # ä¿æŒé•·å¯¬æ¯”
                "padding": 20                       # é‚Šè·åƒç´ 
            }
        }

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                self._deep_update(default_config, user_config)
                logger.info(f"å·²è¼‰å…¥é…ç½®æ–‡ä»¶: {config_file}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥é…ç½®æ–‡ä»¶: {e}ï¼Œä½¿ç”¨é è¨­é…ç½®")

        return default_config

    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if isinstance(value, dict) and key in base_dict:
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def validate_corners(self, corners: List[Tuple[int, int]],
                        image_shape: Tuple[int, int]) -> bool:
        """é©—è­‰è§’é»çš„æœ‰æ•ˆæ€§"""
        if len(corners) != 4:
            logger.warning("è§’é»æ•¸é‡ä¸æ˜¯4å€‹")
            return False

        height, width = image_shape[:2]
        min_distance = self.config["validation"]["min_corner_distance"]

        # æª¢æŸ¥è§’é»æ˜¯å¦åœ¨åœ–åƒç¯„åœå…§
        for x, y in corners:
            if x < 0 or x >= width or y < 0 or y >= height:
                logger.warning(f"è§’é» ({x}, {y}) è¶…å‡ºåœ–åƒç¯„åœ")
                return False

        # æª¢æŸ¥è§’é»é–“è·é›¢
        for i in range(4):
            for j in range(i + 1, 4):
                dist = math.sqrt((corners[i][0] - corners[j][0])**2 +
                               (corners[i][1] - corners[j][1])**2)
                if dist < min_distance:
                    logger.warning(f"è§’é» {i} å’Œ {j} è·é›¢éè¿‘: {dist:.1f}")
                    return False

        # æª¢æŸ¥å››é‚Šå½¢çš„é¢ç©
        area = self._calculate_quadrilateral_area(corners)
        image_area = width * height
        area_ratio = area / image_area

        min_ratio = self.config["validation"]["min_area_ratio"]
        max_ratio = self.config["validation"]["max_area_ratio"]

        if not (min_ratio <= area_ratio <= max_ratio):
            logger.warning(f"å››é‚Šå½¢é¢ç©æ¯”ä¾‹ä¸åˆç†: {area_ratio:.3f}")
            return False

        # æª¢æŸ¥è§’åº¦æ˜¯å¦åˆç†ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if self.config["validation"]["validate_corners"]:
            if not self._validate_corner_angles(corners):
                return False

        return True

    def _calculate_quadrilateral_area(self, corners: List[Tuple[int, int]]) -> float:
        """è¨ˆç®—å››é‚Šå½¢é¢ç©ï¼ˆä½¿ç”¨é‹å¸¶å…¬å¼ï¼‰"""
        if len(corners) != 4:
            return 0

        # ç¢ºä¿è§’é»æŒ‰é †åºæ’åˆ—
        ordered_corners = self._order_corners_for_area(corners)

        # é‹å¸¶å…¬å¼
        area = 0
        n = len(ordered_corners)
        for i in range(n):
            j = (i + 1) % n
            area += ordered_corners[i][0] * ordered_corners[j][1]
            area -= ordered_corners[j][0] * ordered_corners[i][1]

        return abs(area) / 2.0

    def _order_corners_for_area(self, corners: List[Tuple[int, int]]) -> List[Tuple[int, int]]:
        """ç‚ºé¢ç©è¨ˆç®—æ’åºè§’é»ï¼ˆæŒ‰é€†æ™‚é‡é †åºï¼‰"""
        # è¨ˆç®—è³ªå¿ƒ
        cx = sum(x for x, y in corners) / 4
        cy = sum(y for x, y in corners) / 4

        # æŒ‰è§’åº¦æ’åº
        def angle_from_center(corner):
            return math.atan2(corner[1] - cy, corner[0] - cx)

        return sorted(corners, key=angle_from_center)

    def _validate_corner_angles(self, corners: List[Tuple[int, int]]) -> bool:
        """é©—è­‰è§’é»è§’åº¦æ˜¯å¦åˆç†"""
        threshold = self.config["validation"]["corner_angle_threshold"]

        # è¨ˆç®—å››å€‹å…§è§’
        angles = []
        ordered_corners = self._order_corners_for_area(corners)

        for i in range(4):
            p1 = np.array(ordered_corners[(i - 1) % 4])
            p2 = np.array(ordered_corners[i])
            p3 = np.array(ordered_corners[(i + 1) % 4])

            # è¨ˆç®—å…©å€‹å‘é‡
            v1 = p1 - p2
            v2 = p3 - p2

            # è¨ˆç®—è§’åº¦
            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
            cos_angle = np.clip(cos_angle, -1.0, 1.0)
            angle = np.arccos(cos_angle) * 180 / np.pi
            angles.append(angle)

        # æª¢æŸ¥è§’åº¦æ˜¯å¦æ¥è¿‘ç›´è§’
        valid_angles = sum(1 for angle in angles if abs(angle - 90) <= threshold)

        if valid_angles < 3:  # è‡³å°‘3å€‹è§’æ¥è¿‘ç›´è§’
            logger.warning(f"è§’åº¦ä¸åˆç†: {angles}")
            return False

        return True

    def determine_paper_size(self, corners: List[Tuple[int, int]]) -> PaperSize:
        """è‡ªå‹•åˆ¤æ–·ç´™å¼µå°ºå¯¸"""
        if len(corners) != 4:
            return PaperSize.A4  # é è¨­

        # è¨ˆç®—å››é‚Šå½¢çš„å¯¬åº¦å’Œé«˜åº¦
        width = max(abs(corners[1][0] - corners[0][0]),
                   abs(corners[2][0] - corners[3][0]))
        height = max(abs(corners[3][1] - corners[0][1]),
                    abs(corners[2][1] - corners[1][1]))

        if width == 0 or height == 0:
            return PaperSize.A4

        # è¨ˆç®—é•·å¯¬æ¯”
        aspect_ratio = min(width, height) / max(width, height)
        tolerance = self.config["correction"]["aspect_ratio_tolerance"]

        # èˆ‡æ¨™æº–ç´™å¼µæ¯”ä¾‹æ¯”è¼ƒ
        best_match = PaperSize.A4
        min_diff = float('inf')

        for paper_size, standard_ratio in self.paper_ratios.items():
            diff = abs(aspect_ratio - standard_ratio)
            if diff < min_diff and diff <= tolerance:
                min_diff = diff
                best_match = paper_size

        logger.info(f"æª¢æ¸¬åˆ°ç´™å¼µé¡å‹: {best_match.name} (æ¯”ä¾‹: {aspect_ratio:.3f})")
        return best_match

    def calculate_output_size(self, paper_size: PaperSize,
                            corners: List[Tuple[int, int]] = None) -> Tuple[int, int]:
        """è¨ˆç®—è¼¸å‡ºåœ–åƒå°ºå¯¸"""
        dpi = self.config["correction"]["output_dpi"]

        if paper_size == PaperSize.CUSTOM and corners:
            # åŸºæ–¼è§’é»è¨ˆç®—å°ºå¯¸
            width = max(abs(corners[1][0] - corners[0][0]),
                       abs(corners[2][0] - corners[3][0]))
            height = max(abs(corners[3][1] - corners[0][1]),
                        abs(corners[2][1] - corners[1][1]))
            return (int(width), int(height))

        elif paper_size in self.paper_ratios:
            # åŸºæ–¼æ¨™æº–ç´™å¼µå°ºå¯¸
            paper_width_mm, paper_height_mm = paper_size.value

            # è½‰æ›ç‚ºåƒç´ ï¼ˆDPIè½‰æ›ï¼‰
            width_pixels = int(paper_width_mm * dpi / 25.4)
            height_pixels = int(paper_height_mm * dpi / 25.4)

            return (width_pixels, height_pixels)

        else:
            # é è¨­ A4 å°ºå¯¸
            return (int(210 * dpi / 25.4), int(297 * dpi / 25.4))

    def create_perspective_transform(self, corners: List[Tuple[int, int]],
                                   target_size: Tuple[int, int] = None,
                                   paper_size: PaperSize = None) -> PerspectiveTransform:
        """å‰µå»ºé€è¦–è®Šæ›"""
        if not self.validate_corners(corners, (2000, 2000)):  # å‡è¨­æœ€å¤§åœ–åƒå°ºå¯¸
            raise ValueError("ç„¡æ•ˆçš„è§’é»")

        # è‡ªå‹•åˆ¤æ–·ç´™å¼µå°ºå¯¸
        if paper_size is None:
            paper_size = self.determine_paper_size(corners)

        # è¨ˆç®—è¼¸å‡ºå°ºå¯¸
        if target_size is None:
            target_size = self.calculate_output_size(paper_size, corners)

        # æ’åºè§’é»ï¼šå·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹
        ordered_corners = self._order_corners(corners)

        # å®šç¾©ç›®æ¨™è§’é»ï¼ˆæ¨™æº–çŸ©å½¢ï¼‰
        padding = self.config["output"]["padding"]
        target_corners = [
            (padding, padding),                           # å·¦ä¸Š
            (target_size[0] - padding, padding),         # å³ä¸Š
            (target_size[0] - padding, target_size[1] - padding), # å³ä¸‹
            (padding, target_size[1] - padding)          # å·¦ä¸‹
        ]

        # è¨ˆç®—é€è¦–è®Šæ›çŸ©é™£
        src_points = np.array(ordered_corners, dtype=np.float32)
        dst_points = np.array(target_corners, dtype=np.float32)

        transform_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
        inverse_matrix = cv2.getPerspectiveTransform(dst_points, src_points)

        # è¨ˆç®—è®Šæ›ç½®ä¿¡åº¦
        confidence = self._calculate_transform_confidence(ordered_corners, target_corners)

        return PerspectiveTransform(
            source_corners=ordered_corners,
            target_corners=target_corners,
            transform_matrix=transform_matrix,
            inverse_matrix=inverse_matrix,
            output_size=target_size,
            paper_size=paper_size,
            confidence=confidence
        )

    def _order_corners(self, corners: List[Tuple[int, int]]) -> List[Tuple[int, int]]:
        """æ’åºè§’é»ç‚ºå·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹"""
        if len(corners) != 4:
            return corners

        # è½‰æ›ç‚ºnumpyé™£åˆ—
        pts = np.array(corners, dtype=np.float32)

        # æŒ‰x+yçš„å’Œæ’åºï¼Œæ‰¾å‡ºå·¦ä¸Šå’Œå³ä¸‹
        sum_pts = pts.sum(axis=1)
        top_left = pts[np.argmin(sum_pts)]
        bottom_right = pts[np.argmax(sum_pts)]

        # æŒ‰x-yçš„å·®æ’åºï¼Œæ‰¾å‡ºå³ä¸Šå’Œå·¦ä¸‹
        diff_pts = np.diff(pts, axis=1).flatten()
        top_right = pts[np.argmin(diff_pts)]
        bottom_left = pts[np.argmax(diff_pts)]

        return [
            tuple(top_left.astype(int)),
            tuple(top_right.astype(int)),
            tuple(bottom_right.astype(int)),
            tuple(bottom_left.astype(int))
        ]

    def _calculate_transform_confidence(self, source_corners: List[Tuple[int, int]],
                                      target_corners: List[Tuple[int, int]]) -> float:
        """è¨ˆç®—è®Šæ›ç½®ä¿¡åº¦"""
        confidence = 1.0

        # æª¢æŸ¥æºè§’é»çš„çŸ©å½¢åº¦
        rectangularity = self._measure_rectangularity(source_corners)
        confidence *= rectangularity

        # æª¢æŸ¥é¢ç©è®ŠåŒ–åˆç†æ€§
        src_area = self._calculate_quadrilateral_area(source_corners)
        dst_area = self._calculate_quadrilateral_area(target_corners)

        if src_area > 0:
            area_ratio = min(src_area, dst_area) / max(src_area, dst_area)
            confidence *= area_ratio

        return confidence

    def _measure_rectangularity(self, corners: List[Tuple[int, int]]) -> float:
        """æ¸¬é‡å››é‚Šå½¢çš„çŸ©å½¢åº¦ (0-1)"""
        if len(corners) != 4:
            return 0.0

        # è¨ˆç®—å››å€‹å…§è§’
        angles = []
        ordered_corners = self._order_corners_for_area(corners)

        for i in range(4):
            p1 = np.array(ordered_corners[(i - 1) % 4])
            p2 = np.array(ordered_corners[i])
            p3 = np.array(ordered_corners[(i + 1) % 4])

            v1 = p1 - p2
            v2 = p3 - p2

            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
            cos_angle = np.clip(cos_angle, -1.0, 1.0)
            angle = np.arccos(cos_angle) * 180 / np.pi
            angles.append(angle)

        # è¨ˆç®—è§’åº¦èˆ‡90åº¦çš„åå·®
        angle_score = 0.0
        for angle in angles:
            deviation = abs(angle - 90) / 90
            angle_score += max(0, 1 - deviation)

        return angle_score / 4.0  # å¹³å‡åˆ†æ•¸

    def apply_perspective_transform(self, image: np.ndarray,
                                  transform: PerspectiveTransform) -> np.ndarray:
        """æ‡‰ç”¨é€è¦–è®Šæ›"""
        interpolation_map = {
            'linear': cv2.INTER_LINEAR,
            'cubic': cv2.INTER_CUBIC,
            'lanczos': cv2.INTER_LANCZOS4
        }

        interpolation = interpolation_map.get(
            self.config["correction"]["interpolation_method"],
            cv2.INTER_CUBIC
        )

        # æ‡‰ç”¨é€è¦–è®Šæ›
        corrected = cv2.warpPerspective(
            image,
            transform.transform_matrix,
            transform.output_size,
            flags=interpolation,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(255, 255, 255)  # ç™½è‰²é‚Šæ¡†
        )

        return corrected

    def enhance_quality(self, image: np.ndarray) -> np.ndarray:
        """å¢å¼·åœ–åƒå“è³ª"""
        enhanced = image.copy()
        quality_config = self.config["quality_enhancement"]

        # è½‰æ›ç‚ºLABè‰²å½©ç©ºé–“é€²è¡Œè™•ç†
        if len(enhanced.shape) == 3:
            lab = cv2.cvtColor(enhanced, cv2.COLOR_BGR2LAB)
            l_channel = lab[:, :, 0]
        else:
            l_channel = enhanced.copy()

        # è‡ªå‹•å°æ¯”åº¦èª¿æ•´ (CLAHE)
        if quality_config["auto_contrast"]:
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l_channel = clahe.apply(l_channel)

        # å™ªè²æ¸›å°‘
        if quality_config["noise_reduction"]:
            l_channel = cv2.medianBlur(l_channel, 3)

        # éŠ³åŒ–è™•ç†
        if quality_config["sharpening"]:
            kernel = np.array([[-1, -1, -1],
                              [-1,  9, -1],
                              [-1, -1, -1]])
            l_channel = cv2.filter2D(l_channel, -1, kernel)

        # ä¼½é¦¬æ ¡æ­£
        gamma = quality_config["gamma_correction"]
        if gamma != 1.0:
            lookup_table = np.array([((i / 255.0) ** (1.0 / gamma)) * 255
                                   for i in np.arange(0, 256)]).astype("uint8")
            l_channel = cv2.LUT(l_channel, lookup_table)

        # äº®åº¦å’Œå°æ¯”åº¦èª¿æ•´
        brightness = quality_config["brightness_adjustment"]
        contrast = quality_config["contrast_adjustment"]

        if brightness != 0 or contrast != 0:
            alpha = 1.0 + contrast / 100.0  # å°æ¯”åº¦
            beta = brightness  # äº®åº¦
            l_channel = cv2.convertScaleAbs(l_channel, alpha=alpha, beta=beta)

        # é‡çµ„åœ–åƒ
        if len(enhanced.shape) == 3:
            lab[:, :, 0] = l_channel
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        else:
            enhanced = l_channel

        return enhanced

    def remove_border(self, image: np.ndarray) -> np.ndarray:
        """ç§»é™¤åœ–åƒé‚Šæ¡†"""
        if not self.config["correction"]["border_removal"]:
            return image

        threshold_ratio = self.config["correction"]["border_threshold"]
        h, w = image.shape[:2]

        # è¨ˆç®—é‚Šæ¡†æª¢æ¸¬ç¯„åœ
        border_size = int(min(h, w) * threshold_ratio)

        # æª¢æ¸¬ä¸Šä¸‹é‚Šæ¡†
        top_border = 0
        bottom_border = h

        for y in range(border_size):
            if len(image.shape) == 3:
                mean_val = np.mean(image[y, :])
            else:
                mean_val = np.mean(image[y, :])

            if mean_val > 240:  # ç™½è‰²é‚Šæ¡†
                top_border = y + 1
            else:
                break

        for y in range(h - 1, h - border_size - 1, -1):
            if len(image.shape) == 3:
                mean_val = np.mean(image[y, :])
            else:
                mean_val = np.mean(image[y, :])

            if mean_val > 240:
                bottom_border = y
            else:
                break

        # æª¢æ¸¬å·¦å³é‚Šæ¡†
        left_border = 0
        right_border = w

        for x in range(border_size):
            if len(image.shape) == 3:
                mean_val = np.mean(image[:, x])
            else:
                mean_val = np.mean(image[:, x])

            if mean_val > 240:
                left_border = x + 1
            else:
                break

        for x in range(w - 1, w - border_size - 1, -1):
            if len(image.shape) == 3:
                mean_val = np.mean(image[:, x])
            else:
                mean_val = np.mean(image[:, x])

            if mean_val > 240:
                right_border = x
            else:
                break

        # è£å‰ªåœ–åƒ
        if (top_border < bottom_border - 10 and
            left_border < right_border - 10):
            cropped = image[top_border:bottom_border, left_border:right_border]
            logger.info(f"ç§»é™¤é‚Šæ¡†: ä¸Š{top_border}, ä¸‹{h-bottom_border}, "
                       f"å·¦{left_border}, å³{w-right_border}")
            return cropped

        return image

    def correct_document(self, image: np.ndarray,
                        corners: List[Tuple[int, int]],
                        paper_size: PaperSize = None,
                        target_size: Tuple[int, int] = None) -> Dict[str, Any]:
        """å®Œæ•´çš„æ–‡æª”æ ¡æ­£æµç¨‹"""
        results = {
            'success': False,
            'corrected_image': None,
            'transform': None,
            'processing_steps': {},
            'quality_metrics': {}
        }

        start_time = time.time()

        try:
            logger.info("é–‹å§‹æ–‡æª”é€è¦–æ ¡æ­£...")

            # æ­¥é©Ÿ1: å‰µå»ºé€è¦–è®Šæ›
            step_start = time.time()
            transform = self.create_perspective_transform(corners, target_size, paper_size)
            results['processing_steps']['transform_creation'] = (time.time() - step_start) * 1000
            results['transform'] = {
                'paper_size': transform.paper_size.name,
                'output_size': transform.output_size,
                'confidence': transform.confidence
            }

            # æ­¥é©Ÿ2: æ‡‰ç”¨é€è¦–è®Šæ›
            step_start = time.time()
            corrected = self.apply_perspective_transform(image, transform)
            results['processing_steps']['perspective_transform'] = (time.time() - step_start) * 1000

            # æ­¥é©Ÿ3: ç§»é™¤é‚Šæ¡†
            step_start = time.time()
            corrected = self.remove_border(corrected)
            results['processing_steps']['border_removal'] = (time.time() - step_start) * 1000

            # æ­¥é©Ÿ4: å“è³ªå¢å¼·
            step_start = time.time()
            corrected = self.enhance_quality(corrected)
            results['processing_steps']['quality_enhancement'] = (time.time() - step_start) * 1000

            results['corrected_image'] = corrected
            results['success'] = True

            # è¨ˆç®—å“è³ªæŒ‡æ¨™
            results['quality_metrics'] = self._calculate_quality_metrics(
                image, corrected, transform.confidence
            )

            total_time = (time.time() - start_time) * 1000
            results['total_time'] = total_time

            logger.info(f"æ–‡æª”æ ¡æ­£å®Œæˆï¼Œè€—æ™‚ {total_time:.1f}ms")
            logger.info(f"è¼¸å‡ºå°ºå¯¸: {corrected.shape[1]}x{corrected.shape[0]}")
            logger.info(f"è®Šæ›ç½®ä¿¡åº¦: {transform.confidence:.3f}")

        except Exception as e:
            logger.error(f"æ–‡æª”æ ¡æ­£å¤±æ•—: {e}")
            results['error'] = str(e)

        return results

    def _calculate_quality_metrics(self, original: np.ndarray,
                                 corrected: np.ndarray, confidence: float) -> Dict[str, float]:
        """è¨ˆç®—å“è³ªæŒ‡æ¨™"""
        metrics = {
            'transform_confidence': confidence,
            'output_resolution': corrected.shape[1] * corrected.shape[0]
        }

        try:
            # è¨ˆç®—éŠ³åº¦ (Laplacianæ–¹å·®)
            if len(corrected.shape) == 3:
                gray_corrected = cv2.cvtColor(corrected, cv2.COLOR_BGR2GRAY)
            else:
                gray_corrected = corrected

            laplacian = cv2.Laplacian(gray_corrected, cv2.CV_64F)
            metrics['sharpness'] = laplacian.var()

            # è¨ˆç®—å°æ¯”åº¦ (æ¨™æº–å·®)
            metrics['contrast'] = np.std(gray_corrected)

            # è¨ˆç®—äº®åº¦ (å¹³å‡å€¼)
            metrics['brightness'] = np.mean(gray_corrected)

        except Exception as e:
            logger.warning(f"å“è³ªæŒ‡æ¨™è¨ˆç®—å¤±æ•—: {e}")

        return metrics


def demo_perspective_correction():
    """é€è¦–æ ¡æ­£æ¼”ç¤º"""
    print("ğŸ“ æ™ºèƒ½æ–‡æª”é€è¦–æ ¡æ­£æ¼”ç¤º")
    print("=" * 50)

    # å‰µå»ºæ ¡æ­£å™¨
    corrector = DocumentPerspectiveCorrector()

    # æ¸¬è©¦åœ–åƒ
    test_image_path = "../../assets/images/basic/faces01.jpg"

    if not os.path.exists(test_image_path):
        print("âŒ æ¸¬è©¦åœ–åƒä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ“¬æ•¸æ“šæ¼”ç¤º")

        # å‰µå»ºæ¨¡æ“¬æ¸¬è©¦åœ–åƒ
        demo_image = np.ones((600, 800, 3), dtype=np.uint8) * 240

        # æ·»åŠ ä¸€äº›å…§å®¹
        cv2.rectangle(demo_image, (100, 100), (700, 500), (0, 0, 0), 2)
        cv2.putText(demo_image, "Document Content", (200, 300),
                   cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)

        # æ¨¡æ“¬æ–‡æª”è§’é»ï¼ˆç¨å¾®å‚¾æ–œï¼‰
        corners = [(120, 80), (680, 120), (660, 520), (80, 480)]

    else:
        # è¼‰å…¥çœŸå¯¦åœ–åƒ
        demo_image = load_image(test_image_path)
        demo_image = resize_image(demo_image, max_width=800)

        # æ¨¡æ“¬æª¢æ¸¬åˆ°çš„è§’é»
        h, w = demo_image.shape[:2]
        corners = [
            (int(w * 0.1), int(h * 0.1)),     # å·¦ä¸Š
            (int(w * 0.9), int(h * 0.15)),    # å³ä¸Š
            (int(w * 0.85), int(h * 0.9)),    # å³ä¸‹
            (int(w * 0.05), int(h * 0.85))    # å·¦ä¸‹
        ]

    print(f"ğŸ–¼ï¸  æ¸¬è©¦åœ–åƒå°ºå¯¸: {demo_image.shape}")
    print(f"ğŸ“ æ¨¡æ“¬è§’é»: {corners}")

    try:
        # åŸ·è¡Œé€è¦–æ ¡æ­£
        results = corrector.correct_document(
            demo_image,
            corners,
            paper_size=PaperSize.A4
        )

        if results['success']:
            print("âœ… é€è¦–æ ¡æ­£æˆåŠŸï¼")

            # é¡¯ç¤ºçµæœçµ±è¨ˆ
            print(f"ğŸ“Š è™•ç†çµæœ:")
            print(f"  ç¸½è€—æ™‚: {results['total_time']:.1f}ms")
            print(f"  ç´™å¼µé¡å‹: {results['transform']['paper_size']}")
            print(f"  è¼¸å‡ºå°ºå¯¸: {results['transform']['output_size']}")
            print(f"  è®Šæ›ç½®ä¿¡åº¦: {results['transform']['confidence']:.3f}")

            # é¡¯ç¤ºå“è³ªæŒ‡æ¨™
            print(f"ğŸ“ˆ å“è³ªæŒ‡æ¨™:")
            for metric, value in results['quality_metrics'].items():
                if isinstance(value, float):
                    print(f"  {metric}: {value:.2f}")
                else:
                    print(f"  {metric}: {value}")

            # é¡¯ç¤ºè™•ç†æ­¥é©Ÿè€—æ™‚
            print(f"â±ï¸  è™•ç†æ­¥é©Ÿ:")
            for step, time_ms in results['processing_steps'].items():
                print(f"  {step}: {time_ms:.1f}ms")

            # ç¹ªè£½è§’é»åœ¨åŸåœ–ä¸Š
            original_with_corners = demo_image.copy()
            for i, corner in enumerate(corners):
                cv2.circle(original_with_corners, corner, 10, (0, 255, 0), -1)
                cv2.putText(original_with_corners, str(i+1),
                           (corner[0]+15, corner[1]), cv2.FONT_HERSHEY_SIMPLEX,
                           0.8, (255, 0, 0), 2)

            # é€£æ¥è§’é»å½¢æˆå››é‚Šå½¢
            corners_array = np.array(corners, np.int32)
            cv2.polylines(original_with_corners, [corners_array], True, (0, 0, 255), 3)

            # å¯è¦–åŒ–çµæœ
            images = [original_with_corners, results['corrected_image']]
            titles = [
                f"åŸå§‹åœ–åƒ + è§’é»\n{demo_image.shape[1]}x{demo_image.shape[0]}",
                f"æ ¡æ­£çµæœ\n{results['corrected_image'].shape[1]}x{results['corrected_image'].shape[0]}"
            ]

            display_multiple_images(images, titles, figsize=(15, 8))

        else:
            print("âŒ é€è¦–æ ¡æ­£å¤±æ•—")
            if 'error' in results:
                print(f"éŒ¯èª¤ä¿¡æ¯: {results['error']}")

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")


if __name__ == "__main__":
    demo_perspective_correction()