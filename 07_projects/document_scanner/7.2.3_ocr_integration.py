#!/usr/bin/env python3
"""
7.2.3 æ™ºèƒ½æ–‡æª”æƒæå™¨ - OCRæ–‡å­—è­˜åˆ¥æ•´åˆæ¨¡çµ„

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†é«˜ç²¾åº¦çš„å…‰å­¸å­—ç¬¦è­˜åˆ¥(OCR)åŠŸèƒ½ï¼Œæ•´åˆTesseract OCRå¼•æ“ï¼Œ
æ”¯æ´å¤šèªè¨€æ–‡å­—è­˜åˆ¥ã€ç‰ˆé¢åˆ†æã€æ–‡å­—å€åŸŸæª¢æ¸¬ç­‰åŠŸèƒ½ã€‚

åŠŸèƒ½ç‰¹è‰²ï¼š
- Tesseract OCRå¼•æ“æ•´åˆ
- å¤šèªè¨€æ–‡å­—è­˜åˆ¥æ”¯æ´
- æ™ºèƒ½ç‰ˆé¢åˆ†æ (PSMæ¨¡å¼)
- æ–‡å­—å€åŸŸè‡ªå‹•æª¢æ¸¬
- æ–‡å­—æ–¹å‘æ ¡æ­£
- ç½®ä¿¡åº¦è©•ä¼°èˆ‡éæ¿¾
- å¤šæ ¼å¼è¼¸å‡º (TXT, JSON, PDF)
- æ‰¹é‡æ–‡æª”è™•ç†
- æ‰‹å¯«æ–‡å­—è­˜åˆ¥æ”¯æ´

ä½œè€…: OpenCV Computer Vision Toolkit
æ—¥æœŸ: 2024-10-14
ç‰ˆæœ¬: 1.0

ä¾è³´: pip install pytesseract pillow
"""

import cv2
import numpy as np
import os
import sys
import time
import json
import logging
import re
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, asdict
from enum import Enum
import math
from collections import defaultdict

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('../../utils')
try:
    from image_utils import load_image, resize_image
    from visualization import display_image, display_multiple_images
    from performance import time_function
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥å·¥å…·æ¨¡çµ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")

# å˜—è©¦å°å…¥Tesseract OCR
try:
    import pytesseract
    from PIL import Image, ImageEnhance, ImageFilter
    OCR_AVAILABLE = True
    print("âœ… Tesseract OCR å¯ç”¨")
except ImportError:
    OCR_AVAILABLE = False
    print("âŒ Tesseract OCR ä¸å¯ç”¨")
    print("è«‹å®‰è£: pip install pytesseract pillow")
    print("ä¸¦å®‰è£Tesseract-OCR: https://github.com/tesseract-ocr/tesseract")

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TextOrientation(Enum):
    """æ–‡å­—æ–¹å‘æšï¿½èˆ‰"""
    HORIZONTAL = 0    # æ°´å¹³
    VERTICAL_90 = 90  # å‚ç›´90åº¦
    UPSIDE_DOWN = 180 # å€’ç½®180åº¦
    VERTICAL_270 = 270 # å‚ç›´270åº¦

class PSMMode(Enum):
    """Tesseract é é¢åˆ†å‰²æ¨¡å¼"""
    OSD_ONLY = 0                    # åƒ…æ–¹å‘å’Œè…³æœ¬æª¢æ¸¬
    AUTO_OSD = 1                    # è‡ªå‹•é é¢åˆ†å‰²èˆ‡OSD
    AUTO_ONLY = 2                   # è‡ªå‹•é é¢åˆ†å‰²ï¼Œç„¡OSD
    FULLY_AUTO = 3                  # å…¨è‡ªå‹•é é¢åˆ†å‰²
    SINGLE_COLUMN = 4               # å–®åˆ—æ–‡å­—
    SINGLE_BLOCK_VERTICAL = 5       # å–®å€‹å‚ç›´æ–‡å­—å¡Š
    SINGLE_BLOCK = 6                # å–®å€‹æ–‡å­—å¡Š
    SINGLE_LINE = 7                 # å–®è¡Œæ–‡å­—
    SINGLE_WORD = 8                 # å–®å€‹è©èª
    CIRCLE_WORD = 9                 # åœ“å½¢ä¸­çš„å–®è©
    SINGLE_CHAR = 10                # å–®å€‹å­—ç¬¦
    SPARSE_TEXT = 11                # ç¨€ç–æ–‡å­—
    SPARSE_TEXT_OSD = 12            # ç¨€ç–æ–‡å­—èˆ‡OSD
    RAW_LINE = 13                   # åŸå§‹è¡Œ

@dataclass
class TextRegion:
    """æ–‡å­—å€åŸŸæ•¸æ“šçµæ§‹"""
    text: str
    confidence: float
    bbox: Tuple[int, int, int, int]  # (x, y, w, h)
    level: int                       # å±¤ç´š (word/line/paragraph/block)
    page_num: int = 0
    block_num: int = 0
    par_num: int = 0
    line_num: int = 0
    word_num: int = 0

@dataclass
class OCRResult:
    """OCRè­˜åˆ¥çµæœ"""
    full_text: str
    confidence: float
    text_regions: List[TextRegion]
    page_info: Dict[str, Any]
    processing_time: float
    language: str
    orientation: TextOrientation
    success: bool = True
    error_message: str = None

class DocumentOCRProcessor:
    """æ–‡æª”OCRè™•ç†å™¨"""

    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–OCRè™•ç†å™¨"""
        self.config = self._load_config(config_file)

        # æª¢æŸ¥Tesseractæ˜¯å¦å¯ç”¨
        if OCR_AVAILABLE:
            self._verify_tesseract()

        # æ”¯æ´çš„èªè¨€
        self.supported_languages = ["eng", "chi_sim", "chi_tra", "jpn", "kor"]

        logger.info("æ–‡æª”OCRè™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        default_config = {
            "ocr_engine": {
                "tesseract_cmd": "",  # Tesseractå¯åŸ·è¡Œæª”è·¯å¾‘ (ç•™ç©ºä½¿ç”¨ç³»çµ±PATH)
                "default_language": "eng",
                "psm_mode": 3,  # é é¢åˆ†å‰²æ¨¡å¼
                "oem_mode": 3,  # OCRå¼•æ“æ¨¡å¼ (0=Legacy, 1=Neural, 2=Legacy+Neural, 3=Default)
                "dpi": 300,     # è­˜åˆ¥DPI
                "timeout": 30   # è¶…æ™‚æ™‚é–“(ç§’)
            },
            "preprocessing": {
                "auto_rotate": True,           # è‡ªå‹•æ—‹è½‰æ ¡æ­£
                "enhance_contrast": True,      # å¢å¼·å°æ¯”åº¦
                "denoise": True,               # é™å™ª
                "binarization": True,          # äºŒå€¼åŒ–
                "deskew": True,                # å»å‚¾æ–œ
                "resize_factor": 2.0           # æ”¾å¤§å€æ•¸ä»¥æé«˜è­˜åˆ¥ç²¾åº¦
            },
            "text_filtering": {
                "min_confidence": 30,          # æœ€å°ç½®ä¿¡åº¦
                "min_word_length": 2,          # æœ€å°å–®è©é•·åº¦
                "filter_numbers_only": False,  # éæ¿¾ç´”æ•¸å­—
                "filter_special_chars": True,  # éæ¿¾ç‰¹æ®Šå­—ç¬¦
                "whitelist_chars": "",         # å­—ç¬¦ç™½åå–®
                "blacklist_chars": ""          # å­—ç¬¦é»‘åå–®
            },
            "output_format": {
                "include_confidence": True,    # åŒ…å«ç½®ä¿¡åº¦
                "include_coordinates": True,   # åŒ…å«åº§æ¨™ä¿¡æ¯
                "preserve_layout": True,       # ä¿æŒç‰ˆé¢å¸ƒå±€
                "export_formats": ["txt", "json"]  # å°å‡ºæ ¼å¼
            },
            "language_detection": {
                "auto_detect": False,          # è‡ªå‹•èªè¨€æª¢æ¸¬
                "fallback_language": "eng",    # å¾Œå‚™èªè¨€
                "mixed_language": False        # æ··åˆèªè¨€æ”¯æ´
            }
        }

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                self._deep_update(default_config, user_config)
                logger.info(f"å·²è¼‰å…¥é…ç½®æ–‡ä»¶: {config_file}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥é…ç½®æ–‡ä»¶: {e}ï¼Œä½¿ç”¨é è¨­é…ç½®")

        return default_config

    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if isinstance(value, dict) and key in base_dict:
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def _verify_tesseract(self):
        """é©—è­‰Tesseractå®‰è£"""
        try:
            # è¨­ç½®Tesseractè·¯å¾‘ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            tesseract_cmd = self.config["ocr_engine"]["tesseract_cmd"]
            if tesseract_cmd:
                pytesseract.pytesseract.tesseract_cmd = tesseract_cmd

            # æ¸¬è©¦Tesseract
            version = pytesseract.get_tesseract_version()
            logger.info(f"Tesseractç‰ˆæœ¬: {version}")

            # ç²å–æ”¯æ´çš„èªè¨€
            languages = pytesseract.get_languages()
            available_langs = [lang for lang in self.supported_languages if lang in languages]

            if available_langs:
                logger.info(f"å¯ç”¨èªè¨€: {available_langs}")
            else:
                logger.warning("æ²’æœ‰æ‰¾åˆ°æ”¯æ´çš„èªè¨€åŒ…")

        except Exception as e:
            logger.error(f"Tesseracté©—è­‰å¤±æ•—: {e}")
            global OCR_AVAILABLE
            OCR_AVAILABLE = False

    def preprocess_for_ocr(self, image: np.ndarray) -> np.ndarray:
        """é‡å°OCRå„ªåŒ–çš„åœ–åƒé è™•ç†"""
        preprocessed = image.copy()
        config = self.config["preprocessing"]

        # è½‰æ›ç‚ºç°éš
        if len(preprocessed.shape) == 3:
            preprocessed = cv2.cvtColor(preprocessed, cv2.COLOR_BGR2GRAY)

        # æ”¾å¤§åœ–åƒä»¥æé«˜è­˜åˆ¥ç²¾åº¦
        resize_factor = config["resize_factor"]
        if resize_factor != 1.0:
            new_width = int(preprocessed.shape[1] * resize_factor)
            new_height = int(preprocessed.shape[0] * resize_factor)
            preprocessed = cv2.resize(preprocessed, (new_width, new_height),
                                    interpolation=cv2.INTER_CUBIC)

        # é™å™ª
        if config["denoise"]:
            preprocessed = cv2.medianBlur(preprocessed, 3)

        # å¢å¼·å°æ¯”åº¦
        if config["enhance_contrast"]:
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            preprocessed = clahe.apply(preprocessed)

        # å»å‚¾æ–œ (ç°¡åŒ–ç‰ˆ)
        if config["deskew"]:
            preprocessed = self._deskew_image(preprocessed)

        # äºŒå€¼åŒ–
        if config["binarization"]:
            # ä½¿ç”¨è‡ªé©æ‡‰é–¾å€¼
            preprocessed = cv2.adaptiveThreshold(
                preprocessed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                cv2.THRESH_BINARY, 11, 2
            )

        return preprocessed

    def _deskew_image(self, image: np.ndarray) -> np.ndarray:
        """å»é™¤åœ–åƒå‚¾æ–œ"""
        try:
            # ä½¿ç”¨éœå¤«ç·šè®Šæ›æª¢æ¸¬ä¸»è¦ç·šæ¢
            edges = cv2.Canny(image, 50, 150, apertureSize=3)
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)

            if lines is not None:
                # è¨ˆç®—ä¸»è¦è§’åº¦
                angles = []
                for line in lines[:10]:  # åªè€ƒæ…®å‰10æ¢ç·š
                    rho, theta = line[0]
                    angle = theta * 180 / np.pi

                    # è½‰æ›ç‚º-90åˆ°90åº¦ç¯„åœ
                    if angle > 90:
                        angle -= 180
                    elif angle < -90:
                        angle += 180

                    angles.append(angle)

                if angles:
                    # ä½¿ç”¨ä¸­ä½æ•¸ä½œç‚ºä¸»è¦è§’åº¦
                    median_angle = np.median(angles)

                    # å¦‚æœè§’åº¦åå·®è¶…éé–¾å€¼ï¼Œé€²è¡Œæ—‹è½‰æ ¡æ­£
                    if abs(median_angle) > 2:
                        h, w = image.shape
                        center = (w // 2, h // 2)
                        M = cv2.getRotationMatrix2D(center, median_angle, 1.0)

                        # è¨ˆç®—æ–°çš„é‚Šç•Œå¤§å°
                        cos_angle = abs(np.cos(np.radians(median_angle)))
                        sin_angle = abs(np.sin(np.radians(median_angle)))
                        new_w = int((h * sin_angle) + (w * cos_angle))
                        new_h = int((h * cos_angle) + (w * sin_angle))

                        # èª¿æ•´å¹³ç§»
                        M[0, 2] += (new_w - w) / 2
                        M[1, 2] += (new_h - h) / 2

                        deskewed = cv2.warpAffine(image, M, (new_w, new_h),
                                                borderValue=255)

                        logger.debug(f"åœ–åƒå»å‚¾æ–œ: {median_angle:.1f}åº¦")
                        return deskewed

        except Exception as e:
            logger.warning(f"å»å‚¾æ–œè™•ç†å¤±æ•—: {e}")

        return image

    def detect_text_regions(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """æª¢æ¸¬æ–‡å­—å€åŸŸ"""
        # ä½¿ç”¨EASTæ–‡å­—æª¢æ¸¬ï¼ˆå¦‚æœå¯ç”¨ï¼‰æˆ–å‚³çµ±æ–¹æ³•
        try:
            # æ–¹æ³•1: ä½¿ç”¨å½¢æ…‹å­¸æ“ä½œæª¢æ¸¬æ–‡å­—å€åŸŸ
            preprocessed = self.preprocess_for_ocr(image)

            # å‰µå»ºçŸ©å½¢æ ¸ç”¨æ–¼é€£æ¥æ–‡å­—
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 3))

            # æ‡‰ç”¨å½¢æ…‹å­¸æ“ä½œ
            dilated = cv2.dilate(preprocessed, kernel, iterations=2)

            # æŸ¥æ‰¾è¼ªå»“
            contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL,
                                         cv2.CHAIN_APPROX_SIMPLE)

            text_regions = []
            min_area = 500  # æœ€å°æ–‡å­—å€åŸŸé¢ç©

            for contour in contours:
                area = cv2.contourArea(contour)
                if area > min_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    # éæ¿¾é•·å¯¬æ¯”ä¸åˆç†çš„å€åŸŸ
                    aspect_ratio = w / h
                    if 0.1 < aspect_ratio < 20:
                        text_regions.append((x, y, w, h))

            # æŒ‰ä½ç½®æ’åºï¼ˆå¾ä¸Šåˆ°ä¸‹ï¼Œå¾å·¦åˆ°å³ï¼‰
            text_regions.sort(key=lambda region: (region[1], region[0]))

            return text_regions

        except Exception as e:
            logger.error(f"æ–‡å­—å€åŸŸæª¢æ¸¬å¤±æ•—: {e}")
            return []

    def extract_text(self, image: np.ndarray, language: str = None,
                    psm_mode: PSMMode = None) -> OCRResult:
        """æå–æ–‡å­—å…§å®¹"""
        if not OCR_AVAILABLE:
            return OCRResult(
                full_text="",
                confidence=0.0,
                text_regions=[],
                page_info={},
                processing_time=0.0,
                language="",
                orientation=TextOrientation.HORIZONTAL,
                success=False,
                error_message="Tesseract OCR ä¸å¯ç”¨"
            )

        start_time = time.time()

        try:
            # è¨­ç½®èªè¨€
            if language is None:
                language = self.config["ocr_engine"]["default_language"]

            # è¨­ç½®PSMæ¨¡å¼
            if psm_mode is None:
                psm_mode = PSMMode(self.config["ocr_engine"]["psm_mode"])

            # é è™•ç†åœ–åƒ
            preprocessed = self.preprocess_for_ocr(image)

            # è½‰æ›ç‚ºPILåœ–åƒ
            pil_image = Image.fromarray(preprocessed)

            # è¨­ç½®Tesseracté…ç½®
            custom_config = f'--oem {self.config["ocr_engine"]["oem_mode"]} --psm {psm_mode.value}'

            # æ·»åŠ å­—ç¬¦éæ¿¾
            filtering_config = self.config["text_filtering"]
            if filtering_config["whitelist_chars"]:
                custom_config += f' -c tessedit_char_whitelist={filtering_config["whitelist_chars"]}'

            # åŸ·è¡ŒOCR
            full_text = pytesseract.image_to_string(
                pil_image, lang=language, config=custom_config
            )

            # ç²å–è©³ç´°æ•¸æ“š
            data = pytesseract.image_to_data(
                pil_image, lang=language, config=custom_config, output_type=pytesseract.Output.DICT
            )

            # ç²å–é é¢ä¿¡æ¯
            try:
                page_info = pytesseract.image_to_osd(pil_image, output_type=pytesseract.Output.DICT)
            except:
                page_info = {"orientation": 0, "script": "Latin", "confidence": 0}

            # è§£ææ–‡å­—å€åŸŸ
            text_regions = self._parse_text_regions(data)

            # è¨ˆç®—ç¸½é«”ç½®ä¿¡åº¦
            overall_confidence = self._calculate_overall_confidence(text_regions)

            # ç¢ºå®šæ–‡å­—æ–¹å‘
            orientation = TextOrientation(page_info.get("orientation", 0))

            # å¾Œè™•ç†æ–‡å­—
            cleaned_text = self._post_process_text(full_text)

            processing_time = (time.time() - start_time) * 1000

            return OCRResult(
                full_text=cleaned_text,
                confidence=overall_confidence,
                text_regions=text_regions,
                page_info=page_info,
                processing_time=processing_time,
                language=language,
                orientation=orientation,
                success=True
            )

        except Exception as e:
            processing_time = (time.time() - start_time) * 1000
            logger.error(f"OCRè™•ç†å¤±æ•—: {e}")

            return OCRResult(
                full_text="",
                confidence=0.0,
                text_regions=[],
                page_info={},
                processing_time=processing_time,
                language=language or "",
                orientation=TextOrientation.HORIZONTAL,
                success=False,
                error_message=str(e)
            )

    def _parse_text_regions(self, ocr_data: Dict) -> List[TextRegion]:
        """è§£æOCRæ•¸æ“šä¸­çš„æ–‡å­—å€åŸŸ"""
        text_regions = []
        min_confidence = self.config["text_filtering"]["min_confidence"]
        min_word_length = self.config["text_filtering"]["min_word_length"]

        for i in range(len(ocr_data['text'])):
            text = ocr_data['text'][i].strip()
            confidence = int(ocr_data['conf'][i])

            # éæ¿¾ä½ç½®ä¿¡åº¦å’ŒçŸ­æ–‡å­—
            if confidence < min_confidence or len(text) < min_word_length:
                continue

            # éæ¿¾ç©ºæ–‡å­—
            if not text or text.isspace():
                continue

            # ç²å–é‚Šç•Œæ¡†
            x = ocr_data['left'][i]
            y = ocr_data['top'][i]
            w = ocr_data['width'][i]
            h = ocr_data['height'][i]

            # éæ¿¾ç„¡æ•ˆé‚Šç•Œæ¡†
            if w <= 0 or h <= 0:
                continue

            text_region = TextRegion(
                text=text,
                confidence=confidence,
                bbox=(x, y, w, h),
                level=ocr_data['level'][i],
                page_num=ocr_data['page_num'][i],
                block_num=ocr_data['block_num'][i],
                par_num=ocr_data['par_num'][i],
                line_num=ocr_data['line_num'][i],
                word_num=ocr_data['word_num'][i]
            )

            text_regions.append(text_region)

        return text_regions

    def _calculate_overall_confidence(self, text_regions: List[TextRegion]) -> float:
        """è¨ˆç®—æ•´é«”ç½®ä¿¡åº¦"""
        if not text_regions:
            return 0.0

        # ä½¿ç”¨åŠ æ¬Šå¹³å‡ï¼ˆè¼ƒé•·çš„æ–‡å­—æ¬Šé‡æ›´é«˜ï¼‰
        total_weight = 0
        weighted_confidence = 0

        for region in text_regions:
            weight = len(region.text)
            weighted_confidence += region.confidence * weight
            total_weight += weight

        return weighted_confidence / total_weight if total_weight > 0 else 0.0

    def _post_process_text(self, text: str) -> str:
        """å¾Œè™•ç†è­˜åˆ¥çš„æ–‡å­—"""
        if not text:
            return text

        # ç§»é™¤å¤šé¤˜ç©ºç™½
        cleaned = re.sub(r'\s+', ' ', text)
        cleaned = cleaned.strip()

        # éæ¿¾ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if self.config["text_filtering"]["filter_special_chars"]:
            # ä¿ç•™å­—æ¯ã€æ•¸å­—ã€åŸºæœ¬æ¨™é»å’Œç©ºæ ¼
            cleaned = re.sub(r'[^\w\s.,!?;:\-()"\']', '', cleaned)

        # æ‡‰ç”¨å­—ç¬¦é»‘åå–®
        blacklist = self.config["text_filtering"]["blacklist_chars"]
        if blacklist:
            for char in blacklist:
                cleaned = cleaned.replace(char, '')

        return cleaned

    def visualize_ocr_results(self, original_image: np.ndarray,
                            ocr_result: OCRResult) -> np.ndarray:
        """å¯è¦–åŒ–OCRè­˜åˆ¥çµæœ"""
        result = original_image.copy()

        if not ocr_result.success or not ocr_result.text_regions:
            # æ·»åŠ éŒ¯èª¤ä¿¡æ¯
            cv2.putText(result, "OCR Failed", (20, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            return result

        # ç¹ªè£½æ–‡å­—å€åŸŸ
        for i, region in enumerate(ocr_result.text_regions):
            x, y, w, h = region.bbox

            # æ ¹æ“šç½®ä¿¡åº¦é¸æ“‡é¡è‰²
            if region.confidence >= 80:
                color = (0, 255, 0)  # ç¶ è‰² - é«˜ç½®ä¿¡åº¦
            elif region.confidence >= 60:
                color = (0, 255, 255)  # é»ƒè‰² - ä¸­ç­‰ç½®ä¿¡åº¦
            else:
                color = (0, 0, 255)   # ç´…è‰² - ä½ç½®ä¿¡åº¦

            # ç¹ªè£½é‚Šç•Œæ¡†
            cv2.rectangle(result, (x, y), (x + w, y + h), color, 2)

            # é¡¯ç¤ºç½®ä¿¡åº¦
            conf_text = f"{region.confidence:.0f}%"
            cv2.putText(result, conf_text, (x, y - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

        # æ·»åŠ ç¸½é«”ä¿¡æ¯
        info_text = [
            f"èªè¨€: {ocr_result.language}",
            f"ç¸½é«”ç½®ä¿¡åº¦: {ocr_result.confidence:.1f}%",
            f"è™•ç†æ™‚é–“: {ocr_result.processing_time:.0f}ms",
            f"æ–‡å­—å€åŸŸ: {len(ocr_result.text_regions)}"
        ]

        for i, text in enumerate(info_text):
            y_pos = 30 + i * 25
            cv2.putText(result, text, (10, y_pos),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(result, text, (10, y_pos),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)

        return result

    def export_results(self, ocr_result: OCRResult, output_path: str,
                      formats: List[str] = None) -> Dict[str, str]:
        """å°å‡ºOCRçµæœåˆ°ä¸åŒæ ¼å¼"""
        if formats is None:
            formats = self.config["output_format"]["export_formats"]

        exported_files = {}

        try:
            base_path = os.path.splitext(output_path)[0]

            for format_type in formats:
                if format_type == "txt":
                    # ç´”æ–‡å­—æ ¼å¼
                    txt_path = f"{base_path}.txt"
                    with open(txt_path, 'w', encoding='utf-8') as f:
                        f.write(ocr_result.full_text)
                    exported_files["txt"] = txt_path

                elif format_type == "json":
                    # JSONæ ¼å¼ï¼ˆåŒ…å«è©³ç´°ä¿¡æ¯ï¼‰
                    json_path = f"{base_path}.json"

                    export_data = {
                        "full_text": ocr_result.full_text,
                        "confidence": ocr_result.confidence,
                        "language": ocr_result.language,
                        "orientation": ocr_result.orientation.value,
                        "processing_time": ocr_result.processing_time,
                        "page_info": ocr_result.page_info,
                        "text_regions": []
                    }

                    # æ·»åŠ æ–‡å­—å€åŸŸä¿¡æ¯ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
                    if self.config["output_format"]["include_coordinates"]:
                        for region in ocr_result.text_regions:
                            export_data["text_regions"].append({
                                "text": region.text,
                                "confidence": region.confidence,
                                "bbox": region.bbox,
                                "level": region.level
                            })

                    with open(json_path, 'w', encoding='utf-8') as f:
                        json.dump(export_data, f, ensure_ascii=False, indent=2)

                    exported_files["json"] = json_path

            logger.info(f"OCRçµæœå·²å°å‡º: {list(exported_files.keys())}")

        except Exception as e:
            logger.error(f"å°å‡ºOCRçµæœå¤±æ•—: {e}")

        return exported_files

    def batch_process_documents(self, input_dir: str, output_dir: str,
                               language: str = None) -> Dict[str, Any]:
        """æ‰¹é‡è™•ç†æ–‡æª”"""
        results = {
            "processed_files": 0,
            "successful_files": 0,
            "failed_files": [],
            "total_time": 0,
            "average_confidence": 0,
            "exported_files": []
        }

        if not os.path.exists(input_dir):
            logger.error(f"è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨: {input_dir}")
            return results

        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        os.makedirs(output_dir, exist_ok=True)

        # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
        supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif')

        start_time = time.time()
        confidences = []

        # éæ­·è¼¸å…¥ç›®éŒ„
        for filename in os.listdir(input_dir):
            if not filename.lower().endswith(supported_formats):
                continue

            input_path = os.path.join(input_dir, filename)
            base_name = os.path.splitext(filename)[0]
            output_path = os.path.join(output_dir, base_name)

            results["processed_files"] += 1

            try:
                logger.info(f"è™•ç†æ–‡ä»¶: {filename}")

                # è¼‰å…¥åœ–åƒ
                image = load_image(input_path)
                if image is None:
                    results["failed_files"].append(f"{filename}: ç„¡æ³•è¼‰å…¥åœ–åƒ")
                    continue

                # åŸ·è¡ŒOCR
                ocr_result = self.extract_text(image, language)

                if ocr_result.success:
                    # å°å‡ºçµæœ
                    exported = self.export_results(ocr_result, output_path)
                    results["exported_files"].extend(exported.values())
                    results["successful_files"] += 1
                    confidences.append(ocr_result.confidence)

                    logger.info(f"  æˆåŠŸ: ç½®ä¿¡åº¦ {ocr_result.confidence:.1f}%, "
                               f"æ–‡å­—é•·åº¦ {len(ocr_result.full_text)}")
                else:
                    results["failed_files"].append(f"{filename}: {ocr_result.error_message}")

            except Exception as e:
                error_msg = f"{filename}: {e}"
                results["failed_files"].append(error_msg)
                logger.error(f"è™•ç†æ–‡ä»¶å¤±æ•—: {error_msg}")

        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        results["total_time"] = (time.time() - start_time)
        results["average_confidence"] = np.mean(confidences) if confidences else 0

        logger.info(f"æ‰¹é‡è™•ç†å®Œæˆ: {results['successful_files']}/{results['processed_files']} æˆåŠŸ")

        return results


def demo_ocr_integration():
    """OCRæ•´åˆæ¼”ç¤º"""
    print("ğŸ“– æ™ºèƒ½æ–‡æª”OCRè­˜åˆ¥æ¼”ç¤º")
    print("=" * 50)

    if not OCR_AVAILABLE:
        print("âŒ Tesseract OCR ä¸å¯ç”¨ï¼Œç„¡æ³•åŸ·è¡Œæ¼”ç¤º")
        print("è«‹å®‰è£ä¾è³´:")
        print("  pip install pytesseract pillow")
        print("  ä¸¦å®‰è£ Tesseract-OCR è»Ÿé«”")
        return

    # å‰µå»ºOCRè™•ç†å™¨
    ocr_processor = DocumentOCRProcessor()

    # æ¸¬è©¦åœ–åƒ
    test_image_path = "../../assets/images/basic/faces01.jpg"

    if not os.path.exists(test_image_path):
        print("âŒ æ¸¬è©¦åœ–åƒä¸å­˜åœ¨ï¼Œå‰µå»ºæ¨¡æ“¬æ–‡æª”åœ–åƒ")

        # å‰µå»ºæ¨¡æ“¬æ–‡æª”
        demo_image = np.ones((600, 800, 3), dtype=np.uint8) * 255

        # æ·»åŠ ä¸€äº›æ–‡å­—å…§å®¹
        cv2.putText(demo_image, "Sample Document", (50, 100),
                   cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)
        cv2.putText(demo_image, "This is a test document for OCR demonstration.", (50, 200),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        cv2.putText(demo_image, "Line 1: Computer Vision Project", (50, 300),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)
        cv2.putText(demo_image, "Line 2: OpenCV Document Scanner", (50, 350),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)
        cv2.putText(demo_image, "Line 3: OCR Integration Demo", (50, 400),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)

        print("âœ… å·²å‰µå»ºæ¨¡æ“¬æ–‡æª”åœ–åƒ")

    else:
        # è¼‰å…¥çœŸå¯¦åœ–åƒ
        demo_image = load_image(test_image_path)
        demo_image = resize_image(demo_image, max_width=800)
        print(f"âœ… å·²è¼‰å…¥æ¸¬è©¦åœ–åƒ: {os.path.basename(test_image_path)}")

    print(f"ğŸ–¼ï¸  åœ–åƒå°ºå¯¸: {demo_image.shape}")

    # æ¸¬è©¦ä¸åŒçš„PSMæ¨¡å¼
    psm_modes_to_test = [
        (PSMMode.FULLY_AUTO, "å…¨è‡ªå‹•é é¢åˆ†å‰²"),
        (PSMMode.SINGLE_BLOCK, "å–®å€‹æ–‡å­—å¡Š"),
        (PSMMode.SINGLE_COLUMN, "å–®åˆ—æ–‡å­—")
    ]

    for psm_mode, description in psm_modes_to_test:
        print(f"\nğŸ” æ¸¬è©¦ {description} (PSM {psm_mode.value}):")

        # åŸ·è¡ŒOCR
        ocr_result = ocr_processor.extract_text(demo_image, psm_mode=psm_mode)

        if ocr_result.success:
            print(f"  âœ… OCRæˆåŠŸ")
            print(f"     ç¸½é«”ç½®ä¿¡åº¦: {ocr_result.confidence:.1f}%")
            print(f"     è™•ç†æ™‚é–“: {ocr_result.processing_time:.0f}ms")
            print(f"     æ–‡å­—å€åŸŸæ•¸: {len(ocr_result.text_regions)}")
            print(f"     æ–‡å­—é•·åº¦: {len(ocr_result.full_text)} å­—ç¬¦")

            # é¡¯ç¤ºè­˜åˆ¥çš„æ–‡å­—ï¼ˆå‰100å­—ç¬¦ï¼‰
            text_preview = ocr_result.full_text[:100].replace('\n', ' ')
            print(f"     æ–‡å­—é è¦½: {text_preview}{'...' if len(ocr_result.full_text) > 100 else ''}")

            # å¯è¦–åŒ–çµæœ
            visualization = ocr_processor.visualize_ocr_results(demo_image, ocr_result)

            # é¡¯ç¤ºçµæœ
            display_multiple_images(
                [demo_image, visualization],
                ["åŸå§‹åœ–åƒ", f"{description}\nç½®ä¿¡åº¦: {ocr_result.confidence:.1f}%"],
                figsize=(15, 8)
            )

            # å°å‡ºçµæœ
            if ocr_result.full_text.strip():
                export_path = f"ocr_demo_{psm_mode.value}"
                exported_files = ocr_processor.export_results(ocr_result, export_path)
                if exported_files:
                    print(f"     å·²å°å‡º: {list(exported_files.keys())}")

        else:
            print(f"  âŒ OCRå¤±æ•—: {ocr_result.error_message}")

    # é¡¯ç¤ºåŠŸèƒ½ç¸½çµ
    print(f"\nğŸ“‹ OCRæ•´åˆåŠŸèƒ½ç¸½çµ:")
    print(f"â€¢ å¤šèªè¨€æ–‡å­—è­˜åˆ¥ (è‹±æ–‡ã€ä¸­æ–‡ç°¡ç¹ã€æ—¥æ–‡ã€éŸ“æ–‡)")
    print(f"â€¢ æ™ºèƒ½é è™•ç† (å»å‚¾æ–œã€é™å™ªã€å°æ¯”åº¦å¢å¼·)")
    print(f"â€¢ éˆæ´»çš„é é¢åˆ†å‰²æ¨¡å¼")
    print(f"â€¢ ç½®ä¿¡åº¦è©•ä¼°èˆ‡å“è³ªéæ¿¾")
    print(f"â€¢ å¤šæ ¼å¼è¼¸å‡º (TXT, JSON)")
    print(f"â€¢ æ‰¹é‡è™•ç†æ”¯æ´")

    print(f"\nğŸ¯ å¯¦éš›æ‡‰ç”¨å ´æ™¯:")
    print(f"â€¢ æ–‡æª”æ•¸ä½åŒ–")
    print(f"â€¢ ç™¼ç¥¨å’Œæ”¶æ“šè­˜åˆ¥")
    print(f"â€¢ åç‰‡ä¿¡æ¯æå–")
    print(f"â€¢ æ›¸ç±å’Œå ±ç´™æƒæ")
    print(f"â€¢ è¡¨æ ¼æ•¸æ“šæå–")


if __name__ == "__main__":
    demo_ocr_integration()