#!/usr/bin/env python3
"""
7.3.1 é†«å­¸å½±åƒåˆ†æç³»çµ± - å½±åƒå¢å¼·æ¨¡çµ„

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†å°ˆç‚ºé†«å­¸å½±åƒå„ªåŒ–çš„å¢å¼·ç®—æ³•ï¼ŒåŒ…æ‹¬å°æ¯”åº¦å¢å¼·ã€
é™å™ªè™•ç†ã€éŠ³åŒ–ã€ç›´æ–¹åœ–å‡åŒ–ç­‰åŠŸèƒ½ï¼Œé©ç”¨æ–¼Xå…‰ã€CTã€MRIç­‰é†«å­¸å½±åƒã€‚

åŠŸèƒ½ç‰¹è‰²ï¼š
- å¤šç¨®å°æ¯”åº¦å¢å¼·æ–¹æ³• (CLAHE, HE, Gamma)
- å°ˆæ¥­é™å™ªç®—æ³• (Bilateral, NLM, Gaussian)
- è‡ªé©æ‡‰éŠ³åŒ–è™•ç†
- ç›´æ–¹åœ–åˆ†æèˆ‡å‡åŒ–
- é†«å­¸å½±åƒç‰¹å®šå„ªåŒ–
- é‡åŒ–å“è³ªè©•ä¼°
- æ‰¹é‡è™•ç†æ”¯æ´
- DICOMç›¸å®¹æ€§æº–å‚™

ä½œè€…: OpenCV Computer Vision Toolkit
æ—¥æœŸ: 2024-10-14
ç‰ˆæœ¬: 1.0

æ³¨æ„: æœ¬æ¨¡çµ„åƒ…ç”¨æ–¼æ•™å­¸å’Œç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨æ–¼å¯¦éš›é†«ç™‚è¨ºæ–·ã€‚
     çœŸå¯¦é†«å­¸å½±åƒè™•ç†éœ€è¦å°ˆæ¥­é†«ç™‚è»Ÿé«”å’Œé†«å¸«å°ˆæ¥­åˆ¤æ–·ã€‚
"""

import cv2
import numpy as np
import os
import sys
import time
import json
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, asdict
from enum import Enum
import math

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('../../utils')
try:
    from image_utils import load_image, resize_image
    from visualization import display_image, display_multiple_images
    from performance import time_function
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥å·¥å…·æ¨¡çµ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ImagingModality(Enum):
    """é†«å­¸å½±åƒæ¨¡æ…‹æšèˆ‰"""
    XRAY = "X-Ray"           # Xå…‰å½±åƒ
    CT = "CT"                # é›»è…¦æ–·å±¤
    MRI = "MRI"              # ç£å…±æŒ¯
    ULTRASOUND = "US"        # è¶…éŸ³æ³¢
    MAMMOGRAPHY = "MG"       # ä¹³æˆ¿æ”å½±
    GENERAL = "General"      # ä¸€èˆ¬é†«å­¸å½±åƒ

@dataclass
class EnhancementParameters:
    """å½±åƒå¢å¼·åƒæ•¸"""
    contrast_method: str = "clahe"      # å°æ¯”åº¦å¢å¼·æ–¹æ³•
    noise_reduction: str = "bilateral"  # é™å™ªæ–¹æ³•
    sharpening: bool = True            # æ˜¯å¦éŠ³åŒ–
    gamma_correction: float = 1.0      # ä¼½é¦¬æ ¡æ­£
    brightness_adjustment: int = 0      # äº®åº¦èª¿æ•´
    contrast_adjustment: int = 0        # å°æ¯”åº¦èª¿æ•´

@dataclass
class QualityMetrics:
    """å½±åƒå“è³ªæŒ‡æ¨™"""
    contrast: float = 0.0              # å°æ¯”åº¦
    sharpness: float = 0.0             # éŠ³åº¦
    noise_level: float = 0.0           # å™ªè²æ°´æº–
    brightness: float = 0.0            # äº®åº¦
    entropy: float = 0.0               # ç†µå€¼
    snr: float = 0.0                   # ä¿¡å™ªæ¯”

class MedicalImageEnhancer:
    """é†«å­¸å½±åƒå¢å¼·å™¨"""

    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–é†«å­¸å½±åƒå¢å¼·å™¨"""
        self.config = self._load_config(config_file)

        # ä¸åŒé†«å­¸å½±åƒæ¨¡æ…‹çš„é è¨­åƒæ•¸
        self.modality_presets = {
            ImagingModality.XRAY: EnhancementParameters(
                contrast_method="clahe",
                noise_reduction="bilateral",
                sharpening=True,
                gamma_correction=1.2,
                brightness_adjustment=10,
                contrast_adjustment=15
            ),
            ImagingModality.CT: EnhancementParameters(
                contrast_method="histogram_equalization",
                noise_reduction="gaussian",
                sharpening=False,
                gamma_correction=1.0,
                brightness_adjustment=0,
                contrast_adjustment=20
            ),
            ImagingModality.MRI: EnhancementParameters(
                contrast_method="adaptive_histogram",
                noise_reduction="nlm",
                sharpening=True,
                gamma_correction=0.9,
                brightness_adjustment=5,
                contrast_adjustment=10
            ),
            ImagingModality.ULTRASOUND: EnhancementParameters(
                contrast_method="clahe",
                noise_reduction="bilateral",
                sharpening=True,
                gamma_correction=1.1,
                brightness_adjustment=0,
                contrast_adjustment=25
            ),
            ImagingModality.MAMMOGRAPHY: EnhancementParameters(
                contrast_method="clahe",
                noise_reduction="nlm",
                sharpening=True,
                gamma_correction=1.3,
                brightness_adjustment=5,
                contrast_adjustment=20
            ),
            ImagingModality.GENERAL: EnhancementParameters()
        }

        logger.info("é†«å­¸å½±åƒå¢å¼·å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.warning("âš ï¸ åƒ…ç”¨æ–¼æ•™å­¸ç ”ç©¶ï¼Œä¸å¾—ç”¨æ–¼å¯¦éš›é†«ç™‚è¨ºæ–·")

    def _load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        default_config = {
            "enhancement": {
                "default_modality": "GENERAL",
                "preserve_dynamic_range": True,
                "output_bit_depth": 16,  # é†«å­¸å½±åƒé€šå¸¸éœ€è¦æ›´é«˜ä½æ·±
                "roi_based_enhancement": False
            },
            "contrast_enhancement": {
                "clahe_clip_limit": 3.0,
                "clahe_tile_grid_size": [8, 8],
                "adaptive_histogram_window": 64,
                "gamma_range": [0.5, 2.0]
            },
            "noise_reduction": {
                "bilateral_d": 9,
                "bilateral_sigma_color": 75,
                "bilateral_sigma_space": 75,
                "gaussian_kernel_size": 5,
                "gaussian_sigma": 1.0,
                "nlm_h": 10,
                "nlm_template_window": 7,
                "nlm_search_window": 21
            },
            "sharpening": {
                "unsharp_mask_amount": 1.5,
                "unsharp_mask_radius": 1.0,
                "laplacian_kernel_size": 3,
                "adaptive_sharpening": True
            },
            "quality_assessment": {
                "calculate_metrics": True,
                "reference_based": False,
                "save_metrics": True
            },
            "safety": {
                "preserve_original": True,
                "limit_enhancement_range": True,
                "prevent_over_enhancement": True
            }
        }

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                self._deep_update(default_config, user_config)
                logger.info(f"å·²è¼‰å…¥é…ç½®æ–‡ä»¶: {config_file}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥é…ç½®æ–‡ä»¶: {e}ï¼Œä½¿ç”¨é è¨­é…ç½®")

        return default_config

    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if isinstance(value, dict) and key in base_dict:
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def enhance_contrast_clahe(self, image: np.ndarray) -> np.ndarray:
        """CLAHE (å°æ¯”åº¦é™åˆ¶è‡ªé©æ‡‰ç›´æ–¹åœ–å‡åŒ–)"""
        config = self.config["contrast_enhancement"]

        # è½‰æ›ç‚ºé©ç•¶çš„æ•¸æ“šé¡å‹
        if image.dtype != np.uint8:
            if image.max() <= 1.0:
                image_8bit = (image * 255).astype(np.uint8)
            else:
                image_8bit = cv2.convertScaleAbs(image)
        else:
            image_8bit = image.copy()

        # å‰µå»ºCLAHEç‰©ä»¶
        clahe = cv2.createCLAHE(
            clipLimit=config["clahe_clip_limit"],
            tileGridSize=tuple(config["clahe_tile_grid_size"])
        )

        if len(image_8bit.shape) == 3:
            # å½©è‰²å½±åƒï¼šåœ¨Labè‰²å½©ç©ºé–“ä¸­è™•ç†Lé€šé“
            lab = cv2.cvtColor(image_8bit, cv2.COLOR_BGR2LAB)
            lab[:, :, 0] = clahe.apply(lab[:, :, 0])
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        else:
            # ç°éšå½±åƒ
            enhanced = clahe.apply(image_8bit)

        return enhanced

    def enhance_contrast_histogram_equalization(self, image: np.ndarray) -> np.ndarray:
        """å‚³çµ±ç›´æ–¹åœ–å‡åŒ–"""
        if image.dtype != np.uint8:
            if image.max() <= 1.0:
                image_8bit = (image * 255).astype(np.uint8)
            else:
                image_8bit = cv2.convertScaleAbs(image)
        else:
            image_8bit = image.copy()

        if len(image_8bit.shape) == 3:
            # å½©è‰²å½±åƒ
            lab = cv2.cvtColor(image_8bit, cv2.COLOR_BGR2LAB)
            lab[:, :, 0] = cv2.equalizeHist(lab[:, :, 0])
            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        else:
            # ç°éšå½±åƒ
            enhanced = cv2.equalizeHist(image_8bit)

        return enhanced

    def enhance_contrast_adaptive_histogram(self, image: np.ndarray) -> np.ndarray:
        """è‡ªé©æ‡‰ç›´æ–¹åœ–å¢å¼·"""
        if image.dtype != np.uint8:
            if image.max() <= 1.0:
                image_8bit = (image * 255).astype(np.uint8)
            else:
                image_8bit = cv2.convertScaleAbs(image)
        else:
            image_8bit = image.copy()

        window_size = self.config["contrast_enhancement"]["adaptive_histogram_window"]

        if len(image_8bit.shape) == 3:
            lab = cv2.cvtColor(image_8bit, cv2.COLOR_BGR2LAB)
            l_channel = lab[:, :, 0]
        else:
            l_channel = image_8bit.copy()

        # å¯¦ç¾è‡ªé©æ‡‰ç›´æ–¹åœ–å¢å¼·
        h, w = l_channel.shape
        enhanced = np.zeros_like(l_channel)

        for i in range(0, h, window_size // 2):
            for j in range(0, w, window_size // 2):
                # å®šç¾©çª—å£
                y1 = max(0, i - window_size // 2)
                y2 = min(h, i + window_size // 2)
                x1 = max(0, j - window_size // 2)
                x2 = min(w, j + window_size // 2)

                # æå–çª—å£å€åŸŸ
                window = l_channel[y1:y2, x1:x2]

                if window.size > 0:
                    # è¨ˆç®—å±€éƒ¨ç›´æ–¹åœ–å‡åŒ–
                    equalized = cv2.equalizeHist(window)

                    # æ··åˆåŸå§‹å’Œå‡åŒ–çš„çµæœ
                    alpha = 0.7
                    blended = cv2.addWeighted(window, 1 - alpha, equalized, alpha, 0)

                    # å°‡çµæœæ”¾å›å°æ‡‰ä½ç½®
                    enhanced[y1:y2, x1:x2] = blended

        if len(image_8bit.shape) == 3:
            lab[:, :, 0] = enhanced
            result = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        else:
            result = enhanced

        return result

    def apply_gamma_correction(self, image: np.ndarray, gamma: float) -> np.ndarray:
        """ä¼½é¦¬æ ¡æ­£"""
        if gamma <= 0:
            gamma = 1.0

        # é™åˆ¶ä¼½é¦¬å€¼ç¯„åœä»¥é˜²æ­¢éåº¦å¢å¼·
        gamma_range = self.config["contrast_enhancement"]["gamma_range"]
        gamma = np.clip(gamma, gamma_range[0], gamma_range[1])

        # å»ºç«‹æŸ¥æ‰¾è¡¨
        inv_gamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** inv_gamma) * 255
                         for i in np.arange(0, 256)]).astype("uint8")

        # æ‡‰ç”¨ä¼½é¦¬æ ¡æ­£
        if image.dtype != np.uint8:
            if image.max() <= 1.0:
                image_8bit = (image * 255).astype(np.uint8)
            else:
                image_8bit = cv2.convertScaleAbs(image)
        else:
            image_8bit = image.copy()

        corrected = cv2.LUT(image_8bit, table)
        return corrected

    def reduce_noise_bilateral(self, image: np.ndarray) -> np.ndarray:
        """é›™é‚Šæ¿¾æ³¢é™å™ª"""
        config = self.config["noise_reduction"]

        if image.dtype != np.uint8:
            if image.max() <= 1.0:
                image_8bit = (image * 255).astype(np.uint8)
            else:
                image_8bit = cv2.convertScaleAbs(image)
        else:
            image_8bit = image.copy()

        denoised = cv2.bilateralFilter(
            image_8bit,
            config["bilateral_d"],
            config["bilateral_sigma_color"],
            config["bilateral_sigma_space"]
        )

        return denoised

    def reduce_noise_gaussian(self, image: np.ndarray) -> np.ndarray:
        """é«˜æ–¯æ¿¾æ³¢é™å™ª"""
        config = self.config["noise_reduction"]

        kernel_size = config["gaussian_kernel_size"]
        sigma = config["gaussian_sigma"]

        denoised = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)
        return denoised

    def reduce_noise_nlm(self, image: np.ndarray) -> np.ndarray:
        """éå±€éƒ¨å‡å€¼é™å™ª (NLM)"""
        config = self.config["noise_reduction"]

        if image.dtype != np.uint8:
            if image.max() <= 1.0:
                image_8bit = (image * 255).astype(np.uint8)
            else:
                image_8bit = cv2.convertScaleAbs(image)
        else:
            image_8bit = image.copy()

        if len(image_8bit.shape) == 3:
            denoised = cv2.fastNlMeansDenoisingColored(
                image_8bit,
                None,
                config["nlm_h"],
                config["nlm_h"],
                config["nlm_template_window"],
                config["nlm_search_window"]
            )
        else:
            denoised = cv2.fastNlMeansDenoising(
                image_8bit,
                None,
                config["nlm_h"],
                config["nlm_template_window"],
                config["nlm_search_window"]
            )

        return denoised

    def apply_sharpening(self, image: np.ndarray, adaptive: bool = True) -> np.ndarray:
        """éŠ³åŒ–è™•ç†"""
        config = self.config["sharpening"]

        if image.dtype != np.uint8:
            if image.max() <= 1.0:
                working_image = (image * 255).astype(np.uint8)
            else:
                working_image = cv2.convertScaleAbs(image)
        else:
            working_image = image.copy()

        if adaptive and config["adaptive_sharpening"]:
            # è‡ªé©æ‡‰éŠ³åŒ–ï¼šæ ¹æ“šå±€éƒ¨å°æ¯”åº¦èª¿æ•´éŠ³åŒ–å¼·åº¦
            sharpened = self._adaptive_unsharp_mask(working_image)
        else:
            # å‚³çµ±Unsharp MaskéŠ³åŒ–
            sharpened = self._unsharp_mask(working_image)

        return sharpened

    def _unsharp_mask(self, image: np.ndarray) -> np.ndarray:
        """Unsharp MaskéŠ³åŒ–"""
        config = self.config["sharpening"]

        # é«˜æ–¯æ¨¡ç³Š
        radius = config["unsharp_mask_radius"]
        kernel_size = int(2 * math.ceil(2 * radius) + 1)
        blurred = cv2.GaussianBlur(image, (kernel_size, kernel_size), radius)

        # è¨ˆç®—å·®å€¼
        mask = cv2.subtract(image, blurred)

        # æ‡‰ç”¨éŠ³åŒ–
        amount = config["unsharp_mask_amount"]
        sharpened = cv2.addWeighted(image, 1.0, mask, amount, 0)

        return sharpened

    def _adaptive_unsharp_mask(self, image: np.ndarray) -> np.ndarray:
        """è‡ªé©æ‡‰Unsharp MaskéŠ³åŒ–"""
        # è¨ˆç®—å±€éƒ¨æ¨™æº–å·®ä½œç‚ºå°æ¯”åº¦æŒ‡æ¨™
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        # è¨ˆç®—å±€éƒ¨æ¨™æº–å·®
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))
        local_mean = cv2.morphologyEx(gray.astype(np.float32), cv2.MORPH_CLOSE, kernel)
        local_variance = cv2.morphologyEx((gray.astype(np.float32) - local_mean) ** 2,
                                         cv2.MORPH_CLOSE, kernel)
        local_std = np.sqrt(local_variance)

        # æ­£è¦åŒ–æ¨™æº–å·®åˆ°0-1ç¯„åœä½œç‚ºéŠ³åŒ–å¼·åº¦
        std_normalized = cv2.normalize(local_std, None, 0, 1, cv2.NORM_MINMAX, cv2.CV_32F)

        # æ‡‰ç”¨åŸºç¤Unsharp Mask
        base_sharpened = self._unsharp_mask(image)

        # æ ¹æ“šå±€éƒ¨å°æ¯”åº¦æ··åˆåŸå§‹å’ŒéŠ³åŒ–åœ–åƒ
        if len(image.shape) == 3:
            std_normalized = cv2.cvtColor(std_normalized, cv2.COLOR_GRAY2BGR)

        # æ“´å±•std_normalizedç¶­åº¦ä»¥åŒ¹é…åœ–åƒ
        std_normalized = np.repeat(std_normalized[:, :, np.newaxis], image.shape[2] if len(image.shape) == 3 else 1, axis=2)

        adaptive_sharpened = cv2.addWeighted(
            image.astype(np.float32), 1.0 - std_normalized,
            base_sharpened.astype(np.float32), std_normalized, 0
        )

        return np.clip(adaptive_sharpened, 0, 255).astype(np.uint8)

    def calculate_quality_metrics(self, image: np.ndarray,
                                reference: np.ndarray = None) -> QualityMetrics:
        """è¨ˆç®—å½±åƒå“è³ªæŒ‡æ¨™"""
        metrics = QualityMetrics()

        try:
            # è½‰æ›ç‚ºç°éšä»¥ä¾¿è¨ˆç®—
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()

            # å°æ¯”åº¦ (æ¨™æº–å·®)
            metrics.contrast = float(np.std(gray))

            # éŠ³åº¦ (Laplacianæ–¹å·®)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            metrics.sharpness = float(laplacian.var())

            # äº®åº¦ (å¹³å‡å€¼)
            metrics.brightness = float(np.mean(gray))

            # ç†µå€¼ (ä¿¡æ¯é‡)
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            hist_normalized = hist / hist.sum()
            hist_normalized = hist_normalized[hist_normalized > 0]  # é¿å…log(0)
            metrics.entropy = float(-np.sum(hist_normalized * np.log2(hist_normalized)))

            # ä¼°è¨ˆå™ªè²æ°´æº– (ä½¿ç”¨Laplaciançš„æ¨™æº–å·®)
            noise_estimate = cv2.Laplacian(gray, cv2.CV_64F)
            metrics.noise_level = float(np.std(noise_estimate))

            # ä¿¡å™ªæ¯”ä¼°ç®—
            signal_power = np.mean(gray ** 2)
            noise_power = metrics.noise_level ** 2
            if noise_power > 0:
                metrics.snr = float(10 * np.log10(signal_power / noise_power))
            else:
                metrics.snr = float('inf')

        except Exception as e:
            logger.warning(f"å“è³ªæŒ‡æ¨™è¨ˆç®—éƒ¨åˆ†å¤±æ•—: {e}")

        return metrics

    def enhance_medical_image(self, image: np.ndarray,
                            modality: ImagingModality = ImagingModality.GENERAL,
                            custom_params: EnhancementParameters = None) -> Dict[str, Any]:
        """å®Œæ•´çš„é†«å­¸å½±åƒå¢å¼·æµç¨‹"""
        results = {
            'original_image': image.copy(),
            'enhanced_image': None,
            'processing_steps': {},
            'quality_metrics': {
                'original': None,
                'enhanced': None
            },
            'parameters_used': None,
            'success': False
        }

        start_time = time.time()

        try:
            logger.info(f"é–‹å§‹å¢å¼· {modality.value} å½±åƒ...")

            # é¸æ“‡å¢å¼·åƒæ•¸
            if custom_params:
                params = custom_params
            else:
                params = self.modality_presets.get(modality, self.modality_presets[ImagingModality.GENERAL])

            results['parameters_used'] = asdict(params)

            # è¨ˆç®—åŸå§‹å½±åƒå“è³ªæŒ‡æ¨™
            if self.config["quality_assessment"]["calculate_metrics"]:
                step_start = time.time()
                results['quality_metrics']['original'] = asdict(
                    self.calculate_quality_metrics(image)
                )
                results['processing_steps']['original_metrics'] = (time.time() - step_start) * 1000

            # é–‹å§‹è™•ç†
            enhanced = image.copy()

            # æ­¥é©Ÿ1: å°æ¯”åº¦å¢å¼·
            step_start = time.time()
            if params.contrast_method == "clahe":
                enhanced = self.enhance_contrast_clahe(enhanced)
            elif params.contrast_method == "histogram_equalization":
                enhanced = self.enhance_contrast_histogram_equalization(enhanced)
            elif params.contrast_method == "adaptive_histogram":
                enhanced = self.enhance_contrast_adaptive_histogram(enhanced)

            results['processing_steps']['contrast_enhancement'] = (time.time() - step_start) * 1000

            # æ­¥é©Ÿ2: äº®åº¦å’Œå°æ¯”åº¦èª¿æ•´
            if params.brightness_adjustment != 0 or params.contrast_adjustment != 0:
                step_start = time.time()
                alpha = 1.0 + params.contrast_adjustment / 100.0
                beta = params.brightness_adjustment
                enhanced = cv2.convertScaleAbs(enhanced, alpha=alpha, beta=beta)
                results['processing_steps']['brightness_contrast'] = (time.time() - step_start) * 1000

            # æ­¥é©Ÿ3: ä¼½é¦¬æ ¡æ­£
            if params.gamma_correction != 1.0:
                step_start = time.time()
                enhanced = self.apply_gamma_correction(enhanced, params.gamma_correction)
                results['processing_steps']['gamma_correction'] = (time.time() - step_start) * 1000

            # æ­¥é©Ÿ4: é™å™ª
            step_start = time.time()
            if params.noise_reduction == "bilateral":
                enhanced = self.reduce_noise_bilateral(enhanced)
            elif params.noise_reduction == "gaussian":
                enhanced = self.reduce_noise_gaussian(enhanced)
            elif params.noise_reduction == "nlm":
                enhanced = self.reduce_noise_nlm(enhanced)

            results['processing_steps']['noise_reduction'] = (time.time() - step_start) * 1000

            # æ­¥é©Ÿ5: éŠ³åŒ–
            if params.sharpening:
                step_start = time.time()
                enhanced = self.apply_sharpening(enhanced)
                results['processing_steps']['sharpening'] = (time.time() - step_start) * 1000

            results['enhanced_image'] = enhanced

            # è¨ˆç®—å¢å¼·å¾Œçš„å“è³ªæŒ‡æ¨™
            if self.config["quality_assessment"]["calculate_metrics"]:
                step_start = time.time()
                results['quality_metrics']['enhanced'] = asdict(
                    self.calculate_quality_metrics(enhanced, image)
                )
                results['processing_steps']['enhanced_metrics'] = (time.time() - step_start) * 1000

            total_time = (time.time() - start_time) * 1000
            results['total_time'] = total_time
            results['success'] = True

            logger.info(f"é†«å­¸å½±åƒå¢å¼·å®Œæˆï¼Œè€—æ™‚ {total_time:.1f}ms")

        except Exception as e:
            logger.error(f"é†«å­¸å½±åƒå¢å¼·å¤±æ•—: {e}")
            results['error'] = str(e)

        return results


def demo_medical_image_enhancement():
    """é†«å­¸å½±åƒå¢å¼·æ¼”ç¤º"""
    print("ğŸ¥ é†«å­¸å½±åƒå¢å¼·ç³»çµ±æ¼”ç¤º")
    print("=" * 50)
    print("âš ï¸ æ³¨æ„ï¼šåƒ…ç”¨æ–¼æ•™å­¸ç ”ç©¶ï¼Œä¸å¾—ç”¨æ–¼å¯¦éš›é†«ç™‚è¨ºæ–·")

    # å‰µå»ºå¢å¼·å™¨
    enhancer = MedicalImageEnhancer()

    # æ¸¬è©¦ä¸åŒçš„å½±åƒæ¨¡æ…‹
    modalities_to_test = [
        ImagingModality.XRAY,
        ImagingModality.CT,
        ImagingModality.ULTRASOUND
    ]

    # å°‹æ‰¾æ¸¬è©¦åœ–åƒ
    test_image_path = "../../assets/images/basic/faces01.jpg"

    if not os.path.exists(test_image_path):
        print("âŒ æ¸¬è©¦åœ–åƒä¸å­˜åœ¨ï¼Œå‰µå»ºæ¨¡æ“¬é†«å­¸å½±åƒ")

        # å‰µå»ºæ¨¡æ“¬Xå…‰å½±åƒ
        demo_image = np.random.randint(50, 200, (512, 512), dtype=np.uint8)

        # æ·»åŠ ä¸€äº›çµæ§‹ï¼ˆæ¨¡æ“¬éª¨éª¼ï¼‰
        cv2.rectangle(demo_image, (100, 100), (400, 400), 255, -1)
        cv2.circle(demo_image, (250, 250), 80, 100, -1)

        # æ·»åŠ å™ªè²
        noise = np.random.normal(0, 20, demo_image.shape)
        demo_image = np.clip(demo_image.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    else:
        # è¼‰å…¥çœŸå¯¦åœ–åƒä¸¦è½‰æ›ç‚ºç°éšï¼ˆæ¨¡æ“¬é†«å­¸å½±åƒï¼‰
        demo_image = load_image(test_image_path)
        demo_image = cv2.cvtColor(demo_image, cv2.COLOR_BGR2GRAY)
        demo_image = resize_image(demo_image, max_width=512)

    print(f"ğŸ–¼ï¸  æ¸¬è©¦å½±åƒå°ºå¯¸: {demo_image.shape}")

    # æ¸¬è©¦ä¸åŒé†«å­¸å½±åƒæ¨¡æ…‹çš„å¢å¼·
    for modality in modalities_to_test:
        print(f"\nğŸ”¬ æ¸¬è©¦ {modality.value} å½±åƒå¢å¼·:")

        try:
            # åŸ·è¡Œå¢å¼·
            results = enhancer.enhance_medical_image(demo_image, modality)

            if results['success']:
                print("âœ… å¢å¼·æˆåŠŸï¼")

                # é¡¯ç¤ºè™•ç†æ™‚é–“
                print(f"â±ï¸  ç¸½è™•ç†æ™‚é–“: {results['total_time']:.1f}ms")

                # é¡¯ç¤ºè™•ç†æ­¥é©Ÿ
                print("ğŸ“Š è™•ç†æ­¥é©Ÿè€—æ™‚:")
                for step, time_ms in results['processing_steps'].items():
                    if not step.endswith('_metrics'):
                        print(f"  {step}: {time_ms:.1f}ms")

                # é¡¯ç¤ºå“è³ªæŒ‡æ¨™æ¯”è¼ƒ
                if results['quality_metrics']['original'] and results['quality_metrics']['enhanced']:
                    original_metrics = results['quality_metrics']['original']
                    enhanced_metrics = results['quality_metrics']['enhanced']

                    print("ğŸ“ˆ å“è³ªæŒ‡æ¨™æ¯”è¼ƒ:")
                    metrics_to_show = ['contrast', 'sharpness', 'brightness', 'entropy']

                    for metric in metrics_to_show:
                        orig_val = original_metrics[metric]
                        enh_val = enhanced_metrics[metric]
                        improvement = ((enh_val - orig_val) / orig_val * 100) if orig_val != 0 else 0

                        print(f"  {metric:>10}: {orig_val:6.2f} â†’ {enh_val:6.2f} "
                              f"({improvement:+5.1f}%)")

                # å¯è¦–åŒ–çµæœ
                images = [results['original_image'], results['enhanced_image']]
                titles = [
                    f"åŸå§‹ {modality.value} å½±åƒ",
                    f"å¢å¼·å¾Œ {modality.value} å½±åƒ"
                ]

                display_multiple_images(images, titles, figsize=(12, 6))

            else:
                print("âŒ å¢å¼·å¤±æ•—")
                if 'error' in results:
                    print(f"éŒ¯èª¤: {results['error']}")

        except Exception as e:
            print(f"âŒ æ¼”ç¤ºéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

    print("\nğŸ“‹ å¢å¼·å™¨åŠŸèƒ½ç¸½çµ:")
    print("â€¢ æ”¯æ´å¤šç¨®é†«å­¸å½±åƒæ¨¡æ…‹ (X-Ray, CT, MRI, è¶…éŸ³æ³¢ç­‰)")
    print("â€¢ CLAHE å°æ¯”åº¦é™åˆ¶è‡ªé©æ‡‰ç›´æ–¹åœ–å‡åŒ–")
    print("â€¢ å¤šç¨®é™å™ªç®—æ³• (é›™é‚Šæ¿¾æ³¢, é«˜æ–¯æ¿¾æ³¢, éå±€éƒ¨å‡å€¼)")
    print("â€¢ è‡ªé©æ‡‰éŠ³åŒ–è™•ç†")
    print("â€¢ é‡åŒ–å“è³ªè©•ä¼°")
    print("â€¢ å°ˆç‚ºé†«å­¸å½±åƒå„ªåŒ–çš„åƒæ•¸é è¨­")

    print("\nâš ï¸ é‡è¦æé†’:")
    print("æœ¬ç³»çµ±åƒ…ç”¨æ–¼æ•™å­¸å’Œç ”ç©¶ç›®çš„")
    print("å¯¦éš›é†«ç™‚æ‡‰ç”¨éœ€è¦:")
    print("â€¢ å°ˆæ¥­é†«ç™‚è»Ÿé«”èªè­‰")
    print("â€¢ é†«å¸«å°ˆæ¥­åˆ¤æ–·")
    print("â€¢ ç¬¦åˆé†«ç™‚æ¨™æº–çš„å“è³ªæ§åˆ¶")
    print("â€¢ DICOM æ¨™æº–ç›¸å®¹æ€§")


if __name__ == "__main__":
    demo_medical_image_enhancement()