#!/usr/bin/env python3
"""
7.3.2 é†«å­¸å½±åƒåˆ†æç³»çµ± - å€åŸŸåˆ†å‰²æ¨¡çµ„

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†å°ˆç‚ºé†«å­¸å½±åƒè¨­è¨ˆçš„å€åŸŸåˆ†å‰²ç®—æ³•ï¼ŒåŒ…æ‹¬å¤šç¨®åˆ†å‰²æ–¹æ³•ã€
çµ„ç¹”è­˜åˆ¥ã€é‡åŒ–åˆ†æç­‰åŠŸèƒ½ï¼Œé©ç”¨æ–¼é†«å­¸å½±åƒçš„çµæ§‹åˆ†æå’Œæ¸¬é‡ã€‚

åŠŸèƒ½ç‰¹è‰²ï¼š
- å¤šç¨®åˆ†å‰²ç®—æ³• (Watershed, Region Growing, K-means, GrabCut)
- é†«å­¸å½±åƒç‰¹å®šå„ªåŒ–
- çµ„ç¹”é¡å‹è­˜åˆ¥
- 3Dåˆ†å‰²æ”¯æ´æº–å‚™
- é‡åŒ–æ¸¬é‡å·¥å…·
- åˆ†å‰²å“è³ªè©•ä¼°
- äº’å‹•å¼åˆ†å‰²ç•Œé¢
- åˆ†å‰²çµæœå¯è¦–åŒ–

ä½œè€…: OpenCV Computer Vision Toolkit
æ—¥æœŸ: 2024-10-14
ç‰ˆæœ¬: 1.0

æ³¨æ„: æœ¬æ¨¡çµ„åƒ…ç”¨æ–¼æ•™å­¸å’Œç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨æ–¼å¯¦éš›é†«ç™‚è¨ºæ–·ã€‚
     çœŸå¯¦é†«å­¸å½±åƒåˆ†æéœ€è¦å°ˆæ¥­é†«ç™‚è»Ÿé«”å’Œé†«å¸«å°ˆæ¥­åˆ¤æ–·ã€‚
"""

import cv2
import numpy as np
import os
import sys
import time
import json
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, asdict
from enum import Enum
import math
from collections import defaultdict
from sklearn.cluster import KMeans
import scipy.ndimage as ndimage
from skimage import measure, morphology, segmentation

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('../../utils')
try:
    from image_utils import load_image, resize_image
    from visualization import display_image, display_multiple_images
    from performance import time_function
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥å·¥å…·æ¨¡çµ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SegmentationMethod(Enum):
    """åˆ†å‰²æ–¹æ³•æšèˆ‰"""
    WATERSHED = "watershed"
    REGION_GROWING = "region_growing"
    KMEANS = "kmeans"
    GRABCUT = "grabcut"
    OTSU = "otsu"
    ADAPTIVE_THRESHOLD = "adaptive"
    MORPHOLOGICAL = "morphological"

class TissueType(Enum):
    """çµ„ç¹”é¡å‹æšèˆ‰"""
    BACKGROUND = 0
    SOFT_TISSUE = 1
    BONE = 2
    AIR = 3
    CONTRAST_AGENT = 4
    PATHOLOGY = 5

@dataclass
class SegmentationResult:
    """åˆ†å‰²çµæœæ•¸æ“šçµæ§‹"""
    segmented_image: np.ndarray
    region_labels: np.ndarray
    region_count: int
    region_properties: List[Dict[str, Any]]
    processing_time: float
    method_used: SegmentationMethod
    parameters_used: Dict[str, Any]
    quality_score: float

@dataclass
class RegionProperties:
    """å€åŸŸå±¬æ€§"""
    label: int
    area: float
    centroid: Tuple[float, float]
    bbox: Tuple[int, int, int, int]
    perimeter: float
    circularity: float
    eccentricity: float
    mean_intensity: float
    std_intensity: float
    tissue_type: TissueType

class MedicalImageSegmentation:
    """é†«å­¸å½±åƒåˆ†å‰²å™¨"""

    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–é†«å­¸å½±åƒåˆ†å‰²å™¨"""
        self.config = self._load_config(config_file)

        # çµ„ç¹”é¡å‹çš„å¼·åº¦ç¯„åœ (é©ç”¨æ–¼CTå½±åƒçš„HUå€¼)
        self.tissue_intensity_ranges = {
            TissueType.AIR: (-1000, -900),
            TissueType.SOFT_TISSUE: (-100, 200),
            TissueType.BONE: (200, 3000),
            TissueType.CONTRAST_AGENT: (100, 500),
            TissueType.BACKGROUND: (-1024, -900)
        }

        logger.info("é†«å­¸å½±åƒåˆ†å‰²å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.warning("âš ï¸ åƒ…ç”¨æ–¼æ•™å­¸ç ”ç©¶ï¼Œä¸å¾—ç”¨æ–¼å¯¦éš›é†«ç™‚è¨ºæ–·")

    def _load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        default_config = {
            "segmentation": {
                "default_method": "watershed",
                "preprocessing": True,
                "postprocessing": True,
                "min_region_size": 50,
                "max_regions": 1000
            },
            "watershed": {
                "distance_transform": True,
                "noise_removal": True,
                "sure_bg_threshold": 0.7,
                "sure_fg_threshold": 0.5,
                "kernel_size": 3
            },
            "kmeans": {
                "n_clusters": 5,
                "max_iterations": 20,
                "epsilon": 1.0,
                "attempts": 10
            },
            "region_growing": {
                "seed_points": "auto",  # auto, manual, grid
                "similarity_threshold": 10,
                "max_iterations": 1000,
                "connectivity": 8
            },
            "grabcut": {
                "iterations": 5,
                "margin": 10,
                "auto_rectangle": True
            },
            "morphological": {
                "operation": "opening",  # opening, closing, gradient
                "kernel_shape": "ellipse",  # rect, ellipse, cross
                "kernel_size": [5, 5],
                "iterations": 2
            },
            "tissue_analysis": {
                "enable_tissue_classification": True,
                "intensity_based_classification": True,
                "texture_analysis": False,
                "hu_value_analysis": False  # åƒ…é©ç”¨æ–¼DICOM CTå½±åƒ
            },
            "quality_metrics": {
                "calculate_properties": True,
                "measure_accuracy": False,  # éœ€è¦ground truth
                "connectivity_analysis": True,
                "homogeneity_analysis": True
            }
        }

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                self._deep_update(default_config, user_config)
                logger.info(f"å·²è¼‰å…¥é…ç½®æ–‡ä»¶: {config_file}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥é…ç½®æ–‡ä»¶: {e}ï¼Œä½¿ç”¨é è¨­é…ç½®")

        return default_config

    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if isinstance(value, dict) and key in base_dict:
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def preprocess_for_segmentation(self, image: np.ndarray) -> np.ndarray:
        """é‡å°åˆ†å‰²å„ªåŒ–çš„é è™•ç†"""
        if not self.config["segmentation"]["preprocessing"]:
            return image

        processed = image.copy()

        # è½‰æ›ç‚ºç°éš
        if len(processed.shape) == 3:
            processed = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)

        # é™å™ª
        processed = cv2.medianBlur(processed, 3)

        # å¢å¼·å°æ¯”åº¦
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        processed = clahe.apply(processed)

        return processed

    def segment_watershed(self, image: np.ndarray) -> SegmentationResult:
        """Watershedåˆ†å‰²ç®—æ³•"""
        start_time = time.time()
        config = self.config["watershed"]

        # é è™•ç†
        gray = self.preprocess_for_segmentation(image)

        # å™ªè²ç§»é™¤
        if config["noise_removal"]:
            kernel = np.ones((config["kernel_size"], config["kernel_size"]), np.uint8)
            opening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel, iterations=2)
        else:
            opening = gray

        # ç¢ºå®šèƒŒæ™¯å€åŸŸ
        sure_bg = cv2.dilate(opening, kernel, iterations=3)

        # è·é›¢è®Šæ›
        if config["distance_transform"]:
            dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)

            # ç¢ºå®šå‰æ™¯å€åŸŸ
            _, sure_fg = cv2.threshold(dist_transform,
                                     config["sure_fg_threshold"] * dist_transform.max(),
                                     255, 0)
        else:
            # ä½¿ç”¨é–¾å€¼æ–¹æ³•
            _, sure_fg = cv2.threshold(opening, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        # æ‰¾åˆ°æœªçŸ¥å€åŸŸ
        sure_fg = np.uint8(sure_fg)
        unknown = cv2.subtract(sure_bg, sure_fg)

        # æ¨™è¨˜é€£é€šçµ„ä»¶
        _, markers = cv2.connectedComponents(sure_fg)

        # ç‚ºèƒŒæ™¯æ·»åŠ æ¨™è¨˜
        markers = markers + 1
        markers[unknown == 255] = 0

        # æ‡‰ç”¨watershed
        if len(image.shape) == 3:
            markers = cv2.watershed(image, markers)
        else:
            # è½‰æ›ç‚º3é€šé“
            img_3ch = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
            markers = cv2.watershed(img_3ch, markers)

        processing_time = (time.time() - start_time) * 1000

        # å‰µå»ºåˆ†å‰²çµæœåœ–åƒ
        segmented = np.zeros_like(gray)
        segmented[markers > 1] = 255
        segmented[markers == -1] = 128  # é‚Šç•Œ

        # è¨ˆç®—å€åŸŸå±¬æ€§
        region_props = self._calculate_region_properties(markers, gray)

        # è¨ˆç®—å“è³ªåˆ†æ•¸
        quality_score = self._calculate_segmentation_quality(segmented, gray)

        return SegmentationResult(
            segmented_image=segmented,
            region_labels=markers,
            region_count=len(np.unique(markers)) - 1,  # æ’é™¤èƒŒæ™¯
            region_properties=region_props,
            processing_time=processing_time,
            method_used=SegmentationMethod.WATERSHED,
            parameters_used=config,
            quality_score=quality_score
        )

    def segment_kmeans(self, image: np.ndarray) -> SegmentationResult:
        """K-meansåˆ†å‰²ç®—æ³•"""
        start_time = time.time()
        config = self.config["kmeans"]

        # é è™•ç†
        gray = self.preprocess_for_segmentation(image)

        # é‡å¡‘æ•¸æ“šç‚ºK-meansè¼¸å…¥æ ¼å¼
        pixel_values = gray.reshape((-1, 1))
        pixel_values = np.float32(pixel_values)

        # åŸ·è¡ŒK-means
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,
                   config["max_iterations"], config["epsilon"])

        _, labels, centers = cv2.kmeans(
            pixel_values,
            config["n_clusters"],
            None,
            criteria,
            config["attempts"],
            cv2.KMEANS_RANDOM_CENTERS
        )

        # é‡å¡‘çµæœ
        centers = np.uint8(centers)
        segmented = centers[labels.flatten()]
        segmented = segmented.reshape(gray.shape)

        # å‰µå»ºæ¨™ç±¤åœ–åƒ
        region_labels = labels.reshape(gray.shape)

        processing_time = (time.time() - start_time) * 1000

        # è¨ˆç®—å€åŸŸå±¬æ€§
        region_props = self._calculate_region_properties(region_labels, gray)

        # è¨ˆç®—å“è³ªåˆ†æ•¸
        quality_score = self._calculate_segmentation_quality(segmented, gray)

        return SegmentationResult(
            segmented_image=segmented,
            region_labels=region_labels,
            region_count=config["n_clusters"],
            region_properties=region_props,
            processing_time=processing_time,
            method_used=SegmentationMethod.KMEANS,
            parameters_used=config,
            quality_score=quality_score
        )

    def segment_region_growing(self, image: np.ndarray,
                              seed_points: List[Tuple[int, int]] = None) -> SegmentationResult:
        """å€åŸŸç”Ÿé•·åˆ†å‰²ç®—æ³•"""
        start_time = time.time()
        config = self.config["region_growing"]

        # é è™•ç†
        gray = self.preprocess_for_segmentation(image)

        if seed_points is None:
            # è‡ªå‹•ç”Ÿæˆç¨®å­é»
            seed_points = self._generate_seed_points(gray)

        # åˆå§‹åŒ–åˆ†å‰²çµæœ
        h, w = gray.shape
        segmented = np.zeros((h, w), dtype=np.uint8)
        visited = np.zeros((h, w), dtype=bool)

        similarity_threshold = config["similarity_threshold"]
        max_iterations = config["max_iterations"]
        connectivity = config["connectivity"]

        region_label = 1

        # 8-é„°åŸŸæˆ–4-é„°åŸŸ
        if connectivity == 8:
            neighbors = [(-1, -1), (-1, 0), (-1, 1), (0, -1),
                        (0, 1), (1, -1), (1, 0), (1, 1)]
        else:  # 4-é„°åŸŸ
            neighbors = [(-1, 0), (1, 0), (0, -1), (0, 1)]

        # å°æ¯å€‹ç¨®å­é»é€²è¡Œå€åŸŸç”Ÿé•·
        for seed_x, seed_y in seed_points:
            if visited[seed_y, seed_x]:
                continue

            # åˆå§‹åŒ–éšŠåˆ—
            queue = [(seed_x, seed_y)]
            region_pixels = []
            seed_intensity = float(gray[seed_y, seed_x])

            iteration = 0
            while queue and iteration < max_iterations:
                if not queue:
                    break

                x, y = queue.pop(0)

                if visited[y, x]:
                    continue

                current_intensity = float(gray[y, x])

                # æª¢æŸ¥ç›¸ä¼¼æ€§
                if abs(current_intensity - seed_intensity) <= similarity_threshold:
                    visited[y, x] = True
                    segmented[y, x] = region_label
                    region_pixels.append((x, y))

                    # æ·»åŠ é„°åŸŸåƒç´ åˆ°éšŠåˆ—
                    for dx, dy in neighbors:
                        nx, ny = x + dx, y + dy
                        if (0 <= nx < w and 0 <= ny < h and
                            not visited[ny, nx]):
                            queue.append((nx, ny))

                iteration += 1

            # å¦‚æœå€åŸŸè¶³å¤ å¤§ï¼Œä¿ç•™æ­¤å€åŸŸ
            if len(region_pixels) >= self.config["segmentation"]["min_region_size"]:
                region_label += 1
            else:
                # é‡ç½®å°å€åŸŸ
                for x, y in region_pixels:
                    segmented[y, x] = 0
                    visited[y, x] = False

        processing_time = (time.time() - start_time) * 1000

        # è¨ˆç®—å€åŸŸå±¬æ€§
        region_props = self._calculate_region_properties(segmented, gray)

        # è¨ˆç®—å“è³ªåˆ†æ•¸
        quality_score = self._calculate_segmentation_quality(segmented, gray)

        return SegmentationResult(
            segmented_image=segmented,
            region_labels=segmented,
            region_count=region_label - 1,
            region_properties=region_props,
            processing_time=processing_time,
            method_used=SegmentationMethod.REGION_GROWING,
            parameters_used=config,
            quality_score=quality_score
        )

    def _generate_seed_points(self, image: np.ndarray,
                            method: str = "grid") -> List[Tuple[int, int]]:
        """ç”Ÿæˆç¨®å­é»"""
        h, w = image.shape
        seed_points = []

        if method == "grid":
            # ç¶²æ ¼æ¡æ¨£
            step = max(h, w) // 10  # 10x10ç¶²æ ¼
            for y in range(step, h - step, step):
                for x in range(step, w - step, step):
                    seed_points.append((x, y))

        elif method == "harris_corners":
            # ä½¿ç”¨Harrisè§’é»ä½œç‚ºç¨®å­
            corners = cv2.goodFeaturesToTrack(image, 100, 0.01, 10)
            if corners is not None:
                for corner in corners:
                    x, y = corner.ravel()
                    seed_points.append((int(x), int(y)))

        elif method == "intensity_peaks":
            # ä½¿ç”¨å¼·åº¦å³°å€¼ä½œç‚ºç¨®å­
            # ç°¡åŒ–å¯¦ç¾ï¼šä½¿ç”¨å±€éƒ¨æœ€å¤§å€¼
            from scipy.ndimage import maximum_filter
            local_maxima = (image == maximum_filter(image, size=20))
            y_coords, x_coords = np.where(local_maxima)
            for x, y in zip(x_coords, y_coords):
                seed_points.append((int(x), int(y)))

        return seed_points

    def segment_grabcut(self, image: np.ndarray,
                       rect: Tuple[int, int, int, int] = None) -> SegmentationResult:
        """GrabCutåˆ†å‰²ç®—æ³•"""
        start_time = time.time()
        config = self.config["grabcut"]

        if len(image.shape) != 3:
            # GrabCutéœ€è¦å½©è‰²åœ–åƒ
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)

        h, w = image.shape[:2]

        # è‡ªå‹•ç”Ÿæˆå‰æ™¯çŸ©å½¢ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if rect is None or config["auto_rectangle"]:
            margin = config["margin"]
            rect = (margin, margin, w - 2*margin, h - 2*margin)

        # åˆå§‹åŒ–é®ç½©
        mask = np.zeros((h, w), np.uint8)

        # å‰æ™¯å’ŒèƒŒæ™¯æ¨¡å‹
        bgd_model = np.zeros((1, 65), np.float64)
        fgd_model = np.zeros((1, 65), np.float64)

        # æ‡‰ç”¨GrabCut
        cv2.grabCut(image, mask, rect, bgd_model, fgd_model,
                   config["iterations"], cv2.GC_INIT_WITH_RECT)

        # å‰µå»ºæœ€çµ‚é®ç½©
        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')

        processing_time = (time.time() - start_time) * 1000

        # æ‡‰ç”¨é®ç½©åˆ°åœ–åƒ
        segmented = image * mask2[:, :, np.newaxis]

        # è½‰æ›ç‚ºç°éšç”¨æ–¼å±¬æ€§è¨ˆç®—
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image

        # è¨ˆç®—å€åŸŸå±¬æ€§
        region_props = self._calculate_region_properties(mask2, gray)

        # è¨ˆç®—å“è³ªåˆ†æ•¸
        quality_score = self._calculate_segmentation_quality(mask2, gray)

        return SegmentationResult(
            segmented_image=cv2.cvtColor(segmented, cv2.COLOR_BGR2GRAY),
            region_labels=mask2,
            region_count=2,  # å‰æ™¯å’ŒèƒŒæ™¯
            region_properties=region_props,
            processing_time=processing_time,
            method_used=SegmentationMethod.GRABCUT,
            parameters_used=config,
            quality_score=quality_score
        )

    def _calculate_region_properties(self, labels: np.ndarray,
                                   intensity_image: np.ndarray) -> List[Dict[str, Any]]:
        """è¨ˆç®—å€åŸŸå±¬æ€§"""
        properties = []
        unique_labels = np.unique(labels)

        for label in unique_labels:
            if label == 0:  # è·³éèƒŒæ™¯
                continue

            # å‰µå»ºå€åŸŸé®ç½©
            mask = (labels == label).astype(np.uint8)

            if np.sum(mask) == 0:
                continue

            try:
                # åŸºæœ¬å¹¾ä½•å±¬æ€§
                area = np.sum(mask)

                # è³ªå¿ƒ
                moments = cv2.moments(mask)
                if moments['m00'] != 0:
                    centroid_x = moments['m10'] / moments['m00']
                    centroid_y = moments['m01'] / moments['m00']
                    centroid = (centroid_x, centroid_y)
                else:
                    centroid = (0, 0)

                # é‚Šç•Œæ¡†
                y_coords, x_coords = np.where(mask)
                if len(x_coords) > 0 and len(y_coords) > 0:
                    bbox = (int(np.min(x_coords)), int(np.min(y_coords)),
                           int(np.max(x_coords) - np.min(x_coords)),
                           int(np.max(y_coords) - np.min(y_coords)))
                else:
                    bbox = (0, 0, 0, 0)

                # å‘¨é•·
                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                perimeter = cv2.arcLength(contours[0], True) if contours else 0

                # åœ“å½¢åº¦
                if perimeter > 0:
                    circularity = 4 * np.pi * area / (perimeter * perimeter)
                else:
                    circularity = 0

                # å¼·åº¦çµ±è¨ˆ
                masked_intensity = intensity_image[mask > 0]
                if len(masked_intensity) > 0:
                    mean_intensity = float(np.mean(masked_intensity))
                    std_intensity = float(np.std(masked_intensity))
                else:
                    mean_intensity = 0
                    std_intensity = 0

                # çµ„ç¹”é¡å‹åˆ†é¡
                tissue_type = self._classify_tissue_type(mean_intensity)

                properties.append({
                    'label': int(label),
                    'area': float(area),
                    'centroid': centroid,
                    'bbox': bbox,
                    'perimeter': float(perimeter),
                    'circularity': float(circularity),
                    'mean_intensity': mean_intensity,
                    'std_intensity': std_intensity,
                    'tissue_type': tissue_type.value if isinstance(tissue_type, TissueType) else tissue_type
                })

            except Exception as e:
                logger.warning(f"è¨ˆç®—å€åŸŸ {label} å±¬æ€§å¤±æ•—: {e}")

        return properties

    def _classify_tissue_type(self, mean_intensity: float) -> TissueType:
        """æ ¹æ“šå¼·åº¦åˆ†é¡çµ„ç¹”é¡å‹"""
        if not self.config["tissue_analysis"]["intensity_based_classification"]:
            return TissueType.SOFT_TISSUE

        # æ­£è¦åŒ–å¼·åº¦åˆ°HUå€¼ç¯„åœï¼ˆç°¡åŒ–ï¼‰
        # å¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦çœŸå¯¦çš„DICOMæ•¸æ“šå’Œæ¨™å®š
        normalized_intensity = (mean_intensity - 127.5) * 8  # ç°¡åŒ–çš„HUå€¼ä¼°ç®—

        for tissue_type, (min_hu, max_hu) in self.tissue_intensity_ranges.items():
            if min_hu <= normalized_intensity <= max_hu:
                return tissue_type

        # é è¨­ç‚ºè»Ÿçµ„ç¹”
        return TissueType.SOFT_TISSUE

    def _calculate_segmentation_quality(self, segmented: np.ndarray,
                                      original: np.ndarray) -> float:
        """è¨ˆç®—åˆ†å‰²å“è³ªåˆ†æ•¸"""
        try:
            quality_score = 0.0

            # å€åŸŸé€£é€šæ€§ (30% æ¬Šé‡)
            if self.config["quality_metrics"]["connectivity_analysis"]:
                num_labels, labels = cv2.connectedComponents(segmented)
                connectivity_score = 1.0 / (num_labels + 1)  # å€åŸŸè¶Šå°‘è¶Šå¥½
                quality_score += 0.3 * connectivity_score

            # å€åŸŸåŒè³ªæ€§ (40% æ¬Šé‡)
            if self.config["quality_metrics"]["homogeneity_analysis"]:
                unique_regions = np.unique(segmented)
                homogeneity_scores = []

                for region_val in unique_regions:
                    if region_val == 0:  # è·³éèƒŒæ™¯
                        continue

                    mask = segmented == region_val
                    if np.sum(mask) > 0:
                        region_intensities = original[mask]
                        if len(region_intensities) > 1:
                            # ä½¿ç”¨è®Šç•°ä¿‚æ•¸è¡¡é‡åŒè³ªæ€§
                            cv_coeff = np.std(region_intensities) / (np.mean(region_intensities) + 1e-6)
                            homogeneity = 1.0 / (1.0 + cv_coeff)
                            homogeneity_scores.append(homogeneity)

                if homogeneity_scores:
                    avg_homogeneity = np.mean(homogeneity_scores)
                    quality_score += 0.4 * avg_homogeneity

            # é‚Šç•Œæ¸…æ™°åº¦ (30% æ¬Šé‡)
            edges = cv2.Canny(segmented, 50, 150)
            edge_strength = np.mean(edges) / 255.0
            quality_score += 0.3 * edge_strength

            return min(1.0, quality_score)

        except Exception as e:
            logger.warning(f"å“è³ªè©•ä¼°è¨ˆç®—å¤±æ•—: {e}")
            return 0.5  # é è¨­ä¸­ç­‰å“è³ª

    def compare_segmentation_methods(self, image: np.ndarray) -> Dict[str, SegmentationResult]:
        """æ¯”è¼ƒä¸åŒåˆ†å‰²æ–¹æ³•"""
        logger.info("é–‹å§‹æ¯”è¼ƒä¸åŒåˆ†å‰²æ–¹æ³•...")

        methods_to_test = [
            ("watershed", self.segment_watershed),
            ("kmeans", self.segment_kmeans),
            ("grabcut", self.segment_grabcut)
        ]

        results = {}

        for method_name, method_func in methods_to_test:
            try:
                logger.info(f"æ¸¬è©¦ {method_name} åˆ†å‰²...")
                result = method_func(image)
                results[method_name] = result

                logger.info(f"  {method_name}: {result.region_count} å€åŸŸ, "
                           f"{result.processing_time:.1f}ms, "
                           f"å“è³ª: {result.quality_score:.3f}")

            except Exception as e:
                logger.error(f"{method_name} åˆ†å‰²å¤±æ•—: {e}")

        return results

    def visualize_segmentation(self, original: np.ndarray,
                             results: Dict[str, SegmentationResult]) -> np.ndarray:
        """å¯è¦–åŒ–åˆ†å‰²çµæœ"""
        if not results:
            return original

        # è¨ˆç®—é¡¯ç¤ºä½ˆå±€
        num_results = len(results) + 1  # åŒ…æ‹¬åŸå§‹åœ–åƒ
        cols = min(num_results, 3)
        rows = math.ceil(num_results / cols)

        # å‰µå»ºåˆæˆåœ–åƒ
        if len(original.shape) == 3:
            display_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        else:
            display_gray = original

        h, w = display_gray.shape
        combined = np.zeros((rows * h, cols * w, 3), dtype=np.uint8)

        # æ”¾ç½®åŸå§‹åœ–åƒ
        combined[:h, :w] = cv2.cvtColor(display_gray, cv2.COLOR_GRAY2BGR)
        cv2.putText(combined, "Original", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

        # æ”¾ç½®åˆ†å‰²çµæœ
        position = 1
        for method_name, result in results.items():
            row = position // cols
            col = position % cols

            y_start = row * h
            y_end = (row + 1) * h
            x_start = col * w
            x_end = (col + 1) * w

            # å‰µå»ºå½©è‰²åˆ†å‰²åœ–åƒ
            colored_segmentation = self._create_colored_segmentation(result.region_labels)

            combined[y_start:y_end, x_start:x_end] = colored_segmentation

            # æ·»åŠ æ–¹æ³•åç¨±å’Œçµ±è¨ˆä¿¡æ¯
            info_text = f"{method_name}"
            cv2.putText(combined, info_text, (x_start + 10, y_start + 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

            stats_text = f"Regions: {result.region_count}, Quality: {result.quality_score:.2f}"
            cv2.putText(combined, stats_text, (x_start + 10, y_start + 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            position += 1

        return combined

    def _create_colored_segmentation(self, labels: np.ndarray) -> np.ndarray:
        """å‰µå»ºå½©è‰²åˆ†å‰²çµæœ"""
        # å‰µå»ºé¡è‰²æ˜ å°„
        unique_labels = np.unique(labels)
        colors = self._generate_colors(len(unique_labels))

        h, w = labels.shape
        colored = np.zeros((h, w, 3), dtype=np.uint8)

        for i, label in enumerate(unique_labels):
            mask = labels == label
            colored[mask] = colors[i]

        return colored

    def _generate_colors(self, num_colors: int) -> List[Tuple[int, int, int]]:
        """ç”Ÿæˆå€åŸŸé¡è‰²"""
        colors = []

        # èƒŒæ™¯ä½¿ç”¨é»‘è‰²
        colors.append((0, 0, 0))

        # ç‚ºå…¶ä»–å€åŸŸç”Ÿæˆéš¨æ©Ÿé¡è‰²
        np.random.seed(42)  # å›ºå®šç¨®å­ä»¥ç²å¾—ä¸€è‡´çš„é¡è‰²
        for i in range(num_colors - 1):
            color = tuple(np.random.randint(50, 255, 3).tolist())
            colors.append(color)

        return colors


def demo_medical_segmentation():
    """é†«å­¸å½±åƒåˆ†å‰²æ¼”ç¤º"""
    print("ğŸ¥ é†«å­¸å½±åƒå€åŸŸåˆ†å‰²æ¼”ç¤º")
    print("=" * 50)
    print("âš ï¸ æ³¨æ„ï¼šåƒ…ç”¨æ–¼æ•™å­¸ç ”ç©¶ï¼Œä¸å¾—ç”¨æ–¼å¯¦éš›é†«ç™‚è¨ºæ–·")

    # å‰µå»ºåˆ†å‰²å™¨
    segmenter = MedicalImageSegmentation()

    # å°‹æ‰¾æ¸¬è©¦åœ–åƒ
    test_image_path = "../../assets/images/basic/faces01.jpg"

    if not os.path.exists(test_image_path):
        print("âŒ æ¸¬è©¦åœ–åƒä¸å­˜åœ¨ï¼Œå‰µå»ºæ¨¡æ“¬é†«å­¸å½±åƒ")

        # å‰µå»ºæ¨¡æ“¬Xå…‰å½±åƒ
        demo_image = np.zeros((400, 400), dtype=np.uint8)

        # æ·»åŠ ä¸åŒå¯†åº¦çš„çµ„ç¹”çµæ§‹
        # è»Ÿçµ„ç¹”å€åŸŸ
        cv2.rectangle(demo_image, (50, 50), (350, 350), 120, -1)

        # éª¨éª¼çµæ§‹
        cv2.rectangle(demo_image, (100, 100), (150, 300), 220, -1)
        cv2.rectangle(demo_image, (250, 100), (300, 300), 220, -1)

        # è‚ºéƒ¨ï¼ˆä½å¯†åº¦ï¼‰
        cv2.circle(demo_image, (120, 180), 40, 60, -1)
        cv2.circle(demo_image, (280, 180), 40, 60, -1)

        # æ·»åŠ å™ªè²
        noise = np.random.normal(0, 10, demo_image.shape)
        demo_image = np.clip(demo_image.astype(np.float32) + noise, 0, 255).astype(np.uint8)

        print("âœ… å·²å‰µå»ºæ¨¡æ“¬é†«å­¸å½±åƒ")

    else:
        # è¼‰å…¥çœŸå¯¦åœ–åƒä¸¦è½‰æ›ç‚ºé†«å­¸å½±åƒæ ¼å¼
        demo_image = load_image(test_image_path)
        demo_image = cv2.cvtColor(demo_image, cv2.COLOR_BGR2GRAY)
        demo_image = resize_image(demo_image, max_width=400)
        print(f"âœ… å·²è¼‰å…¥æ¸¬è©¦åœ–åƒ: {os.path.basename(test_image_path)}")

    print(f"ğŸ–¼ï¸  å½±åƒå°ºå¯¸: {demo_image.shape}")

    # æ¯”è¼ƒä¸åŒåˆ†å‰²æ–¹æ³•
    comparison_results = segmenter.compare_segmentation_methods(demo_image)

    if comparison_results:
        print(f"\nğŸ“Š åˆ†å‰²æ–¹æ³•æ¯”è¼ƒçµæœ:")
        print("-" * 60)

        # æŒ‰å“è³ªæ’åº
        sorted_results = sorted(comparison_results.items(),
                              key=lambda x: x[1].quality_score, reverse=True)

        for method_name, result in sorted_results:
            print(f"{method_name:12}: {result.region_count:3d} å€åŸŸ, "
                  f"{result.processing_time:6.1f}ms, "
                  f"å“è³ª: {result.quality_score:.3f}")

        # å¯è¦–åŒ–æ¯”è¼ƒçµæœ
        visualization = segmenter.visualize_segmentation(demo_image, comparison_results)
        display_image(visualization, "åˆ†å‰²æ–¹æ³•æ¯”è¼ƒ", figsize=(15, 10))

        # é¡¯ç¤ºæœ€ä½³æ–¹æ³•çš„è©³ç´°çµæœ
        best_method, best_result = sorted_results[0]
        print(f"\nğŸ† æœ€ä½³åˆ†å‰²æ–¹æ³•: {best_method}")
        print(f"ğŸ“ˆ è©³ç´°åˆ†æ:")

        if best_result.region_properties:
            print(f"  å€åŸŸæ•¸é‡: {len(best_result.region_properties)}")
            print(f"  å¹³å‡å€åŸŸå¤§å°: {np.mean([r['area'] for r in best_result.region_properties]):.1f} åƒç´ ")

            # é¡¯ç¤ºå‰5å€‹æœ€å¤§å€åŸŸ
            sorted_regions = sorted(best_result.region_properties,
                                  key=lambda r: r['area'], reverse=True)

            print(f"  å‰5å¤§å€åŸŸ:")
            for i, region in enumerate(sorted_regions[:5], 1):
                tissue_name = TissueType(region['tissue_type']).name if isinstance(region['tissue_type'], int) else region['tissue_type']
                print(f"    {i}. é¢ç©: {region['area']:6.0f}, "
                      f"å¼·åº¦: {region['mean_intensity']:6.1f}, "
                      f"é¡å‹: {tissue_name}")

    else:
        print("âŒ æ²’æœ‰æˆåŠŸçš„åˆ†å‰²çµæœ")

    print(f"\nğŸ“‹ é†«å­¸å½±åƒåˆ†å‰²åŠŸèƒ½ç‰¹è‰²:")
    print(f"â€¢ å¤šç¨®åˆ†å‰²ç®—æ³• (Watershed, K-means, GrabCut)")
    print(f"â€¢ çµ„ç¹”é¡å‹è‡ªå‹•åˆ†é¡")
    print(f"â€¢ é‡åŒ–å€åŸŸå±¬æ€§åˆ†æ")
    print(f"â€¢ åˆ†å‰²å“è³ªè©•ä¼°")
    print(f"â€¢ å¯è¦–åŒ–æ¯”è¼ƒå·¥å…·")

    print(f"\nğŸ¯ è‡¨åºŠæ‡‰ç”¨å ´æ™¯ (ç ”ç©¶ç”¨é€”):")
    print(f"â€¢ è…«ç˜¤å€åŸŸåˆ†å‰²")
    print(f"â€¢ å™¨å®˜é«”ç©æ¸¬é‡")
    print(f"â€¢ ç—…ç†çµ„ç¹”åˆ†æ")
    print(f"â€¢ å½±åƒå¼•å°æ‰‹è¡“")
    print(f"â€¢ æ”¾ç™‚è¨ˆåŠƒåˆ¶å®š")

    print(f"\nâš ï¸ é‡è¦æé†’:")
    print(f"æœ¬åˆ†å‰²ç³»çµ±åƒ…ç”¨æ–¼æ•™å­¸å’Œç ”ç©¶")
    print(f"å¯¦éš›é†«ç™‚æ‡‰ç”¨éœ€è¦:")
    print(f"â€¢ FDA/CEèªè­‰çš„é†«ç™‚è»Ÿé«”")
    print(f"â€¢ å°ˆæ¥­é†«å¸«è¨ºæ–·")
    print(f"â€¢ æ¨™æº–åŒ–çš„å½±åƒå”è­°")
    print(f"â€¢ è³ªé‡æ§åˆ¶å’Œé©—è­‰")


if __name__ == "__main__":
    demo_medical_segmentation()