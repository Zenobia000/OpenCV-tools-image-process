#!/usr/bin/env python3
"""
7.1.2 æ™ºèƒ½å®‰å…¨ç›£æ§ç³»çµ± - é€²éšå‹•ä½œæª¢æ¸¬æ¨¡çµ„

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†é€²éšçš„å‹•ä½œæª¢æ¸¬ç®—æ³•ï¼ŒåŒ…æ‹¬å¤šç¨®èƒŒæ™¯å»ºæ¨¡æ–¹æ³•ã€
æ™ºèƒ½å€åŸŸç›£æ§ã€è¡Œç‚ºåˆ†æç­‰åŠŸèƒ½ã€‚

åŠŸèƒ½ç‰¹è‰²ï¼š
- å¤šç¨®èƒŒæ™¯æ¸›é™¤ç®—æ³• (MOG2, GMM, KNN)
- æ™ºèƒ½å€åŸŸåŠƒåˆ†ç›£æ§
- è¡Œç‚ºæ¨¡å¼åˆ†æ
- ç•°å¸¸è¡Œç‚ºæª¢æ¸¬
- äººå“¡è¨ˆæ•¸èˆ‡è¿½è¹¤
- æ»¯ç•™æª¢æ¸¬
- å…¥ä¾µæª¢æ¸¬
- å¯è¦–åŒ–ç›£æ§ç•Œé¢

ä½œè€…: OpenCV Computer Vision Toolkit
æ—¥æœŸ: 2024-10-14
ç‰ˆæœ¬: 1.0
"""

import cv2
import numpy as np
import os
import sys
import time
import json
import threading
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
from collections import deque, defaultdict
import math

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('../../utils')
try:
    from image_utils import load_image, resize_image
    from visualization import display_image
    from performance import time_function
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥å·¥å…·æ¨¡çµ„ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MotionObject:
    """å‹•ä½œç‰©é«”æ•¸æ“šçµæ§‹"""
    id: int
    center: Tuple[int, int]
    bbox: Tuple[int, int, int, int]  # (x, y, w, h)
    area: float
    confidence: float
    track_history: List[Tuple[int, int]]
    first_seen: float
    last_seen: float
    velocity: Tuple[float, float]  # (vx, vy)
    is_person: bool = False

    def age(self) -> float:
        """ç‰©é«”å­˜åœ¨æ™‚é–“"""
        return self.last_seen - self.first_seen

    def speed(self) -> float:
        """è¨ˆç®—é€Ÿåº¦å¤§å°"""
        return math.sqrt(self.velocity[0]**2 + self.velocity[1]**2)

@dataclass
class MonitoringZone:
    """ç›£æ§å€åŸŸæ•¸æ“šçµæ§‹"""
    name: str
    polygon: List[Tuple[int, int]]
    zone_type: str  # 'restricted', 'entrance', 'exit', 'loitering'
    alert_on_entry: bool = True
    alert_on_exit: bool = False
    max_loitering_time: float = 30.0  # ç§’

    def contains_point(self, point: Tuple[int, int]) -> bool:
        """æª¢æŸ¥é»æ˜¯å¦åœ¨å€åŸŸå…§"""
        return cv2.pointPolygonTest(np.array(self.polygon), point, False) >= 0

class AdvancedMotionDetector:
    """é€²éšå‹•ä½œæª¢æ¸¬å™¨"""

    def __init__(self, config_file: str = None):
        """åˆå§‹åŒ–é€²éšå‹•ä½œæª¢æ¸¬å™¨"""
        self.config = self._load_config(config_file)
        self.background_methods = {}
        self.current_method = "MOG2"
        self.frame_count = 0

        # ç‰©é«”è¿½è¹¤
        self.tracked_objects = {}
        self.next_object_id = 1
        self.max_track_distance = 100
        self.max_track_age = 30  # å¹€æ•¸

        # ç›£æ§å€åŸŸ
        self.monitoring_zones = []
        self.zone_events = deque(maxlen=1000)

        # çµ±è¨ˆæ•¸æ“š
        self.person_count = 0
        self.total_entries = 0
        self.total_exits = 0
        self.loitering_alerts = 0

        # åˆå§‹åŒ–èƒŒæ™¯æ¸›é™¤å™¨
        self._initialize_background_subtractors()

        # è¼‰å…¥ç›£æ§å€åŸŸ
        self._load_monitoring_zones()

        logger.info("é€²éšå‹•ä½œæª¢æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        default_config = {
            "background_subtraction": {
                "method": "MOG2",  # MOG2, KNN, GMG
                "history": 500,
                "var_threshold": 16,
                "detect_shadows": True,
                "learning_rate": -1
            },
            "motion_filtering": {
                "min_area": 500,
                "max_area": 50000,
                "min_width": 20,
                "min_height": 20,
                "morphology_kernel_size": 3,
                "gaussian_blur_kernel": 5
            },
            "tracking": {
                "max_track_distance": 100,
                "max_track_age": 30,
                "min_track_length": 5
            },
            "zones": {
                "config_file": "monitoring_zones.json",
                "show_zones": True,
                "zone_colors": {
                    "restricted": [0, 0, 255],    # ç´…è‰²
                    "entrance": [0, 255, 0],      # ç¶ è‰²
                    "exit": [255, 0, 0],          # è—è‰²
                    "loitering": [0, 255, 255]    # é»ƒè‰²
                }
            },
            "alerts": {
                "loitering_threshold": 30.0,      # ç§’
                "intrusion_alert": True,
                "counting_alert": True,
                "speed_threshold": 5.0            # åƒç´ /å¹€
            }
        }

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                self._deep_update(default_config, user_config)
                logger.info(f"å·²è¼‰å…¥é…ç½®æ–‡ä»¶: {config_file}")
            except Exception as e:
                logger.warning(f"ç„¡æ³•è¼‰å…¥é…ç½®æ–‡ä»¶: {e}ï¼Œä½¿ç”¨é è¨­é…ç½®")

        return default_config

    def _deep_update(self, base_dict: Dict, update_dict: Dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if isinstance(value, dict) and key in base_dict:
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def _initialize_background_subtractors(self):
        """åˆå§‹åŒ–èƒŒæ™¯æ¸›é™¤å™¨"""
        bg_config = self.config["background_subtraction"]

        # MOG2
        self.background_methods["MOG2"] = cv2.createBackgroundSubtractorMOG2(
            history=bg_config["history"],
            varThreshold=bg_config["var_threshold"],
            detectShadows=bg_config["detect_shadows"]
        )

        # KNN
        self.background_methods["KNN"] = cv2.createBackgroundSubtractorKNN(
            history=bg_config["history"],
            dist2Threshold=400.0,
            detectShadows=bg_config["detect_shadows"]
        )

        logger.info(f"åˆå§‹åŒ–äº† {len(self.background_methods)} ç¨®èƒŒæ™¯æ¸›é™¤æ–¹æ³•")

    def _load_monitoring_zones(self):
        """è¼‰å…¥ç›£æ§å€åŸŸé…ç½®"""
        zone_file = self.config["zones"]["config_file"]

        # å‰µå»ºç¯„ä¾‹ç›£æ§å€åŸŸé…ç½®
        if not os.path.exists(zone_file):
            self._create_sample_zones_config(zone_file)

        try:
            with open(zone_file, 'r', encoding='utf-8') as f:
                zones_data = json.load(f)

            for zone_data in zones_data:
                zone = MonitoringZone(
                    name=zone_data["name"],
                    polygon=zone_data["polygon"],
                    zone_type=zone_data["zone_type"],
                    alert_on_entry=zone_data.get("alert_on_entry", True),
                    alert_on_exit=zone_data.get("alert_on_exit", False),
                    max_loitering_time=zone_data.get("max_loitering_time", 30.0)
                )
                self.monitoring_zones.append(zone)

            logger.info(f"è¼‰å…¥äº† {len(self.monitoring_zones)} å€‹ç›£æ§å€åŸŸ")

        except Exception as e:
            logger.warning(f"ç„¡æ³•è¼‰å…¥ç›£æ§å€åŸŸé…ç½®: {e}")

    def _create_sample_zones_config(self, zone_file: str):
        """å‰µå»ºç¯„ä¾‹ç›£æ§å€åŸŸé…ç½®"""
        sample_zones = [
            {
                "name": "å…¥å£å€åŸŸ",
                "zone_type": "entrance",
                "polygon": [[100, 100], [300, 100], [300, 200], [100, 200]],
                "alert_on_entry": True,
                "alert_on_exit": False
            },
            {
                "name": "é™åˆ¶å€åŸŸ",
                "zone_type": "restricted",
                "polygon": [[400, 150], [600, 150], [600, 300], [400, 300]],
                "alert_on_entry": True,
                "alert_on_exit": True
            },
            {
                "name": "æ»¯ç•™ç›£æ§",
                "zone_type": "loitering",
                "polygon": [[200, 300], [400, 300], [400, 400], [200, 400]],
                "max_loitering_time": 15.0,
                "alert_on_entry": False
            }
        ]

        with open(zone_file, 'w', encoding='utf-8') as f:
            json.dump(sample_zones, f, ensure_ascii=False, indent=2)

        logger.info(f"å·²å‰µå»ºç¯„ä¾‹ç›£æ§å€åŸŸé…ç½®: {zone_file}")

    def detect_motion(self, frame: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """æª¢æ¸¬å‹•ä½œä¸¦è¿”å›ç‰©é«”ä¿¡æ¯"""
        # ç²å–ç•¶å‰èƒŒæ™¯æ¸›é™¤å™¨
        bg_subtractor = self.background_methods[self.current_method]

        # å‰è™•ç†
        processed_frame = self._preprocess_frame(frame)

        # èƒŒæ™¯æ¸›é™¤
        learning_rate = self.config["background_subtraction"]["learning_rate"]
        fg_mask = bg_subtractor.apply(processed_frame, learningRate=learning_rate)

        # å¾Œè™•ç†é®ç½©
        cleaned_mask = self._postprocess_mask(fg_mask)

        # æŸ¥æ‰¾é‹å‹•ç‰©é«”
        motion_objects = self._find_motion_objects(cleaned_mask, frame)

        # æ›´æ–°ç‰©é«”è¿½è¹¤
        self._update_tracking(motion_objects)

        # æª¢æŸ¥ç›£æ§å€åŸŸ
        zone_events = self._check_monitoring_zones()

        return cleaned_mask, motion_objects

    def _preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
        """å‰è™•ç†å¹€"""
        # é«˜æ–¯æ¨¡ç³Šæ¸›å°‘å™ªè²
        kernel_size = self.config["motion_filtering"]["gaussian_blur_kernel"]
        if kernel_size > 1:
            frame = cv2.GaussianBlur(frame, (kernel_size, kernel_size), 0)

        return frame

    def _postprocess_mask(self, mask: np.ndarray) -> np.ndarray:
        """å¾Œè™•ç†é®ç½©"""
        # ç§»é™¤é™°å½±ï¼ˆå¦‚æœæª¢æ¸¬åˆ°ï¼‰
        mask[mask == 127] = 0  # 127æ˜¯é™°å½±åƒç´ å€¼

        # å½¢æ…‹å­¸æ“ä½œ
        kernel_size = self.config["motion_filtering"]["morphology_kernel_size"]
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,
                                         (kernel_size, kernel_size))

        # é–‹é‹ç®—å»é™¤å™ªè²
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

        # é–‰é‹ç®—å¡«å……å­”æ´
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        return mask

    def _find_motion_objects(self, mask: np.ndarray, frame: np.ndarray) -> List[Dict]:
        """æŸ¥æ‰¾é‹å‹•ç‰©é«”"""
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        motion_config = self.config["motion_filtering"]
        min_area = motion_config["min_area"]
        max_area = motion_config["max_area"]
        min_width = motion_config["min_width"]
        min_height = motion_config["min_height"]

        objects = []

        for contour in contours:
            area = cv2.contourArea(contour)

            if area < min_area or area > max_area:
                continue

            x, y, w, h = cv2.boundingRect(contour)

            if w < min_width or h < min_height:
                continue

            # è¨ˆç®—ä¸­å¿ƒé»
            center = (int(x + w/2), int(y + h/2))

            # è¨ˆç®—ç‰©é«”ç‰¹å¾µ
            aspect_ratio = float(w) / h
            extent = area / (w * h)

            # ä¼°ç®—æ˜¯å¦ç‚ºäºº
            is_person = self._estimate_person(w, h, area, aspect_ratio)

            obj_info = {
                "center": center,
                "bbox": (x, y, w, h),
                "area": area,
                "confidence": min(1.0, area / min_area),
                "aspect_ratio": aspect_ratio,
                "extent": extent,
                "is_person": is_person
            }

            objects.append(obj_info)

        return objects

    def _estimate_person(self, width: int, height: int, area: float, aspect_ratio: float) -> bool:
        """ä¼°ç®—æ˜¯å¦ç‚ºäºº"""
        # ç°¡å–®çš„äººå½¢æª¢æ¸¬è¦å‰‡
        person_height_range = (40, 200)
        person_width_range = (20, 100)
        person_aspect_ratio_range = (0.3, 0.8)
        person_area_range = (800, 20000)

        height_ok = person_height_range[0] <= height <= person_height_range[1]
        width_ok = person_width_range[0] <= width <= person_width_range[1]
        ratio_ok = person_aspect_ratio_range[0] <= aspect_ratio <= person_aspect_ratio_range[1]
        area_ok = person_area_range[0] <= area <= person_area_range[1]

        # å¦‚æœå¤§éƒ¨åˆ†æ¢ä»¶æ»¿è¶³ï¼Œå‰‡èªç‚ºæ˜¯äºº
        conditions_met = sum([height_ok, width_ok, ratio_ok, area_ok])
        return conditions_met >= 3

    def _update_tracking(self, detected_objects: List[Dict]):
        """æ›´æ–°ç‰©é«”è¿½è¹¤"""
        current_time = time.time()

        # åŒ¹é…æª¢æ¸¬åˆ°çš„ç‰©é«”èˆ‡ç¾æœ‰è»Œè·¡
        matched_objects = {}
        unmatched_detections = detected_objects.copy()

        for obj_id, tracked_obj in self.tracked_objects.items():
            best_match = None
            min_distance = float('inf')

            for i, detection in enumerate(unmatched_detections):
                # è¨ˆç®—è·é›¢
                distance = math.sqrt(
                    (detection["center"][0] - tracked_obj.center[0])**2 +
                    (detection["center"][1] - tracked_obj.center[1])**2
                )

                if distance < min_distance and distance < self.max_track_distance:
                    min_distance = distance
                    best_match = i

            if best_match is not None:
                detection = unmatched_detections.pop(best_match)

                # æ›´æ–°è¿½è¹¤ç‰©é«”
                old_center = tracked_obj.center
                new_center = detection["center"]

                # è¨ˆç®—é€Ÿåº¦
                dt = current_time - tracked_obj.last_seen
                if dt > 0:
                    vx = (new_center[0] - old_center[0]) / dt
                    vy = (new_center[1] - old_center[1]) / dt
                    tracked_obj.velocity = (vx, vy)

                # æ›´æ–°å±¬æ€§
                tracked_obj.center = new_center
                tracked_obj.bbox = detection["bbox"]
                tracked_obj.area = detection["area"]
                tracked_obj.confidence = detection["confidence"]
                tracked_obj.last_seen = current_time
                tracked_obj.is_person = detection["is_person"]

                # æ›´æ–°è»Œè·¡æ­·å²
                tracked_obj.track_history.append(new_center)
                if len(tracked_obj.track_history) > 50:  # é™åˆ¶æ­·å²é•·åº¦
                    tracked_obj.track_history.pop(0)

                matched_objects[obj_id] = tracked_obj

        # å‰µå»ºæ–°çš„è¿½è¹¤ç‰©é«”
        for detection in unmatched_detections:
            new_obj = MotionObject(
                id=self.next_object_id,
                center=detection["center"],
                bbox=detection["bbox"],
                area=detection["area"],
                confidence=detection["confidence"],
                track_history=[detection["center"]],
                first_seen=current_time,
                last_seen=current_time,
                velocity=(0, 0),
                is_person=detection["is_person"]
            )

            matched_objects[self.next_object_id] = new_obj
            self.next_object_id += 1

        # ç§»é™¤éæœŸçš„è¿½è¹¤ç‰©é«”
        self.tracked_objects = {}
        for obj_id, obj in matched_objects.items():
            if (current_time - obj.last_seen) < self.max_track_age:
                self.tracked_objects[obj_id] = obj

        # æ›´æ–°äººå“¡è¨ˆæ•¸
        self.person_count = sum(1 for obj in self.tracked_objects.values() if obj.is_person)

    def _check_monitoring_zones(self) -> List[Dict]:
        """æª¢æŸ¥ç›£æ§å€åŸŸäº‹ä»¶"""
        events = []
        current_time = time.time()

        for zone in self.monitoring_zones:
            for obj_id, obj in self.tracked_objects.items():
                is_in_zone = zone.contains_point(obj.center)

                # æª¢æŸ¥å…¥ä¾µ
                if is_in_zone and zone.zone_type == "restricted":
                    if zone.alert_on_entry:
                        event = {
                            "type": "intrusion",
                            "zone": zone.name,
                            "object_id": obj_id,
                            "timestamp": current_time,
                            "is_person": obj.is_person
                        }
                        events.append(event)
                        logger.warning(f"å…¥ä¾µè­¦å ±: ç‰©é«” {obj_id} é€²å…¥é™åˆ¶å€åŸŸ '{zone.name}'")

                # æª¢æŸ¥æ»¯ç•™
                elif is_in_zone and zone.zone_type == "loitering":
                    loiter_time = current_time - obj.first_seen
                    if loiter_time > zone.max_loitering_time:
                        event = {
                            "type": "loitering",
                            "zone": zone.name,
                            "object_id": obj_id,
                            "timestamp": current_time,
                            "loiter_time": loiter_time,
                            "is_person": obj.is_person
                        }
                        events.append(event)
                        logger.warning(f"æ»¯ç•™è­¦å ±: ç‰©é«” {obj_id} åœ¨ '{zone.name}' æ»¯ç•™ {loiter_time:.1f} ç§’")

                # æª¢æŸ¥å…¥å£/å‡ºå£
                elif zone.zone_type in ["entrance", "exit"]:
                    # é€™è£¡éœ€è¦æ›´è¤‡é›œçš„é‚è¼¯ä¾†æª¢æ¸¬ç©¿è¶Š
                    pass

        self.zone_events.extend(events)
        return events

    def draw_results(self, frame: np.ndarray, mask: np.ndarray) -> np.ndarray:
        """ç¹ªè£½æª¢æ¸¬çµæœ"""
        result_frame = frame.copy()

        # ç¹ªè£½ç›£æ§å€åŸŸ
        if self.config["zones"]["show_zones"]:
            for zone in self.monitoring_zones:
                color = self.config["zones"]["zone_colors"].get(
                    zone.zone_type, [255, 255, 255]
                )

                # ç¹ªè£½å€åŸŸå¤šé‚Šå½¢
                pts = np.array(zone.polygon, np.int32)
                cv2.polylines(result_frame, [pts], True, color, 2)

                # æ·»åŠ å€åŸŸæ¨™ç±¤
                label_pos = (zone.polygon[0][0], zone.polygon[0][1] - 10)
                cv2.putText(result_frame, zone.name, label_pos,
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        # ç¹ªè£½è¿½è¹¤ç‰©é«”
        for obj_id, obj in self.tracked_objects.items():
            x, y, w, h = obj.bbox
            center = obj.center

            # é¸æ“‡é¡è‰²ï¼ˆäºº/éäººï¼‰
            color = (0, 255, 0) if obj.is_person else (255, 0, 0)

            # ç¹ªè£½é‚Šç•Œæ¡†
            cv2.rectangle(result_frame, (x, y), (x+w, y+h), color, 2)

            # ç¹ªè£½ä¸­å¿ƒé»
            cv2.circle(result_frame, center, 3, color, -1)

            # ç¹ªè£½è»Œè·¡
            if len(obj.track_history) > 1:
                pts = np.array(obj.track_history, np.int32)
                cv2.polylines(result_frame, [pts], False, color, 1)

            # æ·»åŠ æ¨™ç±¤
            label = f"ID:{obj_id}"
            if obj.is_person:
                label += " (äºº)"

            label_pos = (x, y - 10)
            cv2.putText(result_frame, label, label_pos,
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            # é¡¯ç¤ºé€Ÿåº¦
            speed = obj.speed()
            if speed > 0.1:
                speed_label = f"é€Ÿåº¦: {speed:.1f}"
                cv2.putText(result_frame, speed_label, (x, y + h + 15),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

        # æ·»åŠ çµ±è¨ˆä¿¡æ¯
        stats_text = [
            f"èƒŒæ™¯æ–¹æ³•: {self.current_method}",
            f"è¿½è¹¤ç‰©é«”: {len(self.tracked_objects)}",
            f"äººå“¡æ•¸é‡: {self.person_count}",
            f"å¹€æ•¸: {self.frame_count}"
        ]

        for i, text in enumerate(stats_text):
            y_pos = 30 + i * 25
            cv2.putText(result_frame, text, (10, y_pos),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        return result_frame

    def switch_background_method(self, method: str):
        """åˆ‡æ›èƒŒæ™¯æ¸›é™¤æ–¹æ³•"""
        if method in self.background_methods:
            self.current_method = method
            logger.info(f"åˆ‡æ›åˆ°èƒŒæ™¯æ¸›é™¤æ–¹æ³•: {method}")
        else:
            logger.warning(f"æœªçŸ¥çš„èƒŒæ™¯æ¸›é™¤æ–¹æ³•: {method}")

    def get_statistics(self) -> Dict:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        return {
            "frame_count": self.frame_count,
            "current_method": self.current_method,
            "tracked_objects": len(self.tracked_objects),
            "person_count": self.person_count,
            "total_entries": self.total_entries,
            "total_exits": self.total_exits,
            "zone_events": len(self.zone_events),
            "monitoring_zones": len(self.monitoring_zones)
        }

    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """è™•ç†å–®å€‹å¹€"""
        self.frame_count += 1

        # æª¢æ¸¬å‹•ä½œ
        mask, objects = self.detect_motion(frame)

        # ç¹ªè£½çµæœ
        result_frame = self.draw_results(frame, mask)

        return result_frame, mask


def demo_motion_detection():
    """å‹•ä½œæª¢æ¸¬æ¼”ç¤º"""
    print("ğŸ¬ é€²éšå‹•ä½œæª¢æ¸¬æ¼”ç¤º")
    print("=" * 50)

    # å‰µå»ºæª¢æ¸¬å™¨
    detector = AdvancedMotionDetector()

    # å˜—è©¦é–‹å•Ÿæ”åƒé ­
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ç„¡æ³•é–‹å•Ÿæ”åƒé ­ï¼Œè«‹æª¢æŸ¥æ”åƒé ­é€£æ¥")
        return

    print("âœ… æ”åƒé ­å·²é–‹å•Ÿ")
    print("\næ“ä½œèªªæ˜:")
    print("  æŒ‰ 'q' æˆ– ESC é€€å‡º")
    print("  æŒ‰ '1' åˆ‡æ›åˆ° MOG2 èƒŒæ™¯æ¸›é™¤")
    print("  æŒ‰ '2' åˆ‡æ›åˆ° KNN èƒŒæ™¯æ¸›é™¤")
    print("  æŒ‰ 's' é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯")
    print("  æŒ‰ 'r' é‡ç½®èƒŒæ™¯æ¨¡å‹")
    print("\né–‹å§‹æª¢æ¸¬...")

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("âŒ ç„¡æ³•è®€å–æ”åƒé ­å¹€")
                break

            # è™•ç†å¹€
            result_frame, mask = detector.process_frame(frame)

            # é¡¯ç¤ºçµæœ
            cv2.imshow('Advanced Motion Detection', result_frame)
            cv2.imshow('Motion Mask', mask)

            # æŒ‰éµè™•ç†
            key = cv2.waitKey(1) & 0xFF

            if key == ord('q') or key == 27:  # 'q' æˆ– ESC
                break
            elif key == ord('1'):
                detector.switch_background_method("MOG2")
            elif key == ord('2'):
                detector.switch_background_method("KNN")
            elif key == ord('s'):
                stats = detector.get_statistics()
                print(f"\nğŸ“Š ç³»çµ±çµ±è¨ˆ: {stats}")
            elif key == ord('r'):
                # é‡æ–°åˆå§‹åŒ–èƒŒæ™¯æ¸›é™¤å™¨
                detector._initialize_background_subtractors()
                print("ğŸ”„ èƒŒæ™¯æ¨¡å‹å·²é‡ç½®")

    except KeyboardInterrupt:
        print("\nâš ï¸ æ¥æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿ")

    finally:
        cap.release()
        cv2.destroyAllWindows()

        # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
        final_stats = detector.get_statistics()
        print(f"\nğŸ“Š æœ€çµ‚çµ±è¨ˆ: {final_stats}")
        print("ğŸ‘‹ å‹•ä½œæª¢æ¸¬æ¼”ç¤ºçµæŸ")


if __name__ == "__main__":
    demo_motion_detection()